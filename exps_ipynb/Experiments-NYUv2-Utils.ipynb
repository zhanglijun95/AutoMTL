{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from framework.mtl_model import MTLModel\n",
    "from framework.trainer import Trainer\n",
    "from data.dataloader.nyuv2_dataloader import NYU_v2\n",
    "from data.heads.pixel2pixel import ASPPHeadNode\n",
    "from data.metrics.pixel2pixel_loss import NYUCriterions\n",
    "from data.metrics.pixel2pixel_metrics import NYUMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/data/NYUv2/'\n",
    "\n",
    "headsDict = nn.ModuleDict()\n",
    "trainDataloaderDict = {}\n",
    "valDataloaderDict = {}\n",
    "criterionDict = {}\n",
    "metricDict = {}\n",
    "\n",
    "tasks = ['segment_semantic','normal','depth_zbuffer']\n",
    "task_cls_num = {'segment_semantic': 40, 'normal':3, 'depth_zbuffer': 1}\n",
    "for task in tasks:\n",
    "    headsDict[task] = ASPPHeadNode(512, task_cls_num[task])\n",
    "\n",
    "    # For model trainer\n",
    "    dataset = NYU_v2(dataroot, 'train', task, crop_h=321, crop_w=321)\n",
    "    trainDataloaderDict[task] = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "    dataset = NYU_v2(dataroot, 'test', task, crop_h=321, crop_w=321)\n",
    "    valDataloaderDict[task] = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "    criterionDict[task] = NYUCriterions(task)\n",
    "    metricDict[task] = NYUMetrics(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt = 'models/deeplab_resnet34_adashare.prototxt'\n",
    "mtlmodel = MTLModel(prototxt, headsDict, BNsp=True)\n",
    "mtlmodel = mtlmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/'\n",
    "trainer = Trainer(mtlmodel, trainDataloaderDict, valDataloaderDict, criterionDict, metricDict, \n",
    "                  print_iters=50, val_iters=200, save_num=1, policy_update_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2050 Task segm] Train Loss: 0.5143\n",
      "[Iter 2050 Task dept] Train Loss: 0.0217\n",
      "[Iter 2050 Total] Train Loss: 0.2680\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Train Loss: 0.4637\n",
      "[Iter 2100 Task dept] Train Loss: 0.0213\n",
      "[Iter 2100 Total] Train Loss: 0.2425\n",
      "======================================================================\n",
      "[Iter 2150 Task segm] Train Loss: 0.4574\n",
      "[Iter 2150 Task dept] Train Loss: 0.0205\n",
      "[Iter 2150 Total] Train Loss: 0.2389\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Train Loss: 0.4476\n",
      "[Iter 2200 Task dept] Train Loss: 0.0203\n",
      "[Iter 2200 Total] Train Loss: 0.2339\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 0.9370\n",
      "{'mIoU': 0.2595, 'Pixel Acc': 0.6065, 'cmp': -0.2713}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0956\n",
      "{'abs_err': 0.0935, 'rel_err': 2.467, 'sigma_1.25': 26.6127, 'sigma_1.25^2': 42.6742, 'sigma_1.25^3': 51.8795, 'cmp': -2.5088}\n",
      "======================================================================\n",
      "[Iter 2250 Task segm] Train Loss: 0.4394\n",
      "[Iter 2250 Task dept] Train Loss: 0.0201\n",
      "[Iter 2250 Total] Train Loss: 0.2298\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Train Loss: 0.4446\n",
      "[Iter 2300 Task dept] Train Loss: 0.0189\n",
      "[Iter 2300 Total] Train Loss: 0.2317\n",
      "======================================================================\n",
      "[Iter 2350 Task segm] Train Loss: 0.4506\n",
      "[Iter 2350 Task dept] Train Loss: 0.0194\n",
      "[Iter 2350 Total] Train Loss: 0.2350\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Train Loss: 0.4373\n",
      "[Iter 2400 Task dept] Train Loss: 0.0199\n",
      "[Iter 2400 Total] Train Loss: 0.2286\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 1.6052\n",
      "{'mIoU': 0.1696, 'Pixel Acc': 0.5136, 'cmp': -0.4453}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0915\n",
      "{'abs_err': 0.0895, 'rel_err': 2.347, 'sigma_1.25': 26.3131, 'sigma_1.25^2': 43.6865, 'sigma_1.25^3': 53.1667, 'cmp': -2.3847}\n",
      "======================================================================\n",
      "[Iter 2450 Task segm] Train Loss: 0.4226\n",
      "[Iter 2450 Task dept] Train Loss: 0.0187\n",
      "[Iter 2450 Total] Train Loss: 0.2206\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Train Loss: 0.4389\n",
      "[Iter 2500 Task dept] Train Loss: 0.0192\n",
      "[Iter 2500 Total] Train Loss: 0.2291\n",
      "======================================================================\n",
      "[Iter 2550 Task segm] Train Loss: 0.4426\n",
      "[Iter 2550 Task dept] Train Loss: 0.0194\n",
      "[Iter 2550 Total] Train Loss: 0.2310\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Train Loss: 0.4308\n",
      "[Iter 2600 Task dept] Train Loss: 0.0193\n",
      "[Iter 2600 Total] Train Loss: 0.2251\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 1.4627\n",
      "{'mIoU': 0.206, 'Pixel Acc': 0.5554, 'cmp': -0.372}\n",
      "[Iter 2600 Task dept] Val Loss: 0.1030\n",
      "{'abs_err': 0.1016, 'rel_err': 2.6878, 'sigma_1.25': 24.7714, 'sigma_1.25^2': 41.4197, 'sigma_1.25^3': 50.1271, 'cmp': -2.7498}\n",
      "======================================================================\n",
      "[Iter 2650 Task segm] Train Loss: 0.4262\n",
      "[Iter 2650 Task dept] Train Loss: 0.0187\n",
      "[Iter 2650 Total] Train Loss: 0.2224\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Train Loss: 0.4304\n",
      "[Iter 2700 Task dept] Train Loss: 0.0191\n",
      "[Iter 2700 Total] Train Loss: 0.2248\n",
      "======================================================================\n",
      "[Iter 2750 Task segm] Train Loss: 0.4223\n",
      "[Iter 2750 Task dept] Train Loss: 0.0189\n",
      "[Iter 2750 Total] Train Loss: 0.2206\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Train Loss: 0.4216\n",
      "[Iter 2800 Task dept] Train Loss: 0.0186\n",
      "[Iter 2800 Total] Train Loss: 0.2201\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 1.1661\n",
      "{'mIoU': 0.1921, 'Pixel Acc': 0.5684, 'cmp': -0.3806}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0932\n",
      "{'abs_err': 0.0919, 'rel_err': 2.3997, 'sigma_1.25': 24.3676, 'sigma_1.25^2': 44.0692, 'sigma_1.25^3': 53.397, 'cmp': -2.4493}\n",
      "======================================================================\n",
      "[Iter 2850 Task segm] Train Loss: 0.4071\n",
      "[Iter 2850 Task dept] Train Loss: 0.0189\n",
      "[Iter 2850 Total] Train Loss: 0.2130\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Train Loss: 0.4139\n",
      "[Iter 2900 Task dept] Train Loss: 0.0190\n",
      "[Iter 2900 Total] Train Loss: 0.2165\n",
      "======================================================================\n",
      "[Iter 2950 Task segm] Train Loss: 0.4207\n",
      "[Iter 2950 Task dept] Train Loss: 0.0185\n",
      "[Iter 2950 Total] Train Loss: 0.2196\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Train Loss: 0.4068\n",
      "[Iter 3000 Task dept] Train Loss: 0.0184\n",
      "[Iter 3000 Total] Train Loss: 0.2126\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 1.7996\n",
      "{'mIoU': 0.1631, 'Pixel Acc': 0.5134, 'cmp': -0.4535}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0870\n",
      "{'abs_err': 0.0862, 'rel_err': 2.1954, 'sigma_1.25': 23.4835, 'sigma_1.25^2': 45.3944, 'sigma_1.25^3': 55.9754, 'cmp': -2.2522}\n",
      "======================================================================\n",
      "[Iter 3050 Task segm] Train Loss: 0.4077\n",
      "[Iter 3050 Task dept] Train Loss: 0.0190\n",
      "[Iter 3050 Total] Train Loss: 0.2134\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Train Loss: 0.4058\n",
      "[Iter 3100 Task dept] Train Loss: 0.0186\n",
      "[Iter 3100 Total] Train Loss: 0.2122\n",
      "======================================================================\n",
      "[Iter 3150 Task segm] Train Loss: 0.4106\n",
      "[Iter 3150 Task dept] Train Loss: 0.0183\n",
      "[Iter 3150 Total] Train Loss: 0.2144\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Train Loss: 0.4002\n",
      "[Iter 3200 Task dept] Train Loss: 0.0181\n",
      "[Iter 3200 Total] Train Loss: 0.2092\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 1.5426\n",
      "{'mIoU': 0.1639, 'Pixel Acc': 0.5346, 'cmp': -0.4383}\n",
      "[Iter 3200 Task dept] Val Loss: 0.1044\n",
      "{'abs_err': 0.1021, 'rel_err': 2.6546, 'sigma_1.25': 24.3518, 'sigma_1.25^2': 40.7884, 'sigma_1.25^3': 49.9315, 'cmp': -2.7397}\n",
      "======================================================================\n",
      "[Iter 3250 Task segm] Train Loss: 0.4122\n",
      "[Iter 3250 Task dept] Train Loss: 0.0177\n",
      "[Iter 3250 Total] Train Loss: 0.2149\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Train Loss: 0.3964\n",
      "[Iter 3300 Task dept] Train Loss: 0.0183\n",
      "[Iter 3300 Total] Train Loss: 0.2074\n",
      "======================================================================\n",
      "[Iter 3350 Task segm] Train Loss: 0.4159\n",
      "[Iter 3350 Task dept] Train Loss: 0.0181\n",
      "[Iter 3350 Total] Train Loss: 0.2170\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Train Loss: 0.3751\n",
      "[Iter 3400 Task dept] Train Loss: 0.0178\n",
      "[Iter 3400 Total] Train Loss: 0.1964\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.3266\n",
      "{'mIoU': 0.1955, 'Pixel Acc': 0.5611, 'cmp': -0.3813}\n",
      "[Iter 3400 Task dept] Val Loss: 0.1168\n",
      "{'abs_err': 0.1152, 'rel_err': 3.0537, 'sigma_1.25': 23.5151, 'sigma_1.25^2': 38.8866, 'sigma_1.25^3': 47.3895, 'cmp': -3.1476}\n",
      "======================================================================\n",
      "[Iter 3450 Task segm] Train Loss: 0.4098\n",
      "[Iter 3450 Task dept] Train Loss: 0.0178\n",
      "[Iter 3450 Total] Train Loss: 0.2138\n",
      "======================================================================\n",
      "[Iter 3500 Task segm] Train Loss: 0.4013\n",
      "[Iter 3500 Task dept] Train Loss: 0.0174\n",
      "[Iter 3500 Total] Train Loss: 0.2093\n",
      "======================================================================\n",
      "[Iter 3550 Task segm] Train Loss: 0.4062\n",
      "[Iter 3550 Task dept] Train Loss: 0.0177\n",
      "[Iter 3550 Total] Train Loss: 0.2119\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3600 Task segm] Train Loss: 0.3689\n",
      "[Iter 3600 Task dept] Train Loss: 0.0177\n",
      "[Iter 3600 Total] Train Loss: 0.1933\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.4957\n",
      "{'mIoU': 0.1748, 'Pixel Acc': 0.5406, 'cmp': -0.4207}\n",
      "[Iter 3600 Task dept] Val Loss: 0.1065\n",
      "{'abs_err': 0.1044, 'rel_err': 2.7337, 'sigma_1.25': 23.15, 'sigma_1.25^2': 40.9303, 'sigma_1.25^3': 50.0324, 'cmp': -2.8173}\n",
      "======================================================================\n",
      "[Iter 3650 Task segm] Train Loss: 0.4020\n",
      "[Iter 3650 Task dept] Train Loss: 0.0181\n",
      "[Iter 3650 Total] Train Loss: 0.2100\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Train Loss: 0.3951\n",
      "[Iter 3700 Task dept] Train Loss: 0.0176\n",
      "[Iter 3700 Total] Train Loss: 0.2064\n",
      "======================================================================\n",
      "[Iter 3750 Task segm] Train Loss: 0.4014\n",
      "[Iter 3750 Task dept] Train Loss: 0.0171\n",
      "[Iter 3750 Total] Train Loss: 0.2093\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Train Loss: 0.3749\n",
      "[Iter 3800 Task dept] Train Loss: 0.0179\n",
      "[Iter 3800 Total] Train Loss: 0.1964\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.6010\n",
      "{'mIoU': 0.1758, 'Pixel Acc': 0.5505, 'cmp': -0.4129}\n",
      "[Iter 3800 Task dept] Val Loss: 0.1092\n",
      "{'abs_err': 0.1075, 'rel_err': 2.8253, 'sigma_1.25': 22.9117, 'sigma_1.25^2': 40.686, 'sigma_1.25^3': 49.4555, 'cmp': -2.912}\n",
      "======================================================================\n",
      "[Iter 3850 Task segm] Train Loss: 0.3928\n",
      "[Iter 3850 Task dept] Train Loss: 0.0174\n",
      "[Iter 3850 Total] Train Loss: 0.2051\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Train Loss: 0.3753\n",
      "[Iter 3900 Task dept] Train Loss: 0.0169\n",
      "[Iter 3900 Total] Train Loss: 0.1961\n",
      "======================================================================\n",
      "[Iter 3950 Task segm] Train Loss: 0.3833\n",
      "[Iter 3950 Task dept] Train Loss: 0.0175\n",
      "[Iter 3950 Total] Train Loss: 0.2004\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Train Loss: 0.3899\n",
      "[Iter 4000 Task dept] Train Loss: 0.0178\n",
      "[Iter 4000 Total] Train Loss: 0.2039\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.5790\n",
      "{'mIoU': 0.2001, 'Pixel Acc': 0.5446, 'cmp': -0.3866}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0980\n",
      "{'abs_err': 0.0962, 'rel_err': 2.4959, 'sigma_1.25': 23.5905, 'sigma_1.25^2': 42.9878, 'sigma_1.25^3': 52.4618, 'cmp': -2.5654}\n",
      "======================================================================\n",
      "[Iter 4050 Task segm] Train Loss: 0.3799\n",
      "[Iter 4050 Task dept] Train Loss: 0.0178\n",
      "[Iter 4050 Total] Train Loss: 0.1988\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Train Loss: 0.3725\n",
      "[Iter 4100 Task dept] Train Loss: 0.0169\n",
      "[Iter 4100 Total] Train Loss: 0.1947\n",
      "======================================================================\n",
      "[Iter 4150 Task segm] Train Loss: 0.3693\n",
      "[Iter 4150 Task dept] Train Loss: 0.0173\n",
      "[Iter 4150 Total] Train Loss: 0.1933\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Train Loss: 0.3879\n",
      "[Iter 4200 Task dept] Train Loss: 0.0175\n",
      "[Iter 4200 Total] Train Loss: 0.2027\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.7209\n",
      "{'mIoU': 0.1843, 'Pixel Acc': 0.508, 'cmp': -0.4307}\n",
      "[Iter 4200 Task dept] Val Loss: 0.1093\n",
      "{'abs_err': 0.1073, 'rel_err': 2.8056, 'sigma_1.25': 23.1175, 'sigma_1.25^2': 40.455, 'sigma_1.25^3': 49.2892, 'cmp': -2.8978}\n",
      "======================================================================\n",
      "[Iter 4250 Task segm] Train Loss: 0.3819\n",
      "[Iter 4250 Task dept] Train Loss: 0.0179\n",
      "[Iter 4250 Total] Train Loss: 0.1999\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Train Loss: 0.3820\n",
      "[Iter 4300 Task dept] Train Loss: 0.0177\n",
      "[Iter 4300 Total] Train Loss: 0.1998\n",
      "======================================================================\n",
      "[Iter 4350 Task segm] Train Loss: 0.3731\n",
      "[Iter 4350 Task dept] Train Loss: 0.0169\n",
      "[Iter 4350 Total] Train Loss: 0.1950\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Train Loss: 0.3712\n",
      "[Iter 4400 Task dept] Train Loss: 0.0169\n",
      "[Iter 4400 Total] Train Loss: 0.1940\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.7049\n",
      "{'mIoU': 0.1839, 'Pixel Acc': 0.5148, 'cmp': -0.4268}\n",
      "[Iter 4400 Task dept] Val Loss: 0.1019\n",
      "{'abs_err': 0.1, 'rel_err': 2.5899, 'sigma_1.25': 22.3116, 'sigma_1.25^2': 42.2162, 'sigma_1.25^3': 51.6136, 'cmp': -2.6745}\n",
      "======================================================================\n",
      "[Iter 4450 Task segm] Train Loss: 0.3580\n",
      "[Iter 4450 Task dept] Train Loss: 0.0173\n",
      "[Iter 4450 Total] Train Loss: 0.1877\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Train Loss: 0.3718\n",
      "[Iter 4500 Task dept] Train Loss: 0.0177\n",
      "[Iter 4500 Total] Train Loss: 0.1947\n",
      "======================================================================\n",
      "[Iter 4550 Task segm] Train Loss: 0.3698\n",
      "[Iter 4550 Task dept] Train Loss: 0.0170\n",
      "[Iter 4550 Total] Train Loss: 0.1934\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Train Loss: 0.3801\n",
      "[Iter 4600 Task dept] Train Loss: 0.0163\n",
      "[Iter 4600 Total] Train Loss: 0.1982\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.4870\n",
      "{'mIoU': 0.1377, 'Pixel Acc': 0.5097, 'cmp': -0.4875}\n",
      "[Iter 4600 Task dept] Val Loss: 0.1018\n",
      "{'abs_err': 0.0995, 'rel_err': 2.5693, 'sigma_1.25': 23.1304, 'sigma_1.25^2': 41.9427, 'sigma_1.25^3': 51.3815, 'cmp': -2.6548}\n",
      "======================================================================\n",
      "[Iter 4650 Task segm] Train Loss: 0.3640\n",
      "[Iter 4650 Task dept] Train Loss: 0.0168\n",
      "[Iter 4650 Total] Train Loss: 0.1904\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Train Loss: 0.3543\n",
      "[Iter 4700 Task dept] Train Loss: 0.0169\n",
      "[Iter 4700 Total] Train Loss: 0.1856\n",
      "======================================================================\n",
      "[Iter 4750 Task segm] Train Loss: 0.3610\n",
      "[Iter 4750 Task dept] Train Loss: 0.0166\n",
      "[Iter 4750 Total] Train Loss: 0.1888\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Train Loss: 0.3478\n",
      "[Iter 4800 Task dept] Train Loss: 0.0173\n",
      "[Iter 4800 Total] Train Loss: 0.1826\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.5884\n",
      "{'mIoU': 0.1708, 'Pixel Acc': 0.5341, 'cmp': -0.4301}\n",
      "[Iter 4800 Task dept] Val Loss: 0.1332\n",
      "{'abs_err': 0.131, 'rel_err': 3.4052, 'sigma_1.25': 22.5862, 'sigma_1.25^2': 35.1043, 'sigma_1.25^3': 43.9235, 'cmp': -3.565}\n",
      "======================================================================\n",
      "[Iter 4850 Task segm] Train Loss: 0.3623\n",
      "[Iter 4850 Task dept] Train Loss: 0.0171\n",
      "[Iter 4850 Total] Train Loss: 0.1897\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Train Loss: 0.3636\n",
      "[Iter 4900 Task dept] Train Loss: 0.0165\n",
      "[Iter 4900 Total] Train Loss: 0.1901\n",
      "======================================================================\n",
      "[Iter 4950 Task segm] Train Loss: 0.3571\n",
      "[Iter 4950 Task dept] Train Loss: 0.0174\n",
      "[Iter 4950 Total] Train Loss: 0.1873\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Train Loss: 0.3523\n",
      "[Iter 5000 Task dept] Train Loss: 0.0170\n",
      "[Iter 5000 Total] Train Loss: 0.1847\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.2556\n",
      "{'mIoU': 0.1696, 'Pixel Acc': 0.587, 'cmp': -0.3962}\n",
      "[Iter 5000 Task dept] Val Loss: 0.1069\n",
      "{'abs_err': 0.1054, 'rel_err': 2.7392, 'sigma_1.25': 21.7582, 'sigma_1.25^2': 40.9451, 'sigma_1.25^3': 50.5153, 'cmp': -2.8352}\n",
      "======================================================================\n",
      "[Iter 5050 Task segm] Train Loss: 0.3549\n",
      "[Iter 5050 Task dept] Train Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5050 Total] Train Loss: 0.1860\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Train Loss: 0.3613\n",
      "[Iter 5100 Task dept] Train Loss: 0.0170\n",
      "[Iter 5100 Total] Train Loss: 0.1892\n",
      "======================================================================\n",
      "[Iter 5150 Task segm] Train Loss: 0.3385\n",
      "[Iter 5150 Task dept] Train Loss: 0.0164\n",
      "[Iter 5150 Total] Train Loss: 0.1775\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Train Loss: 0.3531\n",
      "[Iter 5200 Task dept] Train Loss: 0.0167\n",
      "[Iter 5200 Total] Train Loss: 0.1849\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 2.5822\n",
      "{'mIoU': 0.1622, 'Pixel Acc': 0.42, 'cmp': -0.5171}\n",
      "[Iter 5200 Task dept] Val Loss: 0.1146\n",
      "{'abs_err': 0.1128, 'rel_err': 2.9495, 'sigma_1.25': 22.2777, 'sigma_1.25^2': 39.269, 'sigma_1.25^3': 48.0924, 'cmp': -3.0574}\n",
      "======================================================================\n",
      "[Iter 5250 Task segm] Train Loss: 0.3570\n",
      "[Iter 5250 Task dept] Train Loss: 0.0162\n",
      "[Iter 5250 Total] Train Loss: 0.1866\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Train Loss: 0.3463\n",
      "[Iter 5300 Task dept] Train Loss: 0.0167\n",
      "[Iter 5300 Total] Train Loss: 0.1815\n",
      "======================================================================\n",
      "[Iter 5350 Task segm] Train Loss: 0.3359\n",
      "[Iter 5350 Task dept] Train Loss: 0.0169\n",
      "[Iter 5350 Total] Train Loss: 0.1764\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Train Loss: 0.3472\n",
      "[Iter 5400 Task dept] Train Loss: 0.0164\n",
      "[Iter 5400 Total] Train Loss: 0.1818\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 2.2982\n",
      "{'mIoU': 0.1742, 'Pixel Acc': 0.5249, 'cmp': -0.4319}\n",
      "[Iter 5400 Task dept] Val Loss: 0.1070\n",
      "{'abs_err': 0.1052, 'rel_err': 2.7384, 'sigma_1.25': 22.1472, 'sigma_1.25^2': 41.0512, 'sigma_1.25^3': 50.3471, 'cmp': -2.8311}\n",
      "======================================================================\n",
      "[Iter 5450 Task segm] Train Loss: 0.3522\n",
      "[Iter 5450 Task dept] Train Loss: 0.0167\n",
      "[Iter 5450 Total] Train Loss: 0.1845\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Train Loss: 0.3465\n",
      "[Iter 5500 Task dept] Train Loss: 0.0166\n",
      "[Iter 5500 Total] Train Loss: 0.1816\n",
      "======================================================================\n",
      "[Iter 5550 Task segm] Train Loss: 0.3459\n",
      "[Iter 5550 Task dept] Train Loss: 0.0166\n",
      "[Iter 5550 Total] Train Loss: 0.1813\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Train Loss: 0.3457\n",
      "[Iter 5600 Task dept] Train Loss: 0.0162\n",
      "[Iter 5600 Total] Train Loss: 0.1809\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.3661\n",
      "{'mIoU': 0.1698, 'Pixel Acc': 0.5739, 'cmp': -0.4047}\n",
      "[Iter 5600 Task dept] Val Loss: 0.1102\n",
      "{'abs_err': 0.1077, 'rel_err': 2.8077, 'sigma_1.25': 23.1905, 'sigma_1.25^2': 40.0115, 'sigma_1.25^3': 49.1428, 'cmp': -2.9043}\n",
      "======================================================================\n",
      "[Iter 5650 Task segm] Train Loss: 0.3549\n",
      "[Iter 5650 Task dept] Train Loss: 0.0164\n",
      "[Iter 5650 Total] Train Loss: 0.1856\n",
      "======================================================================\n",
      "[Iter 5700 Task segm] Train Loss: 0.3521\n",
      "[Iter 5700 Task dept] Train Loss: 0.0170\n",
      "[Iter 5700 Total] Train Loss: 0.1845\n",
      "======================================================================\n",
      "[Iter 5750 Task segm] Train Loss: 0.3392\n",
      "[Iter 5750 Task dept] Train Loss: 0.0162\n",
      "[Iter 5750 Total] Train Loss: 0.1777\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Train Loss: 0.3265\n",
      "[Iter 5800 Task dept] Train Loss: 0.0165\n",
      "[Iter 5800 Total] Train Loss: 0.1715\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.1617\n",
      "{'mIoU': 0.1979, 'Pixel Acc': 0.6056, 'cmp': -0.3485}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0993\n",
      "{'abs_err': 0.0979, 'rel_err': 2.474, 'sigma_1.25': 19.9878, 'sigma_1.25^2': 41.0056, 'sigma_1.25^3': 53.3449, 'cmp': -2.5851}\n",
      "======================================================================\n",
      "[Iter 5850 Task segm] Train Loss: 0.3476\n",
      "[Iter 5850 Task dept] Train Loss: 0.0164\n",
      "[Iter 5850 Total] Train Loss: 0.1820\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Train Loss: 0.3374\n",
      "[Iter 5900 Task dept] Train Loss: 0.0165\n",
      "[Iter 5900 Total] Train Loss: 0.1770\n",
      "======================================================================\n",
      "[Iter 5950 Task segm] Train Loss: 0.3478\n",
      "[Iter 5950 Task dept] Train Loss: 0.0164\n",
      "[Iter 5950 Total] Train Loss: 0.1821\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Train Loss: 0.3401\n",
      "[Iter 6000 Task dept] Train Loss: 0.0167\n",
      "[Iter 6000 Total] Train Loss: 0.1784\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.7790\n",
      "{'mIoU': 0.1641, 'Pixel Acc': 0.5313, 'cmp': -0.4403}\n",
      "[Iter 6000 Task dept] Val Loss: 0.1024\n",
      "{'abs_err': 0.1005, 'rel_err': 2.5782, 'sigma_1.25': 21.1839, 'sigma_1.25^2': 41.7631, 'sigma_1.25^3': 52.0935, 'cmp': -2.6767}\n",
      "======================================================================\n",
      "[Iter 6050 Task segm] Train Loss: 0.3435\n",
      "[Iter 6050 Task dept] Train Loss: 0.0162\n",
      "[Iter 6050 Total] Train Loss: 0.1799\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Train Loss: 0.3269\n",
      "[Iter 6100 Task dept] Train Loss: 0.0165\n",
      "[Iter 6100 Total] Train Loss: 0.1717\n",
      "======================================================================\n",
      "[Iter 6150 Task segm] Train Loss: 0.3426\n",
      "[Iter 6150 Task dept] Train Loss: 0.0162\n",
      "[Iter 6150 Total] Train Loss: 0.1794\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Train Loss: 0.3359\n",
      "[Iter 6200 Task dept] Train Loss: 0.0167\n",
      "[Iter 6200 Total] Train Loss: 0.1763\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 0.9747\n",
      "{'mIoU': 0.2158, 'Pixel Acc': 0.6357, 'cmp': -0.3061}\n",
      "[Iter 6200 Task dept] Val Loss: 0.1047\n",
      "{'abs_err': 0.1028, 'rel_err': 2.6571, 'sigma_1.25': 21.5821, 'sigma_1.25^2': 41.1022, 'sigma_1.25^3': 51.4226, 'cmp': -2.7533}\n",
      "======================================================================\n",
      "[Iter 6250 Task segm] Train Loss: 0.3364\n",
      "[Iter 6250 Task dept] Train Loss: 0.0161\n",
      "[Iter 6250 Total] Train Loss: 0.1763\n",
      "======================================================================\n",
      "[Iter 6300 Task segm] Train Loss: 0.3204\n",
      "[Iter 6300 Task dept] Train Loss: 0.0163\n",
      "[Iter 6300 Total] Train Loss: 0.1684\n",
      "======================================================================\n",
      "[Iter 6350 Task segm] Train Loss: 0.3270\n",
      "[Iter 6350 Task dept] Train Loss: 0.0163\n",
      "[Iter 6350 Total] Train Loss: 0.1717\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Train Loss: 0.3445\n",
      "[Iter 6400 Task dept] Train Loss: 0.0163\n",
      "[Iter 6400 Total] Train Loss: 0.1804\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.6024\n",
      "{'mIoU': 0.1699, 'Pixel Acc': 0.5366, 'cmp': -0.4295}\n",
      "[Iter 6400 Task dept] Val Loss: 0.1019\n",
      "{'abs_err': 0.1, 'rel_err': 2.5857, 'sigma_1.25': 22.6008, 'sigma_1.25^2': 41.9145, 'sigma_1.25^3': 51.7038, 'cmp': -2.671}\n",
      "======================================================================\n",
      "[Iter 6450 Task segm] Train Loss: 0.3472\n",
      "[Iter 6450 Task dept] Train Loss: 0.0160\n",
      "[Iter 6450 Total] Train Loss: 0.1816\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Train Loss: 0.3392\n",
      "[Iter 6500 Task dept] Train Loss: 0.0167\n",
      "[Iter 6500 Total] Train Loss: 0.1780\n",
      "======================================================================\n",
      "[Iter 6550 Task segm] Train Loss: 0.3264\n",
      "[Iter 6550 Task dept] Train Loss: 0.0163\n",
      "[Iter 6550 Total] Train Loss: 0.1713\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Train Loss: 0.3416\n",
      "[Iter 6600 Task dept] Train Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6600 Total] Train Loss: 0.1786\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.7116\n",
      "{'mIoU': 0.1817, 'Pixel Acc': 0.5553, 'cmp': -0.4023}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0850\n",
      "{'abs_err': 0.0833, 'rel_err': 1.9788, 'sigma_1.25': 20.714, 'sigma_1.25^2': 42.4984, 'sigma_1.25^3': 58.2807, 'cmp': -2.0965}\n",
      "======================================================================\n",
      "[Iter 6650 Task segm] Train Loss: 0.3350\n",
      "[Iter 6650 Task dept] Train Loss: 0.0162\n",
      "[Iter 6650 Total] Train Loss: 0.1756\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Train Loss: 0.3217\n",
      "[Iter 6700 Task dept] Train Loss: 0.0161\n",
      "[Iter 6700 Total] Train Loss: 0.1689\n",
      "======================================================================\n",
      "[Iter 6750 Task segm] Train Loss: 0.3357\n",
      "[Iter 6750 Task dept] Train Loss: 0.0163\n",
      "[Iter 6750 Total] Train Loss: 0.1760\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Train Loss: 0.3280\n",
      "[Iter 6800 Task dept] Train Loss: 0.0162\n",
      "[Iter 6800 Total] Train Loss: 0.1721\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.1479\n",
      "{'mIoU': 0.2075, 'Pixel Acc': 0.6085, 'cmp': -0.3346}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0758\n",
      "{'abs_err': 0.0745, 'rel_err': 1.6921, 'sigma_1.25': 21.7334, 'sigma_1.25^2': 44.4366, 'sigma_1.25^3': 62.075, 'cmp': -1.8038}\n",
      "======================================================================\n",
      "[Iter 6850 Task segm] Train Loss: 0.3269\n",
      "[Iter 6850 Task dept] Train Loss: 0.0164\n",
      "[Iter 6850 Total] Train Loss: 0.1716\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Train Loss: 0.3340\n",
      "[Iter 6900 Task dept] Train Loss: 0.0156\n",
      "[Iter 6900 Total] Train Loss: 0.1748\n",
      "======================================================================\n",
      "[Iter 6950 Task segm] Train Loss: 0.3364\n",
      "[Iter 6950 Task dept] Train Loss: 0.0159\n",
      "[Iter 6950 Total] Train Loss: 0.1762\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Train Loss: 0.3415\n",
      "[Iter 7000 Task dept] Train Loss: 0.0161\n",
      "[Iter 7000 Total] Train Loss: 0.1788\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 2.3331\n",
      "{'mIoU': 0.151, 'Pixel Acc': 0.509, 'cmp': -0.4715}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0981\n",
      "{'abs_err': 0.096, 'rel_err': 2.4583, 'sigma_1.25': 23.1868, 'sigma_1.25^2': 42.2766, 'sigma_1.25^3': 52.1969, 'cmp': -2.5436}\n",
      "======================================================================\n",
      "[Iter 7050 Task segm] Train Loss: 0.3314\n",
      "[Iter 7050 Task dept] Train Loss: 0.0166\n",
      "[Iter 7050 Total] Train Loss: 0.1740\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Train Loss: 0.3119\n",
      "[Iter 7100 Task dept] Train Loss: 0.0156\n",
      "[Iter 7100 Total] Train Loss: 0.1637\n",
      "======================================================================\n",
      "[Iter 7150 Task segm] Train Loss: 0.3317\n",
      "[Iter 7150 Task dept] Train Loss: 0.0161\n",
      "[Iter 7150 Total] Train Loss: 0.1739\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Train Loss: 0.3375\n",
      "[Iter 7200 Task dept] Train Loss: 0.0156\n",
      "[Iter 7200 Total] Train Loss: 0.1766\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.8431\n",
      "{'mIoU': 0.1587, 'Pixel Acc': 0.5115, 'cmp': -0.4602}\n",
      "[Iter 7200 Task dept] Val Loss: 0.1139\n",
      "{'abs_err': 0.1113, 'rel_err': 2.8461, 'sigma_1.25': 22.8986, 'sigma_1.25^2': 38.0878, 'sigma_1.25^3': 47.569, 'cmp': -2.9788}\n",
      "======================================================================\n",
      "[Iter 7250 Task segm] Train Loss: 0.3302\n",
      "[Iter 7250 Task dept] Train Loss: 0.0164\n",
      "[Iter 7250 Total] Train Loss: 0.1733\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Train Loss: 0.3359\n",
      "[Iter 7300 Task dept] Train Loss: 0.0154\n",
      "[Iter 7300 Total] Train Loss: 0.1757\n",
      "======================================================================\n",
      "[Iter 7350 Task segm] Train Loss: 0.3194\n",
      "[Iter 7350 Task dept] Train Loss: 0.0161\n",
      "[Iter 7350 Total] Train Loss: 0.1677\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Train Loss: 0.3270\n",
      "[Iter 7400 Task dept] Train Loss: 0.0158\n",
      "[Iter 7400 Total] Train Loss: 0.1714\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 2.3700\n",
      "{'mIoU': 0.139, 'Pixel Acc': 0.4525, 'cmp': -0.5242}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0843\n",
      "{'abs_err': 0.0828, 'rel_err': 1.9683, 'sigma_1.25': 20.9844, 'sigma_1.25^2': 42.3429, 'sigma_1.25^3': 58.2388, 'cmp': -2.084}\n",
      "======================================================================\n",
      "[Iter 7450 Task segm] Train Loss: 0.3167\n",
      "[Iter 7450 Task dept] Train Loss: 0.0161\n",
      "[Iter 7450 Total] Train Loss: 0.1664\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Train Loss: 0.3250\n",
      "[Iter 7500 Task dept] Train Loss: 0.0161\n",
      "[Iter 7500 Total] Train Loss: 0.1706\n",
      "======================================================================\n",
      "[Iter 7550 Task segm] Train Loss: 0.3176\n",
      "[Iter 7550 Task dept] Train Loss: 0.0157\n",
      "[Iter 7550 Total] Train Loss: 0.1667\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Train Loss: 0.3280\n",
      "[Iter 7600 Task dept] Train Loss: 0.0161\n",
      "[Iter 7600 Total] Train Loss: 0.1721\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.4451\n",
      "{'mIoU': 0.1816, 'Pixel Acc': 0.5568, 'cmp': -0.4015}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0945\n",
      "{'abs_err': 0.093, 'rel_err': 2.3227, 'sigma_1.25': 21.1652, 'sigma_1.25^2': 41.1186, 'sigma_1.25^3': 54.517, 'cmp': -2.4294}\n",
      "======================================================================\n",
      "[Iter 7650 Task segm] Train Loss: 0.3251\n",
      "[Iter 7650 Task dept] Train Loss: 0.0161\n",
      "[Iter 7650 Total] Train Loss: 0.1706\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Train Loss: 0.3273\n",
      "[Iter 7700 Task dept] Train Loss: 0.0155\n",
      "[Iter 7700 Total] Train Loss: 0.1714\n",
      "======================================================================\n",
      "[Iter 7750 Task segm] Train Loss: 0.3368\n",
      "[Iter 7750 Task dept] Train Loss: 0.0165\n",
      "[Iter 7750 Total] Train Loss: 0.1767\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Train Loss: 0.3292\n",
      "[Iter 7800 Task dept] Train Loss: 0.0164\n",
      "[Iter 7800 Total] Train Loss: 0.1728\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 0.9708\n",
      "{'mIoU': 0.2192, 'Pixel Acc': 0.6221, 'cmp': -0.311}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0846\n",
      "{'abs_err': 0.083, 'rel_err': 1.9745, 'sigma_1.25': 20.7147, 'sigma_1.25^2': 42.5438, 'sigma_1.25^3': 58.2208, 'cmp': -2.0906}\n",
      "======================================================================\n",
      "[Iter 7850 Task segm] Train Loss: 0.3121\n",
      "[Iter 7850 Task dept] Train Loss: 0.0158\n",
      "[Iter 7850 Total] Train Loss: 0.1640\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Train Loss: 0.3158\n",
      "[Iter 7900 Task dept] Train Loss: 0.0159\n",
      "[Iter 7900 Total] Train Loss: 0.1658\n",
      "======================================================================\n",
      "[Iter 7950 Task segm] Train Loss: 0.3324\n",
      "[Iter 7950 Task dept] Train Loss: 0.0157\n",
      "[Iter 7950 Total] Train Loss: 0.1740\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Train Loss: 0.3125\n",
      "[Iter 8000 Task dept] Train Loss: 0.0158\n",
      "[Iter 8000 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 3.1718\n",
      "{'mIoU': 0.152, 'Pixel Acc': 0.4751, 'cmp': -0.493}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0885\n",
      "{'abs_err': 0.0867, 'rel_err': 2.1076, 'sigma_1.25': 21.3724, 'sigma_1.25^2': 42.2772, 'sigma_1.25^3': 56.3626, 'cmp': -2.2176}\n",
      "======================================================================\n",
      "[Iter 8050 Task segm] Train Loss: 0.3188\n",
      "[Iter 8050 Task dept] Train Loss: 0.0159\n",
      "[Iter 8050 Total] Train Loss: 0.1673\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8100 Task segm] Train Loss: 0.3271\n",
      "[Iter 8100 Task dept] Train Loss: 0.0152\n",
      "[Iter 8100 Total] Train Loss: 0.1712\n",
      "======================================================================\n",
      "[Iter 8150 Task segm] Train Loss: 0.3063\n",
      "[Iter 8150 Task dept] Train Loss: 0.0156\n",
      "[Iter 8150 Total] Train Loss: 0.1609\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 0.3051\n",
      "[Iter 8200 Task dept] Train Loss: 0.0154\n",
      "[Iter 8200 Total] Train Loss: 0.1603\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.2307\n",
      "{'mIoU': 0.2002, 'Pixel Acc': 0.5812, 'cmp': -0.362}\n",
      "[Iter 8200 Task dept] Val Loss: 0.0941\n",
      "{'abs_err': 0.0921, 'rel_err': 2.2972, 'sigma_1.25': 22.0893, 'sigma_1.25^2': 42.3863, 'sigma_1.25^3': 53.9933, 'cmp': -2.3984}\n",
      "======================================================================\n",
      "[Iter 8250 Task segm] Train Loss: 0.3006\n",
      "[Iter 8250 Task dept] Train Loss: 0.0161\n",
      "[Iter 8250 Total] Train Loss: 0.1584\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Train Loss: 0.3336\n",
      "[Iter 8300 Task dept] Train Loss: 0.0159\n",
      "[Iter 8300 Total] Train Loss: 0.1747\n",
      "======================================================================\n",
      "[Iter 8350 Task segm] Train Loss: 0.3160\n",
      "[Iter 8350 Task dept] Train Loss: 0.0160\n",
      "[Iter 8350 Total] Train Loss: 0.1660\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 0.3126\n",
      "[Iter 8400 Task dept] Train Loss: 0.0158\n",
      "[Iter 8400 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 1.1843\n",
      "{'mIoU': 0.1963, 'Pixel Acc': 0.6085, 'cmp': -0.3485}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0980\n",
      "{'abs_err': 0.0955, 'rel_err': 2.4151, 'sigma_1.25': 22.6665, 'sigma_1.25^2': 41.6501, 'sigma_1.25^3': 52.6416, 'cmp': -2.5139}\n",
      "======================================================================\n",
      "[Iter 8450 Task segm] Train Loss: 0.3185\n",
      "[Iter 8450 Task dept] Train Loss: 0.0152\n",
      "[Iter 8450 Total] Train Loss: 0.1668\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Train Loss: 0.3084\n",
      "[Iter 8500 Task dept] Train Loss: 0.0154\n",
      "[Iter 8500 Total] Train Loss: 0.1619\n",
      "======================================================================\n",
      "[Iter 8550 Task segm] Train Loss: 0.3213\n",
      "[Iter 8550 Task dept] Train Loss: 0.0162\n",
      "[Iter 8550 Total] Train Loss: 0.1688\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Train Loss: 0.3042\n",
      "[Iter 8600 Task dept] Train Loss: 0.0159\n",
      "[Iter 8600 Total] Train Loss: 0.1601\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 1.4170\n",
      "{'mIoU': 0.172, 'Pixel Acc': 0.5819, 'cmp': -0.3966}\n",
      "[Iter 8600 Task dept] Val Loss: 0.1155\n",
      "{'abs_err': 0.113, 'rel_err': 2.8964, 'sigma_1.25': 21.4123, 'sigma_1.25^2': 38.1598, 'sigma_1.25^3': 48.1969, 'cmp': -3.0325}\n",
      "======================================================================\n",
      "[Iter 8650 Task segm] Train Loss: 0.3111\n",
      "[Iter 8650 Task dept] Train Loss: 0.0153\n",
      "[Iter 8650 Total] Train Loss: 0.1632\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Train Loss: 0.3104\n",
      "[Iter 8700 Task dept] Train Loss: 0.0155\n",
      "[Iter 8700 Total] Train Loss: 0.1629\n",
      "======================================================================\n",
      "[Iter 8750 Task segm] Train Loss: 0.3037\n",
      "[Iter 8750 Task dept] Train Loss: 0.0147\n",
      "[Iter 8750 Total] Train Loss: 0.1592\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.3080\n",
      "[Iter 8800 Task dept] Train Loss: 0.0155\n",
      "[Iter 8800 Total] Train Loss: 0.1618\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.3760\n",
      "{'mIoU': 0.1904, 'Pixel Acc': 0.5828, 'cmp': -0.3731}\n",
      "[Iter 8800 Task dept] Val Loss: 0.1033\n",
      "{'abs_err': 0.1011, 'rel_err': 2.5607, 'sigma_1.25': 21.1996, 'sigma_1.25^2': 39.6832, 'sigma_1.25^3': 51.7942, 'cmp': -2.6783}\n",
      "======================================================================\n",
      "[Iter 8850 Task segm] Train Loss: 0.3205\n",
      "[Iter 8850 Task dept] Train Loss: 0.0164\n",
      "[Iter 8850 Total] Train Loss: 0.1684\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Train Loss: 0.3161\n",
      "[Iter 8900 Task dept] Train Loss: 0.0157\n",
      "[Iter 8900 Total] Train Loss: 0.1659\n",
      "======================================================================\n",
      "[Iter 8950 Task segm] Train Loss: 0.3119\n",
      "[Iter 8950 Task dept] Train Loss: 0.0158\n",
      "[Iter 8950 Total] Train Loss: 0.1639\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.3170\n",
      "[Iter 9000 Task dept] Train Loss: 0.0161\n",
      "[Iter 9000 Total] Train Loss: 0.1665\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 1.0887\n",
      "{'mIoU': 0.217, 'Pixel Acc': 0.618, 'cmp': -0.3164}\n",
      "[Iter 9000 Task dept] Val Loss: 0.1115\n",
      "{'abs_err': 0.1094, 'rel_err': 2.8214, 'sigma_1.25': 21.8089, 'sigma_1.25^2': 39.278, 'sigma_1.25^3': 49.11, 'cmp': -2.9387}\n",
      "======================================================================\n",
      "[Iter 9050 Task segm] Train Loss: 0.3172\n",
      "[Iter 9050 Task dept] Train Loss: 0.0151\n",
      "[Iter 9050 Total] Train Loss: 0.1661\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Train Loss: 0.3164\n",
      "[Iter 9100 Task dept] Train Loss: 0.0157\n",
      "[Iter 9100 Total] Train Loss: 0.1661\n",
      "======================================================================\n",
      "[Iter 9150 Task segm] Train Loss: 0.3134\n",
      "[Iter 9150 Task dept] Train Loss: 0.0162\n",
      "[Iter 9150 Total] Train Loss: 0.1648\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.3028\n",
      "[Iter 9200 Task dept] Train Loss: 0.0158\n",
      "[Iter 9200 Total] Train Loss: 0.1593\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 1.5985\n",
      "{'mIoU': 0.1718, 'Pixel Acc': 0.5596, 'cmp': -0.4118}\n",
      "[Iter 9200 Task dept] Val Loss: 0.0927\n",
      "{'abs_err': 0.0916, 'rel_err': 2.1091, 'sigma_1.25': 17.833, 'sigma_1.25^2': 36.5068, 'sigma_1.25^3': 53.724, 'cmp': -2.3059}\n",
      "======================================================================\n",
      "[Iter 9250 Task segm] Train Loss: 0.3126\n",
      "[Iter 9250 Task dept] Train Loss: 0.0154\n",
      "[Iter 9250 Total] Train Loss: 0.1640\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Train Loss: 0.3175\n",
      "[Iter 9300 Task dept] Train Loss: 0.0152\n",
      "[Iter 9300 Total] Train Loss: 0.1664\n",
      "======================================================================\n",
      "[Iter 9350 Task segm] Train Loss: 0.3119\n",
      "[Iter 9350 Task dept] Train Loss: 0.0159\n",
      "[Iter 9350 Total] Train Loss: 0.1639\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.3065\n",
      "[Iter 9400 Task dept] Train Loss: 0.0159\n",
      "[Iter 9400 Total] Train Loss: 0.1612\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.5920\n",
      "{'mIoU': 0.1855, 'Pixel Acc': 0.5527, 'cmp': -0.3993}\n",
      "[Iter 9400 Task dept] Val Loss: 0.1065\n",
      "{'abs_err': 0.1044, 'rel_err': 2.6555, 'sigma_1.25': 21.3719, 'sigma_1.25^2': 38.8284, 'sigma_1.25^3': 50.6621, 'cmp': -2.7782}\n",
      "======================================================================\n",
      "[Iter 9450 Task segm] Train Loss: 0.3108\n",
      "[Iter 9450 Task dept] Train Loss: 0.0158\n",
      "[Iter 9450 Total] Train Loss: 0.1633\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Train Loss: 0.2962\n",
      "[Iter 9500 Task dept] Train Loss: 0.0151\n",
      "[Iter 9500 Total] Train Loss: 0.1557\n",
      "======================================================================\n",
      "[Iter 9550 Task segm] Train Loss: 0.3125\n",
      "[Iter 9550 Task dept] Train Loss: 0.0159\n",
      "[Iter 9550 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Train Loss: 0.2988\n",
      "[Iter 9600 Task dept] Train Loss: 0.0147\n",
      "[Iter 9600 Total] Train Loss: 0.1567\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9600 Task segm] Val Loss: 1.3054\n",
      "{'mIoU': 0.1964, 'Pixel Acc': 0.5882, 'cmp': -0.362}\n",
      "[Iter 9600 Task dept] Val Loss: 0.1058\n",
      "{'abs_err': 0.1044, 'rel_err': 2.6382, 'sigma_1.25': 19.6295, 'sigma_1.25^2': 38.3761, 'sigma_1.25^3': 51.6513, 'cmp': -2.7714}\n",
      "======================================================================\n",
      "[Iter 9650 Task segm] Train Loss: 0.3068\n",
      "[Iter 9650 Task dept] Train Loss: 0.0154\n",
      "[Iter 9650 Total] Train Loss: 0.1611\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Train Loss: 0.3020\n",
      "[Iter 9700 Task dept] Train Loss: 0.0155\n",
      "[Iter 9700 Total] Train Loss: 0.1588\n",
      "======================================================================\n",
      "[Iter 9750 Task segm] Train Loss: 0.2949\n",
      "[Iter 9750 Task dept] Train Loss: 0.0161\n",
      "[Iter 9750 Total] Train Loss: 0.1555\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.3090\n",
      "[Iter 9800 Task dept] Train Loss: 0.0156\n",
      "[Iter 9800 Total] Train Loss: 0.1623\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 1.2233\n",
      "{'mIoU': 0.1882, 'Pixel Acc': 0.5828, 'cmp': -0.3758}\n",
      "[Iter 9800 Task dept] Val Loss: 0.0981\n",
      "{'abs_err': 0.0964, 'rel_err': 2.4097, 'sigma_1.25': 20.8561, 'sigma_1.25^2': 40.3609, 'sigma_1.25^3': 53.4102, 'cmp': -2.5273}\n",
      "======================================================================\n",
      "[Iter 9850 Task segm] Train Loss: 0.3018\n",
      "[Iter 9850 Task dept] Train Loss: 0.0158\n",
      "[Iter 9850 Total] Train Loss: 0.1588\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Train Loss: 0.2865\n",
      "[Iter 9900 Task dept] Train Loss: 0.0159\n",
      "[Iter 9900 Total] Train Loss: 0.1512\n",
      "======================================================================\n",
      "[Iter 9950 Task segm] Train Loss: 0.3061\n",
      "[Iter 9950 Task dept] Train Loss: 0.0155\n",
      "[Iter 9950 Total] Train Loss: 0.1608\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.3141\n",
      "[Iter 10000 Task dept] Train Loss: 0.0154\n",
      "[Iter 10000 Total] Train Loss: 0.1648\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 2.0799\n",
      "{'mIoU': 0.1601, 'Pixel Acc': 0.4947, 'cmp': -0.4697}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0966\n",
      "{'abs_err': 0.0953, 'rel_err': 2.1922, 'sigma_1.25': 16.9319, 'sigma_1.25^2': 34.9723, 'sigma_1.25^3': 52.4714, 'cmp': -2.4081}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train(iters=10000, lr=0.001, savePath=checkpoint+'NYUv2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 50 Task segm] Task Loss: 2.1043 Reg Loss: 24.9113 Train Loss: 10.5464\n",
      "[Iter 50 Task norm] Task Loss: 0.0688 Reg Loss: 25.8480 Train Loss: 1.4022\n",
      "[Iter 50 Task dept] Task Loss: 0.9776 Reg Loss: 25.2949 Train Loss: 4.9133\n",
      "[Iter 50 Total] Train Loss: 5.6206\n",
      "======================================================================\n",
      "[Iter 100 Task segm] Task Loss: 1.5813 Reg Loss: 23.9434 Train Loss: 7.9303\n",
      "[Iter 100 Task norm] Task Loss: 0.0673 Reg Loss: 24.0723 Train Loss: 1.3708\n",
      "[Iter 100 Task dept] Task Loss: 0.8484 Reg Loss: 23.8673 Train Loss: 4.2659\n",
      "[Iter 100 Total] Train Loss: 4.5223\n",
      "======================================================================\n",
      "[Iter 150 Task segm] Task Loss: 1.4540 Reg Loss: 25.0109 Train Loss: 7.2949\n",
      "[Iter 150 Task norm] Task Loss: 0.0664 Reg Loss: 25.1230 Train Loss: 1.3523\n",
      "[Iter 150 Task dept] Task Loss: 0.8198 Reg Loss: 24.9261 Train Loss: 4.1241\n",
      "[Iter 150 Total] Train Loss: 4.2571\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Task Loss: 1.4359 Reg Loss: 23.9125 Train Loss: 7.2033\n",
      "[Iter 200 Task norm] Task Loss: 0.0663 Reg Loss: 23.8691 Train Loss: 1.3504\n",
      "[Iter 200 Task dept] Task Loss: 0.7856 Reg Loss: 23.8591 Train Loss: 3.9520\n",
      "[Iter 200 Total] Train Loss: 4.1686\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 30.5226\n",
      "{'mIoU': 0.0138, 'Pixel Acc': 0.0452, 'cmp': -0.9366}\n",
      "[Iter 200 Task norm] Val Loss: 0.1385\n",
      "{'Angle Mean': 25.6543, 'Angle Median': 20.8632, 'Angle 11.25': 26.6549, 'Angle 22.5': 53.1791, 'Angle 30': 65.99, 'cmp': -0.3352}\n",
      "[Iter 200 Task dept] Val Loss: 2.9396\n",
      "{'abs_err': 2.9312, 'rel_err': 1.1767, 'sigma_1.25': 49.692, 'sigma_1.25^2': 57.7042, 'sigma_1.25^3': 65.4417, 'cmp': -1.644}\n",
      "======================================================================\n",
      "tau: 4.825\n",
      "[Iter 250 Task segm] Task Loss: 1.4342 Reg Loss: 24.5990 Train Loss: 7.1958\n",
      "[Iter 250 Task norm] Task Loss: 0.0675 Reg Loss: 24.5759 Train Loss: 1.3743\n",
      "[Iter 250 Task dept] Task Loss: 0.7697 Reg Loss: 24.9202 Train Loss: 3.8736\n",
      "[Iter 250 Total] Train Loss: 4.1479\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Task Loss: 1.4016 Reg Loss: 23.8731 Train Loss: 7.0320\n",
      "[Iter 300 Task norm] Task Loss: 0.0659 Reg Loss: 23.8701 Train Loss: 1.3422\n",
      "[Iter 300 Task dept] Task Loss: 0.7861 Reg Loss: 23.8325 Train Loss: 3.9543\n",
      "[Iter 300 Total] Train Loss: 4.1095\n",
      "======================================================================\n",
      "[Iter 350 Task segm] Task Loss: 1.3936 Reg Loss: 24.7576 Train Loss: 6.9927\n",
      "[Iter 350 Task norm] Task Loss: 0.0646 Reg Loss: 25.2688 Train Loss: 1.3181\n",
      "[Iter 350 Task dept] Task Loss: 0.7645 Reg Loss: 24.6804 Train Loss: 3.8471\n",
      "[Iter 350 Total] Train Loss: 4.0526\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Task Loss: 1.3974 Reg Loss: 23.9722 Train Loss: 7.0107\n",
      "[Iter 400 Task norm] Task Loss: 0.0666 Reg Loss: 24.0415 Train Loss: 1.3554\n",
      "[Iter 400 Task dept] Task Loss: 0.7581 Reg Loss: 23.7960 Train Loss: 3.8144\n",
      "[Iter 400 Total] Train Loss: 4.0602\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 30.2865\n",
      "{'mIoU': 0.026, 'Pixel Acc': 0.0887, 'cmp': -0.8774}\n",
      "[Iter 400 Task norm] Val Loss: 0.4976\n",
      "{'Angle Mean': 55.6184, 'Angle Median': 63.9793, 'Angle 11.25': 9.4365, 'Angle 22.5': 19.7571, 'Angle 30': 25.6473, 'cmp': -1.5689}\n",
      "[Iter 400 Task dept] Val Loss: 3.0862\n",
      "{'abs_err': 3.0754, 'rel_err': 1.0987, 'sigma_1.25': 58.3072, 'sigma_1.25^2': 65.0591, 'sigma_1.25^3': 70.9338, 'cmp': -1.5697}\n",
      "======================================================================\n",
      "tau: 4.656125\n",
      "[Iter 450 Task segm] Task Loss: 1.3437 Reg Loss: 24.8801 Train Loss: 6.7434\n",
      "[Iter 450 Task norm] Task Loss: 0.0666 Reg Loss: 24.9884 Train Loss: 1.3560\n",
      "[Iter 450 Task dept] Task Loss: 0.7709 Reg Loss: 23.9266 Train Loss: 3.8785\n",
      "[Iter 450 Total] Train Loss: 3.9926\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Task Loss: 1.3495 Reg Loss: 23.8796 Train Loss: 6.7714\n",
      "[Iter 500 Task norm] Task Loss: 0.0653 Reg Loss: 23.8691 Train Loss: 1.3297\n",
      "[Iter 500 Task dept] Task Loss: 0.7623 Reg Loss: 23.7989 Train Loss: 3.8352\n",
      "[Iter 500 Total] Train Loss: 3.9788\n",
      "======================================================================\n",
      "[Iter 550 Task segm] Task Loss: 1.3517 Reg Loss: 24.8243 Train Loss: 6.7832\n",
      "[Iter 550 Task norm] Task Loss: 0.0651 Reg Loss: 24.9911 Train Loss: 1.3263\n",
      "[Iter 550 Task dept] Task Loss: 0.7216 Reg Loss: 23.7679 Train Loss: 3.6320\n",
      "[Iter 550 Total] Train Loss: 3.9138\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Task Loss: 1.3680 Reg Loss: 23.8493 Train Loss: 6.8638\n",
      "[Iter 600 Task norm] Task Loss: 0.0669 Reg Loss: 23.7943 Train Loss: 1.3628\n",
      "[Iter 600 Task dept] Task Loss: 0.7308 Reg Loss: 23.7087 Train Loss: 3.6775\n",
      "[Iter 600 Total] Train Loss: 3.9680\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 69.5980\n",
      "{'mIoU': 0.0076, 'Pixel Acc': 0.0503, 'cmp': -0.9435}\n",
      "[Iter 600 Task norm] Val Loss: 0.1664\n",
      "{'Angle Mean': 29.6525, 'Angle Median': 29.331, 'Angle 11.25': 14.6989, 'Angle 22.5': 41.7576, 'Angle 30': 51.2228, 'cmp': -0.6343}\n",
      "[Iter 600 Task dept] Val Loss: 2.0777\n",
      "{'abs_err': 2.0667, 'rel_err': 0.7102, 'sigma_1.25': 35.0503, 'sigma_1.25^2': 47.8502, 'sigma_1.25^3': 58.5917, 'cmp': -1.0798}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "[Iter 650 Task segm] Task Loss: 1.3597 Reg Loss: 25.3705 Train Loss: 6.8239\n",
      "[Iter 650 Task norm] Task Loss: 0.0654 Reg Loss: 24.4904 Train Loss: 1.3334\n",
      "[Iter 650 Task dept] Task Loss: 0.7571 Reg Loss: 23.5791 Train Loss: 3.8092\n",
      "[Iter 650 Total] Train Loss: 3.9888\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Task Loss: 1.3581 Reg Loss: 23.9781 Train Loss: 6.8146\n",
      "[Iter 700 Task norm] Task Loss: 0.0657 Reg Loss: 24.0571 Train Loss: 1.3371\n",
      "[Iter 700 Task dept] Task Loss: 0.7374 Reg Loss: 23.6958 Train Loss: 3.7106\n",
      "[Iter 700 Total] Train Loss: 3.9541\n",
      "======================================================================\n",
      "[Iter 750 Task segm] Task Loss: 1.3621 Reg Loss: 25.5211 Train Loss: 6.8358\n",
      "[Iter 750 Task norm] Task Loss: 0.0648 Reg Loss: 24.8405 Train Loss: 1.3216\n",
      "[Iter 750 Task dept] Task Loss: 0.7175 Reg Loss: 24.4334 Train Loss: 3.6121\n",
      "[Iter 750 Total] Train Loss: 3.9232\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Task Loss: 1.3507 Reg Loss: 23.9748 Train Loss: 6.7773\n",
      "[Iter 800 Task norm] Task Loss: 0.0662 Reg Loss: 24.0333 Train Loss: 1.3481\n",
      "[Iter 800 Task dept] Task Loss: 0.7137 Reg Loss: 23.7335 Train Loss: 3.5921\n",
      "[Iter 800 Total] Train Loss: 3.9058\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 276.1598\n",
      "{'mIoU': 0.0107, 'Pixel Acc': 0.0491, 'cmp': -0.9388}\n",
      "[Iter 800 Task norm] Val Loss: 0.7274\n",
      "{'Angle Mean': 73.6805, 'Angle Median': 75.8487, 'Angle 11.25': 0.0088, 'Angle 22.5': 0.4559, 'Angle 30': 1.3866, 'cmp': -2.1058}\n",
      "[Iter 800 Task dept] Val Loss: 5.7274\n",
      "{'abs_err': 5.7188, 'rel_err': 2.1841, 'sigma_1.25': 89.7318, 'sigma_1.25^2': 90.7723, 'sigma_1.25^3': 91.7951, 'cmp': -3.0787}\n",
      "======================================================================\n",
      "tau: 4.3359000031249995\n",
      "[Iter 850 Task segm] Task Loss: 1.3644 Reg Loss: 24.7567 Train Loss: 6.8470\n",
      "[Iter 850 Task norm] Task Loss: 0.0654 Reg Loss: 24.8891 Train Loss: 1.3330\n",
      "[Iter 850 Task dept] Task Loss: 0.7129 Reg Loss: 24.4303 Train Loss: 3.5890\n",
      "[Iter 850 Total] Train Loss: 3.9230\n",
      "======================================================================\n",
      "[Iter 900 Task segm] Task Loss: 1.3423 Reg Loss: 23.8387 Train Loss: 6.7355\n",
      "[Iter 900 Task norm] Task Loss: 0.0651 Reg Loss: 23.8889 Train Loss: 1.3252\n",
      "[Iter 900 Task dept] Task Loss: 0.7303 Reg Loss: 23.9183 Train Loss: 3.6754\n",
      "[Iter 900 Total] Train Loss: 3.9120\n",
      "======================================================================\n",
      "[Iter 950 Task segm] Task Loss: 1.3702 Reg Loss: 24.8283 Train Loss: 6.8761\n",
      "[Iter 950 Task norm] Task Loss: 0.0652 Reg Loss: 25.0062 Train Loss: 1.3287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 950 Task dept] Task Loss: 0.6829 Reg Loss: 25.1700 Train Loss: 3.4399\n",
      "[Iter 950 Total] Train Loss: 3.8815\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Task Loss: 1.3692 Reg Loss: 23.9830 Train Loss: 6.8699\n",
      "[Iter 1000 Task norm] Task Loss: 0.0664 Reg Loss: 23.9455 Train Loss: 1.3521\n",
      "[Iter 1000 Task dept] Task Loss: 0.7132 Reg Loss: 23.8089 Train Loss: 3.5897\n",
      "[Iter 1000 Total] Train Loss: 3.9373\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 14.3512\n",
      "{'mIoU': 0.0324, 'Pixel Acc': 0.1637, 'cmp': -0.8021}\n",
      "[Iter 1000 Task norm] Val Loss: 0.1283\n",
      "{'Angle Mean': 25.6897, 'Angle Median': 22.9543, 'Angle 11.25': 18.7236, 'Angle 22.5': 48.8687, 'Angle 30': 68.068, 'cmp': -0.4174}\n",
      "[Iter 1000 Task dept] Val Loss: 12.3513\n",
      "{'abs_err': 12.3799, 'rel_err': 5.1266, 'sigma_1.25': 73.6491, 'sigma_1.25^2': 76.2525, 'sigma_1.25^3': 78.8484, 'cmp': -7.6979}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "[Iter 1050 Task segm] Task Loss: 1.3147 Reg Loss: 25.8261 Train Loss: 6.5993\n",
      "[Iter 1050 Task norm] Task Loss: 0.0641 Reg Loss: 25.1830 Train Loss: 1.3079\n",
      "[Iter 1050 Task dept] Task Loss: 0.7249 Reg Loss: 25.0544 Train Loss: 3.6498\n",
      "[Iter 1050 Total] Train Loss: 3.8523\n",
      "======================================================================\n",
      "[Iter 1100 Task segm] Task Loss: 1.3587 Reg Loss: 23.7920 Train Loss: 6.8174\n",
      "[Iter 1100 Task norm] Task Loss: 0.0665 Reg Loss: 23.9680 Train Loss: 1.3548\n",
      "[Iter 1100 Task dept] Task Loss: 0.7199 Reg Loss: 23.8077 Train Loss: 3.6235\n",
      "[Iter 1100 Total] Train Loss: 3.9319\n",
      "======================================================================\n",
      "[Iter 1150 Task segm] Task Loss: 1.3456 Reg Loss: 24.9081 Train Loss: 6.7528\n",
      "[Iter 1150 Task norm] Task Loss: 0.0662 Reg Loss: 25.3074 Train Loss: 1.3485\n",
      "[Iter 1150 Task dept] Task Loss: 0.7015 Reg Loss: 24.6417 Train Loss: 3.5321\n",
      "[Iter 1150 Total] Train Loss: 3.8778\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Task Loss: 1.3354 Reg Loss: 23.7920 Train Loss: 6.7008\n",
      "[Iter 1200 Task norm] Task Loss: 0.0640 Reg Loss: 23.8498 Train Loss: 1.3041\n",
      "[Iter 1200 Task dept] Task Loss: 0.7142 Reg Loss: 23.8394 Train Loss: 3.5949\n",
      "[Iter 1200 Total] Train Loss: 3.8666\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 39.8988\n",
      "{'mIoU': 0.0354, 'Pixel Acc': 0.1226, 'cmp': -0.8316}\n",
      "[Iter 1200 Task norm] Val Loss: 0.4232\n",
      "{'Angle Mean': 50.7197, 'Angle Median': 53.889, 'Angle 11.25': 10.4604, 'Angle 22.5': 18.6118, 'Angle 30': 26.1631, 'cmp': -1.3669}\n",
      "[Iter 1200 Task dept] Val Loss: 5.9806\n",
      "{'abs_err': 6.0096, 'rel_err': 2.8081, 'sigma_1.25': 3.5514, 'sigma_1.25^2': 8.9904, 'sigma_1.25^3': 17.9591, 'cmp': -4.3143}\n",
      "======================================================================\n",
      "tau: 4.037698480410078\n",
      "[Iter 1250 Task segm] Task Loss: 1.3358 Reg Loss: 25.6341 Train Loss: 6.7049\n",
      "[Iter 1250 Task norm] Task Loss: 0.0656 Reg Loss: 25.3971 Train Loss: 1.3383\n",
      "[Iter 1250 Task dept] Task Loss: 0.7112 Reg Loss: 25.0079 Train Loss: 3.5813\n",
      "[Iter 1250 Total] Train Loss: 3.8748\n",
      "======================================================================\n",
      "[Iter 1300 Task segm] Task Loss: 1.3392 Reg Loss: 23.8088 Train Loss: 6.7199\n",
      "[Iter 1300 Task norm] Task Loss: 0.0643 Reg Loss: 23.8325 Train Loss: 1.3097\n",
      "[Iter 1300 Task dept] Task Loss: 0.7165 Reg Loss: 23.7757 Train Loss: 3.6062\n",
      "[Iter 1300 Total] Train Loss: 3.8786\n",
      "======================================================================\n",
      "[Iter 1350 Task segm] Task Loss: 1.3202 Reg Loss: 24.9230 Train Loss: 6.6258\n",
      "[Iter 1350 Task norm] Task Loss: 0.0654 Reg Loss: 25.0402 Train Loss: 1.3337\n",
      "[Iter 1350 Task dept] Task Loss: 0.7559 Reg Loss: 24.6224 Train Loss: 3.8042\n",
      "[Iter 1350 Total] Train Loss: 3.9212\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Task Loss: 1.3046 Reg Loss: 23.8360 Train Loss: 6.5468\n",
      "[Iter 1400 Task norm] Task Loss: 0.0646 Reg Loss: 23.8449 Train Loss: 1.3152\n",
      "[Iter 1400 Task dept] Task Loss: 0.7145 Reg Loss: 23.8217 Train Loss: 3.5964\n",
      "[Iter 1400 Total] Train Loss: 3.8195\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 30.7678\n",
      "{'mIoU': 0.0254, 'Pixel Acc': 0.069, 'cmp': -0.8951}\n",
      "[Iter 1400 Task norm] Val Loss: 0.1984\n",
      "{'Angle Mean': 32.8638, 'Angle Median': 32.1414, 'Angle 11.25': 15.1542, 'Angle 22.5': 32.4869, 'Angle 30': 45.5595, 'cmp': -0.7465}\n",
      "[Iter 1400 Task dept] Val Loss: 3.3639\n",
      "{'abs_err': 3.3795, 'rel_err': 1.6865, 'sigma_1.25': 16.0505, 'sigma_1.25^2': 30.1009, 'sigma_1.25^3': 44.0226, 'cmp': -2.4217}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "[Iter 1450 Task segm] Task Loss: 1.3723 Reg Loss: 24.9997 Train Loss: 6.8864\n",
      "[Iter 1450 Task norm] Task Loss: 0.0649 Reg Loss: 25.4851 Train Loss: 1.3237\n",
      "[Iter 1450 Task dept] Task Loss: 0.7020 Reg Loss: 25.0879 Train Loss: 3.5351\n",
      "[Iter 1450 Total] Train Loss: 3.9151\n",
      "======================================================================\n",
      "[Iter 1500 Task segm] Task Loss: 1.3254 Reg Loss: 23.6157 Train Loss: 6.6506\n",
      "[Iter 1500 Task norm] Task Loss: 0.0660 Reg Loss: 23.9177 Train Loss: 1.3437\n",
      "[Iter 1500 Task dept] Task Loss: 0.7116 Reg Loss: 23.7686 Train Loss: 3.5818\n",
      "[Iter 1500 Total] Train Loss: 3.8587\n",
      "======================================================================\n",
      "[Iter 1550 Task segm] Task Loss: 1.3317 Reg Loss: 25.3574 Train Loss: 6.6839\n",
      "[Iter 1550 Task norm] Task Loss: 0.0658 Reg Loss: 25.6205 Train Loss: 1.3422\n",
      "[Iter 1550 Task dept] Task Loss: 0.7022 Reg Loss: 24.6420 Train Loss: 3.5359\n",
      "[Iter 1550 Total] Train Loss: 3.8540\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Task Loss: 1.3240 Reg Loss: 23.7066 Train Loss: 6.6438\n",
      "[Iter 1600 Task norm] Task Loss: 0.0651 Reg Loss: 23.8878 Train Loss: 1.3255\n",
      "[Iter 1600 Task dept] Task Loss: 0.7232 Reg Loss: 23.7059 Train Loss: 3.6399\n",
      "[Iter 1600 Total] Train Loss: 3.8697\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 168.3894\n",
      "{'mIoU': 0.0121, 'Pixel Acc': 0.0557, 'cmp': -0.9307}\n",
      "[Iter 1600 Task norm] Val Loss: 0.0958\n",
      "{'Angle Mean': 21.1201, 'Angle Median': 17.721, 'Angle 11.25': 30.7748, 'Angle 22.5': 61.7154, 'Angle 30': 77.0057, 'cmp': -0.1665}\n",
      "[Iter 1600 Task dept] Val Loss: 5.1427\n",
      "{'abs_err': 5.153, 'rel_err': 2.5321, 'sigma_1.25': 10.1831, 'sigma_1.25^2': 20.9826, 'sigma_1.25^3': 32.8605, 'cmp': -3.7351}\n",
      "======================================================================\n",
      "tau: 3.7600057674198744\n",
      "[Iter 1650 Task segm] Task Loss: 1.3668 Reg Loss: 25.0885 Train Loss: 6.8593\n",
      "[Iter 1650 Task norm] Task Loss: 0.0642 Reg Loss: 25.5411 Train Loss: 1.3091\n",
      "[Iter 1650 Task dept] Task Loss: 0.7102 Reg Loss: 24.4147 Train Loss: 3.5756\n",
      "[Iter 1650 Total] Train Loss: 3.9147\n",
      "======================================================================\n",
      "[Iter 1700 Task segm] Task Loss: 1.3623 Reg Loss: 23.4742 Train Loss: 6.8349\n",
      "[Iter 1700 Task norm] Task Loss: 0.0644 Reg Loss: 23.7975 Train Loss: 1.3113\n",
      "[Iter 1700 Task dept] Task Loss: 0.7232 Reg Loss: 23.6670 Train Loss: 3.6398\n",
      "[Iter 1700 Total] Train Loss: 3.9287\n",
      "======================================================================\n",
      "[Iter 1750 Task segm] Task Loss: 1.3191 Reg Loss: 24.2131 Train Loss: 6.6198\n",
      "[Iter 1750 Task norm] Task Loss: 0.0647 Reg Loss: 25.4228 Train Loss: 1.3190\n",
      "[Iter 1750 Task dept] Task Loss: 0.7187 Reg Loss: 24.6265 Train Loss: 3.6181\n",
      "[Iter 1750 Total] Train Loss: 3.8523\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Task Loss: 1.3417 Reg Loss: 23.7540 Train Loss: 6.7320\n",
      "[Iter 1800 Task norm] Task Loss: 0.0656 Reg Loss: 23.8012 Train Loss: 1.3348\n",
      "[Iter 1800 Task dept] Task Loss: 0.6747 Reg Loss: 23.7126 Train Loss: 3.3970\n",
      "[Iter 1800 Total] Train Loss: 3.8213\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 69.7039\n",
      "{'mIoU': 0.0091, 'Pixel Acc': 0.0496, 'cmp': -0.9413}\n",
      "[Iter 1800 Task norm] Val Loss: 0.1333\n",
      "{'Angle Mean': 26.1095, 'Angle Median': 22.1825, 'Angle 11.25': 15.7878, 'Angle 22.5': 50.9401, 'Angle 30': 69.3299, 'cmp': -0.4196}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1800 Task dept] Val Loss: 9.1679\n",
      "{'abs_err': 9.1862, 'rel_err': 4.2151, 'sigma_1.25': 19.8807, 'sigma_1.25^2': 23.9596, 'sigma_1.25^3': 29.0038, 'cmp': -6.3503}\n",
      "======================================================================\n",
      "tau: 3.6284055655601786\n",
      "[Iter 1850 Task segm] Task Loss: 1.3323 Reg Loss: 24.9713 Train Loss: 6.6866\n",
      "[Iter 1850 Task norm] Task Loss: 0.0642 Reg Loss: 25.1028 Train Loss: 1.3085\n",
      "[Iter 1850 Task dept] Task Loss: 0.7915 Reg Loss: 25.2587 Train Loss: 3.9826\n",
      "[Iter 1850 Total] Train Loss: 3.9925\n",
      "======================================================================\n",
      "[Iter 1900 Task segm] Task Loss: 1.3131 Reg Loss: 23.7460 Train Loss: 6.5893\n",
      "[Iter 1900 Task norm] Task Loss: 0.0643 Reg Loss: 23.7318 Train Loss: 1.3097\n",
      "[Iter 1900 Task dept] Task Loss: 0.6937 Reg Loss: 23.7828 Train Loss: 3.4922\n",
      "[Iter 1900 Total] Train Loss: 3.7971\n",
      "======================================================================\n",
      "[Iter 1950 Task segm] Task Loss: 1.3320 Reg Loss: 25.3533 Train Loss: 6.6852\n",
      "[Iter 1950 Task norm] Task Loss: 0.0644 Reg Loss: 25.3157 Train Loss: 1.3137\n",
      "[Iter 1950 Task dept] Task Loss: 0.6933 Reg Loss: 25.3418 Train Loss: 3.4920\n",
      "[Iter 1950 Total] Train Loss: 3.8303\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Task Loss: 1.3208 Reg Loss: 23.8415 Train Loss: 6.6281\n",
      "[Iter 2000 Task norm] Task Loss: 0.0659 Reg Loss: 23.6973 Train Loss: 1.3421\n",
      "[Iter 2000 Task dept] Task Loss: 0.7065 Reg Loss: 23.8460 Train Loss: 3.5563\n",
      "[Iter 2000 Total] Train Loss: 3.8422\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 55.9591\n",
      "{'mIoU': 0.019, 'Pixel Acc': 0.0647, 'cmp': -0.9105}\n",
      "[Iter 2000 Task norm] Val Loss: 0.8303\n",
      "{'Angle Mean': 79.9319, 'Angle Median': 82.581, 'Angle 11.25': 0.0022, 'Angle 22.5': 0.0345, 'Angle 30': 0.3846, 'cmp': -2.2756}\n",
      "[Iter 2000 Task dept] Val Loss: 54.3929\n",
      "{'abs_err': 54.2089, 'rel_err': 27.7985, 'sigma_1.25': 49.1676, 'sigma_1.25^2': 49.9092, 'sigma_1.25^3': 50.7016, 'cmp': -39.5334}\n",
      "======================================================================\n",
      "tau: 3.501411370765572\n",
      "[Iter 2050 Task segm] Task Loss: 1.3135 Reg Loss: 25.2493 Train Loss: 6.5928\n",
      "[Iter 2050 Task norm] Task Loss: 0.0641 Reg Loss: 24.5834 Train Loss: 1.3065\n",
      "[Iter 2050 Task dept] Task Loss: 0.6898 Reg Loss: 25.1161 Train Loss: 3.4740\n",
      "[Iter 2050 Total] Train Loss: 3.7911\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Task Loss: 1.3390 Reg Loss: 23.7429 Train Loss: 6.7185\n",
      "[Iter 2100 Task norm] Task Loss: 0.0632 Reg Loss: 23.7265 Train Loss: 1.2886\n",
      "[Iter 2100 Task dept] Task Loss: 0.7097 Reg Loss: 23.8100 Train Loss: 3.5725\n",
      "[Iter 2100 Total] Train Loss: 3.8599\n",
      "======================================================================\n",
      "[Iter 2150 Task segm] Task Loss: 1.3572 Reg Loss: 25.2303 Train Loss: 6.8111\n",
      "[Iter 2150 Task norm] Task Loss: 0.0654 Reg Loss: 25.2031 Train Loss: 1.3340\n",
      "[Iter 2150 Task dept] Task Loss: 0.6987 Reg Loss: 25.7937 Train Loss: 3.5193\n",
      "[Iter 2150 Total] Train Loss: 3.8882\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Task Loss: 1.3417 Reg Loss: 23.7512 Train Loss: 6.7322\n",
      "[Iter 2200 Task norm] Task Loss: 0.0637 Reg Loss: 23.8952 Train Loss: 1.2984\n",
      "[Iter 2200 Task dept] Task Loss: 0.6828 Reg Loss: 23.8059 Train Loss: 3.4379\n",
      "[Iter 2200 Total] Train Loss: 3.8228\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 250.6827\n",
      "{'mIoU': 0.0082, 'Pixel Acc': 0.0482, 'cmp': -0.9441}\n",
      "[Iter 2200 Task norm] Val Loss: 0.1669\n",
      "{'Angle Mean': 30.1507, 'Angle Median': 26.438, 'Angle 11.25': 8.7005, 'Angle 22.5': 40.917, 'Angle 30': 56.8315, 'cmp': -0.6228}\n",
      "[Iter 2200 Task dept] Val Loss: 41.8355\n",
      "{'abs_err': 42.0404, 'rel_err': 18.9366, 'sigma_1.25': 9.966, 'sigma_1.25^2': 11.0462, 'sigma_1.25^3': 12.3071, 'cmp': -28.8248}\n",
      "======================================================================\n",
      "tau: 3.3788619727887768\n",
      "[Iter 2250 Task segm] Task Loss: 1.3011 Reg Loss: 25.8014 Train Loss: 6.5315\n",
      "[Iter 2250 Task norm] Task Loss: 0.0643 Reg Loss: 25.4965 Train Loss: 1.3125\n",
      "[Iter 2250 Task dept] Task Loss: 0.6794 Reg Loss: 25.5216 Train Loss: 3.4226\n",
      "[Iter 2250 Total] Train Loss: 3.7555\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Task Loss: 1.3348 Reg Loss: 23.6223 Train Loss: 6.6979\n",
      "[Iter 2300 Task norm] Task Loss: 0.0649 Reg Loss: 23.7631 Train Loss: 1.3225\n",
      "[Iter 2300 Task dept] Task Loss: 0.6948 Reg Loss: 23.6639 Train Loss: 3.4976\n",
      "[Iter 2300 Total] Train Loss: 3.8393\n",
      "======================================================================\n",
      "[Iter 2350 Task segm] Task Loss: 1.3235 Reg Loss: 24.3910 Train Loss: 6.6418\n",
      "[Iter 2350 Task norm] Task Loss: 0.0648 Reg Loss: 25.5800 Train Loss: 1.3218\n",
      "[Iter 2350 Task dept] Task Loss: 0.7265 Reg Loss: 25.8259 Train Loss: 3.6585\n",
      "[Iter 2350 Total] Train Loss: 3.8740\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Task Loss: 1.2987 Reg Loss: 23.7820 Train Loss: 6.5175\n",
      "[Iter 2400 Task norm] Task Loss: 0.0655 Reg Loss: 23.6214 Train Loss: 1.3328\n",
      "[Iter 2400 Task dept] Task Loss: 0.7079 Reg Loss: 23.7022 Train Loss: 3.5632\n",
      "[Iter 2400 Total] Train Loss: 3.8045\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 94.7799\n",
      "{'mIoU': 0.0084, 'Pixel Acc': 0.0371, 'cmp': -0.9532}\n",
      "[Iter 2400 Task norm] Val Loss: 0.0916\n",
      "{'Angle Mean': 20.5032, 'Angle Median': 17.1947, 'Angle 11.25': 33.2988, 'Angle 22.5': 62.5063, 'Angle 30': 77.3961, 'cmp': -0.1345}\n",
      "[Iter 2400 Task dept] Val Loss: 2.1946\n",
      "{'abs_err': 2.205, 'rel_err': 1.0148, 'sigma_1.25': 26.2038, 'sigma_1.25^2': 44.8982, 'sigma_1.25^3': 60.7204, 'cmp': -1.4011}\n",
      "======================================================================\n",
      "tau: 3.2606018037411695\n",
      "[Iter 2450 Task segm] Task Loss: 1.3041 Reg Loss: 25.7133 Train Loss: 6.5460\n",
      "[Iter 2450 Task norm] Task Loss: 0.0644 Reg Loss: 25.5695 Train Loss: 1.3139\n",
      "[Iter 2450 Task dept] Task Loss: 0.6841 Reg Loss: 26.1146 Train Loss: 3.4468\n",
      "[Iter 2450 Total] Train Loss: 3.7689\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Task Loss: 1.3345 Reg Loss: 23.6578 Train Loss: 6.6964\n",
      "[Iter 2500 Task norm] Task Loss: 0.0637 Reg Loss: 23.7098 Train Loss: 1.2981\n",
      "[Iter 2500 Task dept] Task Loss: 0.6972 Reg Loss: 23.6474 Train Loss: 3.5094\n",
      "[Iter 2500 Total] Train Loss: 3.8346\n",
      "======================================================================\n",
      "[Iter 2550 Task segm] Task Loss: 1.3055 Reg Loss: 25.4486 Train Loss: 6.5532\n",
      "[Iter 2550 Task norm] Task Loss: 0.0641 Reg Loss: 25.7898 Train Loss: 1.3079\n",
      "[Iter 2550 Task dept] Task Loss: 0.7150 Reg Loss: 24.4885 Train Loss: 3.5994\n",
      "[Iter 2550 Total] Train Loss: 3.8202\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Task Loss: 1.3133 Reg Loss: 23.7004 Train Loss: 6.5900\n",
      "[Iter 2600 Task norm] Task Loss: 0.0637 Reg Loss: 23.7641 Train Loss: 1.2982\n",
      "[Iter 2600 Task dept] Task Loss: 0.6903 Reg Loss: 23.7191 Train Loss: 3.4751\n",
      "[Iter 2600 Total] Train Loss: 3.7878\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 62.6987\n",
      "{'mIoU': 0.0263, 'Pixel Acc': 0.0411, 'cmp': -0.9173}\n",
      "[Iter 2600 Task norm] Val Loss: 0.1812\n",
      "{'Angle Mean': 32.0488, 'Angle Median': 33.2486, 'Angle 11.25': 5.0106, 'Angle 22.5': 36.233, 'Angle 30': 46.0859, 'cmp': -0.7994}\n",
      "[Iter 2600 Task dept] Val Loss: 4.3186\n",
      "{'abs_err': 4.3153, 'rel_err': 1.6147, 'sigma_1.25': 70.4911, 'sigma_1.25^2': 75.3255, 'sigma_1.25^3': 79.9929, 'cmp': -2.2976}\n",
      "======================================================================\n",
      "tau: 3.1464807406102286\n",
      "[Iter 2650 Task segm] Task Loss: 1.2778 Reg Loss: 25.6549 Train Loss: 6.4145\n",
      "[Iter 2650 Task norm] Task Loss: 0.0638 Reg Loss: 25.5989 Train Loss: 1.3010\n",
      "[Iter 2650 Task dept] Task Loss: 0.7059 Reg Loss: 25.6665 Train Loss: 3.5551\n",
      "[Iter 2650 Total] Train Loss: 3.7569\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Task Loss: 1.3261 Reg Loss: 23.6200 Train Loss: 6.6539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2700 Task norm] Task Loss: 0.0663 Reg Loss: 23.5493 Train Loss: 1.3495\n",
      "[Iter 2700 Task dept] Task Loss: 0.6936 Reg Loss: 23.6854 Train Loss: 3.4916\n",
      "[Iter 2700 Total] Train Loss: 3.8317\n",
      "======================================================================\n",
      "[Iter 2750 Task segm] Task Loss: 1.3050 Reg Loss: 24.9745 Train Loss: 6.5501\n",
      "[Iter 2750 Task norm] Task Loss: 0.0639 Reg Loss: 25.0100 Train Loss: 1.3026\n",
      "[Iter 2750 Task dept] Task Loss: 0.6807 Reg Loss: 25.5081 Train Loss: 3.4291\n",
      "[Iter 2750 Total] Train Loss: 3.7606\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Task Loss: 1.3283 Reg Loss: 23.5381 Train Loss: 6.6652\n",
      "[Iter 2800 Task norm] Task Loss: 0.0642 Reg Loss: 23.7752 Train Loss: 1.3079\n",
      "[Iter 2800 Task dept] Task Loss: 0.6898 Reg Loss: 23.5947 Train Loss: 3.4725\n",
      "[Iter 2800 Total] Train Loss: 3.8152\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 53.1528\n",
      "{'mIoU': 0.0409, 'Pixel Acc': 0.0728, 'cmp': -0.8637}\n",
      "[Iter 2800 Task norm] Val Loss: 0.1121\n",
      "{'Angle Mean': 23.5567, 'Angle Median': 19.678, 'Angle 11.25': 20.9548, 'Angle 22.5': 58.1821, 'Angle 30': 74.4417, 'cmp': -0.2938}\n",
      "[Iter 2800 Task dept] Val Loss: 45.6741\n",
      "{'abs_err': 45.8745, 'rel_err': 19.6893, 'sigma_1.25': 4.4575, 'sigma_1.25^2': 4.9764, 'sigma_1.25^3': 5.5956, 'cmp': -30.711}\n",
      "======================================================================\n",
      "tau: 3.0363539146888705\n",
      "[Iter 2850 Task segm] Task Loss: 1.3201 Reg Loss: 25.6863 Train Loss: 6.6260\n",
      "[Iter 2850 Task norm] Task Loss: 0.0660 Reg Loss: 24.4550 Train Loss: 1.3455\n",
      "[Iter 2850 Task dept] Task Loss: 0.7021 Reg Loss: 25.0527 Train Loss: 3.5355\n",
      "[Iter 2850 Total] Train Loss: 3.8356\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Task Loss: 1.2957 Reg Loss: 23.7316 Train Loss: 6.5024\n",
      "[Iter 2900 Task norm] Task Loss: 0.0641 Reg Loss: 23.4769 Train Loss: 1.3058\n",
      "[Iter 2900 Task dept] Task Loss: 0.6891 Reg Loss: 23.4748 Train Loss: 3.4691\n",
      "[Iter 2900 Total] Train Loss: 3.7591\n",
      "======================================================================\n",
      "[Iter 2950 Task segm] Task Loss: 1.3137 Reg Loss: 25.6366 Train Loss: 6.5942\n",
      "[Iter 2950 Task norm] Task Loss: 0.0638 Reg Loss: 24.8566 Train Loss: 1.3014\n",
      "[Iter 2950 Task dept] Task Loss: 0.6939 Reg Loss: 25.0976 Train Loss: 3.4946\n",
      "[Iter 2950 Total] Train Loss: 3.7968\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Task Loss: 1.3022 Reg Loss: 23.5527 Train Loss: 6.5344\n",
      "[Iter 3000 Task norm] Task Loss: 0.0640 Reg Loss: 23.4508 Train Loss: 1.3032\n",
      "[Iter 3000 Task dept] Task Loss: 0.6746 Reg Loss: 23.4944 Train Loss: 3.3964\n",
      "[Iter 3000 Total] Train Loss: 3.7447\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 95.2281\n",
      "{'mIoU': 0.0133, 'Pixel Acc': 0.0586, 'cmp': -0.9261}\n",
      "[Iter 3000 Task norm] Val Loss: 0.3202\n",
      "{'Angle Mean': 43.875, 'Angle Median': 45.0053, 'Angle 11.25': 1.8015, 'Angle 22.5': 20.2726, 'Angle 30': 29.1114, 'cmp': -1.2017}\n",
      "[Iter 3000 Task dept] Val Loss: 9.7615\n",
      "{'abs_err': 9.7132, 'rel_err': 4.2608, 'sigma_1.25': 80.1142, 'sigma_1.25^2': 83.636, 'sigma_1.25^3': 86.9179, 'cmp': -6.0886}\n",
      "======================================================================\n",
      "tau: 2.93008152767476\n",
      "[Iter 3050 Task segm] Task Loss: 1.2892 Reg Loss: 26.3824 Train Loss: 6.4722\n",
      "[Iter 3050 Task norm] Task Loss: 0.0637 Reg Loss: 25.9379 Train Loss: 1.2997\n",
      "[Iter 3050 Task dept] Task Loss: 0.6767 Reg Loss: 25.2247 Train Loss: 3.4089\n",
      "[Iter 3050 Total] Train Loss: 3.7270\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Task Loss: 1.3198 Reg Loss: 23.7020 Train Loss: 6.6229\n",
      "[Iter 3100 Task norm] Task Loss: 0.0638 Reg Loss: 23.3764 Train Loss: 1.2999\n",
      "[Iter 3100 Task dept] Task Loss: 0.6737 Reg Loss: 23.2982 Train Loss: 3.3916\n",
      "[Iter 3100 Total] Train Loss: 3.7715\n",
      "======================================================================\n",
      "[Iter 3150 Task segm] Task Loss: 1.3071 Reg Loss: 26.7813 Train Loss: 6.5623\n",
      "[Iter 3150 Task norm] Task Loss: 0.0638 Reg Loss: 25.5020 Train Loss: 1.3023\n",
      "[Iter 3150 Task dept] Task Loss: 0.6768 Reg Loss: 24.7208 Train Loss: 3.4086\n",
      "[Iter 3150 Total] Train Loss: 3.7577\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Task Loss: 1.3403 Reg Loss: 23.7484 Train Loss: 6.7250\n",
      "[Iter 3200 Task norm] Task Loss: 0.0636 Reg Loss: 23.6397 Train Loss: 1.2965\n",
      "[Iter 3200 Task dept] Task Loss: 0.7016 Reg Loss: 23.5765 Train Loss: 3.5315\n",
      "[Iter 3200 Total] Train Loss: 3.8510\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 39.4299\n",
      "{'mIoU': 0.0191, 'Pixel Acc': 0.0599, 'cmp': -0.9144}\n",
      "[Iter 3200 Task norm] Val Loss: 0.4838\n",
      "{'Angle Mean': 57.1232, 'Angle Median': 60.5863, 'Angle 11.25': 3.3882, 'Angle 22.5': 7.4925, 'Angle 30': 11.3146, 'cmp': -1.6399}\n",
      "[Iter 3200 Task dept] Val Loss: 1.4615\n",
      "{'abs_err': 1.4588, 'rel_err': 0.6216, 'sigma_1.25': 26.9838, 'sigma_1.25^2': 50.668, 'sigma_1.25^3': 69.3428, 'cmp': -0.8116}\n",
      "======================================================================\n",
      "tau: 2.827528674206143\n",
      "[Iter 3250 Task segm] Task Loss: 1.3089 Reg Loss: 26.2317 Train Loss: 6.5706\n",
      "[Iter 3250 Task norm] Task Loss: 0.0632 Reg Loss: 25.6577 Train Loss: 1.2890\n",
      "[Iter 3250 Task dept] Task Loss: 0.6784 Reg Loss: 24.4573 Train Loss: 3.4167\n",
      "[Iter 3250 Total] Train Loss: 3.7587\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Task Loss: 1.3219 Reg Loss: 23.6822 Train Loss: 6.6332\n",
      "[Iter 3300 Task norm] Task Loss: 0.0641 Reg Loss: 23.5563 Train Loss: 1.3062\n",
      "[Iter 3300 Task dept] Task Loss: 0.6992 Reg Loss: 23.5503 Train Loss: 3.5194\n",
      "[Iter 3300 Total] Train Loss: 3.8196\n",
      "======================================================================\n",
      "[Iter 3350 Task segm] Task Loss: 1.3129 Reg Loss: 26.1394 Train Loss: 6.5909\n",
      "[Iter 3350 Task norm] Task Loss: 0.0636 Reg Loss: 25.8686 Train Loss: 1.2971\n",
      "[Iter 3350 Task dept] Task Loss: 0.7185 Reg Loss: 24.5961 Train Loss: 3.6173\n",
      "[Iter 3350 Total] Train Loss: 3.8351\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Task Loss: 1.2763 Reg Loss: 23.6516 Train Loss: 6.4054\n",
      "[Iter 3400 Task norm] Task Loss: 0.0644 Reg Loss: 23.6322 Train Loss: 1.3121\n",
      "[Iter 3400 Task dept] Task Loss: 0.7050 Reg Loss: 23.3831 Train Loss: 3.5483\n",
      "[Iter 3400 Total] Train Loss: 3.7553\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 17.1311\n",
      "{'mIoU': 0.0307, 'Pixel Acc': 0.1345, 'cmp': -0.8301}\n",
      "[Iter 3400 Task norm] Val Loss: 0.3400\n",
      "{'Angle Mean': 46.5876, 'Angle Median': 45.3928, 'Angle 11.25': 0.885, 'Angle 22.5': 7.7626, 'Angle 30': 16.0089, 'cmp': -1.3082}\n",
      "[Iter 3400 Task dept] Val Loss: 3.2161\n",
      "{'abs_err': 3.2079, 'rel_err': 1.2916, 'sigma_1.25': 50.7128, 'sigma_1.25^2': 60.8697, 'sigma_1.25^3': 69.6429, 'cmp': -1.8054}\n",
      "======================================================================\n",
      "tau: 2.728565170608928\n",
      "[Iter 3450 Task segm] Task Loss: 1.3281 Reg Loss: 25.8200 Train Loss: 6.6661\n",
      "[Iter 3450 Task norm] Task Loss: 0.0635 Reg Loss: 26.1340 Train Loss: 1.2964\n",
      "[Iter 3450 Task dept] Task Loss: 0.6774 Reg Loss: 26.6618 Train Loss: 3.4136\n",
      "[Iter 3450 Total] Train Loss: 3.7920\n",
      "======================================================================\n",
      "[Iter 3500 Task segm] Task Loss: 1.2816 Reg Loss: 23.6900 Train Loss: 6.4315\n",
      "[Iter 3500 Task norm] Task Loss: 0.0646 Reg Loss: 23.4659 Train Loss: 1.3151\n",
      "[Iter 3500 Task dept] Task Loss: 0.6694 Reg Loss: 23.4487 Train Loss: 3.3707\n",
      "[Iter 3500 Total] Train Loss: 3.7057\n",
      "======================================================================\n",
      "[Iter 3550 Task segm] Task Loss: 1.3114 Reg Loss: 25.8657 Train Loss: 6.5827\n",
      "[Iter 3550 Task norm] Task Loss: 0.0635 Reg Loss: 25.7959 Train Loss: 1.2956\n",
      "[Iter 3550 Task dept] Task Loss: 0.6830 Reg Loss: 25.4170 Train Loss: 3.4403\n",
      "[Iter 3550 Total] Train Loss: 3.7729\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Task Loss: 1.3049 Reg Loss: 23.6424 Train Loss: 6.5481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3600 Task norm] Task Loss: 0.0633 Reg Loss: 23.6149 Train Loss: 1.2887\n",
      "[Iter 3600 Task dept] Task Loss: 0.6749 Reg Loss: 23.3503 Train Loss: 3.3979\n",
      "[Iter 3600 Total] Train Loss: 3.7449\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 47.9486\n",
      "{'mIoU': 0.0108, 'Pixel Acc': 0.0504, 'cmp': -0.9375}\n",
      "[Iter 3600 Task norm] Val Loss: 0.3682\n",
      "{'Angle Mean': 47.9269, 'Angle Median': 46.372, 'Angle 11.25': 3.5123, 'Angle 22.5': 12.2033, 'Angle 30': 21.5922, 'cmp': -1.297}\n",
      "[Iter 3600 Task dept] Val Loss: 54.6358\n",
      "{'abs_err': 54.6919, 'rel_err': 23.9124, 'sigma_1.25': 99.6492, 'sigma_1.25^2': 99.7086, 'sigma_1.25^3': 99.7654, 'cmp': -36.1874}\n",
      "======================================================================\n",
      "tau: 2.6330653896376153\n",
      "[Iter 3650 Task segm] Task Loss: 1.2692 Reg Loss: 26.6416 Train Loss: 6.3728\n",
      "[Iter 3650 Task norm] Task Loss: 0.0643 Reg Loss: 25.4937 Train Loss: 1.3107\n",
      "[Iter 3650 Task dept] Task Loss: 0.7105 Reg Loss: 25.5708 Train Loss: 3.5781\n",
      "[Iter 3650 Total] Train Loss: 3.7539\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Task Loss: 1.3252 Reg Loss: 23.4339 Train Loss: 6.6494\n",
      "[Iter 3700 Task norm] Task Loss: 0.0651 Reg Loss: 23.6927 Train Loss: 1.3249\n",
      "[Iter 3700 Task dept] Task Loss: 0.6931 Reg Loss: 23.5335 Train Loss: 3.4892\n",
      "[Iter 3700 Total] Train Loss: 3.8212\n",
      "======================================================================\n",
      "[Iter 3750 Task segm] Task Loss: 1.3063 Reg Loss: 24.7705 Train Loss: 6.5563\n",
      "[Iter 3750 Task norm] Task Loss: 0.0628 Reg Loss: 26.4583 Train Loss: 1.2829\n",
      "[Iter 3750 Task dept] Task Loss: 0.6798 Reg Loss: 25.5549 Train Loss: 3.4248\n",
      "[Iter 3750 Total] Train Loss: 3.7547\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Task Loss: 1.2602 Reg Loss: 23.3610 Train Loss: 6.3245\n",
      "[Iter 3800 Task norm] Task Loss: 0.0638 Reg Loss: 23.5640 Train Loss: 1.2987\n",
      "[Iter 3800 Task dept] Task Loss: 0.6718 Reg Loss: 23.4324 Train Loss: 3.3823\n",
      "[Iter 3800 Total] Train Loss: 3.6685\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 148.8805\n",
      "{'mIoU': 0.0129, 'Pixel Acc': 0.0503, 'cmp': -0.9339}\n",
      "[Iter 3800 Task norm] Val Loss: 0.2173\n",
      "{'Angle Mean': 35.3264, 'Angle Median': 32.8069, 'Angle 11.25': 4.3772, 'Angle 22.5': 28.5519, 'Angle 30': 44.3184, 'cmp': -0.8594}\n",
      "[Iter 3800 Task dept] Val Loss: 7.4850\n",
      "{'abs_err': 7.5311, 'rel_err': 3.2555, 'sigma_1.25': 4.1111, 'sigma_1.25^2': 8.8133, 'sigma_1.25^3': 15.9352, 'cmp': -5.1657}\n",
      "======================================================================\n",
      "tau: 2.5409081010002987\n",
      "[Iter 3850 Task segm] Task Loss: 1.3323 Reg Loss: 25.7464 Train Loss: 6.6870\n",
      "[Iter 3850 Task norm] Task Loss: 0.0637 Reg Loss: 25.8148 Train Loss: 1.3002\n",
      "[Iter 3850 Task dept] Task Loss: 0.7042 Reg Loss: 25.5031 Train Loss: 3.5464\n",
      "[Iter 3850 Total] Train Loss: 3.8445\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Task Loss: 1.2910 Reg Loss: 23.2474 Train Loss: 6.4782\n",
      "[Iter 3900 Task norm] Task Loss: 0.0625 Reg Loss: 23.2617 Train Loss: 1.2733\n",
      "[Iter 3900 Task dept] Task Loss: 0.7051 Reg Loss: 23.4679 Train Loss: 3.5492\n",
      "[Iter 3900 Total] Train Loss: 3.7669\n",
      "======================================================================\n",
      "[Iter 3950 Task segm] Task Loss: 1.3391 Reg Loss: 24.6431 Train Loss: 6.7203\n",
      "[Iter 3950 Task norm] Task Loss: 0.0638 Reg Loss: 24.6096 Train Loss: 1.3009\n",
      "[Iter 3950 Task dept] Task Loss: 0.6783 Reg Loss: 26.8990 Train Loss: 3.4184\n",
      "[Iter 3950 Total] Train Loss: 3.8132\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Task Loss: 1.3177 Reg Loss: 23.0607 Train Loss: 6.6116\n",
      "[Iter 4000 Task norm] Task Loss: 0.0626 Reg Loss: 23.1172 Train Loss: 1.2752\n",
      "[Iter 4000 Task dept] Task Loss: 0.6800 Reg Loss: 23.3095 Train Loss: 3.4231\n",
      "[Iter 4000 Total] Train Loss: 3.7699\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 140.1950\n",
      "{'mIoU': 0.0081, 'Pixel Acc': 0.0498, 'cmp': -0.943}\n",
      "[Iter 4000 Task norm] Val Loss: 0.1499\n",
      "{'Angle Mean': 28.3907, 'Angle Median': 23.993, 'Angle 11.25': 9.2903, 'Angle 22.5': 45.7727, 'Angle 30': 64.5237, 'cmp': -0.5337}\n",
      "[Iter 4000 Task dept] Val Loss: 13.1983\n",
      "{'abs_err': 13.1812, 'rel_err': 5.6771, 'sigma_1.25': 93.1837, 'sigma_1.25^2': 94.3459, 'sigma_1.25^3': 95.4432, 'cmp': -8.2524}\n",
      "======================================================================\n",
      "tau: 2.451976317465288\n",
      "[Iter 4050 Task segm] Task Loss: 1.2899 Reg Loss: 25.6401 Train Loss: 6.4753\n",
      "[Iter 4050 Task norm] Task Loss: 0.0639 Reg Loss: 25.0986 Train Loss: 1.3039\n",
      "[Iter 4050 Task dept] Task Loss: 0.6964 Reg Loss: 26.2532 Train Loss: 3.5082\n",
      "[Iter 4050 Total] Train Loss: 3.7625\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Task Loss: 1.3455 Reg Loss: 23.1190 Train Loss: 6.7506\n",
      "[Iter 4100 Task norm] Task Loss: 0.0626 Reg Loss: 23.2020 Train Loss: 1.2750\n",
      "[Iter 4100 Task dept] Task Loss: 0.6948 Reg Loss: 23.6348 Train Loss: 3.4974\n",
      "[Iter 4100 Total] Train Loss: 3.8410\n",
      "======================================================================\n",
      "[Iter 4150 Task segm] Task Loss: 1.2735 Reg Loss: 24.7758 Train Loss: 6.3921\n",
      "[Iter 4150 Task norm] Task Loss: 0.0645 Reg Loss: 25.4341 Train Loss: 1.3155\n",
      "[Iter 4150 Task dept] Task Loss: 0.6646 Reg Loss: 25.8365 Train Loss: 3.3490\n",
      "[Iter 4150 Total] Train Loss: 3.6856\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Task Loss: 1.2686 Reg Loss: 23.1263 Train Loss: 6.3661\n",
      "[Iter 4200 Task norm] Task Loss: 0.0634 Reg Loss: 23.2334 Train Loss: 1.2908\n",
      "[Iter 4200 Task dept] Task Loss: 0.6909 Reg Loss: 23.1641 Train Loss: 3.4779\n",
      "[Iter 4200 Total] Train Loss: 3.7116\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 50.3409\n",
      "{'mIoU': 0.0408, 'Pixel Acc': 0.1161, 'cmp': -0.8272}\n",
      "[Iter 4200 Task norm] Val Loss: 0.1651\n",
      "{'Angle Mean': 29.7974, 'Angle Median': 25.8701, 'Angle 11.25': 10.0682, 'Angle 22.5': 40.4241, 'Angle 30': 60.8973, 'cmp': -0.5948}\n",
      "[Iter 4200 Task dept] Val Loss: 5.1290\n",
      "{'abs_err': 5.1082, 'rel_err': 2.2154, 'sigma_1.25': 63.9494, 'sigma_1.25^2': 69.6041, 'sigma_1.25^3': 74.9027, 'cmp': -3.0804}\n",
      "======================================================================\n",
      "tau: 2.366157146354003\n",
      "[Iter 4250 Task segm] Task Loss: 1.3484 Reg Loss: 24.5216 Train Loss: 6.7664\n",
      "[Iter 4250 Task norm] Task Loss: 0.0637 Reg Loss: 26.4498 Train Loss: 1.3002\n",
      "[Iter 4250 Task dept] Task Loss: 0.6939 Reg Loss: 26.0408 Train Loss: 3.4954\n",
      "[Iter 4250 Total] Train Loss: 3.8540\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Task Loss: 1.2861 Reg Loss: 23.0159 Train Loss: 6.4535\n",
      "[Iter 4300 Task norm] Task Loss: 0.0649 Reg Loss: 23.1402 Train Loss: 1.3214\n",
      "[Iter 4300 Task dept] Task Loss: 0.6956 Reg Loss: 23.3347 Train Loss: 3.5012\n",
      "[Iter 4300 Total] Train Loss: 3.7587\n",
      "======================================================================\n",
      "[Iter 4350 Task segm] Task Loss: 1.3025 Reg Loss: 25.8026 Train Loss: 6.5381\n",
      "[Iter 4350 Task norm] Task Loss: 0.0645 Reg Loss: 25.8598 Train Loss: 1.3166\n",
      "[Iter 4350 Task dept] Task Loss: 0.6853 Reg Loss: 25.4694 Train Loss: 3.4518\n",
      "[Iter 4350 Total] Train Loss: 3.7688\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Task Loss: 1.2667 Reg Loss: 23.1105 Train Loss: 6.3566\n",
      "[Iter 4400 Task norm] Task Loss: 0.0633 Reg Loss: 23.2094 Train Loss: 1.2897\n",
      "[Iter 4400 Task dept] Task Loss: 0.6908 Reg Loss: 23.4127 Train Loss: 3.4775\n",
      "[Iter 4400 Total] Train Loss: 3.7079\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 51.2208\n",
      "{'mIoU': 0.0317, 'Pixel Acc': 0.0839, 'cmp': -0.8711}\n",
      "[Iter 4400 Task norm] Val Loss: 0.5210\n",
      "{'Angle Mean': 60.1792, 'Angle Median': 61.9641, 'Angle 11.25': 0.6581, 'Angle 22.5': 4.2425, 'Angle 30': 7.8648, 'cmp': -1.7268}\n",
      "[Iter 4400 Task dept] Val Loss: 12.3327\n",
      "{'abs_err': 12.3249, 'rel_err': 5.3197, 'sigma_1.25': 97.0182, 'sigma_1.25^2': 97.4604, 'sigma_1.25^3': 97.8726, 'cmp': -7.6647}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 2.2833416462316127\n",
      "[Iter 4450 Task segm] Task Loss: 1.3092 Reg Loss: 26.1177 Train Loss: 6.5720\n",
      "[Iter 4450 Task norm] Task Loss: 0.0630 Reg Loss: 26.9675 Train Loss: 1.2874\n",
      "[Iter 4450 Task dept] Task Loss: 0.6919 Reg Loss: 27.0756 Train Loss: 3.4866\n",
      "[Iter 4450 Total] Train Loss: 3.7820\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Task Loss: 1.3491 Reg Loss: 23.2768 Train Loss: 6.7688\n",
      "[Iter 4500 Task norm] Task Loss: 0.0628 Reg Loss: 23.1237 Train Loss: 1.2798\n",
      "[Iter 4500 Task dept] Task Loss: 0.6778 Reg Loss: 23.5218 Train Loss: 3.4124\n",
      "[Iter 4500 Total] Train Loss: 3.8204\n",
      "======================================================================\n",
      "[Iter 4550 Task segm] Task Loss: 1.2826 Reg Loss: 25.7371 Train Loss: 6.4386\n",
      "[Iter 4550 Task norm] Task Loss: 0.0644 Reg Loss: 26.6762 Train Loss: 1.3146\n",
      "[Iter 4550 Task dept] Task Loss: 0.6845 Reg Loss: 26.7442 Train Loss: 3.4492\n",
      "[Iter 4550 Total] Train Loss: 3.7341\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Task Loss: 1.2701 Reg Loss: 23.0645 Train Loss: 6.3736\n",
      "[Iter 4600 Task norm] Task Loss: 0.0640 Reg Loss: 23.1586 Train Loss: 1.3027\n",
      "[Iter 4600 Task dept] Task Loss: 0.6954 Reg Loss: 23.2342 Train Loss: 3.5003\n",
      "[Iter 4600 Total] Train Loss: 3.7256\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 16.8888\n",
      "{'mIoU': 0.0271, 'Pixel Acc': 0.1611, 'cmp': -0.8141}\n",
      "[Iter 4600 Task norm] Val Loss: 0.1024\n",
      "{'Angle Mean': 22.3112, 'Angle Median': 19.8408, 'Angle 11.25': 29.7898, 'Angle 22.5': 55.4125, 'Angle 30': 70.7219, 'cmp': -0.2475}\n",
      "[Iter 4600 Task dept] Val Loss: 35.2463\n",
      "{'abs_err': 35.1153, 'rel_err': 16.4713, 'sigma_1.25': 85.3256, 'sigma_1.25^2': 87.3791, 'sigma_1.25^3': 89.3889, 'cmp': -24.0193}\n",
      "======================================================================\n",
      "tau: 2.2034246886135063\n",
      "[Iter 4650 Task segm] Task Loss: 1.3078 Reg Loss: 25.3212 Train Loss: 6.5643\n",
      "[Iter 4650 Task norm] Task Loss: 0.0640 Reg Loss: 26.2032 Train Loss: 1.3060\n",
      "[Iter 4650 Task dept] Task Loss: 0.6590 Reg Loss: 25.4869 Train Loss: 3.3205\n",
      "[Iter 4650 Total] Train Loss: 3.7302\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Task Loss: 1.3475 Reg Loss: 22.9949 Train Loss: 6.7605\n",
      "[Iter 4700 Task norm] Task Loss: 0.0624 Reg Loss: 23.3210 Train Loss: 1.2723\n",
      "[Iter 4700 Task dept] Task Loss: 0.6927 Reg Loss: 23.1425 Train Loss: 3.4869\n",
      "[Iter 4700 Total] Train Loss: 3.8399\n",
      "======================================================================\n",
      "[Iter 4750 Task segm] Task Loss: 1.3270 Reg Loss: 26.5608 Train Loss: 6.6618\n",
      "[Iter 4750 Task norm] Task Loss: 0.0627 Reg Loss: 26.7344 Train Loss: 1.2803\n",
      "[Iter 4750 Task dept] Task Loss: 0.6903 Reg Loss: 27.5655 Train Loss: 3.4792\n",
      "[Iter 4750 Total] Train Loss: 3.8071\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Task Loss: 1.2931 Reg Loss: 23.1540 Train Loss: 6.4887\n",
      "[Iter 4800 Task norm] Task Loss: 0.0637 Reg Loss: 23.2357 Train Loss: 1.2975\n",
      "[Iter 4800 Task dept] Task Loss: 0.6658 Reg Loss: 23.1222 Train Loss: 3.3520\n",
      "[Iter 4800 Total] Train Loss: 3.7127\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 101.5927\n",
      "{'mIoU': 0.0152, 'Pixel Acc': 0.0645, 'cmp': -0.9176}\n",
      "[Iter 4800 Task norm] Val Loss: 0.5344\n",
      "{'Angle Mean': 61.1251, 'Angle Median': 64.0888, 'Angle 11.25': 1.4574, 'Angle 22.5': 4.4483, 'Angle 30': 7.3925, 'cmp': -1.7635}\n",
      "[Iter 4800 Task dept] Val Loss: 2.8910\n",
      "{'abs_err': 2.893, 'rel_err': 1.1988, 'sigma_1.25': 31.4106, 'sigma_1.25^2': 48.0335, 'sigma_1.25^3': 61.8979, 'cmp': -1.7424}\n",
      "======================================================================\n",
      "tau: 2.1263048245120335\n",
      "[Iter 4850 Task segm] Task Loss: 1.3201 Reg Loss: 26.2151 Train Loss: 6.6268\n",
      "[Iter 4850 Task norm] Task Loss: 0.0634 Reg Loss: 25.9140 Train Loss: 1.2942\n",
      "[Iter 4850 Task dept] Task Loss: 0.6886 Reg Loss: 25.6658 Train Loss: 3.4686\n",
      "[Iter 4850 Total] Train Loss: 3.7965\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Task Loss: 1.2824 Reg Loss: 23.0864 Train Loss: 6.4352\n",
      "[Iter 4900 Task norm] Task Loss: 0.0636 Reg Loss: 23.3251 Train Loss: 1.2943\n",
      "[Iter 4900 Task dept] Task Loss: 0.7158 Reg Loss: 23.0623 Train Loss: 3.6020\n",
      "[Iter 4900 Total] Train Loss: 3.7772\n",
      "======================================================================\n",
      "[Iter 4950 Task segm] Task Loss: 1.2578 Reg Loss: 26.2777 Train Loss: 6.3151\n",
      "[Iter 4950 Task norm] Task Loss: 0.0645 Reg Loss: 25.4041 Train Loss: 1.3155\n",
      "[Iter 4950 Task dept] Task Loss: 0.6862 Reg Loss: 27.2219 Train Loss: 3.4584\n",
      "[Iter 4950 Total] Train Loss: 3.6963\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Task Loss: 1.3349 Reg Loss: 23.3543 Train Loss: 6.6979\n",
      "[Iter 5000 Task norm] Task Loss: 0.0636 Reg Loss: 23.4095 Train Loss: 1.2954\n",
      "[Iter 5000 Task dept] Task Loss: 0.6792 Reg Loss: 23.2698 Train Loss: 3.4194\n",
      "[Iter 5000 Total] Train Loss: 3.8042\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 20.6977\n",
      "{'mIoU': 0.0228, 'Pixel Acc': 0.1588, 'cmp': -0.8238}\n",
      "[Iter 5000 Task norm] Val Loss: 0.1673\n",
      "{'Angle Mean': 29.792, 'Angle Median': 26.3882, 'Angle 11.25': 10.6553, 'Angle 22.5': 41.4303, 'Angle 30': 57.3083, 'cmp': -0.6043}\n",
      "[Iter 5000 Task dept] Val Loss: 1.7915\n",
      "{'abs_err': 1.7736, 'rel_err': 0.6576, 'sigma_1.25': 34.6901, 'sigma_1.25^2': 51.1841, 'sigma_1.25^3': 64.5615, 'cmp': -0.9241}\n",
      "======================================================================\n",
      "tau: 2.051884155654112\n",
      "[Iter 5050 Task segm] Task Loss: 1.2750 Reg Loss: 27.9573 Train Loss: 6.4031\n",
      "[Iter 5050 Task norm] Task Loss: 0.0640 Reg Loss: 27.4753 Train Loss: 1.3077\n",
      "[Iter 5050 Task dept] Task Loss: 0.6835 Reg Loss: 25.8531 Train Loss: 3.4434\n",
      "[Iter 5050 Total] Train Loss: 3.7181\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Task Loss: 1.2878 Reg Loss: 23.5651 Train Loss: 6.4627\n",
      "[Iter 5100 Task norm] Task Loss: 0.0627 Reg Loss: 23.1178 Train Loss: 1.2763\n",
      "[Iter 5100 Task dept] Task Loss: 0.6940 Reg Loss: 23.2043 Train Loss: 3.4933\n",
      "[Iter 5100 Total] Train Loss: 3.7441\n",
      "======================================================================\n",
      "[Iter 5150 Task segm] Task Loss: 1.2724 Reg Loss: 27.1458 Train Loss: 6.3891\n",
      "[Iter 5150 Task norm] Task Loss: 0.0636 Reg Loss: 26.4252 Train Loss: 1.2978\n",
      "[Iter 5150 Task dept] Task Loss: 0.6788 Reg Loss: 25.7949 Train Loss: 3.4198\n",
      "[Iter 5150 Total] Train Loss: 3.7022\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Task Loss: 1.3085 Reg Loss: 23.3418 Train Loss: 6.5661\n",
      "[Iter 5200 Task norm] Task Loss: 0.0629 Reg Loss: 23.3331 Train Loss: 1.2810\n",
      "[Iter 5200 Task dept] Task Loss: 0.7037 Reg Loss: 23.0620 Train Loss: 3.5413\n",
      "[Iter 5200 Total] Train Loss: 3.7961\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 19.3111\n",
      "{'mIoU': 0.0228, 'Pixel Acc': 0.0892, 'cmp': -0.8828}\n",
      "[Iter 5200 Task norm] Val Loss: 0.2044\n",
      "{'Angle Mean': 34.0489, 'Angle Median': 31.402, 'Angle 11.25': 3.8664, 'Angle 22.5': 31.7651, 'Angle 30': 47.3979, 'cmp': -0.812}\n",
      "[Iter 5200 Task dept] Val Loss: 5.9271\n",
      "{'abs_err': 5.9445, 'rel_err': 2.4139, 'sigma_1.25': 74.1158, 'sigma_1.25^2': 78.7747, 'sigma_1.25^3': 82.9995, 'cmp': -3.4356}\n",
      "======================================================================\n",
      "tau: 1.9800682102062181\n",
      "[Iter 5250 Task segm] Task Loss: 1.3166 Reg Loss: 27.7177 Train Loss: 6.6105\n",
      "[Iter 5250 Task norm] Task Loss: 0.0644 Reg Loss: 27.3090 Train Loss: 1.3155\n",
      "[Iter 5250 Task dept] Task Loss: 0.6671 Reg Loss: 25.2945 Train Loss: 3.3608\n",
      "[Iter 5250 Total] Train Loss: 3.7623\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Task Loss: 1.2872 Reg Loss: 23.2594 Train Loss: 6.4593\n",
      "[Iter 5300 Task norm] Task Loss: 0.0642 Reg Loss: 23.2887 Train Loss: 1.3077\n",
      "[Iter 5300 Task dept] Task Loss: 0.6745 Reg Loss: 22.6827 Train Loss: 3.3950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5300 Total] Train Loss: 3.7206\n",
      "======================================================================\n",
      "[Iter 5350 Task segm] Task Loss: 1.2953 Reg Loss: 27.2082 Train Loss: 6.5039\n",
      "[Iter 5350 Task norm] Task Loss: 0.0628 Reg Loss: 26.7245 Train Loss: 1.2832\n",
      "[Iter 5350 Task dept] Task Loss: 0.6733 Reg Loss: 24.9442 Train Loss: 3.3913\n",
      "[Iter 5350 Total] Train Loss: 3.7261\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Task Loss: 1.3000 Reg Loss: 23.1614 Train Loss: 6.5234\n",
      "[Iter 5400 Task norm] Task Loss: 0.0637 Reg Loss: 23.1031 Train Loss: 1.2962\n",
      "[Iter 5400 Task dept] Task Loss: 0.7042 Reg Loss: 22.6239 Train Loss: 3.5437\n",
      "[Iter 5400 Total] Train Loss: 3.7878\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 13.1472\n",
      "{'mIoU': 0.0309, 'Pixel Acc': 0.1651, 'cmp': -0.8037}\n",
      "[Iter 5400 Task norm] Val Loss: 0.1725\n",
      "{'Angle Mean': 30.8519, 'Angle Median': 31.401, 'Angle 11.25': 9.5905, 'Angle 22.5': 39.2176, 'Angle 30': 48.158, 'cmp': -0.7205}\n",
      "[Iter 5400 Task dept] Val Loss: 6.9144\n",
      "{'abs_err': 6.9847, 'rel_err': 2.8142, 'sigma_1.25': 12.0587, 'sigma_1.25^2': 22.7746, 'sigma_1.25^3': 33.5772, 'cmp': -4.5396}\n",
      "======================================================================\n",
      "tau: 1.9107658228490005\n",
      "[Iter 5450 Task segm] Task Loss: 1.2716 Reg Loss: 28.5181 Train Loss: 6.3866\n",
      "[Iter 5450 Task norm] Task Loss: 0.0634 Reg Loss: 26.8701 Train Loss: 1.2954\n",
      "[Iter 5450 Task dept] Task Loss: 0.6838 Reg Loss: 25.5667 Train Loss: 3.4448\n",
      "[Iter 5450 Total] Train Loss: 3.7089\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Task Loss: 1.3001 Reg Loss: 22.9142 Train Loss: 6.5232\n",
      "[Iter 5500 Task norm] Task Loss: 0.0630 Reg Loss: 22.9555 Train Loss: 1.2836\n",
      "[Iter 5500 Task dept] Task Loss: 0.6817 Reg Loss: 22.5167 Train Loss: 3.4313\n",
      "[Iter 5500 Total] Train Loss: 3.7460\n",
      "======================================================================\n",
      "[Iter 5550 Task segm] Task Loss: 1.3072 Reg Loss: 26.6951 Train Loss: 6.5626\n",
      "[Iter 5550 Task norm] Task Loss: 0.0627 Reg Loss: 26.5712 Train Loss: 1.2814\n",
      "[Iter 5550 Task dept] Task Loss: 0.6735 Reg Loss: 25.4780 Train Loss: 3.3928\n",
      "[Iter 5550 Total] Train Loss: 3.7456\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Task Loss: 1.2925 Reg Loss: 22.8844 Train Loss: 6.4852\n",
      "[Iter 5600 Task norm] Task Loss: 0.0640 Reg Loss: 23.1110 Train Loss: 1.3032\n",
      "[Iter 5600 Task dept] Task Loss: 0.6875 Reg Loss: 22.7985 Train Loss: 3.4601\n",
      "[Iter 5600 Total] Train Loss: 3.7495\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 26.3812\n",
      "{'mIoU': 0.019, 'Pixel Acc': 0.0837, 'cmp': -0.8944}\n",
      "[Iter 5600 Task norm] Val Loss: 0.1902\n",
      "{'Angle Mean': 32.5237, 'Angle Median': 29.565, 'Angle 11.25': 5.3115, 'Angle 22.5': 34.5556, 'Angle 30': 50.8948, 'cmp': -0.7446}\n",
      "[Iter 5600 Task dept] Val Loss: 2.3379\n",
      "{'abs_err': 2.3396, 'rel_err': 0.9788, 'sigma_1.25': 37.2603, 'sigma_1.25^2': 53.0367, 'sigma_1.25^3': 66.3448, 'cmp': -1.3468}\n",
      "======================================================================\n",
      "tau: 1.8438890190492854\n",
      "[Iter 5650 Task segm] Task Loss: 1.2946 Reg Loss: 26.9057 Train Loss: 6.4997\n",
      "[Iter 5650 Task norm] Task Loss: 0.0627 Reg Loss: 26.5751 Train Loss: 1.2812\n",
      "[Iter 5650 Task dept] Task Loss: 0.6769 Reg Loss: 24.7200 Train Loss: 3.4094\n",
      "[Iter 5650 Total] Train Loss: 3.7301\n",
      "======================================================================\n",
      "[Iter 5700 Task segm] Task Loss: 1.3071 Reg Loss: 22.9314 Train Loss: 6.5585\n",
      "[Iter 5700 Task norm] Task Loss: 0.0621 Reg Loss: 22.7451 Train Loss: 1.2653\n",
      "[Iter 5700 Task dept] Task Loss: 0.6626 Reg Loss: 22.6789 Train Loss: 3.3359\n",
      "[Iter 5700 Total] Train Loss: 3.7199\n",
      "======================================================================\n",
      "[Iter 5750 Task segm] Task Loss: 1.2926 Reg Loss: 26.5295 Train Loss: 6.4896\n",
      "[Iter 5750 Task norm] Task Loss: 0.0629 Reg Loss: 26.4799 Train Loss: 1.2847\n",
      "[Iter 5750 Task dept] Task Loss: 0.6870 Reg Loss: 25.3110 Train Loss: 3.4604\n",
      "[Iter 5750 Total] Train Loss: 3.7449\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Task Loss: 1.3238 Reg Loss: 22.7668 Train Loss: 6.6417\n",
      "[Iter 5800 Task norm] Task Loss: 0.0641 Reg Loss: 23.1009 Train Loss: 1.3056\n",
      "[Iter 5800 Task dept] Task Loss: 0.6725 Reg Loss: 22.5930 Train Loss: 3.3850\n",
      "[Iter 5800 Total] Train Loss: 3.7774\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 25.9818\n",
      "{'mIoU': 0.0124, 'Pixel Acc': 0.0652, 'cmp': -0.9221}\n",
      "[Iter 5800 Task norm] Val Loss: 0.4036\n",
      "{'Angle Mean': 51.4487, 'Angle Median': 52.6736, 'Angle 11.25': 2.3414, 'Angle 22.5': 8.2707, 'Angle 30': 14.4894, 'cmp': -1.4601}\n",
      "[Iter 5800 Task dept] Val Loss: 3.2574\n",
      "{'abs_err': 3.278, 'rel_err': 1.4148, 'sigma_1.25': 19.6254, 'sigma_1.25^2': 34.2975, 'sigma_1.25^3': 49.0043, 'cmp': -2.1391}\n",
      "======================================================================\n",
      "tau: 1.7793529033825604\n",
      "[Iter 5850 Task segm] Task Loss: 1.2904 Reg Loss: 27.8785 Train Loss: 6.4797\n",
      "[Iter 5850 Task norm] Task Loss: 0.0633 Reg Loss: 25.9190 Train Loss: 1.2915\n",
      "[Iter 5850 Task dept] Task Loss: 0.6551 Reg Loss: 25.7118 Train Loss: 3.3010\n",
      "[Iter 5850 Total] Train Loss: 3.6907\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Task Loss: 1.2933 Reg Loss: 22.9025 Train Loss: 6.4892\n",
      "[Iter 5900 Task norm] Task Loss: 0.0634 Reg Loss: 22.8214 Train Loss: 1.2917\n",
      "[Iter 5900 Task dept] Task Loss: 0.6879 Reg Loss: 22.5080 Train Loss: 3.4622\n",
      "[Iter 5900 Total] Train Loss: 3.7477\n",
      "======================================================================\n",
      "[Iter 5950 Task segm] Task Loss: 1.2819 Reg Loss: 28.6444 Train Loss: 6.4380\n",
      "[Iter 5950 Task norm] Task Loss: 0.0636 Reg Loss: 25.3902 Train Loss: 1.2983\n",
      "[Iter 5950 Task dept] Task Loss: 0.7008 Reg Loss: 25.2639 Train Loss: 3.5294\n",
      "[Iter 5950 Total] Train Loss: 3.7552\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Task Loss: 1.2896 Reg Loss: 23.0163 Train Loss: 6.4709\n",
      "[Iter 6000 Task norm] Task Loss: 0.0640 Reg Loss: 23.0358 Train Loss: 1.3029\n",
      "[Iter 6000 Task dept] Task Loss: 0.6861 Reg Loss: 22.4603 Train Loss: 3.4532\n",
      "[Iter 6000 Total] Train Loss: 3.7424\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 26.7146\n",
      "{'mIoU': 0.0306, 'Pixel Acc': 0.1409, 'cmp': -0.8247}\n",
      "[Iter 6000 Task norm] Val Loss: 0.2216\n",
      "{'Angle Mean': 35.2913, 'Angle Median': 34.0384, 'Angle 11.25': 4.7971, 'Angle 22.5': 30.6032, 'Angle 30': 44.2604, 'cmp': -0.8685}\n",
      "[Iter 6000 Task dept] Val Loss: 1.8739\n",
      "{'abs_err': 1.8625, 'rel_err': 0.6743, 'sigma_1.25': 30.678, 'sigma_1.25^2': 44.8133, 'sigma_1.25^3': 57.0525, 'cmp': -1.0106}\n",
      "======================================================================\n",
      "tau: 1.7170755517641707\n",
      "[Iter 6050 Task segm] Task Loss: 1.3156 Reg Loss: 27.0886 Train Loss: 6.6049\n",
      "[Iter 6050 Task norm] Task Loss: 0.0630 Reg Loss: 26.5515 Train Loss: 1.2873\n",
      "[Iter 6050 Task dept] Task Loss: 0.6996 Reg Loss: 23.4964 Train Loss: 3.5215\n",
      "[Iter 6050 Total] Train Loss: 3.8045\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Task Loss: 1.2708 Reg Loss: 22.7118 Train Loss: 6.3769\n",
      "[Iter 6100 Task norm] Task Loss: 0.0638 Reg Loss: 22.6325 Train Loss: 1.2989\n",
      "[Iter 6100 Task dept] Task Loss: 0.6798 Reg Loss: 21.9892 Train Loss: 3.4211\n",
      "[Iter 6100 Total] Train Loss: 3.6990\n",
      "======================================================================\n",
      "[Iter 6150 Task segm] Task Loss: 1.2836 Reg Loss: 28.0996 Train Loss: 6.4461\n",
      "[Iter 6150 Task norm] Task Loss: 0.0620 Reg Loss: 27.7005 Train Loss: 1.2680\n",
      "[Iter 6150 Task dept] Task Loss: 0.7035 Reg Loss: 25.1956 Train Loss: 3.5427\n",
      "[Iter 6150 Total] Train Loss: 3.7523\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Task Loss: 1.2983 Reg Loss: 23.3025 Train Loss: 6.5146\n",
      "[Iter 6200 Task norm] Task Loss: 0.0633 Reg Loss: 22.7893 Train Loss: 1.2892\n",
      "[Iter 6200 Task dept] Task Loss: 0.6681 Reg Loss: 22.1175 Train Loss: 3.3625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6200 Total] Train Loss: 3.7221\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 16.7988\n",
      "{'mIoU': 0.0146, 'Pixel Acc': 0.0566, 'cmp': -0.9255}\n",
      "[Iter 6200 Task norm] Val Loss: 0.2392\n",
      "{'Angle Mean': 37.7833, 'Angle Median': 37.9651, 'Angle 11.25': 1.013, 'Angle 22.5': 24.2316, 'Angle 30': 37.445, 'cmp': -1.0072}\n",
      "[Iter 6200 Task dept] Val Loss: 2.5369\n",
      "{'abs_err': 2.5382, 'rel_err': 1.018, 'sigma_1.25': 43.7817, 'sigma_1.25^2': 59.1216, 'sigma_1.25^3': 71.2918, 'cmp': -1.3952}\n",
      "======================================================================\n",
      "tau: 1.6569779074524247\n",
      "[Iter 6250 Task segm] Task Loss: 1.3171 Reg Loss: 28.1579 Train Loss: 6.6137\n",
      "[Iter 6250 Task norm] Task Loss: 0.0631 Reg Loss: 27.4571 Train Loss: 1.2889\n",
      "[Iter 6250 Task dept] Task Loss: 0.6893 Reg Loss: 24.6002 Train Loss: 3.4713\n",
      "[Iter 6250 Total] Train Loss: 3.7913\n",
      "======================================================================\n",
      "[Iter 6300 Task segm] Task Loss: 1.2993 Reg Loss: 22.8635 Train Loss: 6.5192\n",
      "[Iter 6300 Task norm] Task Loss: 0.0645 Reg Loss: 22.9012 Train Loss: 1.3137\n",
      "[Iter 6300 Task dept] Task Loss: 0.6788 Reg Loss: 22.1607 Train Loss: 3.4160\n",
      "[Iter 6300 Total] Train Loss: 3.7496\n",
      "======================================================================\n",
      "[Iter 6350 Task segm] Task Loss: 1.2793 Reg Loss: 27.6868 Train Loss: 6.4242\n",
      "[Iter 6350 Task norm] Task Loss: 0.0633 Reg Loss: 28.0712 Train Loss: 1.2940\n",
      "[Iter 6350 Task dept] Task Loss: 0.6803 Reg Loss: 26.4483 Train Loss: 3.4282\n",
      "[Iter 6350 Total] Train Loss: 3.7154\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Task Loss: 1.2807 Reg Loss: 22.9595 Train Loss: 6.4265\n",
      "[Iter 6400 Task norm] Task Loss: 0.0623 Reg Loss: 22.9269 Train Loss: 1.2692\n",
      "[Iter 6400 Task dept] Task Loss: 0.7031 Reg Loss: 22.2419 Train Loss: 3.5377\n",
      "[Iter 6400 Total] Train Loss: 3.7445\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 24.0467\n",
      "{'mIoU': 0.0181, 'Pixel Acc': 0.0795, 'cmp': -0.8996}\n",
      "[Iter 6400 Task norm] Val Loss: 0.2006\n",
      "{'Angle Mean': 33.4633, 'Angle Median': 30.4094, 'Angle 11.25': 4.6938, 'Angle 22.5': 33.34, 'Angle 30': 49.2285, 'cmp': -0.778}\n",
      "[Iter 6400 Task dept] Val Loss: 2.9932\n",
      "{'abs_err': 3.0125, 'rel_err': 1.4482, 'sigma_1.25': 14.3461, 'sigma_1.25^2': 29.8343, 'sigma_1.25^3': 46.2673, 'cmp': -2.1145}\n",
      "======================================================================\n",
      "tau: 1.5989836806915898\n",
      "[Iter 6450 Task segm] Task Loss: 1.3145 Reg Loss: 26.8530 Train Loss: 6.5995\n",
      "[Iter 6450 Task norm] Task Loss: 0.0620 Reg Loss: 27.3910 Train Loss: 1.2665\n",
      "[Iter 6450 Task dept] Task Loss: 0.6877 Reg Loss: 24.4110 Train Loss: 3.4630\n",
      "[Iter 6450 Total] Train Loss: 3.7764\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Task Loss: 1.2861 Reg Loss: 22.5049 Train Loss: 6.4530\n",
      "[Iter 6500 Task norm] Task Loss: 0.0630 Reg Loss: 22.9569 Train Loss: 1.2834\n",
      "[Iter 6500 Task dept] Task Loss: 0.6808 Reg Loss: 22.1392 Train Loss: 3.4260\n",
      "[Iter 6500 Total] Train Loss: 3.7208\n",
      "======================================================================\n",
      "[Iter 6550 Task segm] Task Loss: 1.2673 Reg Loss: 29.2079 Train Loss: 6.3656\n",
      "[Iter 6550 Task norm] Task Loss: 0.0622 Reg Loss: 27.2983 Train Loss: 1.2715\n",
      "[Iter 6550 Task dept] Task Loss: 0.6933 Reg Loss: 24.5799 Train Loss: 3.4910\n",
      "[Iter 6550 Total] Train Loss: 3.7094\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Task Loss: 1.3183 Reg Loss: 22.5824 Train Loss: 6.6142\n",
      "[Iter 6600 Task norm] Task Loss: 0.0617 Reg Loss: 22.8546 Train Loss: 1.2575\n",
      "[Iter 6600 Task dept] Task Loss: 0.6972 Reg Loss: 22.3326 Train Loss: 3.5082\n",
      "[Iter 6600 Total] Train Loss: 3.7933\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 6.7758\n",
      "{'mIoU': 0.0391, 'Pixel Acc': 0.206, 'cmp': -0.754}\n",
      "[Iter 6600 Task norm] Val Loss: 0.1256\n",
      "{'Angle Mean': 24.8424, 'Angle Median': 20.2985, 'Angle 11.25': 18.8953, 'Angle 22.5': 56.5127, 'Angle 30': 72.6426, 'cmp': -0.3378}\n",
      "[Iter 6600 Task dept] Val Loss: 8.8362\n",
      "{'abs_err': 8.8571, 'rel_err': 3.6655, 'sigma_1.25': 94.6854, 'sigma_1.25^2': 95.2102, 'sigma_1.25^3': 95.7432, 'cmp': -5.2404}\n",
      "======================================================================\n",
      "tau: 1.5430192518673842\n",
      "[Iter 6650 Task segm] Task Loss: 1.2953 Reg Loss: 27.8307 Train Loss: 6.5042\n",
      "[Iter 6650 Task norm] Task Loss: 0.0638 Reg Loss: 25.9331 Train Loss: 1.3020\n",
      "[Iter 6650 Task dept] Task Loss: 0.6847 Reg Loss: 23.8413 Train Loss: 3.4473\n",
      "[Iter 6650 Total] Train Loss: 3.7512\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Task Loss: 1.2710 Reg Loss: 22.5180 Train Loss: 6.3775\n",
      "[Iter 6700 Task norm] Task Loss: 0.0636 Reg Loss: 22.6650 Train Loss: 1.2956\n",
      "[Iter 6700 Task dept] Task Loss: 0.6861 Reg Loss: 21.9785 Train Loss: 3.4526\n",
      "[Iter 6700 Total] Train Loss: 3.7086\n",
      "======================================================================\n",
      "[Iter 6750 Task segm] Task Loss: 1.3441 Reg Loss: 29.5168 Train Loss: 6.7499\n",
      "[Iter 6750 Task norm] Task Loss: 0.0651 Reg Loss: 27.3269 Train Loss: 1.3302\n",
      "[Iter 6750 Task dept] Task Loss: 0.6868 Reg Loss: 23.7975 Train Loss: 3.4579\n",
      "[Iter 6750 Total] Train Loss: 3.8460\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Task Loss: 1.3147 Reg Loss: 22.5767 Train Loss: 6.5960\n",
      "[Iter 6800 Task norm] Task Loss: 0.0611 Reg Loss: 22.7984 Train Loss: 1.2444\n",
      "[Iter 6800 Task dept] Task Loss: 0.6549 Reg Loss: 21.9766 Train Loss: 3.2967\n",
      "[Iter 6800 Total] Train Loss: 3.7123\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 4.4138\n",
      "{'mIoU': 0.0514, 'Pixel Acc': 0.3033, 'cmp': -0.6491}\n",
      "[Iter 6800 Task norm] Val Loss: 0.2244\n",
      "{'Angle Mean': 36.1054, 'Angle Median': 36.0495, 'Angle 11.25': 1.4968, 'Angle 22.5': 29.191, 'Angle 30': 41.8586, 'cmp': -0.9345}\n",
      "[Iter 6800 Task dept] Val Loss: 7.6453\n",
      "{'abs_err': 7.6502, 'rel_err': 3.1219, 'sigma_1.25': 87.4512, 'sigma_1.25^2': 88.8673, 'sigma_1.25^3': 90.2754, 'cmp': -4.4675}\n",
      "======================================================================\n",
      "tau: 1.4890135780520257\n",
      "[Iter 6850 Task segm] Task Loss: 1.2542 Reg Loss: 29.4020 Train Loss: 6.3002\n",
      "[Iter 6850 Task norm] Task Loss: 0.0632 Reg Loss: 28.1996 Train Loss: 1.2913\n",
      "[Iter 6850 Task dept] Task Loss: 0.6708 Reg Loss: 26.0960 Train Loss: 3.3801\n",
      "[Iter 6850 Total] Train Loss: 3.6572\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Task Loss: 1.3014 Reg Loss: 22.5668 Train Loss: 6.5295\n",
      "[Iter 6900 Task norm] Task Loss: 0.0632 Reg Loss: 22.3485 Train Loss: 1.2860\n",
      "[Iter 6900 Task dept] Task Loss: 0.7013 Reg Loss: 22.1066 Train Loss: 3.5286\n",
      "[Iter 6900 Total] Train Loss: 3.7813\n",
      "======================================================================\n",
      "[Iter 6950 Task segm] Task Loss: 1.3071 Reg Loss: 27.5787 Train Loss: 6.5629\n",
      "[Iter 6950 Task norm] Task Loss: 0.0632 Reg Loss: 28.3032 Train Loss: 1.2932\n",
      "[Iter 6950 Task dept] Task Loss: 0.6846 Reg Loss: 25.0553 Train Loss: 3.4483\n",
      "[Iter 6950 Total] Train Loss: 3.7681\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Task Loss: 1.2913 Reg Loss: 22.4958 Train Loss: 6.4791\n",
      "[Iter 7000 Task norm] Task Loss: 0.0645 Reg Loss: 22.2972 Train Loss: 1.3115\n",
      "[Iter 7000 Task dept] Task Loss: 0.6964 Reg Loss: 21.9231 Train Loss: 3.5042\n",
      "[Iter 7000 Total] Train Loss: 3.7649\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 7.5561\n",
      "{'mIoU': 0.0336, 'Pixel Acc': 0.1361, 'cmp': -0.8234}\n",
      "[Iter 7000 Task norm] Val Loss: 0.2129\n",
      "{'Angle Mean': 34.787, 'Angle Median': 34.3018, 'Angle 11.25': 2.3765, 'Angle 22.5': 32.4295, 'Angle 30': 44.6249, 'cmp': -0.8744}\n",
      "[Iter 7000 Task dept] Val Loss: 2.9818\n",
      "{'abs_err': 2.9753, 'rel_err': 1.1521, 'sigma_1.25': 53.7885, 'sigma_1.25^2': 61.8711, 'sigma_1.25^3': 69.117, 'cmp': -1.607}\n",
      "======================================================================\n",
      "tau: 1.4368981028202048\n",
      "[Iter 7050 Task segm] Task Loss: 1.2496 Reg Loss: 29.3515 Train Loss: 6.2776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7050 Task norm] Task Loss: 0.0625 Reg Loss: 27.3443 Train Loss: 1.2774\n",
      "[Iter 7050 Task dept] Task Loss: 0.6935 Reg Loss: 25.0163 Train Loss: 3.4925\n",
      "[Iter 7050 Total] Train Loss: 3.6825\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Task Loss: 1.2915 Reg Loss: 22.5520 Train Loss: 6.4802\n",
      "[Iter 7100 Task norm] Task Loss: 0.0643 Reg Loss: 22.5582 Train Loss: 1.3085\n",
      "[Iter 7100 Task dept] Task Loss: 0.6779 Reg Loss: 21.8237 Train Loss: 3.4115\n",
      "[Iter 7100 Total] Train Loss: 3.7334\n",
      "======================================================================\n",
      "[Iter 7150 Task segm] Task Loss: 1.3062 Reg Loss: 28.1617 Train Loss: 6.5592\n",
      "[Iter 7150 Task norm] Task Loss: 0.0630 Reg Loss: 29.1557 Train Loss: 1.2901\n",
      "[Iter 7150 Task dept] Task Loss: 0.6838 Reg Loss: 24.4399 Train Loss: 3.4435\n",
      "[Iter 7150 Total] Train Loss: 3.7643\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Task Loss: 1.2704 Reg Loss: 22.7238 Train Loss: 6.3748\n",
      "[Iter 7200 Task norm] Task Loss: 0.0624 Reg Loss: 22.4764 Train Loss: 1.2696\n",
      "[Iter 7200 Task dept] Task Loss: 0.6910 Reg Loss: 21.6013 Train Loss: 3.4767\n",
      "[Iter 7200 Total] Train Loss: 3.7070\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 6.0460\n",
      "{'mIoU': 0.0554, 'Pixel Acc': 0.2234, 'cmp': -0.7096}\n",
      "[Iter 7200 Task norm] Val Loss: 0.1752\n",
      "{'Angle Mean': 31.0818, 'Angle Median': 28.3898, 'Angle 11.25': 7.3324, 'Angle 22.5': 36.1677, 'Angle 30': 54.0114, 'cmp': -0.6883}\n",
      "[Iter 7200 Task dept] Val Loss: 7.0844\n",
      "{'abs_err': 7.1031, 'rel_err': 3.0389, 'sigma_1.25': 63.0755, 'sigma_1.25^2': 70.0906, 'sigma_1.25^3': 76.772, 'cmp': -4.3807}\n",
      "======================================================================\n",
      "tau: 1.3866066692214976\n",
      "[Iter 7250 Task segm] Task Loss: 1.3025 Reg Loss: 30.3917 Train Loss: 6.5428\n",
      "[Iter 7250 Task norm] Task Loss: 0.0619 Reg Loss: 28.0546 Train Loss: 1.2652\n",
      "[Iter 7250 Task dept] Task Loss: 0.6584 Reg Loss: 24.7514 Train Loss: 3.3168\n",
      "[Iter 7250 Total] Train Loss: 3.7083\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Task Loss: 1.3056 Reg Loss: 22.6842 Train Loss: 6.5508\n",
      "[Iter 7300 Task norm] Task Loss: 0.0651 Reg Loss: 22.5698 Train Loss: 1.3246\n",
      "[Iter 7300 Task dept] Task Loss: 0.6878 Reg Loss: 21.7783 Train Loss: 3.4607\n",
      "[Iter 7300 Total] Train Loss: 3.7787\n",
      "======================================================================\n",
      "[Iter 7350 Task segm] Task Loss: 1.2925 Reg Loss: 30.3718 Train Loss: 6.4928\n",
      "[Iter 7350 Task norm] Task Loss: 0.0630 Reg Loss: 27.9775 Train Loss: 1.2880\n",
      "[Iter 7350 Task dept] Task Loss: 0.6726 Reg Loss: 25.5519 Train Loss: 3.3883\n",
      "[Iter 7350 Total] Train Loss: 3.7231\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Task Loss: 1.3016 Reg Loss: 22.6067 Train Loss: 6.5305\n",
      "[Iter 7400 Task norm] Task Loss: 0.0645 Reg Loss: 22.2666 Train Loss: 1.3117\n",
      "[Iter 7400 Task dept] Task Loss: 0.6897 Reg Loss: 21.8043 Train Loss: 3.4705\n",
      "[Iter 7400 Total] Train Loss: 3.7709\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 4.5485\n",
      "{'mIoU': 0.0465, 'Pixel Acc': 0.2556, 'cmp': -0.6986}\n",
      "[Iter 7400 Task norm] Val Loss: 0.1979\n",
      "{'Angle Mean': 31.5425, 'Angle Median': 28.4502, 'Angle 11.25': 23.5393, 'Angle 22.5': 40.4821, 'Angle 30': 52.4028, 'cmp': -0.5935}\n",
      "[Iter 7400 Task dept] Val Loss: 2.1108\n",
      "{'abs_err': 2.1033, 'rel_err': 0.8279, 'sigma_1.25': 37.9681, 'sigma_1.25^2': 52.4587, 'sigma_1.25^3': 64.3786, 'cmp': -1.1528}\n",
      "======================================================================\n",
      "tau: 1.338075435798745\n",
      "[Iter 7450 Task segm] Task Loss: 1.2743 Reg Loss: 31.9883 Train Loss: 6.4033\n",
      "[Iter 7450 Task norm] Task Loss: 0.0633 Reg Loss: 28.5600 Train Loss: 1.2943\n",
      "[Iter 7450 Task dept] Task Loss: 0.7054 Reg Loss: 27.4195 Train Loss: 3.5543\n",
      "[Iter 7450 Total] Train Loss: 3.7506\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Task Loss: 1.2923 Reg Loss: 22.6981 Train Loss: 6.4844\n",
      "[Iter 7500 Task norm] Task Loss: 0.0623 Reg Loss: 22.0664 Train Loss: 1.2679\n",
      "[Iter 7500 Task dept] Task Loss: 0.6961 Reg Loss: 21.8573 Train Loss: 3.5025\n",
      "[Iter 7500 Total] Train Loss: 3.7516\n",
      "======================================================================\n",
      "[Iter 7550 Task segm] Task Loss: 1.2861 Reg Loss: 29.6151 Train Loss: 6.4602\n",
      "[Iter 7550 Task norm] Task Loss: 0.0616 Reg Loss: 25.9152 Train Loss: 1.2587\n",
      "[Iter 7550 Task dept] Task Loss: 0.6721 Reg Loss: 27.0090 Train Loss: 3.3875\n",
      "[Iter 7550 Total] Train Loss: 3.7021\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Task Loss: 1.2917 Reg Loss: 22.6243 Train Loss: 6.4812\n",
      "[Iter 7600 Task norm] Task Loss: 0.0629 Reg Loss: 22.2069 Train Loss: 1.2793\n",
      "[Iter 7600 Task dept] Task Loss: 0.6750 Reg Loss: 21.9118 Train Loss: 3.3972\n",
      "[Iter 7600 Total] Train Loss: 3.7192\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 5.7964\n",
      "{'mIoU': 0.0301, 'Pixel Acc': 0.2302, 'cmp': -0.7499}\n",
      "[Iter 7600 Task norm] Val Loss: 0.1950\n",
      "{'Angle Mean': 32.8905, 'Angle Median': 34.1634, 'Angle 11.25': 12.3649, 'Angle 22.5': 28.6659, 'Angle 30': 41.1276, 'cmp': -0.812}\n",
      "[Iter 7600 Task dept] Val Loss: 1.6773\n",
      "{'abs_err': 1.6729, 'rel_err': 0.6549, 'sigma_1.25': 34.0671, 'sigma_1.25^2': 53.2563, 'sigma_1.25^3': 67.8978, 'cmp': -0.8798}\n",
      "======================================================================\n",
      "tau: 1.2912427955457888\n",
      "[Iter 7650 Task segm] Task Loss: 1.2838 Reg Loss: 29.1754 Train Loss: 6.4481\n",
      "[Iter 7650 Task norm] Task Loss: 0.0630 Reg Loss: 27.7204 Train Loss: 1.2878\n",
      "[Iter 7650 Task dept] Task Loss: 0.6824 Reg Loss: 26.0745 Train Loss: 3.4382\n",
      "[Iter 7650 Total] Train Loss: 3.7247\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Task Loss: 1.3099 Reg Loss: 22.5141 Train Loss: 6.5721\n",
      "[Iter 7700 Task norm] Task Loss: 0.0630 Reg Loss: 22.3290 Train Loss: 1.2823\n",
      "[Iter 7700 Task dept] Task Loss: 0.6903 Reg Loss: 21.8479 Train Loss: 3.4731\n",
      "[Iter 7700 Total] Train Loss: 3.7758\n",
      "======================================================================\n",
      "[Iter 7750 Task segm] Task Loss: 1.2852 Reg Loss: 29.5784 Train Loss: 6.4556\n",
      "[Iter 7750 Task norm] Task Loss: 0.0619 Reg Loss: 28.9324 Train Loss: 1.2666\n",
      "[Iter 7750 Task dept] Task Loss: 0.7104 Reg Loss: 26.4896 Train Loss: 3.5785\n",
      "[Iter 7750 Total] Train Loss: 3.7669\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Task Loss: 1.3020 Reg Loss: 22.3058 Train Loss: 6.5323\n",
      "[Iter 7800 Task norm] Task Loss: 0.0629 Reg Loss: 22.2848 Train Loss: 1.2803\n",
      "[Iter 7800 Task dept] Task Loss: 0.6847 Reg Loss: 21.6911 Train Loss: 3.4450\n",
      "[Iter 7800 Total] Train Loss: 3.7525\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 7.0286\n",
      "{'mIoU': 0.0401, 'Pixel Acc': 0.2139, 'cmp': -0.7456}\n",
      "[Iter 7800 Task norm] Val Loss: 0.2142\n",
      "{'Angle Mean': 35.0029, 'Angle Median': 33.8271, 'Angle 11.25': 0.9984, 'Angle 22.5': 31.7359, 'Angle 30': 44.7802, 'cmp': -0.8797}\n",
      "[Iter 7800 Task dept] Val Loss: 1.9259\n",
      "{'abs_err': 1.9345, 'rel_err': 0.8391, 'sigma_1.25': 27.0926, 'sigma_1.25^2': 47.0903, 'sigma_1.25^3': 64.4569, 'cmp': -1.1573}\n",
      "======================================================================\n",
      "tau: 1.2460492977016862\n",
      "[Iter 7850 Task segm] Task Loss: 1.2931 Reg Loss: 29.0245 Train Loss: 6.4945\n",
      "[Iter 7850 Task norm] Task Loss: 0.0633 Reg Loss: 28.1950 Train Loss: 1.2933\n",
      "[Iter 7850 Task dept] Task Loss: 0.6851 Reg Loss: 26.2334 Train Loss: 3.4515\n",
      "[Iter 7850 Total] Train Loss: 3.7465\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Task Loss: 1.3033 Reg Loss: 21.7988 Train Loss: 6.5384\n",
      "[Iter 7900 Task norm] Task Loss: 0.0639 Reg Loss: 22.5702 Train Loss: 1.3010\n",
      "[Iter 7900 Task dept] Task Loss: 0.6756 Reg Loss: 21.7706 Train Loss: 3.3996\n",
      "[Iter 7900 Total] Train Loss: 3.7463\n",
      "======================================================================\n",
      "[Iter 7950 Task segm] Task Loss: 1.2841 Reg Loss: 29.0493 Train Loss: 6.4493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7950 Task norm] Task Loss: 0.0632 Reg Loss: 27.7785 Train Loss: 1.2916\n",
      "[Iter 7950 Task dept] Task Loss: 0.6687 Reg Loss: 26.4310 Train Loss: 3.3700\n",
      "[Iter 7950 Total] Train Loss: 3.7036\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Task Loss: 1.3088 Reg Loss: 22.3748 Train Loss: 6.5665\n",
      "[Iter 8000 Task norm] Task Loss: 0.0637 Reg Loss: 22.2337 Train Loss: 1.2959\n",
      "[Iter 8000 Task dept] Task Loss: 0.6947 Reg Loss: 21.6399 Train Loss: 3.4950\n",
      "[Iter 8000 Total] Train Loss: 3.7858\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 4.1518\n",
      "{'mIoU': 0.0574, 'Pixel Acc': 0.2607, 'cmp': -0.6744}\n",
      "[Iter 8000 Task norm] Val Loss: 0.2206\n",
      "{'Angle Mean': 35.6842, 'Angle Median': 35.6368, 'Angle 11.25': 1.5066, 'Angle 22.5': 30.2742, 'Angle 30': 42.7407, 'cmp': -0.9188}\n",
      "[Iter 8000 Task dept] Val Loss: 1.4905\n",
      "{'abs_err': 1.491, 'rel_err': 0.6611, 'sigma_1.25': 27.3456, 'sigma_1.25^2': 50.8222, 'sigma_1.25^3': 69.4664, 'cmp': -0.8518}\n",
      "======================================================================\n",
      "tau: 1.202437572282127\n",
      "[Iter 8050 Task segm] Task Loss: 1.2927 Reg Loss: 29.0076 Train Loss: 6.4923\n",
      "[Iter 8050 Task norm] Task Loss: 0.0637 Reg Loss: 29.6730 Train Loss: 1.3029\n",
      "[Iter 8050 Task dept] Task Loss: 0.6994 Reg Loss: 26.5753 Train Loss: 3.5233\n",
      "[Iter 8050 Total] Train Loss: 3.7728\n",
      "======================================================================\n",
      "[Iter 8100 Task segm] Task Loss: 1.3189 Reg Loss: 22.1481 Train Loss: 6.6165\n",
      "[Iter 8100 Task norm] Task Loss: 0.0631 Reg Loss: 22.3511 Train Loss: 1.2849\n",
      "[Iter 8100 Task dept] Task Loss: 0.6891 Reg Loss: 21.6798 Train Loss: 3.4673\n",
      "[Iter 8100 Total] Train Loss: 3.7896\n",
      "======================================================================\n",
      "[Iter 8150 Task segm] Task Loss: 1.3215 Reg Loss: 29.8046 Train Loss: 6.6374\n",
      "[Iter 8150 Task norm] Task Loss: 0.0636 Reg Loss: 28.5809 Train Loss: 1.3006\n",
      "[Iter 8150 Task dept] Task Loss: 0.6947 Reg Loss: 26.5253 Train Loss: 3.5000\n",
      "[Iter 8150 Total] Train Loss: 3.8127\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Task Loss: 1.2796 Reg Loss: 22.1154 Train Loss: 6.4200\n",
      "[Iter 8200 Task norm] Task Loss: 0.0636 Reg Loss: 22.0678 Train Loss: 1.2933\n",
      "[Iter 8200 Task dept] Task Loss: 0.6697 Reg Loss: 21.3219 Train Loss: 3.3700\n",
      "[Iter 8200 Total] Train Loss: 3.6944\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 2.7679\n",
      "{'mIoU': 0.0793, 'Pixel Acc': 0.3553, 'cmp': -0.5542}\n",
      "[Iter 8200 Task norm] Val Loss: 0.3655\n",
      "{'Angle Mean': 47.5833, 'Angle Median': 47.3078, 'Angle 11.25': 4.5254, 'Angle 22.5': 15.901, 'Angle 30': 25.0328, 'cmp': -1.2824}\n",
      "[Iter 8200 Task dept] Val Loss: 2.1969\n",
      "{'abs_err': 2.2101, 'rel_err': 1.0733, 'sigma_1.25': 21.0417, 'sigma_1.25^2': 41.3045, 'sigma_1.25^3': 59.3807, 'cmp': -1.4785}\n",
      "======================================================================\n",
      "tau: 1.1603522572522524\n",
      "[Iter 8250 Task segm] Task Loss: 1.2970 Reg Loss: 28.4645 Train Loss: 6.5132\n",
      "[Iter 8250 Task norm] Task Loss: 0.0634 Reg Loss: 28.9902 Train Loss: 1.2964\n",
      "[Iter 8250 Task dept] Task Loss: 0.6926 Reg Loss: 26.1895 Train Loss: 3.4892\n",
      "[Iter 8250 Total] Train Loss: 3.7663\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Task Loss: 1.3135 Reg Loss: 22.3334 Train Loss: 6.5899\n",
      "[Iter 8300 Task norm] Task Loss: 0.0639 Reg Loss: 21.6747 Train Loss: 1.3001\n",
      "[Iter 8300 Task dept] Task Loss: 0.6818 Reg Loss: 21.7046 Train Loss: 3.4309\n",
      "[Iter 8300 Total] Train Loss: 3.7737\n",
      "======================================================================\n",
      "[Iter 8350 Task segm] Task Loss: 1.2724 Reg Loss: 30.1793 Train Loss: 6.3922\n",
      "[Iter 8350 Task norm] Task Loss: 0.0632 Reg Loss: 27.7513 Train Loss: 1.2912\n",
      "[Iter 8350 Task dept] Task Loss: 0.6831 Reg Loss: 24.3609 Train Loss: 3.4399\n",
      "[Iter 8350 Total] Train Loss: 3.7077\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Task Loss: 1.2797 Reg Loss: 22.1592 Train Loss: 6.4205\n",
      "[Iter 8400 Task norm] Task Loss: 0.0634 Reg Loss: 21.8323 Train Loss: 1.2901\n",
      "[Iter 8400 Task dept] Task Loss: 0.6656 Reg Loss: 20.7043 Train Loss: 3.3488\n",
      "[Iter 8400 Total] Train Loss: 3.6865\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 3.5601\n",
      "{'mIoU': 0.0523, 'Pixel Acc': 0.2484, 'cmp': -0.6941}\n",
      "[Iter 8400 Task norm] Val Loss: 0.2367\n",
      "{'Angle Mean': 36.3638, 'Angle Median': 30.9775, 'Angle 11.25': 6.1463, 'Angle 22.5': 31.821, 'Angle 30': 48.2955, 'cmp': -0.8171}\n",
      "[Iter 8400 Task dept] Val Loss: 1.1267\n",
      "{'abs_err': 1.1184, 'rel_err': 0.4097, 'sigma_1.25': 31.8168, 'sigma_1.25^2': 57.8831, 'sigma_1.25^3': 75.7691, 'cmp': -0.4854}\n",
      "======================================================================\n",
      "tau: 1.1197399282484235\n",
      "[Iter 8450 Task segm] Task Loss: 1.2611 Reg Loss: 31.1999 Train Loss: 6.3367\n",
      "[Iter 8450 Task norm] Task Loss: 0.0613 Reg Loss: 28.1875 Train Loss: 1.2541\n",
      "[Iter 8450 Task dept] Task Loss: 0.7077 Reg Loss: 25.9119 Train Loss: 3.5643\n",
      "[Iter 8450 Total] Train Loss: 3.7184\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Task Loss: 1.2761 Reg Loss: 22.4543 Train Loss: 6.4030\n",
      "[Iter 8500 Task norm] Task Loss: 0.0635 Reg Loss: 21.9837 Train Loss: 1.2917\n",
      "[Iter 8500 Task dept] Task Loss: 0.6959 Reg Loss: 21.6298 Train Loss: 3.5011\n",
      "[Iter 8500 Total] Train Loss: 3.7319\n",
      "======================================================================\n",
      "[Iter 8550 Task segm] Task Loss: 1.2845 Reg Loss: 31.9225 Train Loss: 6.4544\n",
      "[Iter 8550 Task norm] Task Loss: 0.0642 Reg Loss: 26.2890 Train Loss: 1.3097\n",
      "[Iter 8550 Task dept] Task Loss: 0.6686 Reg Loss: 25.0050 Train Loss: 3.3679\n",
      "[Iter 8550 Total] Train Loss: 3.7107\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Task Loss: 1.2684 Reg Loss: 22.2380 Train Loss: 6.3641\n",
      "[Iter 8600 Task norm] Task Loss: 0.0627 Reg Loss: 21.6370 Train Loss: 1.2765\n",
      "[Iter 8600 Task dept] Task Loss: 0.6842 Reg Loss: 21.3014 Train Loss: 3.4421\n",
      "[Iter 8600 Total] Train Loss: 3.6942\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 6.1897\n",
      "{'mIoU': 0.0331, 'Pixel Acc': 0.2166, 'cmp': -0.7559}\n",
      "[Iter 8600 Task norm] Val Loss: 0.1983\n",
      "{'Angle Mean': 33.5204, 'Angle Median': 31.3856, 'Angle 11.25': 5.5892, 'Angle 22.5': 30.8612, 'Angle 30': 46.836, 'cmp': -0.7996}\n",
      "[Iter 8600 Task dept] Val Loss: 1.4843\n",
      "{'abs_err': 1.4747, 'rel_err': 0.552, 'sigma_1.25': 34.1784, 'sigma_1.25^2': 54.9307, 'sigma_1.25^3': 69.8478, 'cmp': -0.7252}\n",
      "======================================================================\n",
      "tau: 1.0805490307597287\n",
      "[Iter 8650 Task segm] Task Loss: 1.3100 Reg Loss: 31.1902 Train Loss: 6.5810\n",
      "[Iter 8650 Task norm] Task Loss: 0.0629 Reg Loss: 28.5529 Train Loss: 1.2867\n",
      "[Iter 8650 Task dept] Task Loss: 0.6926 Reg Loss: 28.1725 Train Loss: 3.4912\n",
      "[Iter 8650 Total] Train Loss: 3.7863\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Task Loss: 1.2457 Reg Loss: 22.3092 Train Loss: 6.2506\n",
      "[Iter 8700 Task norm] Task Loss: 0.0625 Reg Loss: 21.6655 Train Loss: 1.2711\n",
      "[Iter 8700 Task dept] Task Loss: 0.7002 Reg Loss: 20.9304 Train Loss: 3.5220\n",
      "[Iter 8700 Total] Train Loss: 3.6812\n",
      "======================================================================\n",
      "[Iter 8750 Task segm] Task Loss: 1.2654 Reg Loss: 30.0803 Train Loss: 6.3569\n",
      "[Iter 8750 Task norm] Task Loss: 0.0632 Reg Loss: 30.0284 Train Loss: 1.2947\n",
      "[Iter 8750 Task dept] Task Loss: 0.6670 Reg Loss: 27.5560 Train Loss: 3.3627\n",
      "[Iter 8750 Total] Train Loss: 3.6714\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Task Loss: 1.2657 Reg Loss: 22.2989 Train Loss: 6.3510\n",
      "[Iter 8800 Task norm] Task Loss: 0.0626 Reg Loss: 21.9840 Train Loss: 1.2740\n",
      "[Iter 8800 Task dept] Task Loss: 0.6799 Reg Loss: 21.3146 Train Loss: 3.4207\n",
      "[Iter 8800 Total] Train Loss: 3.6819\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 3.7790\n",
      "{'mIoU': 0.0572, 'Pixel Acc': 0.2845, 'cmp': -0.6544}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8800 Task norm] Val Loss: 0.2035\n",
      "{'Angle Mean': 32.8477, 'Angle Median': 27.7315, 'Angle 11.25': 9.6169, 'Angle 22.5': 35.804, 'Angle 30': 55.0326, 'cmp': -0.6848}\n",
      "[Iter 8800 Task dept] Val Loss: 1.2552\n",
      "{'abs_err': 1.2569, 'rel_err': 0.554, 'sigma_1.25': 31.4462, 'sigma_1.25^2': 57.2488, 'sigma_1.25^3': 75.3419, 'cmp': -0.6491}\n",
      "======================================================================\n",
      "tau: 1.0427298146831383\n",
      "[Iter 8850 Task segm] Task Loss: 1.2654 Reg Loss: 30.5561 Train Loss: 6.3578\n",
      "[Iter 8850 Task norm] Task Loss: 0.0651 Reg Loss: 29.4615 Train Loss: 1.3323\n",
      "[Iter 8850 Task dept] Task Loss: 0.6919 Reg Loss: 26.4275 Train Loss: 3.4861\n",
      "[Iter 8850 Total] Train Loss: 3.7254\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Task Loss: 1.3005 Reg Loss: 21.6972 Train Loss: 6.5243\n",
      "[Iter 8900 Task norm] Task Loss: 0.0615 Reg Loss: 22.1493 Train Loss: 1.2523\n",
      "[Iter 8900 Task dept] Task Loss: 0.6880 Reg Loss: 21.1374 Train Loss: 3.4611\n",
      "[Iter 8900 Total] Train Loss: 3.7459\n",
      "======================================================================\n",
      "[Iter 8950 Task segm] Task Loss: 1.2804 Reg Loss: 30.5702 Train Loss: 6.4324\n",
      "[Iter 8950 Task norm] Task Loss: 0.0642 Reg Loss: 29.4664 Train Loss: 1.3137\n",
      "[Iter 8950 Task dept] Task Loss: 0.6858 Reg Loss: 26.3960 Train Loss: 3.4556\n",
      "[Iter 8950 Total] Train Loss: 3.7339\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Task Loss: 1.2821 Reg Loss: 21.9988 Train Loss: 6.4325\n",
      "[Iter 9000 Task norm] Task Loss: 0.0623 Reg Loss: 21.9103 Train Loss: 1.2673\n",
      "[Iter 9000 Task dept] Task Loss: 0.6854 Reg Loss: 20.9960 Train Loss: 3.4480\n",
      "[Iter 9000 Total] Train Loss: 3.7159\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 3.9282\n",
      "{'mIoU': 0.0556, 'Pixel Acc': 0.2676, 'cmp': -0.6718}\n",
      "[Iter 9000 Task norm] Val Loss: 0.2083\n",
      "{'Angle Mean': 34.4411, 'Angle Median': 32.7058, 'Angle 11.25': 4.7516, 'Angle 22.5': 30.1791, 'Angle 30': 44.7645, 'cmp': -0.8402}\n",
      "[Iter 9000 Task dept] Val Loss: 4.9565\n",
      "{'abs_err': 4.9766, 'rel_err': 2.387, 'sigma_1.25': 6.2576, 'sigma_1.25^2': 14.2082, 'sigma_1.25^3': 25.397, 'cmp': -3.6071}\n",
      "======================================================================\n",
      "tau: 1.0062342711692285\n",
      "[Iter 9050 Task segm] Task Loss: 1.2764 Reg Loss: 30.2035 Train Loss: 6.4122\n",
      "[Iter 9050 Task norm] Task Loss: 0.0622 Reg Loss: 30.1948 Train Loss: 1.2732\n",
      "[Iter 9050 Task dept] Task Loss: 0.7062 Reg Loss: 27.7756 Train Loss: 3.5589\n",
      "[Iter 9050 Total] Train Loss: 3.7481\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Task Loss: 1.2934 Reg Loss: 21.7141 Train Loss: 6.4887\n",
      "[Iter 9100 Task norm] Task Loss: 0.0636 Reg Loss: 22.1329 Train Loss: 1.2936\n",
      "[Iter 9100 Task dept] Task Loss: 0.6811 Reg Loss: 20.5886 Train Loss: 3.4260\n",
      "[Iter 9100 Total] Train Loss: 3.7361\n",
      "======================================================================\n",
      "[Iter 9150 Task segm] Task Loss: 1.3188 Reg Loss: 29.7167 Train Loss: 6.6237\n",
      "[Iter 9150 Task norm] Task Loss: 0.0617 Reg Loss: 29.6890 Train Loss: 1.2638\n",
      "[Iter 9150 Task dept] Task Loss: 0.6950 Reg Loss: 27.4701 Train Loss: 3.5023\n",
      "[Iter 9150 Total] Train Loss: 3.7966\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Task Loss: 1.2984 Reg Loss: 21.7498 Train Loss: 6.5137\n",
      "[Iter 9200 Task norm] Task Loss: 0.0633 Reg Loss: 21.5505 Train Loss: 1.2884\n",
      "[Iter 9200 Task dept] Task Loss: 0.6955 Reg Loss: 20.8977 Train Loss: 3.4984\n",
      "[Iter 9200 Total] Train Loss: 3.7668\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 3.7648\n",
      "{'mIoU': 0.05, 'Pixel Acc': 0.2771, 'cmp': -0.6738}\n",
      "[Iter 9200 Task norm] Val Loss: 0.1850\n",
      "{'Angle Mean': 32.0571, 'Angle Median': 29.2638, 'Angle 11.25': 6.0419, 'Angle 22.5': 36.2088, 'Angle 30': 51.3903, 'cmp': -0.7252}\n",
      "[Iter 9200 Task dept] Val Loss: 1.7274\n",
      "{'abs_err': 1.7161, 'rel_err': 0.594, 'sigma_1.25': 23.7373, 'sigma_1.25^2': 38.2071, 'sigma_1.25^3': 52.2092, 'cmp': -0.9487}\n",
      "======================================================================\n",
      "tau: 0.9710160716783055\n",
      "[Iter 9250 Task segm] Task Loss: 1.2937 Reg Loss: 32.2694 Train Loss: 6.5008\n",
      "[Iter 9250 Task norm] Task Loss: 0.0632 Reg Loss: 29.6996 Train Loss: 1.2931\n",
      "[Iter 9250 Task dept] Task Loss: 0.6611 Reg Loss: 26.6194 Train Loss: 3.3319\n",
      "[Iter 9250 Total] Train Loss: 3.7086\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Task Loss: 1.2989 Reg Loss: 21.3633 Train Loss: 6.5160\n",
      "[Iter 9300 Task norm] Task Loss: 0.0646 Reg Loss: 21.3576 Train Loss: 1.3130\n",
      "[Iter 9300 Task dept] Task Loss: 0.6817 Reg Loss: 21.2537 Train Loss: 3.4297\n",
      "[Iter 9300 Total] Train Loss: 3.7529\n",
      "======================================================================\n",
      "[Iter 9350 Task segm] Task Loss: 1.2673 Reg Loss: 30.4580 Train Loss: 6.3668\n",
      "[Iter 9350 Task norm] Task Loss: 0.0618 Reg Loss: 31.0729 Train Loss: 1.2672\n",
      "[Iter 9350 Task dept] Task Loss: 0.6894 Reg Loss: 26.5335 Train Loss: 3.4737\n",
      "[Iter 9350 Total] Train Loss: 3.7026\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Task Loss: 1.2727 Reg Loss: 22.0558 Train Loss: 6.3857\n",
      "[Iter 9400 Task norm] Task Loss: 0.0628 Reg Loss: 21.3664 Train Loss: 1.2783\n",
      "[Iter 9400 Task dept] Task Loss: 0.6955 Reg Loss: 21.0049 Train Loss: 3.4984\n",
      "[Iter 9400 Total] Train Loss: 3.7208\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 3.6552\n",
      "{'mIoU': 0.0543, 'Pixel Acc': 0.3121, 'cmp': -0.6363}\n",
      "[Iter 9400 Task norm] Val Loss: 0.1319\n",
      "{'Angle Mean': 25.04, 'Angle Median': 23.792, 'Angle 11.25': 30.4129, 'Angle 22.5': 47.9165, 'Angle 30': 61.1316, 'cmp': -0.3736}\n",
      "[Iter 9400 Task dept] Val Loss: 1.0183\n",
      "{'abs_err': 1.0152, 'rel_err': 0.4408, 'sigma_1.25': 37.46, 'sigma_1.25^2': 66.3328, 'sigma_1.25^3': 84.1597, 'cmp': -0.4202}\n",
      "======================================================================\n",
      "tau: 0.9370305091695648\n",
      "[Iter 9450 Task segm] Task Loss: 1.2827 Reg Loss: 32.3637 Train Loss: 6.4458\n",
      "[Iter 9450 Task norm] Task Loss: 0.0652 Reg Loss: 28.4438 Train Loss: 1.3326\n",
      "[Iter 9450 Task dept] Task Loss: 0.6672 Reg Loss: 26.5809 Train Loss: 3.3627\n",
      "[Iter 9450 Total] Train Loss: 3.7137\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Task Loss: 1.2792 Reg Loss: 22.1090 Train Loss: 6.4183\n",
      "[Iter 9500 Task norm] Task Loss: 0.0633 Reg Loss: 21.2950 Train Loss: 1.2866\n",
      "[Iter 9500 Task dept] Task Loss: 0.6812 Reg Loss: 20.3514 Train Loss: 3.4262\n",
      "[Iter 9500 Total] Train Loss: 3.7104\n",
      "======================================================================\n",
      "[Iter 9550 Task segm] Task Loss: 1.2810 Reg Loss: 31.2162 Train Loss: 6.4362\n",
      "[Iter 9550 Task norm] Task Loss: 0.0638 Reg Loss: 29.6964 Train Loss: 1.3048\n",
      "[Iter 9550 Task dept] Task Loss: 0.6918 Reg Loss: 25.4444 Train Loss: 3.4843\n",
      "[Iter 9550 Total] Train Loss: 3.7418\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Task Loss: 1.2598 Reg Loss: 21.9248 Train Loss: 6.3208\n",
      "[Iter 9600 Task norm] Task Loss: 0.0633 Reg Loss: 21.3793 Train Loss: 1.2881\n",
      "[Iter 9600 Task dept] Task Loss: 0.7115 Reg Loss: 19.9832 Train Loss: 3.5773\n",
      "[Iter 9600 Total] Train Loss: 3.7287\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 2.3158\n",
      "{'mIoU': 0.1115, 'Pixel Acc': 0.4126, 'cmp': -0.4471}\n",
      "[Iter 9600 Task norm] Val Loss: 0.1894\n",
      "{'Angle Mean': 32.1755, 'Angle Median': 27.7468, 'Angle 11.25': 8.3686, 'Angle 22.5': 36.2054, 'Angle 30': 55.2836, 'cmp': -0.6828}\n",
      "[Iter 9600 Task dept] Val Loss: 0.9409\n",
      "{'abs_err': 0.9304, 'rel_err': 0.3557, 'sigma_1.25': 39.1363, 'sigma_1.25^2': 67.4747, 'sigma_1.25^3': 84.1704, 'cmp': -0.3163}\n",
      "======================================================================\n",
      "tau: 0.90423444134863\n",
      "[Iter 9650 Task segm] Task Loss: 1.2899 Reg Loss: 31.3202 Train Loss: 6.4807\n",
      "[Iter 9650 Task norm] Task Loss: 0.0622 Reg Loss: 29.8761 Train Loss: 1.2738\n",
      "[Iter 9650 Task dept] Task Loss: 0.6671 Reg Loss: 23.3903 Train Loss: 3.3586\n",
      "[Iter 9650 Total] Train Loss: 3.7044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 9700 Task segm] Task Loss: 1.3082 Reg Loss: 21.7357 Train Loss: 6.5629\n",
      "[Iter 9700 Task norm] Task Loss: 0.0643 Reg Loss: 21.7342 Train Loss: 1.3087\n",
      "[Iter 9700 Task dept] Task Loss: 0.6588 Reg Loss: 20.1037 Train Loss: 3.3140\n",
      "[Iter 9700 Total] Train Loss: 3.7285\n",
      "======================================================================\n",
      "[Iter 9750 Task segm] Task Loss: 1.2607 Reg Loss: 33.7998 Train Loss: 6.3371\n",
      "[Iter 9750 Task norm] Task Loss: 0.0622 Reg Loss: 29.8447 Train Loss: 1.2731\n",
      "[Iter 9750 Task dept] Task Loss: 0.6823 Reg Loss: 24.9233 Train Loss: 3.4364\n",
      "[Iter 9750 Total] Train Loss: 3.6822\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Task Loss: 1.2910 Reg Loss: 21.9412 Train Loss: 6.4768\n",
      "[Iter 9800 Task norm] Task Loss: 0.0633 Reg Loss: 21.3086 Train Loss: 1.2879\n",
      "[Iter 9800 Task dept] Task Loss: 0.6887 Reg Loss: 20.0754 Train Loss: 3.4636\n",
      "[Iter 9800 Total] Train Loss: 3.7428\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 2.5976\n",
      "{'mIoU': 0.0892, 'Pixel Acc': 0.3636, 'cmp': -0.5291}\n",
      "[Iter 9800 Task norm] Val Loss: 0.1067\n",
      "{'Angle Mean': 22.7414, 'Angle Median': 19.4299, 'Angle 11.25': 25.9689, 'Angle 22.5': 57.8545, 'Angle 30': 74.0956, 'cmp': -0.254}\n",
      "[Iter 9800 Task dept] Val Loss: 1.1331\n",
      "{'abs_err': 1.1202, 'rel_err': 0.4044, 'sigma_1.25': 29.5953, 'sigma_1.25^2': 54.7613, 'sigma_1.25^3': 73.3632, 'cmp': -0.5016}\n",
      "======================================================================\n",
      "tau: 0.8725862359014279\n",
      "[Iter 9850 Task segm] Task Loss: 1.2464 Reg Loss: 33.5092 Train Loss: 6.2655\n",
      "[Iter 9850 Task norm] Task Loss: 0.0641 Reg Loss: 30.9783 Train Loss: 1.3124\n",
      "[Iter 9850 Task dept] Task Loss: 0.7033 Reg Loss: 24.9171 Train Loss: 3.5415\n",
      "[Iter 9850 Total] Train Loss: 3.7065\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Task Loss: 1.2644 Reg Loss: 21.9645 Train Loss: 6.3437\n",
      "[Iter 9900 Task norm] Task Loss: 0.0636 Reg Loss: 21.0631 Train Loss: 1.2924\n",
      "[Iter 9900 Task dept] Task Loss: 0.6764 Reg Loss: 20.3920 Train Loss: 3.4025\n",
      "[Iter 9900 Total] Train Loss: 3.6795\n",
      "======================================================================\n",
      "[Iter 9950 Task segm] Task Loss: 1.2813 Reg Loss: 34.4359 Train Loss: 6.4410\n",
      "[Iter 9950 Task norm] Task Loss: 0.0642 Reg Loss: 28.7147 Train Loss: 1.3119\n",
      "[Iter 9950 Task dept] Task Loss: 0.6742 Reg Loss: 25.1314 Train Loss: 3.3963\n",
      "[Iter 9950 Total] Train Loss: 3.7164\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Task Loss: 1.2880 Reg Loss: 21.9165 Train Loss: 6.4618\n",
      "[Iter 10000 Task norm] Task Loss: 0.0636 Reg Loss: 21.6927 Train Loss: 1.2942\n",
      "[Iter 10000 Task dept] Task Loss: 0.6848 Reg Loss: 19.9640 Train Loss: 3.4441\n",
      "[Iter 10000 Total] Train Loss: 3.7334\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 2.4814\n",
      "{'mIoU': 0.1132, 'Pixel Acc': 0.399, 'cmp': -0.4554}\n",
      "[Iter 10000 Task norm] Val Loss: 0.1964\n",
      "{'Angle Mean': 33.2537, 'Angle Median': 32.2244, 'Angle 11.25': 4.4211, 'Angle 22.5': 34.3743, 'Angle 30': 46.9508, 'cmp': -0.8052}\n",
      "[Iter 10000 Task dept] Val Loss: 1.0973\n",
      "{'abs_err': 1.0854, 'rel_err': 0.3826, 'sigma_1.25': 29.6867, 'sigma_1.25^2': 55.5908, 'sigma_1.25^3': 74.4273, 'cmp': -0.4686}\n",
      "======================================================================\n",
      "lr changed\n",
      "tau: 0.8420457176448779\n",
      "[Iter 10050 Task segm] Task Loss: 1.2789 Reg Loss: 30.6951 Train Loss: 6.4253\n",
      "[Iter 10050 Task norm] Task Loss: 0.0631 Reg Loss: 31.0439 Train Loss: 1.2928\n",
      "[Iter 10050 Task dept] Task Loss: 0.7097 Reg Loss: 25.0435 Train Loss: 3.5737\n",
      "[Iter 10050 Total] Train Loss: 3.7639\n",
      "======================================================================\n",
      "[Iter 10100 Task segm] Task Loss: 1.2912 Reg Loss: 21.9743 Train Loss: 6.4782\n",
      "[Iter 10100 Task norm] Task Loss: 0.0618 Reg Loss: 21.6192 Train Loss: 1.2576\n",
      "[Iter 10100 Task dept] Task Loss: 0.6750 Reg Loss: 20.1435 Train Loss: 3.3952\n",
      "[Iter 10100 Total] Train Loss: 3.7103\n",
      "======================================================================\n",
      "[Iter 10150 Task segm] Task Loss: 1.2806 Reg Loss: 33.8575 Train Loss: 6.4369\n",
      "[Iter 10150 Task norm] Task Loss: 0.0631 Reg Loss: 29.9446 Train Loss: 1.2927\n",
      "[Iter 10150 Task dept] Task Loss: 0.6887 Reg Loss: 26.4879 Train Loss: 3.4698\n",
      "[Iter 10150 Total] Train Loss: 3.7331\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Task Loss: 1.3004 Reg Loss: 21.9232 Train Loss: 6.5239\n",
      "[Iter 10200 Task norm] Task Loss: 0.0625 Reg Loss: 21.6882 Train Loss: 1.2711\n",
      "[Iter 10200 Task dept] Task Loss: 0.6702 Reg Loss: 20.0834 Train Loss: 3.3712\n",
      "[Iter 10200 Total] Train Loss: 3.7221\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Val Loss: 2.1982\n",
      "{'mIoU': 0.1372, 'Pixel Acc': 0.4342, 'cmp': -0.382}\n",
      "[Iter 10200 Task norm] Val Loss: 0.2002\n",
      "{'Angle Mean': 33.6116, 'Angle Median': 32.5862, 'Angle 11.25': 3.5952, 'Angle 22.5': 33.8611, 'Angle 30': 46.4737, 'cmp': -0.8216}\n",
      "[Iter 10200 Task dept] Val Loss: 1.0059\n",
      "{'abs_err': 0.9952, 'rel_err': 0.3526, 'sigma_1.25': 34.9629, 'sigma_1.25^2': 62.0639, 'sigma_1.25^3': 80.432, 'cmp': -0.3695}\n",
      "======================================================================\n",
      "[Iter 10250 Task segm] Task Loss: 1.2498 Reg Loss: 34.7017 Train Loss: 6.2839\n",
      "[Iter 10250 Task norm] Task Loss: 0.0644 Reg Loss: 32.3076 Train Loss: 1.3195\n",
      "[Iter 10250 Task dept] Task Loss: 0.7003 Reg Loss: 25.9937 Train Loss: 3.5274\n",
      "[Iter 10250 Total] Train Loss: 3.7102\n",
      "======================================================================\n",
      "[Iter 10300 Task segm] Task Loss: 1.2763 Reg Loss: 21.6714 Train Loss: 6.4030\n",
      "[Iter 10300 Task norm] Task Loss: 0.0622 Reg Loss: 21.5410 Train Loss: 1.2657\n",
      "[Iter 10300 Task dept] Task Loss: 0.6832 Reg Loss: 19.8199 Train Loss: 3.4358\n",
      "[Iter 10300 Total] Train Loss: 3.7015\n",
      "======================================================================\n",
      "tau: 0.8125741175273071\n",
      "[Iter 10350 Task segm] Task Loss: 1.3120 Reg Loss: 35.0547 Train Loss: 6.5949\n",
      "[Iter 10350 Task norm] Task Loss: 0.0633 Reg Loss: 30.9497 Train Loss: 1.2967\n",
      "[Iter 10350 Task dept] Task Loss: 0.6752 Reg Loss: 25.4050 Train Loss: 3.4015\n",
      "[Iter 10350 Total] Train Loss: 3.7644\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Task Loss: 1.2449 Reg Loss: 22.0016 Train Loss: 6.2463\n",
      "[Iter 10400 Task norm] Task Loss: 0.0624 Reg Loss: 21.8739 Train Loss: 1.2708\n",
      "[Iter 10400 Task dept] Task Loss: 0.6985 Reg Loss: 19.5467 Train Loss: 3.5121\n",
      "[Iter 10400 Total] Train Loss: 3.6764\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Val Loss: 1.8963\n",
      "{'mIoU': 0.155, 'Pixel Acc': 0.4821, 'cmp': -0.3089}\n",
      "[Iter 10400 Task norm] Val Loss: 0.2008\n",
      "{'Angle Mean': 33.6914, 'Angle Median': 32.7121, 'Angle 11.25': 3.4488, 'Angle 22.5': 33.762, 'Angle 30': 46.3304, 'cmp': -0.8258}\n",
      "[Iter 10400 Task dept] Val Loss: 1.2281\n",
      "{'abs_err': 1.2135, 'rel_err': 0.4046, 'sigma_1.25': 23.9074, 'sigma_1.25^2': 47.6838, 'sigma_1.25^3': 68.1185, 'cmp': -0.579}\n",
      "======================================================================\n",
      "[Iter 10450 Task segm] Task Loss: 1.2921 Reg Loss: 35.6342 Train Loss: 6.4961\n",
      "[Iter 10450 Task norm] Task Loss: 0.0625 Reg Loss: 30.9407 Train Loss: 1.2818\n",
      "[Iter 10450 Task dept] Task Loss: 0.7103 Reg Loss: 26.1527 Train Loss: 3.5775\n",
      "[Iter 10450 Total] Train Loss: 3.7851\n",
      "======================================================================\n",
      "[Iter 10500 Task segm] Task Loss: 1.2615 Reg Loss: 21.8079 Train Loss: 6.3294\n",
      "[Iter 10500 Task norm] Task Loss: 0.0640 Reg Loss: 21.1716 Train Loss: 1.3010\n",
      "[Iter 10500 Task dept] Task Loss: 0.6780 Reg Loss: 19.9627 Train Loss: 3.4102\n",
      "[Iter 10500 Total] Train Loss: 3.6802\n",
      "======================================================================\n",
      "tau: 0.7841340234138513\n",
      "[Iter 10550 Task segm] Task Loss: 1.2908 Reg Loss: 35.9366 Train Loss: 6.4899\n",
      "[Iter 10550 Task norm] Task Loss: 0.0628 Reg Loss: 31.5017 Train Loss: 1.2865\n",
      "[Iter 10550 Task dept] Task Loss: 0.6856 Reg Loss: 25.6796 Train Loss: 3.4537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10550 Total] Train Loss: 3.7434\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Task Loss: 1.2263 Reg Loss: 21.6393 Train Loss: 6.1533\n",
      "[Iter 10600 Task norm] Task Loss: 0.0624 Reg Loss: 21.7592 Train Loss: 1.2695\n",
      "[Iter 10600 Task dept] Task Loss: 0.7061 Reg Loss: 19.8588 Train Loss: 3.5505\n",
      "[Iter 10600 Total] Train Loss: 3.6578\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Val Loss: 2.2967\n",
      "{'mIoU': 0.1245, 'Pixel Acc': 0.4246, 'cmp': -0.4132}\n",
      "[Iter 10600 Task norm] Val Loss: 0.1929\n",
      "{'Angle Mean': 32.8955, 'Angle Median': 31.6774, 'Angle 11.25': 5.2078, 'Angle 22.5': 35.0182, 'Angle 30': 47.6452, 'cmp': -0.7855}\n",
      "[Iter 10600 Task dept] Val Loss: 0.9162\n",
      "{'abs_err': 0.905, 'rel_err': 0.3223, 'sigma_1.25': 38.1272, 'sigma_1.25^2': 67.1841, 'sigma_1.25^3': 85.3822, 'cmp': -0.283}\n",
      "======================================================================\n",
      "[Iter 10650 Task segm] Task Loss: 1.2632 Reg Loss: 35.6730 Train Loss: 6.3516\n",
      "[Iter 10650 Task norm] Task Loss: 0.0643 Reg Loss: 31.5640 Train Loss: 1.3175\n",
      "[Iter 10650 Task dept] Task Loss: 0.6895 Reg Loss: 27.2455 Train Loss: 3.4746\n",
      "[Iter 10650 Total] Train Loss: 3.7146\n",
      "======================================================================\n",
      "[Iter 10700 Task segm] Task Loss: 1.2787 Reg Loss: 21.7005 Train Loss: 6.4153\n",
      "[Iter 10700 Task norm] Task Loss: 0.0626 Reg Loss: 21.5976 Train Loss: 1.2728\n",
      "[Iter 10700 Task dept] Task Loss: 0.6971 Reg Loss: 19.9612 Train Loss: 3.5052\n",
      "[Iter 10700 Total] Train Loss: 3.7311\n",
      "======================================================================\n",
      "tau: 0.7566893325943664\n",
      "[Iter 10750 Task segm] Task Loss: 1.2890 Reg Loss: 35.2842 Train Loss: 6.4801\n",
      "[Iter 10750 Task norm] Task Loss: 0.0637 Reg Loss: 30.4661 Train Loss: 1.3053\n",
      "[Iter 10750 Task dept] Task Loss: 0.6867 Reg Loss: 27.2644 Train Loss: 3.4608\n",
      "[Iter 10750 Total] Train Loss: 3.7487\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Task Loss: 1.2900 Reg Loss: 22.1728 Train Loss: 6.4720\n",
      "[Iter 10800 Task norm] Task Loss: 0.0612 Reg Loss: 21.0467 Train Loss: 1.2457\n",
      "[Iter 10800 Task dept] Task Loss: 0.6812 Reg Loss: 19.7885 Train Loss: 3.4256\n",
      "[Iter 10800 Total] Train Loss: 3.7144\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Val Loss: 2.0568\n",
      "{'mIoU': 0.14, 'Pixel Acc': 0.4553, 'cmp': -0.359}\n",
      "[Iter 10800 Task norm] Val Loss: 0.1990\n",
      "{'Angle Mean': 33.4764, 'Angle Median': 32.3746, 'Angle 11.25': 4.14, 'Angle 22.5': 34.1969, 'Angle 30': 46.763, 'cmp': -0.8124}\n",
      "[Iter 10800 Task dept] Val Loss: 0.8338\n",
      "{'abs_err': 0.8224, 'rel_err': 0.3017, 'sigma_1.25': 43.8924, 'sigma_1.25^2': 74.2654, 'sigma_1.25^3': 90.2514, 'cmp': -0.1933}\n",
      "======================================================================\n",
      "[Iter 10850 Task segm] Task Loss: 1.2854 Reg Loss: 33.1163 Train Loss: 6.4601\n",
      "[Iter 10850 Task norm] Task Loss: 0.0633 Reg Loss: 32.9294 Train Loss: 1.2990\n",
      "[Iter 10850 Task dept] Task Loss: 0.7023 Reg Loss: 26.9555 Train Loss: 3.5384\n",
      "[Iter 10850 Total] Train Loss: 3.7658\n",
      "======================================================================\n",
      "[Iter 10900 Task segm] Task Loss: 1.2747 Reg Loss: 21.7153 Train Loss: 6.3952\n",
      "[Iter 10900 Task norm] Task Loss: 0.0620 Reg Loss: 21.2608 Train Loss: 1.2607\n",
      "[Iter 10900 Task dept] Task Loss: 0.6853 Reg Loss: 20.0836 Train Loss: 3.4467\n",
      "[Iter 10900 Total] Train Loss: 3.7009\n",
      "======================================================================\n",
      "tau: 0.7302052059535636\n",
      "[Iter 10950 Task segm] Task Loss: 1.2985 Reg Loss: 36.8305 Train Loss: 6.5292\n",
      "[Iter 10950 Task norm] Task Loss: 0.0638 Reg Loss: 33.5380 Train Loss: 1.3089\n",
      "[Iter 10950 Task dept] Task Loss: 0.6952 Reg Loss: 26.2886 Train Loss: 3.5025\n",
      "[Iter 10950 Total] Train Loss: 3.7802\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Task Loss: 1.2531 Reg Loss: 22.0606 Train Loss: 6.2876\n",
      "[Iter 11000 Task norm] Task Loss: 0.0618 Reg Loss: 21.2981 Train Loss: 1.2571\n",
      "[Iter 11000 Task dept] Task Loss: 0.6556 Reg Loss: 19.7803 Train Loss: 3.2978\n",
      "[Iter 11000 Total] Train Loss: 3.6142\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 2.1335\n",
      "{'mIoU': 0.1385, 'Pixel Acc': 0.4517, 'cmp': -0.3648}\n",
      "[Iter 11000 Task norm] Val Loss: 0.2003\n",
      "{'Angle Mean': 33.6262, 'Angle Median': 32.9105, 'Angle 11.25': 4.3031, 'Angle 22.5': 33.8221, 'Angle 30': 46.1228, 'cmp': -0.8232}\n",
      "[Iter 11000 Task dept] Val Loss: 0.8038\n",
      "{'abs_err': 0.7959, 'rel_err': 0.3037, 'sigma_1.25': 46.3456, 'sigma_1.25^2': 76.3296, 'sigma_1.25^3': 91.1724, 'cmp': -0.1711}\n",
      "======================================================================\n",
      "[Iter 11050 Task segm] Task Loss: 1.2593 Reg Loss: 36.2892 Train Loss: 6.3327\n",
      "[Iter 11050 Task norm] Task Loss: 0.0642 Reg Loss: 34.5857 Train Loss: 1.3194\n",
      "[Iter 11050 Task dept] Task Loss: 0.7029 Reg Loss: 27.4052 Train Loss: 3.5419\n",
      "[Iter 11050 Total] Train Loss: 3.7313\n",
      "======================================================================\n",
      "[Iter 11100 Task segm] Task Loss: 1.2745 Reg Loss: 21.7693 Train Loss: 6.3941\n",
      "[Iter 11100 Task norm] Task Loss: 0.0616 Reg Loss: 21.0889 Train Loss: 1.2538\n",
      "[Iter 11100 Task dept] Task Loss: 0.7349 Reg Loss: 20.2532 Train Loss: 3.6946\n",
      "[Iter 11100 Total] Train Loss: 3.7809\n",
      "======================================================================\n",
      "tau: 0.7046480237451889\n",
      "[Iter 11150 Task segm] Task Loss: 1.2999 Reg Loss: 35.3876 Train Loss: 6.5346\n",
      "[Iter 11150 Task norm] Task Loss: 0.0630 Reg Loss: 34.7010 Train Loss: 1.2937\n",
      "[Iter 11150 Task dept] Task Loss: 0.6778 Reg Loss: 27.6383 Train Loss: 3.4164\n",
      "[Iter 11150 Total] Train Loss: 3.7483\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Task Loss: 1.2884 Reg Loss: 21.5447 Train Loss: 6.4633\n",
      "[Iter 11200 Task norm] Task Loss: 0.0654 Reg Loss: 21.1470 Train Loss: 1.3293\n",
      "[Iter 11200 Task dept] Task Loss: 0.6953 Reg Loss: 20.0863 Train Loss: 3.4966\n",
      "[Iter 11200 Total] Train Loss: 3.7631\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Val Loss: 2.1010\n",
      "{'mIoU': 0.1389, 'Pixel Acc': 0.4472, 'cmp': -0.3678}\n",
      "[Iter 11200 Task norm] Val Loss: 0.1915\n",
      "{'Angle Mean': 32.728, 'Angle Median': 31.6262, 'Angle 11.25': 6.3116, 'Angle 22.5': 35.2986, 'Angle 30': 47.734, 'cmp': -0.7756}\n",
      "[Iter 11200 Task dept] Val Loss: 0.8916\n",
      "{'abs_err': 0.885, 'rel_err': 0.3322, 'sigma_1.25': 40.8002, 'sigma_1.25^2': 69.2521, 'sigma_1.25^3': 85.4711, 'cmp': -0.2703}\n",
      "======================================================================\n",
      "[Iter 11250 Task segm] Task Loss: 1.2496 Reg Loss: 37.2800 Train Loss: 6.2855\n",
      "[Iter 11250 Task norm] Task Loss: 0.0631 Reg Loss: 32.0462 Train Loss: 1.2932\n",
      "[Iter 11250 Task dept] Task Loss: 0.6860 Reg Loss: 29.0877 Train Loss: 3.4592\n",
      "[Iter 11250 Total] Train Loss: 3.6793\n",
      "======================================================================\n",
      "[Iter 11300 Task segm] Task Loss: 1.3067 Reg Loss: 21.9544 Train Loss: 6.5552\n",
      "[Iter 11300 Task norm] Task Loss: 0.0636 Reg Loss: 21.4258 Train Loss: 1.2932\n",
      "[Iter 11300 Task dept] Task Loss: 0.6671 Reg Loss: 19.7886 Train Loss: 3.3555\n",
      "[Iter 11300 Total] Train Loss: 3.7346\n",
      "======================================================================\n",
      "tau: 0.6799853429141073\n",
      "[Iter 11350 Task segm] Task Loss: 1.2669 Reg Loss: 36.4062 Train Loss: 6.3711\n",
      "[Iter 11350 Task norm] Task Loss: 0.0629 Reg Loss: 33.8241 Train Loss: 1.2920\n",
      "[Iter 11350 Task dept] Task Loss: 0.6778 Reg Loss: 27.4821 Train Loss: 3.4164\n",
      "[Iter 11350 Total] Train Loss: 3.6932\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Task Loss: 1.3013 Reg Loss: 21.1875 Train Loss: 6.5276\n",
      "[Iter 11400 Task norm] Task Loss: 0.0638 Reg Loss: 21.1244 Train Loss: 1.2977\n",
      "[Iter 11400 Task dept] Task Loss: 0.6995 Reg Loss: 19.5600 Train Loss: 3.5172\n",
      "[Iter 11400 Total] Train Loss: 3.7808\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Val Loss: 1.9592\n",
      "{'mIoU': 0.1521, 'Pixel Acc': 0.4612, 'cmp': -0.3319}\n",
      "[Iter 11400 Task norm] Val Loss: 0.1895\n",
      "{'Angle Mean': 32.51, 'Angle Median': 31.4989, 'Angle 11.25': 6.8799, 'Angle 22.5': 35.6663, 'Angle 30': 47.932, 'cmp': -0.7666}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 11400 Task dept] Val Loss: 0.8220\n",
      "{'abs_err': 0.8123, 'rel_err': 0.2961, 'sigma_1.25': 44.1502, 'sigma_1.25^2': 74.74, 'sigma_1.25^3': 91.0173, 'cmp': -0.1819}\n",
      "======================================================================\n",
      "[Iter 11450 Task segm] Task Loss: 1.2678 Reg Loss: 38.0965 Train Loss: 6.3772\n",
      "[Iter 11450 Task norm] Task Loss: 0.0628 Reg Loss: 32.2198 Train Loss: 1.2875\n",
      "[Iter 11450 Task dept] Task Loss: 0.6815 Reg Loss: 29.2031 Train Loss: 3.4368\n",
      "[Iter 11450 Total] Train Loss: 3.7005\n",
      "======================================================================\n",
      "[Iter 11500 Task segm] Task Loss: 1.2537 Reg Loss: 21.8371 Train Loss: 6.2903\n",
      "[Iter 11500 Task norm] Task Loss: 0.0639 Reg Loss: 20.9960 Train Loss: 1.2986\n",
      "[Iter 11500 Task dept] Task Loss: 0.6689 Reg Loss: 20.2394 Train Loss: 3.3645\n",
      "[Iter 11500 Total] Train Loss: 3.6512\n",
      "======================================================================\n",
      "tau: 0.6561858559121135\n",
      "[Iter 11550 Task segm] Task Loss: 1.2519 Reg Loss: 39.3226 Train Loss: 6.2986\n",
      "[Iter 11550 Task norm] Task Loss: 0.0614 Reg Loss: 32.0056 Train Loss: 1.2602\n",
      "[Iter 11550 Task dept] Task Loss: 0.6890 Reg Loss: 26.1779 Train Loss: 3.4712\n",
      "[Iter 11550 Total] Train Loss: 3.6767\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Task Loss: 1.3320 Reg Loss: 21.7800 Train Loss: 6.6816\n",
      "[Iter 11600 Task norm] Task Loss: 0.0630 Reg Loss: 21.0686 Train Loss: 1.2802\n",
      "[Iter 11600 Task dept] Task Loss: 0.6979 Reg Loss: 20.0473 Train Loss: 3.5096\n",
      "[Iter 11600 Total] Train Loss: 3.8238\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Val Loss: 2.1692\n",
      "{'mIoU': 0.1425, 'Pixel Acc': 0.4384, 'cmp': -0.3687}\n",
      "[Iter 11600 Task norm] Val Loss: 0.1749\n",
      "{'Angle Mean': 30.9265, 'Angle Median': 30.4661, 'Angle 11.25': 11.8855, 'Angle 22.5': 38.0803, 'Angle 30': 49.3876, 'cmp': -0.6953}\n",
      "[Iter 11600 Task dept] Val Loss: 0.8056\n",
      "{'abs_err': 0.7996, 'rel_err': 0.3257, 'sigma_1.25': 46.5137, 'sigma_1.25^2': 76.4207, 'sigma_1.25^3': 91.2438, 'cmp': -0.189}\n",
      "======================================================================\n",
      "[Iter 11650 Task segm] Task Loss: 1.2355 Reg Loss: 35.5840 Train Loss: 6.2133\n",
      "[Iter 11650 Task norm] Task Loss: 0.0643 Reg Loss: 34.0723 Train Loss: 1.3198\n",
      "[Iter 11650 Task dept] Task Loss: 0.6900 Reg Loss: 28.8121 Train Loss: 3.4786\n",
      "[Iter 11650 Total] Train Loss: 3.6706\n",
      "======================================================================\n",
      "[Iter 11700 Task segm] Task Loss: 1.2460 Reg Loss: 21.5079 Train Loss: 6.2515\n",
      "[Iter 11700 Task norm] Task Loss: 0.0635 Reg Loss: 20.6919 Train Loss: 1.2899\n",
      "[Iter 11700 Task dept] Task Loss: 0.6935 Reg Loss: 19.9702 Train Loss: 3.4874\n",
      "[Iter 11700 Total] Train Loss: 3.6763\n",
      "======================================================================\n",
      "tau: 0.6332193509551896\n",
      "[Iter 11750 Task segm] Task Loss: 1.2568 Reg Loss: 36.9149 Train Loss: 6.3207\n",
      "[Iter 11750 Task norm] Task Loss: 0.0637 Reg Loss: 31.9600 Train Loss: 1.3063\n",
      "[Iter 11750 Task dept] Task Loss: 0.6729 Reg Loss: 28.7078 Train Loss: 3.3934\n",
      "[Iter 11750 Total] Train Loss: 3.6735\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Task Loss: 1.2905 Reg Loss: 21.8537 Train Loss: 6.4743\n",
      "[Iter 11800 Task norm] Task Loss: 0.0637 Reg Loss: 21.0433 Train Loss: 1.2960\n",
      "[Iter 11800 Task dept] Task Loss: 0.6801 Reg Loss: 19.6953 Train Loss: 3.4204\n",
      "[Iter 11800 Total] Train Loss: 3.7302\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Val Loss: 2.1631\n",
      "{'mIoU': 0.139, 'Pixel Acc': 0.4415, 'cmp': -0.3725}\n",
      "[Iter 11800 Task norm] Val Loss: 0.1709\n",
      "{'Angle Mean': 30.4826, 'Angle Median': 29.8976, 'Angle 11.25': 12.634, 'Angle 22.5': 38.6871, 'Angle 30': 50.1377, 'cmp': -0.6745}\n",
      "[Iter 11800 Task dept] Val Loss: 0.7541\n",
      "{'abs_err': 0.7446, 'rel_err': 0.2902, 'sigma_1.25': 47.627, 'sigma_1.25^2': 78.9459, 'sigma_1.25^3': 92.8534, 'cmp': -0.1298}\n",
      "======================================================================\n",
      "[Iter 11850 Task segm] Task Loss: 1.2746 Reg Loss: 37.9612 Train Loss: 6.4110\n",
      "[Iter 11850 Task norm] Task Loss: 0.0632 Reg Loss: 32.2874 Train Loss: 1.2954\n",
      "[Iter 11850 Task dept] Task Loss: 0.7182 Reg Loss: 29.0199 Train Loss: 3.6200\n",
      "[Iter 11850 Total] Train Loss: 3.7755\n",
      "======================================================================\n",
      "[Iter 11900 Task segm] Task Loss: 1.2917 Reg Loss: 21.9747 Train Loss: 6.4803\n",
      "[Iter 11900 Task norm] Task Loss: 0.0631 Reg Loss: 21.1439 Train Loss: 1.2837\n",
      "[Iter 11900 Task dept] Task Loss: 0.6922 Reg Loss: 19.6639 Train Loss: 3.4804\n",
      "[Iter 11900 Total] Train Loss: 3.7482\n",
      "======================================================================\n",
      "tau: 0.6110566736717579\n",
      "[Iter 11950 Task segm] Task Loss: 1.3086 Reg Loss: 38.0233 Train Loss: 6.5812\n",
      "[Iter 11950 Task norm] Task Loss: 0.0630 Reg Loss: 33.2132 Train Loss: 1.2933\n",
      "[Iter 11950 Task dept] Task Loss: 0.6909 Reg Loss: 28.9422 Train Loss: 3.4835\n",
      "[Iter 11950 Total] Train Loss: 3.7860\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Task Loss: 1.2841 Reg Loss: 21.7623 Train Loss: 6.4422\n",
      "[Iter 12000 Task norm] Task Loss: 0.0620 Reg Loss: 20.7600 Train Loss: 1.2605\n",
      "[Iter 12000 Task dept] Task Loss: 0.7128 Reg Loss: 19.7932 Train Loss: 3.5836\n",
      "[Iter 12000 Total] Train Loss: 3.7621\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 2.2323\n",
      "{'mIoU': 0.1384, 'Pixel Acc': 0.4243, 'cmp': -0.3882}\n",
      "[Iter 12000 Task norm] Val Loss: 0.1767\n",
      "{'Angle Mean': 31.1153, 'Angle Median': 30.948, 'Angle 11.25': 11.8892, 'Angle 22.5': 37.4076, 'Angle 30': 48.7146, 'cmp': -0.7076}\n",
      "[Iter 12000 Task dept] Val Loss: 0.8765\n",
      "{'abs_err': 0.8755, 'rel_err': 0.3905, 'sigma_1.25': 45.8471, 'sigma_1.25^2': 75.2311, 'sigma_1.25^3': 89.697, 'cmp': -0.2736}\n",
      "======================================================================\n",
      "[Iter 12050 Task segm] Task Loss: 1.2691 Reg Loss: 38.5430 Train Loss: 6.3839\n",
      "[Iter 12050 Task norm] Task Loss: 0.0637 Reg Loss: 34.4149 Train Loss: 1.3092\n",
      "[Iter 12050 Task dept] Task Loss: 0.7003 Reg Loss: 27.5463 Train Loss: 3.5288\n",
      "[Iter 12050 Total] Train Loss: 3.7406\n",
      "======================================================================\n",
      "[Iter 12100 Task segm] Task Loss: 1.3846 Reg Loss: 21.6812 Train Loss: 6.9449\n",
      "[Iter 12100 Task norm] Task Loss: 0.0640 Reg Loss: 21.0209 Train Loss: 1.3001\n",
      "[Iter 12100 Task dept] Task Loss: 0.7144 Reg Loss: 19.6244 Train Loss: 3.5919\n",
      "[Iter 12100 Total] Train Loss: 3.9456\n",
      "======================================================================\n",
      "tau: 0.5896696900932463\n",
      "[Iter 12150 Task segm] Task Loss: 1.2669 Reg Loss: 38.6180 Train Loss: 6.3731\n",
      "[Iter 12150 Task norm] Task Loss: 0.0643 Reg Loss: 33.1082 Train Loss: 1.3190\n",
      "[Iter 12150 Task dept] Task Loss: 0.6823 Reg Loss: 28.3328 Train Loss: 3.4396\n",
      "[Iter 12150 Total] Train Loss: 3.7105\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Task Loss: 1.2982 Reg Loss: 21.7334 Train Loss: 6.5128\n",
      "[Iter 12200 Task norm] Task Loss: 0.0632 Reg Loss: 20.9587 Train Loss: 1.2845\n",
      "[Iter 12200 Task dept] Task Loss: 0.6695 Reg Loss: 19.4953 Train Loss: 3.3672\n",
      "[Iter 12200 Total] Train Loss: 3.7215\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Val Loss: 1.8976\n",
      "{'mIoU': 0.1649, 'Pixel Acc': 0.4817, 'cmp': -0.2912}\n",
      "[Iter 12200 Task norm] Val Loss: 0.1673\n",
      "{'Angle Mean': 30.1109, 'Angle Median': 29.4745, 'Angle 11.25': 13.4206, 'Angle 22.5': 39.1087, 'Angle 30': 50.7545, 'cmp': -0.6572}\n",
      "[Iter 12200 Task dept] Val Loss: 0.7585\n",
      "{'abs_err': 0.7511, 'rel_err': 0.2848, 'sigma_1.25': 48.1758, 'sigma_1.25^2': 78.9436, 'sigma_1.25^3': 92.7219, 'cmp': -0.126}\n",
      "======================================================================\n",
      "[Iter 12250 Task segm] Task Loss: 1.2762 Reg Loss: 39.0100 Train Loss: 6.4198\n",
      "[Iter 12250 Task norm] Task Loss: 0.0626 Reg Loss: 34.3550 Train Loss: 1.2872\n",
      "[Iter 12250 Task dept] Task Loss: 0.6810 Reg Loss: 29.5468 Train Loss: 3.4345\n",
      "[Iter 12250 Total] Train Loss: 3.7138\n",
      "======================================================================\n",
      "[Iter 12300 Task segm] Task Loss: 1.2984 Reg Loss: 22.0042 Train Loss: 6.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12300 Task norm] Task Loss: 0.0628 Reg Loss: 21.1739 Train Loss: 1.2770\n",
      "[Iter 12300 Task dept] Task Loss: 0.6604 Reg Loss: 19.2553 Train Loss: 3.3214\n",
      "[Iter 12300 Total] Train Loss: 3.7041\n",
      "======================================================================\n",
      "tau: 0.5690312509399826\n",
      "[Iter 12350 Task segm] Task Loss: 1.2852 Reg Loss: 37.6240 Train Loss: 6.4638\n",
      "[Iter 12350 Task norm] Task Loss: 0.0628 Reg Loss: 33.1899 Train Loss: 1.2899\n",
      "[Iter 12350 Task dept] Task Loss: 0.6759 Reg Loss: 29.7457 Train Loss: 3.4091\n",
      "[Iter 12350 Total] Train Loss: 3.7209\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Task Loss: 1.2837 Reg Loss: 21.5335 Train Loss: 6.4403\n",
      "[Iter 12400 Task norm] Task Loss: 0.0628 Reg Loss: 21.2201 Train Loss: 1.2765\n",
      "[Iter 12400 Task dept] Task Loss: 0.6913 Reg Loss: 19.9958 Train Loss: 3.4766\n",
      "[Iter 12400 Total] Train Loss: 3.7311\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Val Loss: 1.9256\n",
      "{'mIoU': 0.1606, 'Pixel Acc': 0.4646, 'cmp': -0.3136}\n",
      "[Iter 12400 Task norm] Val Loss: 0.1765\n",
      "{'Angle Mean': 31.0223, 'Angle Median': 30.867, 'Angle 11.25': 12.5719, 'Angle 22.5': 37.813, 'Angle 30': 48.8609, 'cmp': -0.7}\n",
      "[Iter 12400 Task dept] Val Loss: 0.7343\n",
      "{'abs_err': 0.7305, 'rel_err': 0.2955, 'sigma_1.25': 50.6942, 'sigma_1.25^2': 81.0146, 'sigma_1.25^3': 93.272, 'cmp': -0.1132}\n",
      "======================================================================\n",
      "[Iter 12450 Task segm] Task Loss: 1.2877 Reg Loss: 38.9738 Train Loss: 6.4772\n",
      "[Iter 12450 Task norm] Task Loss: 0.0626 Reg Loss: 34.2186 Train Loss: 1.2859\n",
      "[Iter 12450 Task dept] Task Loss: 0.6924 Reg Loss: 27.2039 Train Loss: 3.4894\n",
      "[Iter 12450 Total] Train Loss: 3.7509\n",
      "======================================================================\n",
      "[Iter 12500 Task segm] Task Loss: 1.2442 Reg Loss: 21.6331 Train Loss: 6.2427\n",
      "[Iter 12500 Task norm] Task Loss: 0.0628 Reg Loss: 20.7458 Train Loss: 1.2773\n",
      "[Iter 12500 Task dept] Task Loss: 0.6846 Reg Loss: 19.7316 Train Loss: 3.4425\n",
      "[Iter 12500 Total] Train Loss: 3.6542\n",
      "======================================================================\n",
      "tau: 0.5491151571570833\n",
      "[Iter 12550 Task segm] Task Loss: 1.2741 Reg Loss: 38.1581 Train Loss: 6.4089\n",
      "[Iter 12550 Task norm] Task Loss: 0.0629 Reg Loss: 33.2767 Train Loss: 1.2920\n",
      "[Iter 12550 Task dept] Task Loss: 0.7077 Reg Loss: 28.8412 Train Loss: 3.5674\n",
      "[Iter 12550 Total] Train Loss: 3.7561\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Task Loss: 1.2487 Reg Loss: 21.9483 Train Loss: 6.2656\n",
      "[Iter 12600 Task norm] Task Loss: 0.0652 Reg Loss: 20.5293 Train Loss: 1.3246\n",
      "[Iter 12600 Task dept] Task Loss: 0.6803 Reg Loss: 19.6658 Train Loss: 3.4213\n",
      "[Iter 12600 Total] Train Loss: 3.6705\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Val Loss: 1.7647\n",
      "{'mIoU': 0.1838, 'Pixel Acc': 0.5009, 'cmp': -0.2407}\n",
      "[Iter 12600 Task norm] Val Loss: 0.1676\n",
      "{'Angle Mean': 30.1217, 'Angle Median': 29.5833, 'Angle 11.25': 13.3888, 'Angle 22.5': 39.2516, 'Angle 30': 50.5585, 'cmp': -0.6591}\n",
      "[Iter 12600 Task dept] Val Loss: 0.7560\n",
      "{'abs_err': 0.7472, 'rel_err': 0.2833, 'sigma_1.25': 48.0274, 'sigma_1.25^2': 79.524, 'sigma_1.25^3': 93.2428, 'cmp': -0.1215}\n",
      "======================================================================\n",
      "[Iter 12650 Task segm] Task Loss: 1.3259 Reg Loss: 40.5219 Train Loss: 6.6700\n",
      "[Iter 12650 Task norm] Task Loss: 0.0630 Reg Loss: 31.3835 Train Loss: 1.2920\n",
      "[Iter 12650 Task dept] Task Loss: 0.6742 Reg Loss: 26.7672 Train Loss: 3.3978\n",
      "[Iter 12650 Total] Train Loss: 3.7866\n",
      "======================================================================\n",
      "[Iter 12700 Task segm] Task Loss: 1.3189 Reg Loss: 21.7846 Train Loss: 6.6163\n",
      "[Iter 12700 Task norm] Task Loss: 0.0643 Reg Loss: 20.9543 Train Loss: 1.3071\n",
      "[Iter 12700 Task dept] Task Loss: 0.6970 Reg Loss: 19.3073 Train Loss: 3.5043\n",
      "[Iter 12700 Total] Train Loss: 3.8092\n",
      "======================================================================\n",
      "tau: 0.5298961266565854\n",
      "[Iter 12750 Task segm] Task Loss: 1.2778 Reg Loss: 40.5563 Train Loss: 6.4296\n",
      "[Iter 12750 Task norm] Task Loss: 0.0631 Reg Loss: 35.8834 Train Loss: 1.2973\n",
      "[Iter 12750 Task dept] Task Loss: 0.7144 Reg Loss: 28.1401 Train Loss: 3.6003\n",
      "[Iter 12750 Total] Train Loss: 3.7757\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Task Loss: 1.2408 Reg Loss: 21.8740 Train Loss: 6.2260\n",
      "[Iter 12800 Task norm] Task Loss: 0.0629 Reg Loss: 20.2493 Train Loss: 1.2790\n",
      "[Iter 12800 Task dept] Task Loss: 0.6930 Reg Loss: 19.5135 Train Loss: 3.4847\n",
      "[Iter 12800 Total] Train Loss: 3.6632\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Val Loss: 1.8375\n",
      "{'mIoU': 0.1769, 'Pixel Acc': 0.489, 'cmp': -0.2633}\n",
      "[Iter 12800 Task norm] Val Loss: 0.1507\n",
      "{'Angle Mean': 28.2579, 'Angle Median': 27.5157, 'Angle 11.25': 17.0476, 'Angle 22.5': 41.7697, 'Angle 30': 54.2292, 'cmp': -0.5723}\n",
      "[Iter 12800 Task dept] Val Loss: 0.7543\n",
      "{'abs_err': 0.7477, 'rel_err': 0.2913, 'sigma_1.25': 49.5136, 'sigma_1.25^2': 79.7301, 'sigma_1.25^3': 92.7791, 'cmp': -0.1235}\n",
      "======================================================================\n",
      "[Iter 12850 Task segm] Task Loss: 1.2803 Reg Loss: 41.3844 Train Loss: 6.4428\n",
      "[Iter 12850 Task norm] Task Loss: 0.0631 Reg Loss: 35.4621 Train Loss: 1.2979\n",
      "[Iter 12850 Task dept] Task Loss: 0.6894 Reg Loss: 29.0083 Train Loss: 3.4761\n",
      "[Iter 12850 Total] Train Loss: 3.7390\n",
      "======================================================================\n",
      "[Iter 12900 Task segm] Task Loss: 1.2932 Reg Loss: 21.6273 Train Loss: 6.4878\n",
      "[Iter 12900 Task norm] Task Loss: 0.0643 Reg Loss: 21.0838 Train Loss: 1.3063\n",
      "[Iter 12900 Task dept] Task Loss: 0.6807 Reg Loss: 19.8389 Train Loss: 3.4232\n",
      "[Iter 12900 Total] Train Loss: 3.7391\n",
      "======================================================================\n",
      "tau: 0.5113497622236048\n",
      "[Iter 12950 Task segm] Task Loss: 1.2776 Reg Loss: 40.2634 Train Loss: 6.4284\n",
      "[Iter 12950 Task norm] Task Loss: 0.0632 Reg Loss: 33.0104 Train Loss: 1.2975\n",
      "[Iter 12950 Task dept] Task Loss: 0.6690 Reg Loss: 29.1754 Train Loss: 3.3743\n",
      "[Iter 12950 Total] Train Loss: 3.7001\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Task Loss: 1.2988 Reg Loss: 21.4330 Train Loss: 6.5155\n",
      "[Iter 13000 Task norm] Task Loss: 0.0625 Reg Loss: 21.3204 Train Loss: 1.2717\n",
      "[Iter 13000 Task dept] Task Loss: 0.7045 Reg Loss: 19.1258 Train Loss: 3.5418\n",
      "[Iter 13000 Total] Train Loss: 3.7764\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Val Loss: 2.0886\n",
      "{'mIoU': 0.1424, 'Pixel Acc': 0.4396, 'cmp': -0.3679}\n",
      "[Iter 13000 Task norm] Val Loss: 0.1708\n",
      "{'Angle Mean': 30.5244, 'Angle Median': 29.9473, 'Angle 11.25': 12.5418, 'Angle 22.5': 38.4832, 'Angle 30': 50.0728, 'cmp': -0.6769}\n",
      "[Iter 13000 Task dept] Val Loss: 0.7153\n",
      "{'abs_err': 0.708, 'rel_err': 0.2809, 'sigma_1.25': 51.6427, 'sigma_1.25^2': 81.9809, 'sigma_1.25^3': 93.886, 'cmp': -0.0874}\n",
      "======================================================================\n",
      "[Iter 13050 Task segm] Task Loss: 1.2918 Reg Loss: 40.2636 Train Loss: 6.4994\n",
      "[Iter 13050 Task norm] Task Loss: 0.0641 Reg Loss: 36.6223 Train Loss: 1.3195\n",
      "[Iter 13050 Task dept] Task Loss: 0.6659 Reg Loss: 31.7027 Train Loss: 3.3611\n",
      "[Iter 13050 Total] Train Loss: 3.7267\n",
      "======================================================================\n",
      "[Iter 13100 Task segm] Task Loss: 1.2612 Reg Loss: 21.5957 Train Loss: 6.3274\n",
      "[Iter 13100 Task norm] Task Loss: 0.0621 Reg Loss: 20.6084 Train Loss: 1.2627\n",
      "[Iter 13100 Task dept] Task Loss: 0.6994 Reg Loss: 19.4767 Train Loss: 3.5165\n",
      "[Iter 13100 Total] Train Loss: 3.7022\n",
      "======================================================================\n",
      "tau: 0.49345252054577865\n",
      "[Iter 13150 Task segm] Task Loss: 1.2509 Reg Loss: 37.2792 Train Loss: 6.2920\n",
      "[Iter 13150 Task norm] Task Loss: 0.0628 Reg Loss: 34.5990 Train Loss: 1.2897\n",
      "[Iter 13150 Task dept] Task Loss: 0.6696 Reg Loss: 30.0597 Train Loss: 3.3780\n",
      "[Iter 13150 Total] Train Loss: 3.6532\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 13200 Task segm] Task Loss: 1.2733 Reg Loss: 22.0206 Train Loss: 6.3884\n",
      "[Iter 13200 Task norm] Task Loss: 0.0641 Reg Loss: 20.3736 Train Loss: 1.3034\n",
      "[Iter 13200 Task dept] Task Loss: 0.7006 Reg Loss: 19.5179 Train Loss: 3.5223\n",
      "[Iter 13200 Total] Train Loss: 3.7380\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Val Loss: 2.1380\n",
      "{'mIoU': 0.1364, 'Pixel Acc': 0.4319, 'cmp': -0.3853}\n",
      "[Iter 13200 Task norm] Val Loss: 0.1679\n",
      "{'Angle Mean': 30.1532, 'Angle Median': 29.4969, 'Angle 11.25': 13.4474, 'Angle 22.5': 39.1358, 'Angle 30': 50.7142, 'cmp': -0.6579}\n",
      "[Iter 13200 Task dept] Val Loss: 0.8083\n",
      "{'abs_err': 0.8007, 'rel_err': 0.3002, 'sigma_1.25': 46.6334, 'sigma_1.25^2': 76.3436, 'sigma_1.25^3': 90.7851, 'cmp': -0.1697}\n",
      "======================================================================\n",
      "[Iter 13250 Task segm] Task Loss: 1.2792 Reg Loss: 40.0600 Train Loss: 6.4358\n",
      "[Iter 13250 Task norm] Task Loss: 0.0629 Reg Loss: 35.3005 Train Loss: 1.2940\n",
      "[Iter 13250 Task dept] Task Loss: 0.6711 Reg Loss: 27.5336 Train Loss: 3.3828\n",
      "[Iter 13250 Total] Train Loss: 3.7042\n",
      "======================================================================\n",
      "[Iter 13300 Task segm] Task Loss: 1.2782 Reg Loss: 21.3874 Train Loss: 6.4125\n",
      "[Iter 13300 Task norm] Task Loss: 0.0646 Reg Loss: 20.5356 Train Loss: 1.3129\n",
      "[Iter 13300 Task dept] Task Loss: 0.7097 Reg Loss: 19.5475 Train Loss: 3.5682\n",
      "[Iter 13300 Total] Train Loss: 3.7645\n",
      "======================================================================\n",
      "tau: 0.4761816823266764\n",
      "[Iter 13350 Task segm] Task Loss: 1.2903 Reg Loss: 40.7656 Train Loss: 6.4922\n",
      "[Iter 13350 Task norm] Task Loss: 0.0646 Reg Loss: 32.6722 Train Loss: 1.3245\n",
      "[Iter 13350 Task dept] Task Loss: 0.6891 Reg Loss: 28.7094 Train Loss: 3.4743\n",
      "[Iter 13350 Total] Train Loss: 3.7637\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Task Loss: 1.2395 Reg Loss: 21.6807 Train Loss: 6.2194\n",
      "[Iter 13400 Task norm] Task Loss: 0.0632 Reg Loss: 20.3462 Train Loss: 1.2846\n",
      "[Iter 13400 Task dept] Task Loss: 0.6610 Reg Loss: 19.1049 Train Loss: 3.3243\n",
      "[Iter 13400 Total] Train Loss: 3.6094\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Val Loss: 1.8875\n",
      "{'mIoU': 0.1573, 'Pixel Acc': 0.4671, 'cmp': -0.3174}\n",
      "[Iter 13400 Task norm] Val Loss: 0.1525\n",
      "{'Angle Mean': 28.3605, 'Angle Median': 27.1598, 'Angle 11.25': 16.0213, 'Angle 22.5': 41.3911, 'Angle 30': 55.6341, 'cmp': -0.5721}\n",
      "[Iter 13400 Task dept] Val Loss: 0.8553\n",
      "{'abs_err': 0.844, 'rel_err': 0.2905, 'sigma_1.25': 38.7287, 'sigma_1.25^2': 70.7072, 'sigma_1.25^3': 89.2568, 'cmp': -0.2195}\n",
      "======================================================================\n",
      "[Iter 13450 Task segm] Task Loss: 1.2581 Reg Loss: 39.3206 Train Loss: 6.3299\n",
      "[Iter 13450 Task norm] Task Loss: 0.0629 Reg Loss: 33.4992 Train Loss: 1.2906\n",
      "[Iter 13450 Task dept] Task Loss: 0.6760 Reg Loss: 29.5950 Train Loss: 3.4094\n",
      "[Iter 13450 Total] Train Loss: 3.6767\n",
      "======================================================================\n",
      "[Iter 13500 Task segm] Task Loss: 1.2139 Reg Loss: 21.4013 Train Loss: 6.0911\n",
      "[Iter 13500 Task norm] Task Loss: 0.0634 Reg Loss: 20.4772 Train Loss: 1.2886\n",
      "[Iter 13500 Task dept] Task Loss: 0.7110 Reg Loss: 19.0646 Train Loss: 3.5742\n",
      "[Iter 13500 Total] Train Loss: 3.6513\n",
      "======================================================================\n",
      "tau: 0.4595153234452427\n",
      "[Iter 13550 Task segm] Task Loss: 1.2791 Reg Loss: 40.1005 Train Loss: 6.4354\n",
      "[Iter 13550 Task norm] Task Loss: 0.0619 Reg Loss: 34.5646 Train Loss: 1.2728\n",
      "[Iter 13550 Task dept] Task Loss: 0.6696 Reg Loss: 30.0820 Train Loss: 3.3783\n",
      "[Iter 13550 Total] Train Loss: 3.6955\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Task Loss: 1.2938 Reg Loss: 21.8330 Train Loss: 6.4908\n",
      "[Iter 13600 Task norm] Task Loss: 0.0619 Reg Loss: 20.2921 Train Loss: 1.2587\n",
      "[Iter 13600 Task dept] Task Loss: 0.6857 Reg Loss: 19.2557 Train Loss: 3.4478\n",
      "[Iter 13600 Total] Train Loss: 3.7324\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Val Loss: 2.3114\n",
      "{'mIoU': 0.123, 'Pixel Acc': 0.4107, 'cmp': -0.4278}\n",
      "[Iter 13600 Task norm] Val Loss: 0.1504\n",
      "{'Angle Mean': 28.1994, 'Angle Median': 26.4624, 'Angle 11.25': 14.4153, 'Angle 22.5': 41.061, 'Angle 30': 59.2431, 'cmp': -0.5621}\n",
      "[Iter 13600 Task dept] Val Loss: 0.7529\n",
      "{'abs_err': 0.7441, 'rel_err': 0.2802, 'sigma_1.25': 47.5712, 'sigma_1.25^2': 79.07, 'sigma_1.25^3': 93.1714, 'cmp': -0.1209}\n",
      "======================================================================\n",
      "[Iter 13650 Task segm] Task Loss: 1.3007 Reg Loss: 42.2396 Train Loss: 6.5459\n",
      "[Iter 13650 Task norm] Task Loss: 0.0630 Reg Loss: 35.1676 Train Loss: 1.2961\n",
      "[Iter 13650 Task dept] Task Loss: 0.6945 Reg Loss: 29.5851 Train Loss: 3.5022\n",
      "[Iter 13650 Total] Train Loss: 3.7814\n",
      "======================================================================\n",
      "[Iter 13700 Task segm] Task Loss: 1.2201 Reg Loss: 21.8708 Train Loss: 6.1223\n",
      "[Iter 13700 Task norm] Task Loss: 0.0641 Reg Loss: 20.9232 Train Loss: 1.3035\n",
      "[Iter 13700 Task dept] Task Loss: 0.6989 Reg Loss: 19.3222 Train Loss: 3.5140\n",
      "[Iter 13700 Total] Train Loss: 3.6466\n",
      "======================================================================\n",
      "tau: 0.4434322871246592\n",
      "[Iter 13750 Task segm] Task Loss: 1.2691 Reg Loss: 40.6783 Train Loss: 6.3861\n",
      "[Iter 13750 Task norm] Task Loss: 0.0644 Reg Loss: 33.9394 Train Loss: 1.3210\n",
      "[Iter 13750 Task dept] Task Loss: 0.6843 Reg Loss: 31.0238 Train Loss: 3.4526\n",
      "[Iter 13750 Total] Train Loss: 3.7199\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Task Loss: 1.2678 Reg Loss: 21.5754 Train Loss: 6.3604\n",
      "[Iter 13800 Task norm] Task Loss: 0.0635 Reg Loss: 20.0436 Train Loss: 1.2907\n",
      "[Iter 13800 Task dept] Task Loss: 0.6696 Reg Loss: 19.4456 Train Loss: 3.3674\n",
      "[Iter 13800 Total] Train Loss: 3.6728\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Val Loss: 1.8839\n",
      "{'mIoU': 0.1567, 'Pixel Acc': 0.4561, 'cmp': -0.3279}\n",
      "[Iter 13800 Task norm] Val Loss: 0.1903\n",
      "{'Angle Mean': 32.5699, 'Angle Median': 31.7119, 'Angle 11.25': 7.181, 'Angle 22.5': 34.7726, 'Angle 30': 47.402, 'cmp': -0.7722}\n",
      "[Iter 13800 Task dept] Val Loss: 0.7723\n",
      "{'abs_err': 0.7618, 'rel_err': 0.2827, 'sigma_1.25': 45.4075, 'sigma_1.25^2': 77.2772, 'sigma_1.25^3': 92.4256, 'cmp': -0.1417}\n",
      "======================================================================\n",
      "[Iter 13850 Task segm] Task Loss: 1.2340 Reg Loss: 40.1766 Train Loss: 6.2101\n",
      "[Iter 13850 Task norm] Task Loss: 0.0622 Reg Loss: 36.7277 Train Loss: 1.2816\n",
      "[Iter 13850 Task dept] Task Loss: 0.6668 Reg Loss: 29.4706 Train Loss: 3.3637\n",
      "[Iter 13850 Total] Train Loss: 3.6184\n",
      "======================================================================\n",
      "[Iter 13900 Task segm] Task Loss: 1.2893 Reg Loss: 21.7740 Train Loss: 6.4683\n",
      "[Iter 13900 Task norm] Task Loss: 0.0633 Reg Loss: 20.3559 Train Loss: 1.2867\n",
      "[Iter 13900 Task dept] Task Loss: 0.6863 Reg Loss: 19.2153 Train Loss: 3.4507\n",
      "[Iter 13900 Total] Train Loss: 3.7352\n",
      "======================================================================\n",
      "tau: 0.4279121570752961\n",
      "[Iter 13950 Task segm] Task Loss: 1.3348 Reg Loss: 42.5668 Train Loss: 6.7164\n",
      "[Iter 13950 Task norm] Task Loss: 0.0647 Reg Loss: 35.3833 Train Loss: 1.3300\n",
      "[Iter 13950 Task dept] Task Loss: 0.6577 Reg Loss: 29.7858 Train Loss: 3.3184\n",
      "[Iter 13950 Total] Train Loss: 3.7883\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Task Loss: 1.2945 Reg Loss: 21.7529 Train Loss: 6.4944\n",
      "[Iter 14000 Task norm] Task Loss: 0.0621 Reg Loss: 20.5390 Train Loss: 1.2616\n",
      "[Iter 14000 Task dept] Task Loss: 0.7015 Reg Loss: 19.2172 Train Loss: 3.5268\n",
      "[Iter 14000 Total] Train Loss: 3.7609\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Val Loss: 1.8043\n",
      "{'mIoU': 0.1739, 'Pixel Acc': 0.4962, 'cmp': -0.2626}\n",
      "[Iter 14000 Task norm] Val Loss: 0.1627\n",
      "{'Angle Mean': 29.5524, 'Angle Median': 28.5505, 'Angle 11.25': 13.5428, 'Angle 22.5': 39.1014, 'Angle 30': 52.7529, 'cmp': -0.6325}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 14000 Task dept] Val Loss: 0.7616\n",
      "{'abs_err': 0.7519, 'rel_err': 0.2776, 'sigma_1.25': 46.4177, 'sigma_1.25^2': 78.4698, 'sigma_1.25^3': 93.0637, 'cmp': -0.1269}\n",
      "======================================================================\n",
      "[Iter 14050 Task segm] Task Loss: 1.2434 Reg Loss: 39.0403 Train Loss: 6.2562\n",
      "[Iter 14050 Task norm] Task Loss: 0.0626 Reg Loss: 36.6004 Train Loss: 1.2892\n",
      "[Iter 14050 Task dept] Task Loss: 0.6789 Reg Loss: 31.5152 Train Loss: 3.4262\n",
      "[Iter 14050 Total] Train Loss: 3.6572\n",
      "======================================================================\n",
      "[Iter 14100 Task segm] Task Loss: 1.3210 Reg Loss: 21.2958 Train Loss: 6.6263\n",
      "[Iter 14100 Task norm] Task Loss: 0.0631 Reg Loss: 20.0499 Train Loss: 1.2823\n",
      "[Iter 14100 Task dept] Task Loss: 0.6825 Reg Loss: 19.4333 Train Loss: 3.4318\n",
      "[Iter 14100 Total] Train Loss: 3.7801\n",
      "======================================================================\n",
      "tau: 0.41293523157766077\n",
      "[Iter 14150 Task segm] Task Loss: 1.2404 Reg Loss: 39.0775 Train Loss: 6.2409\n",
      "[Iter 14150 Task norm] Task Loss: 0.0635 Reg Loss: 34.0139 Train Loss: 1.3043\n",
      "[Iter 14150 Task dept] Task Loss: 0.6744 Reg Loss: 29.0402 Train Loss: 3.4009\n",
      "[Iter 14150 Total] Train Loss: 3.6487\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Task Loss: 1.2794 Reg Loss: 21.7191 Train Loss: 6.4189\n",
      "[Iter 14200 Task norm] Task Loss: 0.0645 Reg Loss: 20.6330 Train Loss: 1.3116\n",
      "[Iter 14200 Task dept] Task Loss: 0.7101 Reg Loss: 18.9062 Train Loss: 3.5692\n",
      "[Iter 14200 Total] Train Loss: 3.7665\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Val Loss: 1.8972\n",
      "{'mIoU': 0.1597, 'Pixel Acc': 0.4703, 'cmp': -0.3104}\n",
      "[Iter 14200 Task norm] Val Loss: 0.1648\n",
      "{'Angle Mean': 29.8364, 'Angle Median': 28.5408, 'Angle 11.25': 12.2363, 'Angle 22.5': 38.5149, 'Angle 30': 52.9541, 'cmp': -0.6442}\n",
      "[Iter 14200 Task dept] Val Loss: 0.7911\n",
      "{'abs_err': 0.7819, 'rel_err': 0.2882, 'sigma_1.25': 45.76, 'sigma_1.25^2': 77.2553, 'sigma_1.25^3': 92.002, 'cmp': -0.1523}\n",
      "======================================================================\n",
      "[Iter 14250 Task segm] Task Loss: 1.2769 Reg Loss: 39.6437 Train Loss: 6.4239\n",
      "[Iter 14250 Task norm] Task Loss: 0.0644 Reg Loss: 35.5933 Train Loss: 1.3227\n",
      "[Iter 14250 Task dept] Task Loss: 0.6994 Reg Loss: 30.5704 Train Loss: 3.5274\n",
      "[Iter 14250 Total] Train Loss: 3.7580\n",
      "======================================================================\n",
      "[Iter 14300 Task segm] Task Loss: 1.2417 Reg Loss: 21.2539 Train Loss: 6.2299\n",
      "[Iter 14300 Task norm] Task Loss: 0.0636 Reg Loss: 20.5434 Train Loss: 1.2929\n",
      "[Iter 14300 Task dept] Task Loss: 0.6803 Reg Loss: 19.3080 Train Loss: 3.4207\n",
      "[Iter 14300 Total] Train Loss: 3.6478\n",
      "======================================================================\n",
      "tau: 0.3984824984724426\n",
      "[Iter 14350 Task segm] Task Loss: 1.2581 Reg Loss: 41.9883 Train Loss: 6.3327\n",
      "[Iter 14350 Task norm] Task Loss: 0.0623 Reg Loss: 34.9282 Train Loss: 1.2802\n",
      "[Iter 14350 Task dept] Task Loss: 0.7206 Reg Loss: 29.9678 Train Loss: 3.6330\n",
      "[Iter 14350 Total] Train Loss: 3.7486\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Task Loss: 1.2746 Reg Loss: 21.2338 Train Loss: 6.3943\n",
      "[Iter 14400 Task norm] Task Loss: 0.0624 Reg Loss: 19.8922 Train Loss: 1.2670\n",
      "[Iter 14400 Task dept] Task Loss: 0.6899 Reg Loss: 18.9802 Train Loss: 3.4687\n",
      "[Iter 14400 Total] Train Loss: 3.7100\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Val Loss: 1.9771\n",
      "{'mIoU': 0.1444, 'Pixel Acc': 0.4566, 'cmp': -0.3498}\n",
      "[Iter 14400 Task norm] Val Loss: 0.1629\n",
      "{'Angle Mean': 29.6068, 'Angle Median': 28.6004, 'Angle 11.25': 13.6618, 'Angle 22.5': 39.3632, 'Angle 30': 52.4259, 'cmp': -0.6331}\n",
      "[Iter 14400 Task dept] Val Loss: 0.8465\n",
      "{'abs_err': 0.8323, 'rel_err': 0.2859, 'sigma_1.25': 40.1178, 'sigma_1.25^2': 73.7947, 'sigma_1.25^3': 91.4301, 'cmp': -0.1955}\n",
      "======================================================================\n",
      "[Iter 14450 Task segm] Task Loss: 1.2641 Reg Loss: 42.0046 Train Loss: 6.3626\n",
      "[Iter 14450 Task norm] Task Loss: 0.0636 Reg Loss: 35.5203 Train Loss: 1.3073\n",
      "[Iter 14450 Task dept] Task Loss: 0.6978 Reg Loss: 30.2999 Train Loss: 3.5191\n",
      "[Iter 14450 Total] Train Loss: 3.7297\n",
      "======================================================================\n",
      "[Iter 14500 Task segm] Task Loss: 1.2826 Reg Loss: 21.8392 Train Loss: 6.4349\n",
      "[Iter 14500 Task norm] Task Loss: 0.0627 Reg Loss: 20.2147 Train Loss: 1.2740\n",
      "[Iter 14500 Task dept] Task Loss: 0.6877 Reg Loss: 19.0780 Train Loss: 3.4577\n",
      "[Iter 14500 Total] Train Loss: 3.7222\n",
      "======================================================================\n",
      "tau: 0.3845356110259071\n",
      "[Iter 14550 Task segm] Task Loss: 1.2670 Reg Loss: 40.3552 Train Loss: 6.3752\n",
      "[Iter 14550 Task norm] Task Loss: 0.0640 Reg Loss: 33.4333 Train Loss: 1.3142\n",
      "[Iter 14550 Task dept] Task Loss: 0.6907 Reg Loss: 31.5836 Train Loss: 3.4852\n",
      "[Iter 14550 Total] Train Loss: 3.7249\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Task Loss: 1.2892 Reg Loss: 21.7836 Train Loss: 6.4678\n",
      "[Iter 14600 Task norm] Task Loss: 0.0646 Reg Loss: 20.5009 Train Loss: 1.3131\n",
      "[Iter 14600 Task dept] Task Loss: 0.7014 Reg Loss: 19.0804 Train Loss: 3.5263\n",
      "[Iter 14600 Total] Train Loss: 3.7691\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Val Loss: 2.3013\n",
      "{'mIoU': 0.117, 'Pixel Acc': 0.4142, 'cmp': -0.4357}\n",
      "[Iter 14600 Task norm] Val Loss: 0.1078\n",
      "{'Angle Mean': 23.2053, 'Angle Median': 21.5234, 'Angle 11.25': 21.7811, 'Angle 22.5': 53.3108, 'Angle 30': 76.1434, 'cmp': -0.3204}\n",
      "[Iter 14600 Task dept] Val Loss: 0.7427\n",
      "{'abs_err': 0.7334, 'rel_err': 0.2792, 'sigma_1.25': 49.2193, 'sigma_1.25^2': 80.8584, 'sigma_1.25^3': 93.6363, 'cmp': -0.1058}\n",
      "======================================================================\n",
      "[Iter 14650 Task segm] Task Loss: 1.2811 Reg Loss: 43.1466 Train Loss: 6.4485\n",
      "[Iter 14650 Task norm] Task Loss: 0.0634 Reg Loss: 36.5947 Train Loss: 1.3040\n",
      "[Iter 14650 Task dept] Task Loss: 0.6714 Reg Loss: 31.4127 Train Loss: 3.3885\n",
      "[Iter 14650 Total] Train Loss: 3.7137\n",
      "======================================================================\n",
      "[Iter 14700 Task segm] Task Loss: 1.3296 Reg Loss: 21.1739 Train Loss: 6.6689\n",
      "[Iter 14700 Task norm] Task Loss: 0.0626 Reg Loss: 19.9855 Train Loss: 1.2717\n",
      "[Iter 14700 Task dept] Task Loss: 0.6769 Reg Loss: 19.0536 Train Loss: 3.4035\n",
      "[Iter 14700 Total] Train Loss: 3.7814\n",
      "======================================================================\n",
      "tau: 0.37107686464000034\n",
      "[Iter 14750 Task segm] Task Loss: 1.2743 Reg Loss: 39.5855 Train Loss: 6.4111\n",
      "[Iter 14750 Task norm] Task Loss: 0.0639 Reg Loss: 33.7243 Train Loss: 1.3112\n",
      "[Iter 14750 Task dept] Task Loss: 0.6754 Reg Loss: 29.8594 Train Loss: 3.4069\n",
      "[Iter 14750 Total] Train Loss: 3.7097\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Task Loss: 1.3064 Reg Loss: 21.0230 Train Loss: 6.5528\n",
      "[Iter 14800 Task norm] Task Loss: 0.0625 Reg Loss: 20.2706 Train Loss: 1.2710\n",
      "[Iter 14800 Task dept] Task Loss: 0.6982 Reg Loss: 19.1603 Train Loss: 3.5099\n",
      "[Iter 14800 Total] Train Loss: 3.7779\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Val Loss: 2.1621\n",
      "{'mIoU': 0.1261, 'Pixel Acc': 0.4227, 'cmp': -0.4119}\n",
      "[Iter 14800 Task norm] Val Loss: 0.1317\n",
      "{'Angle Mean': 26.0293, 'Angle Median': 25.0391, 'Angle 11.25': 19.495, 'Angle 22.5': 44.7468, 'Angle 30': 62.3818, 'cmp': -0.4707}\n",
      "[Iter 14800 Task dept] Val Loss: 0.7087\n",
      "{'abs_err': 0.6999, 'rel_err': 0.2677, 'sigma_1.25': 51.3359, 'sigma_1.25^2': 82.3016, 'sigma_1.25^3': 94.3163, 'cmp': -0.0737}\n",
      "======================================================================\n",
      "[Iter 14850 Task segm] Task Loss: 1.2610 Reg Loss: 39.8470 Train Loss: 6.3447\n",
      "[Iter 14850 Task norm] Task Loss: 0.0637 Reg Loss: 33.2507 Train Loss: 1.3072\n",
      "[Iter 14850 Task dept] Task Loss: 0.6709 Reg Loss: 31.6283 Train Loss: 3.3862\n",
      "[Iter 14850 Total] Train Loss: 3.6794\n",
      "======================================================================\n",
      "[Iter 14900 Task segm] Task Loss: 1.2509 Reg Loss: 21.2344 Train Loss: 6.2755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 14900 Task norm] Task Loss: 0.0637 Reg Loss: 20.1342 Train Loss: 1.2946\n",
      "[Iter 14900 Task dept] Task Loss: 0.6911 Reg Loss: 18.7288 Train Loss: 3.4743\n",
      "[Iter 14900 Total] Train Loss: 3.6815\n",
      "======================================================================\n",
      "tau: 0.3580891743776003\n",
      "[Iter 14950 Task segm] Task Loss: 1.2937 Reg Loss: 42.6066 Train Loss: 6.5112\n",
      "[Iter 14950 Task norm] Task Loss: 0.0631 Reg Loss: 34.0813 Train Loss: 1.2969\n",
      "[Iter 14950 Task dept] Task Loss: 0.6950 Reg Loss: 29.4492 Train Loss: 3.5044\n",
      "[Iter 14950 Total] Train Loss: 3.7708\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Task Loss: 1.2857 Reg Loss: 21.3524 Train Loss: 6.4497\n",
      "[Iter 15000 Task norm] Task Loss: 0.0620 Reg Loss: 20.0636 Train Loss: 1.2593\n",
      "[Iter 15000 Task dept] Task Loss: 0.6932 Reg Loss: 19.1517 Train Loss: 3.4854\n",
      "[Iter 15000 Total] Train Loss: 3.7315\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Val Loss: 2.0797\n",
      "{'mIoU': 0.133, 'Pixel Acc': 0.4364, 'cmp': -0.3878}\n",
      "[Iter 15000 Task norm] Val Loss: 0.1168\n",
      "{'Angle Mean': 24.2589, 'Angle Median': 22.7833, 'Angle 11.25': 21.4456, 'Angle 22.5': 49.2917, 'Angle 30': 69.8096, 'cmp': -0.3778}\n",
      "[Iter 15000 Task dept] Val Loss: 0.7536\n",
      "{'abs_err': 0.743, 'rel_err': 0.2699, 'sigma_1.25': 47.7988, 'sigma_1.25^2': 80.1473, 'sigma_1.25^3': 93.9607, 'cmp': -0.1073}\n",
      "======================================================================\n",
      "[Iter 15050 Task segm] Task Loss: 1.3116 Reg Loss: 41.8119 Train Loss: 6.5997\n",
      "[Iter 15050 Task norm] Task Loss: 0.0636 Reg Loss: 35.0067 Train Loss: 1.3068\n",
      "[Iter 15050 Task dept] Task Loss: 0.6972 Reg Loss: 32.7443 Train Loss: 3.5186\n",
      "[Iter 15050 Total] Train Loss: 3.8084\n",
      "======================================================================\n",
      "[Iter 15100 Task segm] Task Loss: 1.2425 Reg Loss: 21.8019 Train Loss: 6.2345\n",
      "[Iter 15100 Task norm] Task Loss: 0.0626 Reg Loss: 19.7071 Train Loss: 1.2719\n",
      "[Iter 15100 Task dept] Task Loss: 0.6972 Reg Loss: 19.3605 Train Loss: 3.5056\n",
      "[Iter 15100 Total] Train Loss: 3.6707\n",
      "======================================================================\n",
      "tau: 0.34555605327438427\n",
      "[Iter 15150 Task segm] Task Loss: 1.2446 Reg Loss: 42.3587 Train Loss: 6.2655\n",
      "[Iter 15150 Task norm] Task Loss: 0.0628 Reg Loss: 34.4057 Train Loss: 1.2911\n",
      "[Iter 15150 Task dept] Task Loss: 0.6956 Reg Loss: 30.4637 Train Loss: 3.5087\n",
      "[Iter 15150 Total] Train Loss: 3.6884\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Task Loss: 1.2533 Reg Loss: 20.8367 Train Loss: 6.2874\n",
      "[Iter 15200 Task norm] Task Loss: 0.0639 Reg Loss: 20.2033 Train Loss: 1.2989\n",
      "[Iter 15200 Task dept] Task Loss: 0.6838 Reg Loss: 18.5888 Train Loss: 3.4375\n",
      "[Iter 15200 Total] Train Loss: 3.6746\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Val Loss: 1.7531\n",
      "{'mIoU': 0.1827, 'Pixel Acc': 0.5026, 'cmp': -0.241}\n",
      "[Iter 15200 Task norm] Val Loss: 0.1048\n",
      "{'Angle Mean': 22.9073, 'Angle Median': 21.1103, 'Angle 11.25': 22.2475, 'Angle 22.5': 54.1268, 'Angle 30': 75.2584, 'cmp': -0.3083}\n",
      "[Iter 15200 Task dept] Val Loss: 0.6853\n",
      "{'abs_err': 0.6809, 'rel_err': 0.282, 'sigma_1.25': 53.9573, 'sigma_1.25^2': 83.3634, 'sigma_1.25^3': 94.1702, 'cmp': -0.0678}\n",
      "======================================================================\n",
      "[Iter 15250 Task segm] Task Loss: 1.2857 Reg Loss: 44.8004 Train Loss: 6.4733\n",
      "[Iter 15250 Task norm] Task Loss: 0.0642 Reg Loss: 38.9304 Train Loss: 1.3227\n",
      "[Iter 15250 Task dept] Task Loss: 0.6959 Reg Loss: 30.9910 Train Loss: 3.5107\n",
      "[Iter 15250 Total] Train Loss: 3.7689\n",
      "======================================================================\n",
      "[Iter 15300 Task segm] Task Loss: 1.2888 Reg Loss: 21.7538 Train Loss: 6.4657\n",
      "[Iter 15300 Task norm] Task Loss: 0.0625 Reg Loss: 19.7338 Train Loss: 1.2694\n",
      "[Iter 15300 Task dept] Task Loss: 0.6746 Reg Loss: 18.9664 Train Loss: 3.3918\n",
      "[Iter 15300 Total] Train Loss: 3.7090\n",
      "======================================================================\n",
      "tau: 0.3334615914097808\n",
      "[Iter 15350 Task segm] Task Loss: 1.2829 Reg Loss: 43.8602 Train Loss: 6.4585\n",
      "[Iter 15350 Task norm] Task Loss: 0.0625 Reg Loss: 35.3310 Train Loss: 1.2850\n",
      "[Iter 15350 Task dept] Task Loss: 0.6885 Reg Loss: 31.5757 Train Loss: 3.4742\n",
      "[Iter 15350 Total] Train Loss: 3.7392\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Task Loss: 1.3230 Reg Loss: 21.3895 Train Loss: 6.6363\n",
      "[Iter 15400 Task norm] Task Loss: 0.0625 Reg Loss: 19.9360 Train Loss: 1.2702\n",
      "[Iter 15400 Task dept] Task Loss: 0.6910 Reg Loss: 19.0521 Train Loss: 3.4740\n",
      "[Iter 15400 Total] Train Loss: 3.7935\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Val Loss: 1.8477\n",
      "{'mIoU': 0.1705, 'Pixel Acc': 0.4785, 'cmp': -0.2838}\n",
      "[Iter 15400 Task norm] Val Loss: 0.1274\n",
      "{'Angle Mean': 25.4382, 'Angle Median': 24.1788, 'Angle 11.25': 20.3105, 'Angle 22.5': 46.2949, 'Angle 30': 65.5086, 'cmp': -0.4357}\n",
      "[Iter 15400 Task dept] Val Loss: 0.7511\n",
      "{'abs_err': 0.7401, 'rel_err': 0.2665, 'sigma_1.25': 48.2997, 'sigma_1.25^2': 79.5371, 'sigma_1.25^3': 93.4078, 'cmp': -0.1045}\n",
      "======================================================================\n",
      "[Iter 15450 Task segm] Task Loss: 1.2548 Reg Loss: 44.9761 Train Loss: 6.3190\n",
      "[Iter 15450 Task norm] Task Loss: 0.0622 Reg Loss: 35.6314 Train Loss: 1.2802\n",
      "[Iter 15450 Task dept] Task Loss: 0.6808 Reg Loss: 30.8980 Train Loss: 3.4350\n",
      "[Iter 15450 Total] Train Loss: 3.6781\n",
      "======================================================================\n",
      "[Iter 15500 Task segm] Task Loss: 1.2961 Reg Loss: 20.8995 Train Loss: 6.5015\n",
      "[Iter 15500 Task norm] Task Loss: 0.0634 Reg Loss: 19.7763 Train Loss: 1.2883\n",
      "[Iter 15500 Task dept] Task Loss: 0.6705 Reg Loss: 18.8798 Train Loss: 3.3714\n",
      "[Iter 15500 Total] Train Loss: 3.7204\n",
      "======================================================================\n",
      "tau: 0.32179043571043847\n",
      "[Iter 15550 Task segm] Task Loss: 1.2945 Reg Loss: 42.3657 Train Loss: 6.5150\n",
      "[Iter 15550 Task norm] Task Loss: 0.0646 Reg Loss: 34.3443 Train Loss: 1.3257\n",
      "[Iter 15550 Task dept] Task Loss: 0.6860 Reg Loss: 30.1445 Train Loss: 3.4604\n",
      "[Iter 15550 Total] Train Loss: 3.7670\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Task Loss: 1.2718 Reg Loss: 21.2754 Train Loss: 6.3804\n",
      "[Iter 15600 Task norm] Task Loss: 0.0641 Reg Loss: 19.9509 Train Loss: 1.3027\n",
      "[Iter 15600 Task dept] Task Loss: 0.6796 Reg Loss: 18.8552 Train Loss: 3.4167\n",
      "[Iter 15600 Total] Train Loss: 3.6999\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Val Loss: 1.6919\n",
      "{'mIoU': 0.1967, 'Pixel Acc': 0.5107, 'cmp': -0.2088}\n",
      "[Iter 15600 Task norm] Val Loss: 0.0771\n",
      "{'Angle Mean': 19.8621, 'Angle Median': 17.5485, 'Angle 11.25': 21.5375, 'Angle 22.5': 69.7007, 'Angle 30': 85.124, 'cmp': -0.1619}\n",
      "[Iter 15600 Task dept] Val Loss: 0.7144\n",
      "{'abs_err': 0.7132, 'rel_err': 0.3119, 'sigma_1.25': 52.9368, 'sigma_1.25^2': 81.5884, 'sigma_1.25^3': 92.8992, 'cmp': -0.1124}\n",
      "======================================================================\n",
      "[Iter 15650 Task segm] Task Loss: 1.2495 Reg Loss: 44.3307 Train Loss: 6.2918\n",
      "[Iter 15650 Task norm] Task Loss: 0.0630 Reg Loss: 36.5372 Train Loss: 1.2971\n",
      "[Iter 15650 Task dept] Task Loss: 0.6782 Reg Loss: 31.4725 Train Loss: 3.4227\n",
      "[Iter 15650 Total] Train Loss: 3.6705\n",
      "======================================================================\n",
      "[Iter 15700 Task segm] Task Loss: 1.3059 Reg Loss: 21.2060 Train Loss: 6.5506\n",
      "[Iter 15700 Task norm] Task Loss: 0.0628 Reg Loss: 20.1411 Train Loss: 1.2764\n",
      "[Iter 15700 Task dept] Task Loss: 0.6882 Reg Loss: 18.9447 Train Loss: 3.4598\n",
      "[Iter 15700 Total] Train Loss: 3.7623\n",
      "======================================================================\n",
      "tau: 0.3105277704605731\n",
      "[Iter 15750 Task segm] Task Loss: 1.2675 Reg Loss: 43.7620 Train Loss: 6.3811\n",
      "[Iter 15750 Task norm] Task Loss: 0.0647 Reg Loss: 34.2151 Train Loss: 1.3290\n",
      "[Iter 15750 Task dept] Task Loss: 0.7050 Reg Loss: 29.1821 Train Loss: 3.5543\n",
      "[Iter 15750 Total] Train Loss: 3.7548\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 15800 Task segm] Task Loss: 1.2935 Reg Loss: 21.1342 Train Loss: 6.4888\n",
      "[Iter 15800 Task norm] Task Loss: 0.0637 Reg Loss: 19.8816 Train Loss: 1.2935\n",
      "[Iter 15800 Task dept] Task Loss: 0.6718 Reg Loss: 18.7034 Train Loss: 3.3778\n",
      "[Iter 15800 Total] Train Loss: 3.7200\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Val Loss: 1.6627\n",
      "{'mIoU': 0.1957, 'Pixel Acc': 0.522, 'cmp': -0.201}\n",
      "[Iter 15800 Task norm] Val Loss: 0.1113\n",
      "{'Angle Mean': 23.6121, 'Angle Median': 22.2102, 'Angle 11.25': 22.799, 'Angle 22.5': 50.7082, 'Angle 30': 71.2529, 'cmp': -0.3474}\n",
      "[Iter 15800 Task dept] Val Loss: 0.7606\n",
      "{'abs_err': 0.75, 'rel_err': 0.2729, 'sigma_1.25': 48.167, 'sigma_1.25^2': 79.1609, 'sigma_1.25^3': 93.1102, 'cmp': -0.1147}\n",
      "======================================================================\n",
      "[Iter 15850 Task segm] Task Loss: 1.2813 Reg Loss: 41.7311 Train Loss: 6.4485\n",
      "[Iter 15850 Task norm] Task Loss: 0.0634 Reg Loss: 35.8425 Train Loss: 1.3043\n",
      "[Iter 15850 Task dept] Task Loss: 0.6788 Reg Loss: 30.5853 Train Loss: 3.4248\n",
      "[Iter 15850 Total] Train Loss: 3.7258\n",
      "======================================================================\n",
      "[Iter 15900 Task segm] Task Loss: 1.2839 Reg Loss: 21.0106 Train Loss: 6.4404\n",
      "[Iter 15900 Task norm] Task Loss: 0.0630 Reg Loss: 20.5179 Train Loss: 1.2803\n",
      "[Iter 15900 Task dept] Task Loss: 0.6871 Reg Loss: 18.6808 Train Loss: 3.4542\n",
      "[Iter 15900 Total] Train Loss: 3.7249\n",
      "======================================================================\n",
      "tau: 0.29965929849445305\n",
      "[Iter 15950 Task segm] Task Loss: 1.2669 Reg Loss: 43.3416 Train Loss: 6.3778\n",
      "[Iter 15950 Task norm] Task Loss: 0.0649 Reg Loss: 35.0739 Train Loss: 1.3336\n",
      "[Iter 15950 Task dept] Task Loss: 0.6623 Reg Loss: 32.1155 Train Loss: 3.3435\n",
      "[Iter 15950 Total] Train Loss: 3.6850\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Task Loss: 1.2955 Reg Loss: 21.4676 Train Loss: 6.4989\n",
      "[Iter 16000 Task norm] Task Loss: 0.0621 Reg Loss: 20.0246 Train Loss: 1.2627\n",
      "[Iter 16000 Task dept] Task Loss: 0.7238 Reg Loss: 18.7526 Train Loss: 3.6375\n",
      "[Iter 16000 Total] Train Loss: 3.7997\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Val Loss: 1.6626\n",
      "{'mIoU': 0.1946, 'Pixel Acc': 0.5213, 'cmp': -0.2037}\n",
      "[Iter 16000 Task norm] Val Loss: 0.1339\n",
      "{'Angle Mean': 26.203, 'Angle Median': 25.1655, 'Angle 11.25': 19.8707, 'Angle 22.5': 44.9238, 'Angle 30': 60.7834, 'cmp': -0.4756}\n",
      "[Iter 16000 Task dept] Val Loss: 0.6722\n",
      "{'abs_err': 0.6671, 'rel_err': 0.271, 'sigma_1.25': 55.3299, 'sigma_1.25^2': 84.1047, 'sigma_1.25^3': 94.6339, 'cmp': -0.0471}\n",
      "======================================================================\n",
      "[Iter 16050 Task segm] Task Loss: 1.3344 Reg Loss: 42.3896 Train Loss: 6.7145\n",
      "[Iter 16050 Task norm] Task Loss: 0.0634 Reg Loss: 36.6061 Train Loss: 1.3056\n",
      "[Iter 16050 Task dept] Task Loss: 0.6758 Reg Loss: 30.0861 Train Loss: 3.4089\n",
      "[Iter 16050 Total] Train Loss: 3.8097\n",
      "======================================================================\n",
      "[Iter 16100 Task segm] Task Loss: 1.2675 Reg Loss: 20.7649 Train Loss: 6.3582\n",
      "[Iter 16100 Task norm] Task Loss: 0.0640 Reg Loss: 20.0053 Train Loss: 1.3009\n",
      "[Iter 16100 Task dept] Task Loss: 0.6753 Reg Loss: 18.7835 Train Loss: 3.3951\n",
      "[Iter 16100 Total] Train Loss: 3.6848\n",
      "======================================================================\n",
      "tau: 0.2891712230471472\n",
      "[Iter 16150 Task segm] Task Loss: 1.2851 Reg Loss: 42.1746 Train Loss: 6.4675\n",
      "[Iter 16150 Task norm] Task Loss: 0.0624 Reg Loss: 35.4510 Train Loss: 1.2845\n",
      "[Iter 16150 Task dept] Task Loss: 0.6918 Reg Loss: 32.4827 Train Loss: 3.4915\n",
      "[Iter 16150 Total] Train Loss: 3.7478\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Task Loss: 1.2599 Reg Loss: 20.9715 Train Loss: 6.3203\n",
      "[Iter 16200 Task norm] Task Loss: 0.0635 Reg Loss: 20.2897 Train Loss: 1.2898\n",
      "[Iter 16200 Task dept] Task Loss: 0.7111 Reg Loss: 18.5993 Train Loss: 3.5740\n",
      "[Iter 16200 Total] Train Loss: 3.7280\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Val Loss: 1.7634\n",
      "{'mIoU': 0.1866, 'Pixel Acc': 0.5074, 'cmp': -0.23}\n",
      "[Iter 16200 Task norm] Val Loss: 0.1552\n",
      "{'Angle Mean': 28.6501, 'Angle Median': 27.9068, 'Angle 11.25': 16.4921, 'Angle 22.5': 41.049, 'Angle 30': 53.4397, 'cmp': -0.5893}\n",
      "[Iter 16200 Task dept] Val Loss: 0.6728\n",
      "{'abs_err': 0.6698, 'rel_err': 0.2835, 'sigma_1.25': 55.2616, 'sigma_1.25^2': 84.1236, 'sigma_1.25^3': 94.4647, 'cmp': -0.0585}\n",
      "======================================================================\n",
      "[Iter 16250 Task segm] Task Loss: 1.2851 Reg Loss: 42.8504 Train Loss: 6.4682\n",
      "[Iter 16250 Task norm] Task Loss: 0.0638 Reg Loss: 36.3140 Train Loss: 1.3125\n",
      "[Iter 16250 Task dept] Task Loss: 0.6923 Reg Loss: 31.1463 Train Loss: 3.4924\n",
      "[Iter 16250 Total] Train Loss: 3.7577\n",
      "======================================================================\n",
      "[Iter 16300 Task segm] Task Loss: 1.3218 Reg Loss: 21.2879 Train Loss: 6.6304\n",
      "[Iter 16300 Task norm] Task Loss: 0.0622 Reg Loss: 19.7969 Train Loss: 1.2632\n",
      "[Iter 16300 Task dept] Task Loss: 0.7118 Reg Loss: 18.6865 Train Loss: 3.5776\n",
      "[Iter 16300 Total] Train Loss: 3.8238\n",
      "======================================================================\n",
      "tau: 0.279050230240497\n",
      "[Iter 16350 Task segm] Task Loss: 1.2532 Reg Loss: 43.5351 Train Loss: 6.3095\n",
      "[Iter 16350 Task norm] Task Loss: 0.0627 Reg Loss: 36.5879 Train Loss: 1.2903\n",
      "[Iter 16350 Task dept] Task Loss: 0.7016 Reg Loss: 32.5555 Train Loss: 3.5406\n",
      "[Iter 16350 Total] Train Loss: 3.7135\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Task Loss: 1.2337 Reg Loss: 20.8867 Train Loss: 6.1896\n",
      "[Iter 16400 Task norm] Task Loss: 0.0638 Reg Loss: 19.4487 Train Loss: 1.2958\n",
      "[Iter 16400 Task dept] Task Loss: 0.6726 Reg Loss: 18.1653 Train Loss: 3.3812\n",
      "[Iter 16400 Total] Train Loss: 3.6222\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Val Loss: 1.6688\n",
      "{'mIoU': 0.1975, 'Pixel Acc': 0.5229, 'cmp': -0.197}\n",
      "[Iter 16400 Task norm] Val Loss: 0.0758\n",
      "{'Angle Mean': 19.8278, 'Angle Median': 17.6775, 'Angle 11.25': 20.5436, 'Angle 22.5': 70.2214, 'Angle 30': 85.5458, 'cmp': -0.1666}\n",
      "[Iter 16400 Task dept] Val Loss: 0.6753\n",
      "{'abs_err': 0.6743, 'rel_err': 0.288, 'sigma_1.25': 55.3251, 'sigma_1.25^2': 83.8031, 'sigma_1.25^3': 94.1797, 'cmp': -0.0647}\n",
      "======================================================================\n",
      "[Iter 16450 Task segm] Task Loss: 1.2725 Reg Loss: 43.9485 Train Loss: 6.4066\n",
      "[Iter 16450 Task norm] Task Loss: 0.0632 Reg Loss: 36.7884 Train Loss: 1.2999\n",
      "[Iter 16450 Task dept] Task Loss: 0.6876 Reg Loss: 31.4473 Train Loss: 3.4696\n",
      "[Iter 16450 Total] Train Loss: 3.7254\n",
      "======================================================================\n",
      "[Iter 16500 Task segm] Task Loss: 1.3287 Reg Loss: 21.4616 Train Loss: 6.6649\n",
      "[Iter 16500 Task norm] Task Loss: 0.0633 Reg Loss: 20.0270 Train Loss: 1.2858\n",
      "[Iter 16500 Task dept] Task Loss: 0.6916 Reg Loss: 18.8755 Train Loss: 3.4768\n",
      "[Iter 16500 Total] Train Loss: 3.8092\n",
      "======================================================================\n",
      "tau: 0.2692834721820796\n",
      "[Iter 16550 Task segm] Task Loss: 1.3012 Reg Loss: 42.3368 Train Loss: 6.5482\n",
      "[Iter 16550 Task norm] Task Loss: 0.0632 Reg Loss: 37.1250 Train Loss: 1.3017\n",
      "[Iter 16550 Task dept] Task Loss: 0.6969 Reg Loss: 31.2913 Train Loss: 3.5158\n",
      "[Iter 16550 Total] Train Loss: 3.7885\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Task Loss: 1.3362 Reg Loss: 21.4330 Train Loss: 6.7024\n",
      "[Iter 16600 Task norm] Task Loss: 0.0641 Reg Loss: 19.7867 Train Loss: 1.3020\n",
      "[Iter 16600 Task dept] Task Loss: 0.6778 Reg Loss: 18.4574 Train Loss: 3.4075\n",
      "[Iter 16600 Total] Train Loss: 3.8040\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Val Loss: 1.7382\n",
      "{'mIoU': 0.1845, 'Pixel Acc': 0.5103, 'cmp': -0.2314}\n",
      "[Iter 16600 Task norm] Val Loss: 0.1188\n",
      "{'Angle Mean': 24.4669, 'Angle Median': 22.9915, 'Angle 11.25': 21.9176, 'Angle 22.5': 48.8642, 'Angle 30': 67.7472, 'cmp': -0.3864}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 16600 Task dept] Val Loss: 0.6515\n",
      "{'abs_err': 0.6514, 'rel_err': 0.2819, 'sigma_1.25': 56.8762, 'sigma_1.25^2': 84.8397, 'sigma_1.25^3': 94.6883, 'cmp': -0.0436}\n",
      "======================================================================\n",
      "[Iter 16650 Task segm] Task Loss: 1.2813 Reg Loss: 44.6801 Train Loss: 6.4512\n",
      "[Iter 16650 Task norm] Task Loss: 0.0646 Reg Loss: 35.1747 Train Loss: 1.3275\n",
      "[Iter 16650 Task dept] Task Loss: 0.6768 Reg Loss: 30.3186 Train Loss: 3.4145\n",
      "[Iter 16650 Total] Train Loss: 3.7311\n",
      "======================================================================\n",
      "[Iter 16700 Task segm] Task Loss: 1.3126 Reg Loss: 21.1396 Train Loss: 6.5842\n",
      "[Iter 16700 Task norm] Task Loss: 0.0624 Reg Loss: 20.3545 Train Loss: 1.2674\n",
      "[Iter 16700 Task dept] Task Loss: 0.6925 Reg Loss: 18.4068 Train Loss: 3.4810\n",
      "[Iter 16700 Total] Train Loss: 3.7775\n",
      "======================================================================\n",
      "tau: 0.2598585506557068\n",
      "[Iter 16750 Task segm] Task Loss: 1.2692 Reg Loss: 44.8026 Train Loss: 6.3906\n",
      "[Iter 16750 Task norm] Task Loss: 0.0630 Reg Loss: 36.3311 Train Loss: 1.2966\n",
      "[Iter 16750 Task dept] Task Loss: 0.6813 Reg Loss: 30.0448 Train Loss: 3.4367\n",
      "[Iter 16750 Total] Train Loss: 3.7079\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Task Loss: 1.3118 Reg Loss: 21.2856 Train Loss: 6.5803\n",
      "[Iter 16800 Task norm] Task Loss: 0.0637 Reg Loss: 19.7380 Train Loss: 1.2939\n",
      "[Iter 16800 Task dept] Task Loss: 0.7139 Reg Loss: 18.4776 Train Loss: 3.5879\n",
      "[Iter 16800 Total] Train Loss: 3.8207\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Val Loss: 1.7766\n",
      "{'mIoU': 0.1867, 'Pixel Acc': 0.5089, 'cmp': -0.2285}\n",
      "[Iter 16800 Task norm] Val Loss: 0.0824\n",
      "{'Angle Mean': 20.4769, 'Angle Median': 18.5335, 'Angle 11.25': 22.4344, 'Angle 22.5': 65.7012, 'Angle 30': 83.7342, 'cmp': -0.1918}\n",
      "[Iter 16800 Task dept] Val Loss: 0.6854\n",
      "{'abs_err': 0.6806, 'rel_err': 0.2734, 'sigma_1.25': 54.0993, 'sigma_1.25^2': 83.2885, 'sigma_1.25^3': 94.517, 'cmp': -0.0597}\n",
      "======================================================================\n",
      "[Iter 16850 Task segm] Task Loss: 1.2485 Reg Loss: 41.9388 Train Loss: 6.2844\n",
      "[Iter 16850 Task norm] Task Loss: 0.0634 Reg Loss: 35.3642 Train Loss: 1.3033\n",
      "[Iter 16850 Task dept] Task Loss: 0.6820 Reg Loss: 29.3302 Train Loss: 3.4392\n",
      "[Iter 16850 Total] Train Loss: 3.6756\n",
      "======================================================================\n",
      "[Iter 16900 Task segm] Task Loss: 1.2653 Reg Loss: 21.1752 Train Loss: 6.3478\n",
      "[Iter 16900 Task norm] Task Loss: 0.0624 Reg Loss: 19.5918 Train Loss: 1.2683\n",
      "[Iter 16900 Task dept] Task Loss: 0.6916 Reg Loss: 18.3908 Train Loss: 3.4765\n",
      "[Iter 16900 Total] Train Loss: 3.6975\n",
      "======================================================================\n",
      "tau: 0.25076350138275705\n",
      "[Iter 16950 Task segm] Task Loss: 1.2343 Reg Loss: 43.4477 Train Loss: 6.2148\n",
      "[Iter 16950 Task norm] Task Loss: 0.0627 Reg Loss: 37.4826 Train Loss: 1.2907\n",
      "[Iter 16950 Task dept] Task Loss: 0.6768 Reg Loss: 31.2974 Train Loss: 3.4151\n",
      "[Iter 16950 Total] Train Loss: 3.6402\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Task Loss: 1.2754 Reg Loss: 21.1603 Train Loss: 6.3981\n",
      "[Iter 17000 Task norm] Task Loss: 0.0632 Reg Loss: 19.8576 Train Loss: 1.2836\n",
      "[Iter 17000 Task dept] Task Loss: 0.7014 Reg Loss: 17.9815 Train Loss: 3.5250\n",
      "[Iter 17000 Total] Train Loss: 3.7356\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Val Loss: 1.8065\n",
      "{'mIoU': 0.1741, 'Pixel Acc': 0.4921, 'cmp': -0.2658}\n",
      "[Iter 17000 Task norm] Val Loss: 0.1480\n",
      "{'Angle Mean': 27.8033, 'Angle Median': 27.097, 'Angle 11.25': 18.0354, 'Angle 22.5': 41.963, 'Angle 30': 55.4713, 'cmp': -0.5521}\n",
      "[Iter 17000 Task dept] Val Loss: 0.7117\n",
      "{'abs_err': 0.7046, 'rel_err': 0.2718, 'sigma_1.25': 52.7124, 'sigma_1.25^2': 81.8609, 'sigma_1.25^3': 93.7648, 'cmp': -0.0758}\n",
      "======================================================================\n",
      "[Iter 17050 Task segm] Task Loss: 1.2742 Reg Loss: 43.1086 Train Loss: 6.4142\n",
      "[Iter 17050 Task norm] Task Loss: 0.0618 Reg Loss: 36.9639 Train Loss: 1.2728\n",
      "[Iter 17050 Task dept] Task Loss: 0.6898 Reg Loss: 31.3137 Train Loss: 3.4801\n",
      "[Iter 17050 Total] Train Loss: 3.7224\n",
      "======================================================================\n",
      "[Iter 17100 Task segm] Task Loss: 1.2280 Reg Loss: 21.2227 Train Loss: 6.1612\n",
      "[Iter 17100 Task norm] Task Loss: 0.0621 Reg Loss: 19.9640 Train Loss: 1.2618\n",
      "[Iter 17100 Task dept] Task Loss: 0.6939 Reg Loss: 18.9036 Train Loss: 3.4885\n",
      "[Iter 17100 Total] Train Loss: 3.6372\n",
      "======================================================================\n",
      "tau: 0.24198677883436054\n",
      "[Iter 17150 Task segm] Task Loss: 1.2834 Reg Loss: 45.7927 Train Loss: 6.4628\n",
      "[Iter 17150 Task norm] Task Loss: 0.0645 Reg Loss: 38.1354 Train Loss: 1.3290\n",
      "[Iter 17150 Task dept] Task Loss: 0.6809 Reg Loss: 31.6642 Train Loss: 3.4361\n",
      "[Iter 17150 Total] Train Loss: 3.7426\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Task Loss: 1.3156 Reg Loss: 20.8949 Train Loss: 6.5991\n",
      "[Iter 17200 Task norm] Task Loss: 0.0636 Reg Loss: 19.8938 Train Loss: 1.2912\n",
      "[Iter 17200 Task dept] Task Loss: 0.6730 Reg Loss: 17.9893 Train Loss: 3.3830\n",
      "[Iter 17200 Total] Train Loss: 3.7578\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Val Loss: 1.6899\n",
      "{'mIoU': 0.1907, 'Pixel Acc': 0.5212, 'cmp': -0.2109}\n",
      "[Iter 17200 Task norm] Val Loss: 0.1299\n",
      "{'Angle Mean': 25.7272, 'Angle Median': 24.5273, 'Angle 11.25': 20.8422, 'Angle 22.5': 45.8721, 'Angle 30': 62.5175, 'cmp': -0.449}\n",
      "[Iter 17200 Task dept] Val Loss: 0.7243\n",
      "{'abs_err': 0.7262, 'rel_err': 0.3265, 'sigma_1.25': 52.1805, 'sigma_1.25^2': 81.7459, 'sigma_1.25^3': 93.1999, 'cmp': -0.1299}\n",
      "======================================================================\n",
      "[Iter 17250 Task segm] Task Loss: 1.2585 Reg Loss: 46.0613 Train Loss: 6.3385\n",
      "[Iter 17250 Task norm] Task Loss: 0.0632 Reg Loss: 36.7934 Train Loss: 1.3005\n",
      "[Iter 17250 Task dept] Task Loss: 0.6666 Reg Loss: 30.1808 Train Loss: 3.3632\n",
      "[Iter 17250 Total] Train Loss: 3.6674\n",
      "======================================================================\n",
      "[Iter 17300 Task segm] Task Loss: 1.3320 Reg Loss: 20.7649 Train Loss: 6.6806\n",
      "[Iter 17300 Task norm] Task Loss: 0.0635 Reg Loss: 19.4314 Train Loss: 1.2885\n",
      "[Iter 17300 Task dept] Task Loss: 0.7014 Reg Loss: 18.6722 Train Loss: 3.5258\n",
      "[Iter 17300 Total] Train Loss: 3.8316\n",
      "======================================================================\n",
      "tau: 0.2335172415751579\n",
      "[Iter 17350 Task segm] Task Loss: 1.2978 Reg Loss: 43.6659 Train Loss: 6.5327\n",
      "[Iter 17350 Task norm] Task Loss: 0.0636 Reg Loss: 35.6685 Train Loss: 1.3086\n",
      "[Iter 17350 Task dept] Task Loss: 0.6751 Reg Loss: 31.4149 Train Loss: 3.4067\n",
      "[Iter 17350 Total] Train Loss: 3.7493\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Task Loss: 1.2519 Reg Loss: 21.1997 Train Loss: 6.2805\n",
      "[Iter 17400 Task norm] Task Loss: 0.0646 Reg Loss: 19.9925 Train Loss: 1.3127\n",
      "[Iter 17400 Task dept] Task Loss: 0.6911 Reg Loss: 18.0056 Train Loss: 3.4736\n",
      "[Iter 17400 Total] Train Loss: 3.6890\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Val Loss: 1.6750\n",
      "{'mIoU': 0.197, 'Pixel Acc': 0.5184, 'cmp': -0.2018}\n",
      "[Iter 17400 Task norm] Val Loss: 0.0736\n",
      "{'Angle Mean': 19.6625, 'Angle Median': 17.5601, 'Angle 11.25': 19.5913, 'Angle 22.5': 71.1376, 'Angle 30': 86.091, 'cmp': -0.1648}\n",
      "[Iter 17400 Task dept] Val Loss: 0.6589\n",
      "{'abs_err': 0.6538, 'rel_err': 0.2609, 'sigma_1.25': 55.7153, 'sigma_1.25^2': 84.8321, 'sigma_1.25^3': 95.0624, 'cmp': -0.0308}\n",
      "======================================================================\n",
      "[Iter 17450 Task segm] Task Loss: 1.2772 Reg Loss: 44.6525 Train Loss: 6.4304\n",
      "[Iter 17450 Task norm] Task Loss: 0.0626 Reg Loss: 36.5426 Train Loss: 1.2891\n",
      "[Iter 17450 Task dept] Task Loss: 0.6707 Reg Loss: 30.0642 Train Loss: 3.3838\n",
      "[Iter 17450 Total] Train Loss: 3.7011\n",
      "======================================================================\n",
      "[Iter 17500 Task segm] Task Loss: 1.2489 Reg Loss: 20.7160 Train Loss: 6.2652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 17500 Task norm] Task Loss: 0.0622 Reg Loss: 19.2994 Train Loss: 1.2632\n",
      "[Iter 17500 Task dept] Task Loss: 0.6851 Reg Loss: 18.3872 Train Loss: 3.4441\n",
      "[Iter 17500 Total] Train Loss: 3.6575\n",
      "======================================================================\n",
      "tau: 0.22534413812002738\n",
      "[Iter 17550 Task segm] Task Loss: 1.3087 Reg Loss: 43.0544 Train Loss: 6.5866\n",
      "[Iter 17550 Task norm] Task Loss: 0.0636 Reg Loss: 37.6493 Train Loss: 1.3088\n",
      "[Iter 17550 Task dept] Task Loss: 0.6925 Reg Loss: 30.9070 Train Loss: 3.4932\n",
      "[Iter 17550 Total] Train Loss: 3.7962\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Task Loss: 1.2547 Reg Loss: 20.7722 Train Loss: 6.2944\n",
      "[Iter 17600 Task norm] Task Loss: 0.0648 Reg Loss: 19.8497 Train Loss: 1.3160\n",
      "[Iter 17600 Task dept] Task Loss: 0.6970 Reg Loss: 18.1999 Train Loss: 3.5034\n",
      "[Iter 17600 Total] Train Loss: 3.7046\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Val Loss: 1.6518\n",
      "{'mIoU': 0.2065, 'Pixel Acc': 0.5276, 'cmp': -0.1767}\n",
      "[Iter 17600 Task norm] Val Loss: 0.1037\n",
      "{'Angle Mean': 22.7775, 'Angle Median': 21.1185, 'Angle 11.25': 22.8311, 'Angle 22.5': 54.0175, 'Angle 30': 75.7624, 'cmp': -0.3027}\n",
      "[Iter 17600 Task dept] Val Loss: 0.6480\n",
      "{'abs_err': 0.6463, 'rel_err': 0.2739, 'sigma_1.25': 57.4044, 'sigma_1.25^2': 84.9101, 'sigma_1.25^3': 94.6645, 'cmp': -0.0335}\n",
      "======================================================================\n",
      "[Iter 17650 Task segm] Task Loss: 1.2745 Reg Loss: 45.4419 Train Loss: 6.4179\n",
      "[Iter 17650 Task norm] Task Loss: 0.0627 Reg Loss: 36.9470 Train Loss: 1.2918\n",
      "[Iter 17650 Task dept] Task Loss: 0.6912 Reg Loss: 33.4495 Train Loss: 3.4892\n",
      "[Iter 17650 Total] Train Loss: 3.7330\n",
      "======================================================================\n",
      "[Iter 17700 Task segm] Task Loss: 1.2645 Reg Loss: 21.2809 Train Loss: 6.3438\n",
      "[Iter 17700 Task norm] Task Loss: 0.0631 Reg Loss: 19.0617 Train Loss: 1.2814\n",
      "[Iter 17700 Task dept] Task Loss: 0.6851 Reg Loss: 18.5561 Train Loss: 3.4442\n",
      "[Iter 17700 Total] Train Loss: 3.6898\n",
      "======================================================================\n",
      "tau: 0.2174570932858264\n",
      "[Iter 17750 Task segm] Task Loss: 1.2714 Reg Loss: 44.6667 Train Loss: 6.4017\n",
      "[Iter 17750 Task norm] Task Loss: 0.0640 Reg Loss: 36.7454 Train Loss: 1.3163\n",
      "[Iter 17750 Task dept] Task Loss: 0.7203 Reg Loss: 30.2644 Train Loss: 3.6320\n",
      "[Iter 17750 Total] Train Loss: 3.7834\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Task Loss: 1.2264 Reg Loss: 21.2861 Train Loss: 6.1532\n",
      "[Iter 17800 Task norm] Task Loss: 0.0637 Reg Loss: 19.0725 Train Loss: 1.2929\n",
      "[Iter 17800 Task dept] Task Loss: 0.6912 Reg Loss: 18.0056 Train Loss: 3.4739\n",
      "[Iter 17800 Total] Train Loss: 3.6400\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Val Loss: 1.8090\n",
      "{'mIoU': 0.1809, 'Pixel Acc': 0.4881, 'cmp': -0.2568}\n",
      "[Iter 17800 Task norm] Val Loss: 0.1057\n",
      "{'Angle Mean': 22.9737, 'Angle Median': 21.13, 'Angle 11.25': 22.745, 'Angle 22.5': 53.883, 'Angle 30': 74.6081, 'cmp': -0.3087}\n",
      "[Iter 17800 Task dept] Val Loss: 0.6624\n",
      "{'abs_err': 0.6559, 'rel_err': 0.2539, 'sigma_1.25': 55.3249, 'sigma_1.25^2': 84.4364, 'sigma_1.25^3': 95.3389, 'cmp': -0.0276}\n",
      "======================================================================\n",
      "[Iter 17850 Task segm] Task Loss: 1.2219 Reg Loss: 42.8620 Train Loss: 6.1525\n",
      "[Iter 17850 Task norm] Task Loss: 0.0643 Reg Loss: 36.0706 Train Loss: 1.3211\n",
      "[Iter 17850 Task dept] Task Loss: 0.6691 Reg Loss: 33.5778 Train Loss: 3.3790\n",
      "[Iter 17850 Total] Train Loss: 3.6176\n",
      "======================================================================\n",
      "[Iter 17900 Task segm] Task Loss: 1.2918 Reg Loss: 21.0414 Train Loss: 6.4802\n",
      "[Iter 17900 Task norm] Task Loss: 0.0622 Reg Loss: 19.6252 Train Loss: 1.2640\n",
      "[Iter 17900 Task dept] Task Loss: 0.6842 Reg Loss: 18.0261 Train Loss: 3.4388\n",
      "[Iter 17900 Total] Train Loss: 3.7277\n",
      "======================================================================\n",
      "tau: 0.20984609502082247\n",
      "[Iter 17950 Task segm] Task Loss: 1.2592 Reg Loss: 44.2894 Train Loss: 6.3403\n",
      "[Iter 17950 Task norm] Task Loss: 0.0633 Reg Loss: 37.3983 Train Loss: 1.3039\n",
      "[Iter 17950 Task dept] Task Loss: 0.6940 Reg Loss: 32.7236 Train Loss: 3.5028\n",
      "[Iter 17950 Total] Train Loss: 3.7157\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Task Loss: 1.2765 Reg Loss: 21.2352 Train Loss: 6.4037\n",
      "[Iter 18000 Task norm] Task Loss: 0.0636 Reg Loss: 20.0412 Train Loss: 1.2922\n",
      "[Iter 18000 Task dept] Task Loss: 0.6814 Reg Loss: 18.1314 Train Loss: 3.4253\n",
      "[Iter 18000 Total] Train Loss: 3.7071\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Val Loss: 1.7999\n",
      "{'mIoU': 0.1755, 'Pixel Acc': 0.4939, 'cmp': -0.2618}\n",
      "[Iter 18000 Task norm] Val Loss: 0.1207\n",
      "{'Angle Mean': 24.7034, 'Angle Median': 23.2956, 'Angle 11.25': 21.558, 'Angle 22.5': 48.1481, 'Angle 30': 67.227, 'cmp': -0.3986}\n",
      "[Iter 18000 Task dept] Val Loss: 0.7602\n",
      "{'abs_err': 0.7622, 'rel_err': 0.3361, 'sigma_1.25': 50.9393, 'sigma_1.25^2': 80.7749, 'sigma_1.25^3': 92.9422, 'cmp': -0.1563}\n",
      "======================================================================\n",
      "[Iter 18050 Task segm] Task Loss: 1.2416 Reg Loss: 42.9935 Train Loss: 6.2508\n",
      "[Iter 18050 Task norm] Task Loss: 0.0633 Reg Loss: 37.6848 Train Loss: 1.3029\n",
      "[Iter 18050 Task dept] Task Loss: 0.6924 Reg Loss: 29.3381 Train Loss: 3.4915\n",
      "[Iter 18050 Total] Train Loss: 3.6817\n",
      "======================================================================\n",
      "[Iter 18100 Task segm] Task Loss: 1.2685 Reg Loss: 20.7049 Train Loss: 6.3632\n",
      "[Iter 18100 Task norm] Task Loss: 0.0628 Reg Loss: 19.4925 Train Loss: 1.2753\n",
      "[Iter 18100 Task dept] Task Loss: 0.7074 Reg Loss: 18.2326 Train Loss: 3.5555\n",
      "[Iter 18100 Total] Train Loss: 3.7313\n",
      "======================================================================\n",
      "tau: 0.20250148169509366\n",
      "[Iter 18150 Task segm] Task Loss: 1.2671 Reg Loss: 44.0958 Train Loss: 6.3796\n",
      "[Iter 18150 Task norm] Task Loss: 0.0625 Reg Loss: 37.5083 Train Loss: 1.2871\n",
      "[Iter 18150 Task dept] Task Loss: 0.6858 Reg Loss: 31.3401 Train Loss: 3.4601\n",
      "[Iter 18150 Total] Train Loss: 3.7089\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Task Loss: 1.2393 Reg Loss: 21.0314 Train Loss: 6.2178\n",
      "[Iter 18200 Task norm] Task Loss: 0.0636 Reg Loss: 20.1012 Train Loss: 1.2916\n",
      "[Iter 18200 Task dept] Task Loss: 0.6932 Reg Loss: 18.3809 Train Loss: 3.4845\n",
      "[Iter 18200 Total] Train Loss: 3.6646\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Val Loss: 1.6669\n",
      "{'mIoU': 0.1971, 'Pixel Acc': 0.5214, 'cmp': -0.199}\n",
      "[Iter 18200 Task norm] Val Loss: 0.0776\n",
      "{'Angle Mean': 19.9673, 'Angle Median': 17.6742, 'Angle 11.25': 21.748, 'Angle 22.5': 69.6383, 'Angle 30': 84.7296, 'cmp': -0.1648}\n",
      "[Iter 18200 Task dept] Val Loss: 0.6706\n",
      "{'abs_err': 0.6653, 'rel_err': 0.2692, 'sigma_1.25': 55.3052, 'sigma_1.25^2': 84.0655, 'sigma_1.25^3': 94.7675, 'cmp': -0.0449}\n",
      "======================================================================\n",
      "[Iter 18250 Task segm] Task Loss: 1.2557 Reg Loss: 43.1152 Train Loss: 6.3216\n",
      "[Iter 18250 Task norm] Task Loss: 0.0656 Reg Loss: 38.5717 Train Loss: 1.3501\n",
      "[Iter 18250 Task dept] Task Loss: 0.6736 Reg Loss: 32.5677 Train Loss: 3.4005\n",
      "[Iter 18250 Total] Train Loss: 3.6907\n",
      "======================================================================\n",
      "[Iter 18300 Task segm] Task Loss: 1.2778 Reg Loss: 21.1772 Train Loss: 6.4104\n",
      "[Iter 18300 Task norm] Task Loss: 0.0629 Reg Loss: 19.9534 Train Loss: 1.2786\n",
      "[Iter 18300 Task dept] Task Loss: 0.7007 Reg Loss: 18.2608 Train Loss: 3.5220\n",
      "[Iter 18300 Total] Train Loss: 3.7370\n",
      "======================================================================\n",
      "tau: 0.1954139298357654\n",
      "[Iter 18350 Task segm] Task Loss: 1.3098 Reg Loss: 42.4573 Train Loss: 6.5914\n",
      "[Iter 18350 Task norm] Task Loss: 0.0641 Reg Loss: 38.2754 Train Loss: 1.3198\n",
      "[Iter 18350 Task dept] Task Loss: 0.6960 Reg Loss: 30.5575 Train Loss: 3.5105\n",
      "[Iter 18350 Total] Train Loss: 3.8072\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 18400 Task segm] Task Loss: 1.2552 Reg Loss: 20.7227 Train Loss: 6.2969\n",
      "[Iter 18400 Task norm] Task Loss: 0.0628 Reg Loss: 19.5193 Train Loss: 1.2762\n",
      "[Iter 18400 Task dept] Task Loss: 0.6752 Reg Loss: 18.0781 Train Loss: 3.3938\n",
      "[Iter 18400 Total] Train Loss: 3.6556\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Val Loss: 1.7291\n",
      "{'mIoU': 0.1836, 'Pixel Acc': 0.5045, 'cmp': -0.238}\n",
      "[Iter 18400 Task norm] Val Loss: 0.1322\n",
      "{'Angle Mean': 25.9103, 'Angle Median': 25.4121, 'Angle 11.25': 22.0564, 'Angle 22.5': 45.1334, 'Angle 30': 58.7627, 'cmp': -0.4674}\n",
      "[Iter 18400 Task dept] Val Loss: 0.7474\n",
      "{'abs_err': 0.737, 'rel_err': 0.2584, 'sigma_1.25': 48.7993, 'sigma_1.25^2': 79.8746, 'sigma_1.25^3': 93.4364, 'cmp': -0.0944}\n",
      "======================================================================\n",
      "[Iter 18450 Task segm] Task Loss: 1.2558 Reg Loss: 44.2281 Train Loss: 6.3233\n",
      "[Iter 18450 Task norm] Task Loss: 0.0654 Reg Loss: 35.6512 Train Loss: 1.3438\n",
      "[Iter 18450 Task dept] Task Loss: 0.7093 Reg Loss: 31.1965 Train Loss: 3.5777\n",
      "[Iter 18450 Total] Train Loss: 3.7483\n",
      "======================================================================\n",
      "[Iter 18500 Task segm] Task Loss: 1.2988 Reg Loss: 20.5543 Train Loss: 6.5144\n",
      "[Iter 18500 Task norm] Task Loss: 0.0620 Reg Loss: 19.8509 Train Loss: 1.2597\n",
      "[Iter 18500 Task dept] Task Loss: 0.6841 Reg Loss: 18.6529 Train Loss: 3.4392\n",
      "[Iter 18500 Total] Train Loss: 3.7378\n",
      "======================================================================\n",
      "tau: 0.1885744422915136\n",
      "[Iter 18550 Task segm] Task Loss: 1.2206 Reg Loss: 45.0148 Train Loss: 6.1482\n",
      "[Iter 18550 Task norm] Task Loss: 0.0651 Reg Loss: 38.5044 Train Loss: 1.3409\n",
      "[Iter 18550 Task dept] Task Loss: 0.6832 Reg Loss: 30.6568 Train Loss: 3.4468\n",
      "[Iter 18550 Total] Train Loss: 3.6453\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Task Loss: 1.2054 Reg Loss: 20.7365 Train Loss: 6.0476\n",
      "[Iter 18600 Task norm] Task Loss: 0.0630 Reg Loss: 19.2557 Train Loss: 1.2791\n",
      "[Iter 18600 Task dept] Task Loss: 0.6713 Reg Loss: 18.2862 Train Loss: 3.3747\n",
      "[Iter 18600 Total] Train Loss: 3.5672\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Val Loss: 1.7745\n",
      "{'mIoU': 0.1793, 'Pixel Acc': 0.498, 'cmp': -0.2513}\n",
      "[Iter 18600 Task norm] Val Loss: 0.0941\n",
      "{'Angle Mean': 21.8993, 'Angle Median': 20.3422, 'Angle 11.25': 22.7328, 'Angle 22.5': 56.3515, 'Angle 30': 79.2249, 'cmp': -0.2679}\n",
      "[Iter 18600 Task dept] Val Loss: 0.7111\n",
      "{'abs_err': 0.7138, 'rel_err': 0.3242, 'sigma_1.25': 52.7717, 'sigma_1.25^2': 81.555, 'sigma_1.25^3': 92.9242, 'cmp': -0.123}\n",
      "======================================================================\n",
      "[Iter 18650 Task segm] Task Loss: 1.2823 Reg Loss: 42.1765 Train Loss: 6.4538\n",
      "[Iter 18650 Task norm] Task Loss: 0.0618 Reg Loss: 36.6451 Train Loss: 1.2722\n",
      "[Iter 18650 Task dept] Task Loss: 0.6919 Reg Loss: 29.7324 Train Loss: 3.4893\n",
      "[Iter 18650 Total] Train Loss: 3.7384\n",
      "======================================================================\n",
      "[Iter 18700 Task segm] Task Loss: 1.2825 Reg Loss: 20.5359 Train Loss: 6.4329\n",
      "[Iter 18700 Task norm] Task Loss: 0.0625 Reg Loss: 18.6576 Train Loss: 1.2684\n",
      "[Iter 18700 Task dept] Task Loss: 0.6956 Reg Loss: 17.8797 Train Loss: 3.4961\n",
      "[Iter 18700 Total] Train Loss: 3.7324\n",
      "======================================================================\n",
      "tau: 0.18197433681131062\n",
      "[Iter 18750 Task segm] Task Loss: 1.2254 Reg Loss: 43.2616 Train Loss: 6.1703\n",
      "[Iter 18750 Task norm] Task Loss: 0.0642 Reg Loss: 35.4789 Train Loss: 1.3197\n",
      "[Iter 18750 Task dept] Task Loss: 0.6993 Reg Loss: 30.7448 Train Loss: 3.5273\n",
      "[Iter 18750 Total] Train Loss: 3.6724\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Task Loss: 1.2350 Reg Loss: 20.9711 Train Loss: 6.1962\n",
      "[Iter 18800 Task norm] Task Loss: 0.0643 Reg Loss: 19.6316 Train Loss: 1.3050\n",
      "[Iter 18800 Task dept] Task Loss: 0.7187 Reg Loss: 17.9203 Train Loss: 3.6117\n",
      "[Iter 18800 Total] Train Loss: 3.7043\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Val Loss: 1.8227\n",
      "{'mIoU': 0.1774, 'Pixel Acc': 0.4743, 'cmp': -0.2749}\n",
      "[Iter 18800 Task norm] Val Loss: 0.0861\n",
      "{'Angle Mean': 20.9089, 'Angle Median': 19.1323, 'Angle 11.25': 23.2395, 'Angle 22.5': 62.861, 'Angle 30': 82.6766, 'cmp': -0.2108}\n",
      "[Iter 18800 Task dept] Val Loss: 0.6286\n",
      "{'abs_err': 0.6242, 'rel_err': 0.2471, 'sigma_1.25': 57.9886, 'sigma_1.25^2': 86.3099, 'sigma_1.25^3': 95.9781, 'cmp': 0.003}\n",
      "======================================================================\n",
      "[Iter 18850 Task segm] Task Loss: 1.2267 Reg Loss: 42.9547 Train Loss: 6.1766\n",
      "[Iter 18850 Task norm] Task Loss: 0.0632 Reg Loss: 39.9933 Train Loss: 1.3050\n",
      "[Iter 18850 Task dept] Task Loss: 0.6746 Reg Loss: 28.5813 Train Loss: 3.4014\n",
      "[Iter 18850 Total] Train Loss: 3.6277\n",
      "======================================================================\n",
      "[Iter 18900 Task segm] Task Loss: 1.2420 Reg Loss: 20.9419 Train Loss: 6.2310\n",
      "[Iter 18900 Task norm] Task Loss: 0.0638 Reg Loss: 19.7815 Train Loss: 1.2950\n",
      "[Iter 18900 Task dept] Task Loss: 0.7004 Reg Loss: 17.8703 Train Loss: 3.5199\n",
      "[Iter 18900 Total] Train Loss: 3.6819\n",
      "======================================================================\n",
      "tau: 0.17560523502291475\n",
      "[Iter 18950 Task segm] Task Loss: 1.2105 Reg Loss: 44.0307 Train Loss: 6.0965\n",
      "[Iter 18950 Task norm] Task Loss: 0.0633 Reg Loss: 36.9703 Train Loss: 1.3037\n",
      "[Iter 18950 Task dept] Task Loss: 0.6958 Reg Loss: 31.7684 Train Loss: 3.5110\n",
      "[Iter 18950 Total] Train Loss: 3.6370\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Task Loss: 1.2505 Reg Loss: 20.8681 Train Loss: 6.2732\n",
      "[Iter 19000 Task norm] Task Loss: 0.0635 Reg Loss: 20.1164 Train Loss: 1.2892\n",
      "[Iter 19000 Task dept] Task Loss: 0.6605 Reg Loss: 18.0885 Train Loss: 3.3205\n",
      "[Iter 19000 Total] Train Loss: 3.6276\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Val Loss: 1.8642\n",
      "{'mIoU': 0.1692, 'Pixel Acc': 0.4883, 'cmp': -0.278}\n",
      "[Iter 19000 Task norm] Val Loss: 0.0867\n",
      "{'Angle Mean': 21.0556, 'Angle Median': 19.2368, 'Angle 11.25': 21.8289, 'Angle 22.5': 62.6606, 'Angle 30': 82.4143, 'cmp': -0.2232}\n",
      "[Iter 19000 Task dept] Val Loss: 0.7807\n",
      "{'abs_err': 0.7696, 'rel_err': 0.2698, 'sigma_1.25': 45.4904, 'sigma_1.25^2': 77.5813, 'sigma_1.25^3': 92.7872, 'cmp': -0.1322}\n",
      "======================================================================\n",
      "[Iter 19050 Task segm] Task Loss: 1.2558 Reg Loss: 44.9393 Train Loss: 6.3241\n",
      "[Iter 19050 Task norm] Task Loss: 0.0627 Reg Loss: 40.2549 Train Loss: 1.2945\n",
      "[Iter 19050 Task dept] Task Loss: 0.7022 Reg Loss: 30.4185 Train Loss: 3.5412\n",
      "[Iter 19050 Total] Train Loss: 3.7199\n",
      "======================================================================\n",
      "[Iter 19100 Task segm] Task Loss: 1.3169 Reg Loss: 20.9775 Train Loss: 6.6056\n",
      "[Iter 19100 Task norm] Task Loss: 0.0628 Reg Loss: 19.7081 Train Loss: 1.2766\n",
      "[Iter 19100 Task dept] Task Loss: 0.6999 Reg Loss: 18.4806 Train Loss: 3.5179\n",
      "[Iter 19100 Total] Train Loss: 3.8000\n",
      "======================================================================\n",
      "tau: 0.16945905179711274\n",
      "[Iter 19150 Task segm] Task Loss: 1.2463 Reg Loss: 43.3784 Train Loss: 6.2747\n",
      "[Iter 19150 Task norm] Task Loss: 0.0625 Reg Loss: 39.0850 Train Loss: 1.2891\n",
      "[Iter 19150 Task dept] Task Loss: 0.6875 Reg Loss: 32.5621 Train Loss: 3.4701\n",
      "[Iter 19150 Total] Train Loss: 3.6780\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Task Loss: 1.2856 Reg Loss: 20.4086 Train Loss: 6.4484\n",
      "[Iter 19200 Task norm] Task Loss: 0.0653 Reg Loss: 20.1696 Train Loss: 1.3263\n",
      "[Iter 19200 Task dept] Task Loss: 0.6986 Reg Loss: 17.9859 Train Loss: 3.5112\n",
      "[Iter 19200 Total] Train Loss: 3.7620\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Val Loss: 1.8063\n",
      "{'mIoU': 0.1713, 'Pixel Acc': 0.4921, 'cmp': -0.2709}\n",
      "[Iter 19200 Task norm] Val Loss: 0.0808\n",
      "{'Angle Mean': 20.3505, 'Angle Median': 18.2175, 'Angle 11.25': 21.7994, 'Angle 22.5': 67.8427, 'Angle 30': 83.9349, 'cmp': -0.1832}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 19200 Task dept] Val Loss: 0.6427\n",
      "{'abs_err': 0.6402, 'rel_err': 0.262, 'sigma_1.25': 56.6246, 'sigma_1.25^2': 85.8364, 'sigma_1.25^3': 95.7016, 'cmp': -0.0205}\n",
      "======================================================================\n",
      "[Iter 19250 Task segm] Task Loss: 1.2276 Reg Loss: 45.1984 Train Loss: 6.1832\n",
      "[Iter 19250 Task norm] Task Loss: 0.0630 Reg Loss: 38.7156 Train Loss: 1.2980\n",
      "[Iter 19250 Task dept] Task Loss: 0.6852 Reg Loss: 31.8566 Train Loss: 3.4581\n",
      "[Iter 19250 Total] Train Loss: 3.6464\n",
      "======================================================================\n",
      "[Iter 19300 Task segm] Task Loss: 1.2684 Reg Loss: 20.8125 Train Loss: 6.3627\n",
      "[Iter 19300 Task norm] Task Loss: 0.0640 Reg Loss: 20.0725 Train Loss: 1.2993\n",
      "[Iter 19300 Task dept] Task Loss: 0.7007 Reg Loss: 18.3412 Train Loss: 3.5218\n",
      "[Iter 19300 Total] Train Loss: 3.7279\n",
      "======================================================================\n",
      "tau: 0.16352798498421378\n",
      "[Iter 19350 Task segm] Task Loss: 1.2733 Reg Loss: 42.7775 Train Loss: 6.4092\n",
      "[Iter 19350 Task norm] Task Loss: 0.0610 Reg Loss: 39.1026 Train Loss: 1.2581\n",
      "[Iter 19350 Task dept] Task Loss: 0.6871 Reg Loss: 32.0642 Train Loss: 3.4675\n",
      "[Iter 19350 Total] Train Loss: 3.7116\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Task Loss: 1.2542 Reg Loss: 20.7540 Train Loss: 6.2920\n",
      "[Iter 19400 Task norm] Task Loss: 0.0633 Reg Loss: 19.6039 Train Loss: 1.2850\n",
      "[Iter 19400 Task dept] Task Loss: 0.6724 Reg Loss: 18.1427 Train Loss: 3.3800\n",
      "[Iter 19400 Total] Train Loss: 3.6523\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Val Loss: 1.8364\n",
      "{'mIoU': 0.1733, 'Pixel Acc': 0.4898, 'cmp': -0.2691}\n",
      "[Iter 19400 Task norm] Val Loss: 0.0976\n",
      "{'Angle Mean': 22.1127, 'Angle Median': 20.5698, 'Angle 11.25': 23.4859, 'Angle 22.5': 56.0329, 'Angle 30': 78.4948, 'cmp': -0.2718}\n",
      "[Iter 19400 Task dept] Val Loss: 0.6421\n",
      "{'abs_err': 0.6398, 'rel_err': 0.2595, 'sigma_1.25': 56.7761, 'sigma_1.25^2': 85.3822, 'sigma_1.25^3': 95.4395, 'cmp': -0.0193}\n",
      "======================================================================\n",
      "[Iter 19450 Task segm] Task Loss: 1.2815 Reg Loss: 43.0736 Train Loss: 6.4504\n",
      "[Iter 19450 Task norm] Task Loss: 0.0624 Reg Loss: 36.6207 Train Loss: 1.2853\n",
      "[Iter 19450 Task dept] Task Loss: 0.7146 Reg Loss: 32.2135 Train Loss: 3.6050\n",
      "[Iter 19450 Total] Train Loss: 3.7802\n",
      "======================================================================\n",
      "[Iter 19500 Task segm] Task Loss: 1.2470 Reg Loss: 20.6939 Train Loss: 6.2558\n",
      "[Iter 19500 Task norm] Task Loss: 0.0625 Reg Loss: 19.3665 Train Loss: 1.2702\n",
      "[Iter 19500 Task dept] Task Loss: 0.6616 Reg Loss: 17.9542 Train Loss: 3.3261\n",
      "[Iter 19500 Total] Train Loss: 3.6174\n",
      "======================================================================\n",
      "tau: 0.1578045055097663\n",
      "[Iter 19550 Task segm] Task Loss: 1.2434 Reg Loss: 44.6227 Train Loss: 6.2617\n",
      "[Iter 19550 Task norm] Task Loss: 0.0640 Reg Loss: 37.6843 Train Loss: 1.3174\n",
      "[Iter 19550 Task dept] Task Loss: 0.6954 Reg Loss: 30.4826 Train Loss: 3.5074\n",
      "[Iter 19550 Total] Train Loss: 3.6955\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Task Loss: 1.2128 Reg Loss: 20.9681 Train Loss: 6.0849\n",
      "[Iter 19600 Task norm] Task Loss: 0.0648 Reg Loss: 20.1917 Train Loss: 1.3153\n",
      "[Iter 19600 Task dept] Task Loss: 0.6719 Reg Loss: 17.6583 Train Loss: 3.3774\n",
      "[Iter 19600 Total] Train Loss: 3.5926\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Val Loss: 1.7224\n",
      "{'mIoU': 0.1852, 'Pixel Acc': 0.5133, 'cmp': -0.2275}\n",
      "[Iter 19600 Task norm] Val Loss: 0.0754\n",
      "{'Angle Mean': 19.9914, 'Angle Median': 17.7446, 'Angle 11.25': 17.3984, 'Angle 22.5': 72.2776, 'Angle 30': 85.1835, 'cmp': -0.1827}\n",
      "[Iter 19600 Task dept] Val Loss: 0.6734\n",
      "{'abs_err': 0.6676, 'rel_err': 0.2687, 'sigma_1.25': 53.9256, 'sigma_1.25^2': 84.0645, 'sigma_1.25^3': 95.2561, 'cmp': -0.049}\n",
      "======================================================================\n",
      "[Iter 19650 Task segm] Task Loss: 1.2442 Reg Loss: 43.0205 Train Loss: 6.2638\n",
      "[Iter 19650 Task norm] Task Loss: 0.0631 Reg Loss: 38.0004 Train Loss: 1.3000\n",
      "[Iter 19650 Task dept] Task Loss: 0.6857 Reg Loss: 31.1977 Train Loss: 3.4595\n",
      "[Iter 19650 Total] Train Loss: 3.6744\n",
      "======================================================================\n",
      "[Iter 19700 Task segm] Task Loss: 1.2408 Reg Loss: 21.0650 Train Loss: 6.2249\n",
      "[Iter 19700 Task norm] Task Loss: 0.0645 Reg Loss: 19.7065 Train Loss: 1.3092\n",
      "[Iter 19700 Task dept] Task Loss: 0.6824 Reg Loss: 17.7849 Train Loss: 3.4300\n",
      "[Iter 19700 Total] Train Loss: 3.6547\n",
      "======================================================================\n",
      "tau: 0.15228134781692448\n",
      "[Iter 19750 Task segm] Task Loss: 1.2316 Reg Loss: 43.8871 Train Loss: 6.2020\n",
      "[Iter 19750 Task norm] Task Loss: 0.0623 Reg Loss: 38.4009 Train Loss: 1.2839\n",
      "[Iter 19750 Task dept] Task Loss: 0.6600 Reg Loss: 34.2455 Train Loss: 3.3343\n",
      "[Iter 19750 Total] Train Loss: 3.6067\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Task Loss: 1.2464 Reg Loss: 20.6229 Train Loss: 6.2525\n",
      "[Iter 19800 Task norm] Task Loss: 0.0627 Reg Loss: 19.3560 Train Loss: 1.2744\n",
      "[Iter 19800 Task dept] Task Loss: 0.7006 Reg Loss: 17.7378 Train Loss: 3.5205\n",
      "[Iter 19800 Total] Train Loss: 3.6825\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Val Loss: 1.7330\n",
      "{'mIoU': 0.1897, 'Pixel Acc': 0.5055, 'cmp': -0.2261}\n",
      "[Iter 19800 Task norm] Val Loss: 0.0739\n",
      "{'Angle Mean': 19.8334, 'Angle Median': 17.7037, 'Angle 11.25': 17.426, 'Angle 22.5': 73.0983, 'Angle 30': 85.6297, 'cmp': -0.1769}\n",
      "[Iter 19800 Task dept] Val Loss: 0.6808\n",
      "{'abs_err': 0.6775, 'rel_err': 0.2756, 'sigma_1.25': 53.8444, 'sigma_1.25^2': 83.9374, 'sigma_1.25^3': 95.0074, 'cmp': -0.0588}\n",
      "======================================================================\n",
      "[Iter 19850 Task segm] Task Loss: 1.2318 Reg Loss: 44.5296 Train Loss: 6.2034\n",
      "[Iter 19850 Task norm] Task Loss: 0.0638 Reg Loss: 38.4374 Train Loss: 1.3140\n",
      "[Iter 19850 Task dept] Task Loss: 0.6550 Reg Loss: 30.5466 Train Loss: 3.3057\n",
      "[Iter 19850 Total] Train Loss: 3.6077\n",
      "======================================================================\n",
      "[Iter 19900 Task segm] Task Loss: 1.2532 Reg Loss: 20.5839 Train Loss: 6.2866\n",
      "[Iter 19900 Task norm] Task Loss: 0.0639 Reg Loss: 19.6293 Train Loss: 1.2967\n",
      "[Iter 19900 Task dept] Task Loss: 0.6992 Reg Loss: 17.9919 Train Loss: 3.5140\n",
      "[Iter 19900 Total] Train Loss: 3.6991\n",
      "======================================================================\n",
      "tau: 0.14695150064333212\n",
      "[Iter 19950 Task segm] Task Loss: 1.2776 Reg Loss: 43.3463 Train Loss: 6.4313\n",
      "[Iter 19950 Task norm] Task Loss: 0.0642 Reg Loss: 38.2319 Train Loss: 1.3232\n",
      "[Iter 19950 Task dept] Task Loss: 0.6882 Reg Loss: 32.9029 Train Loss: 3.4737\n",
      "[Iter 19950 Total] Train Loss: 3.7427\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Task Loss: 1.2531 Reg Loss: 20.4421 Train Loss: 6.2861\n",
      "[Iter 20000 Task norm] Task Loss: 0.0627 Reg Loss: 19.6688 Train Loss: 1.2741\n",
      "[Iter 20000 Task dept] Task Loss: 0.6873 Reg Loss: 17.4347 Train Loss: 3.4539\n",
      "[Iter 20000 Total] Train Loss: 3.6714\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Val Loss: 1.8872\n",
      "{'mIoU': 0.1687, 'Pixel Acc': 0.4791, 'cmp': -0.2866}\n",
      "[Iter 20000 Task norm] Val Loss: 0.0739\n",
      "{'Angle Mean': 19.4965, 'Angle Median': 17.0654, 'Angle 11.25': 22.6327, 'Angle 22.5': 70.9829, 'Angle 30': 85.5927, 'cmp': -0.14}\n",
      "[Iter 20000 Task dept] Val Loss: 0.6650\n",
      "{'abs_err': 0.6597, 'rel_err': 0.2532, 'sigma_1.25': 54.3119, 'sigma_1.25^2': 84.4627, 'sigma_1.25^3': 95.3837, 'cmp': -0.0316}\n",
      "======================================================================\n",
      "lr changed\n"
     ]
    }
   ],
   "source": [
    "loss_lambda = {'segment_semantic': 5, 'normal':20, 'depth_zbuffer': 5, 'policy':0.001}\n",
    "trainer.alter_train_with_reg(iters=20000, policy_network_iters=(50,50), policy_lr=0.01, network_lr=0.001, \n",
    "                             loss_lambda=loss_lambda,\n",
    "                             savePath=checkpoint+'NYUv2/', reload='pre_train_all_10000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 22850 Task segm] Train Loss: 0.8102\n",
      "[Iter 22850 Task norm] Train Loss: 0.9453\n",
      "[Iter 22850 Task dept] Train Loss: 1.3399\n",
      "[Iter 22850 Total] Train Loss: 1.0318\n",
      "======================================================================\n",
      "[Iter 22900 Task segm] Train Loss: 0.8031\n",
      "[Iter 22900 Task norm] Train Loss: 0.9400\n",
      "[Iter 22900 Task dept] Train Loss: 1.3344\n",
      "[Iter 22900 Total] Train Loss: 1.0258\n",
      "======================================================================\n",
      "[Iter 22950 Task segm] Train Loss: 0.8091\n",
      "[Iter 22950 Task norm] Train Loss: 0.9392\n",
      "[Iter 22950 Task dept] Train Loss: 1.3625\n",
      "[Iter 22950 Total] Train Loss: 1.0369\n",
      "======================================================================\n",
      "[Iter 23000 Task segm] Train Loss: 0.8469\n",
      "[Iter 23000 Task norm] Train Loss: 0.9556\n",
      "[Iter 23000 Task dept] Train Loss: 1.3303\n",
      "[Iter 23000 Total] Train Loss: 1.0443\n",
      "======================================================================\n",
      "[Iter 23000 Task segm] Val Loss: 1.6095\n",
      "{'mIoU': 0.2362, 'Pixel Acc': 0.5521, 'cmp': -0.1019}\n",
      "[Iter 23000 Task norm] Val Loss: 0.0649\n",
      "{'Angle Mean': 17.4512, 'Angle Median': 15.0718, 'Angle 11.25': 35.4624, 'Angle 22.5': 71.715, 'Angle 30': 84.7502, 'cmp': -0.015}\n",
      "[Iter 23000 Task dept] Val Loss: 0.5914\n",
      "{'abs_err': 0.5895, 'rel_err': 0.2318, 'sigma_1.25': 61.0697, 'sigma_1.25^2': 87.7886, 'sigma_1.25^3': 96.4423, 'cmp': 0.0415}\n",
      "======================================================================\n",
      "[Iter 23050 Task segm] Train Loss: 0.8038\n",
      "[Iter 23050 Task norm] Train Loss: 0.9510\n",
      "[Iter 23050 Task dept] Train Loss: 1.3158\n",
      "[Iter 23050 Total] Train Loss: 1.0235\n",
      "======================================================================\n",
      "[Iter 23100 Task segm] Train Loss: 0.8097\n",
      "[Iter 23100 Task norm] Train Loss: 0.9459\n",
      "[Iter 23100 Task dept] Train Loss: 1.3270\n",
      "[Iter 23100 Total] Train Loss: 1.0275\n",
      "======================================================================\n",
      "[Iter 23150 Task segm] Train Loss: 0.8073\n",
      "[Iter 23150 Task norm] Train Loss: 0.9735\n",
      "[Iter 23150 Task dept] Train Loss: 1.3016\n",
      "[Iter 23150 Total] Train Loss: 1.0275\n",
      "======================================================================\n",
      "[Iter 23200 Task segm] Train Loss: 0.8184\n",
      "[Iter 23200 Task norm] Train Loss: 0.9483\n",
      "[Iter 23200 Task dept] Train Loss: 1.3116\n",
      "[Iter 23200 Total] Train Loss: 1.0261\n",
      "======================================================================\n",
      "[Iter 23200 Task segm] Val Loss: 1.5885\n",
      "{'mIoU': 0.2439, 'Pixel Acc': 0.5579, 'cmp': -0.083}\n",
      "[Iter 23200 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 17.5918, 'Angle Median': 15.1724, 'Angle 11.25': 35.3816, 'Angle 22.5': 71.0786, 'Angle 30': 84.2758, 'cmp': -0.0214}\n",
      "[Iter 23200 Task dept] Val Loss: 0.5898\n",
      "{'abs_err': 0.587, 'rel_err': 0.2317, 'sigma_1.25': 61.2712, 'sigma_1.25^2': 87.9652, 'sigma_1.25^3': 96.4627, 'cmp': 0.0436}\n",
      "======================================================================\n",
      "[Iter 23250 Task segm] Train Loss: 0.8035\n",
      "[Iter 23250 Task norm] Train Loss: 0.9311\n",
      "[Iter 23250 Task dept] Train Loss: 1.3520\n",
      "[Iter 23250 Total] Train Loss: 1.0289\n",
      "======================================================================\n",
      "[Iter 23300 Task segm] Train Loss: 0.8273\n",
      "[Iter 23300 Task norm] Train Loss: 0.9578\n",
      "[Iter 23300 Task dept] Train Loss: 1.3174\n",
      "[Iter 23300 Total] Train Loss: 1.0342\n",
      "======================================================================\n",
      "[Iter 23350 Task segm] Train Loss: 0.8005\n",
      "[Iter 23350 Task norm] Train Loss: 0.9761\n",
      "[Iter 23350 Task dept] Train Loss: 1.3228\n",
      "[Iter 23350 Total] Train Loss: 1.0331\n",
      "======================================================================\n",
      "[Iter 23400 Task segm] Train Loss: 0.8130\n",
      "[Iter 23400 Task norm] Train Loss: 0.9308\n",
      "[Iter 23400 Task dept] Train Loss: 1.3291\n",
      "[Iter 23400 Total] Train Loss: 1.0243\n",
      "======================================================================\n",
      "[Iter 23400 Task segm] Val Loss: 1.5958\n",
      "{'mIoU': 0.2449, 'Pixel Acc': 0.5586, 'cmp': -0.0806}\n",
      "[Iter 23400 Task norm] Val Loss: 0.0662\n",
      "{'Angle Mean': 17.6717, 'Angle Median': 15.3913, 'Angle 11.25': 34.7399, 'Angle 22.5': 70.5651, 'Angle 30': 84.1389, 'cmp': -0.0308}\n",
      "[Iter 23400 Task dept] Val Loss: 0.5929\n",
      "{'abs_err': 0.5909, 'rel_err': 0.238, 'sigma_1.25': 61.1041, 'sigma_1.25^2': 87.6106, 'sigma_1.25^3': 96.3202, 'cmp': 0.0355}\n",
      "======================================================================\n",
      "[Iter 23450 Task segm] Train Loss: 0.8117\n",
      "[Iter 23450 Task norm] Train Loss: 0.9642\n",
      "[Iter 23450 Task dept] Train Loss: 1.3149\n",
      "[Iter 23450 Total] Train Loss: 1.0303\n",
      "======================================================================\n",
      "[Iter 23500 Task segm] Train Loss: 0.8356\n",
      "[Iter 23500 Task norm] Train Loss: 0.9332\n",
      "[Iter 23500 Task dept] Train Loss: 1.2953\n",
      "[Iter 23500 Total] Train Loss: 1.0214\n",
      "======================================================================\n",
      "[Iter 23550 Task segm] Train Loss: 0.8078\n",
      "[Iter 23550 Task norm] Train Loss: 0.9238\n",
      "[Iter 23550 Task dept] Train Loss: 1.3178\n",
      "[Iter 23550 Total] Train Loss: 1.0165\n",
      "======================================================================\n",
      "[Iter 23600 Task segm] Train Loss: 0.8223\n",
      "[Iter 23600 Task norm] Train Loss: 0.9336\n",
      "[Iter 23600 Task dept] Train Loss: 1.2938\n",
      "[Iter 23600 Total] Train Loss: 1.0166\n",
      "======================================================================\n",
      "[Iter 23600 Task segm] Val Loss: 1.5896\n",
      "{'mIoU': 0.2444, 'Pixel Acc': 0.558, 'cmp': -0.082}\n",
      "[Iter 23600 Task norm] Val Loss: 0.0663\n",
      "{'Angle Mean': 17.6236, 'Angle Median': 15.3503, 'Angle 11.25': 35.1826, 'Angle 22.5': 70.4639, 'Angle 30': 84.1422, 'cmp': -0.0274}\n",
      "[Iter 23600 Task dept] Val Loss: 0.5921\n",
      "{'abs_err': 0.5906, 'rel_err': 0.239, 'sigma_1.25': 60.9198, 'sigma_1.25^2': 87.6872, 'sigma_1.25^3': 96.361, 'cmp': 0.0345}\n",
      "======================================================================\n",
      "[Iter 23650 Task segm] Train Loss: 0.8003\n",
      "[Iter 23650 Task norm] Train Loss: 0.9052\n",
      "[Iter 23650 Task dept] Train Loss: 1.3438\n",
      "[Iter 23650 Total] Train Loss: 1.0164\n",
      "======================================================================\n",
      "[Iter 23700 Task segm] Train Loss: 0.8265\n",
      "[Iter 23700 Task norm] Train Loss: 0.9324\n",
      "[Iter 23700 Task dept] Train Loss: 1.2687\n",
      "[Iter 23700 Total] Train Loss: 1.0092\n",
      "======================================================================\n",
      "[Iter 23750 Task segm] Train Loss: 0.8234\n",
      "[Iter 23750 Task norm] Train Loss: 0.9234\n",
      "[Iter 23750 Task dept] Train Loss: 1.3432\n",
      "[Iter 23750 Total] Train Loss: 1.0300\n",
      "======================================================================\n",
      "[Iter 23800 Task segm] Train Loss: 0.7992\n",
      "[Iter 23800 Task norm] Train Loss: 0.9370\n",
      "[Iter 23800 Task dept] Train Loss: 1.2760\n",
      "[Iter 23800 Total] Train Loss: 1.0041\n",
      "======================================================================\n",
      "[Iter 23800 Task segm] Val Loss: 1.5895\n",
      "{'mIoU': 0.2425, 'Pixel Acc': 0.5582, 'cmp': -0.0853}\n",
      "[Iter 23800 Task norm] Val Loss: 0.0653\n",
      "{'Angle Mean': 17.4738, 'Angle Median': 15.1047, 'Angle 11.25': 35.6597, 'Angle 22.5': 71.2363, 'Angle 30': 84.597, 'cmp': -0.0163}\n",
      "[Iter 23800 Task dept] Val Loss: 0.5814\n",
      "{'abs_err': 0.5799, 'rel_err': 0.2357, 'sigma_1.25': 61.9141, 'sigma_1.25^2': 88.122, 'sigma_1.25^3': 96.5255, 'cmp': 0.0454}\n",
      "======================================================================\n",
      "[Iter 23850 Task segm] Train Loss: 0.8080\n",
      "[Iter 23850 Task norm] Train Loss: 0.9388\n",
      "[Iter 23850 Task dept] Train Loss: 1.3338\n",
      "[Iter 23850 Total] Train Loss: 1.0269\n",
      "======================================================================\n",
      "[Iter 23900 Task segm] Train Loss: 0.8029\n",
      "[Iter 23900 Task norm] Train Loss: 0.9557\n",
      "[Iter 23900 Task dept] Train Loss: 1.3472\n",
      "[Iter 23900 Total] Train Loss: 1.0353\n",
      "======================================================================\n",
      "[Iter 23950 Task segm] Train Loss: 0.8276\n",
      "[Iter 23950 Task norm] Train Loss: 0.9303\n",
      "[Iter 23950 Task dept] Train Loss: 1.3429\n",
      "[Iter 23950 Total] Train Loss: 1.0336\n",
      "======================================================================\n",
      "[Iter 24000 Task segm] Train Loss: 0.8138\n",
      "[Iter 24000 Task norm] Train Loss: 0.9430\n",
      "[Iter 24000 Task dept] Train Loss: 1.3032\n",
      "[Iter 24000 Total] Train Loss: 1.0200\n",
      "======================================================================\n",
      "[Iter 24000 Task segm] Val Loss: 1.5767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mIoU': 0.2441, 'Pixel Acc': 0.5596, 'cmp': -0.0812}\n",
      "[Iter 24000 Task norm] Val Loss: 0.0673\n",
      "{'Angle Mean': 17.739, 'Angle Median': 15.2477, 'Angle 11.25': 35.3035, 'Angle 22.5': 70.6953, 'Angle 30': 83.7917, 'cmp': -0.0267}\n",
      "[Iter 24000 Task dept] Val Loss: 0.5878\n",
      "{'abs_err': 0.5856, 'rel_err': 0.2361, 'sigma_1.25': 61.4264, 'sigma_1.25^2': 87.8102, 'sigma_1.25^3': 96.4575, 'cmp': 0.0406}\n",
      "======================================================================\n",
      "[Iter 24050 Task segm] Train Loss: 0.8089\n",
      "[Iter 24050 Task norm] Train Loss: 0.9583\n",
      "[Iter 24050 Task dept] Train Loss: 1.2824\n",
      "[Iter 24050 Total] Train Loss: 1.0165\n",
      "======================================================================\n",
      "[Iter 24100 Task segm] Train Loss: 0.8164\n",
      "[Iter 24100 Task norm] Train Loss: 0.9197\n",
      "[Iter 24100 Task dept] Train Loss: 1.3165\n",
      "[Iter 24100 Total] Train Loss: 1.0175\n",
      "======================================================================\n",
      "[Iter 24150 Task segm] Train Loss: 0.8044\n",
      "[Iter 24150 Task norm] Train Loss: 0.9413\n",
      "[Iter 24150 Task dept] Train Loss: 1.3472\n",
      "[Iter 24150 Total] Train Loss: 1.0310\n",
      "======================================================================\n",
      "[Iter 24200 Task segm] Train Loss: 0.8220\n",
      "[Iter 24200 Task norm] Train Loss: 0.9653\n",
      "[Iter 24200 Task dept] Train Loss: 1.3465\n",
      "[Iter 24200 Total] Train Loss: 1.0446\n",
      "======================================================================\n",
      "[Iter 24200 Task segm] Val Loss: 1.5990\n",
      "{'mIoU': 0.2441, 'Pixel Acc': 0.5568, 'cmp': -0.0836}\n",
      "[Iter 24200 Task norm] Val Loss: 0.0679\n",
      "{'Angle Mean': 17.8097, 'Angle Median': 15.4767, 'Angle 11.25': 35.241, 'Angle 22.5': 69.6226, 'Angle 30': 83.3408, 'cmp': -0.0351}\n",
      "[Iter 24200 Task dept] Val Loss: 0.5873\n",
      "{'abs_err': 0.5862, 'rel_err': 0.2386, 'sigma_1.25': 61.3559, 'sigma_1.25^2': 87.929, 'sigma_1.25^3': 96.4709, 'cmp': 0.0386}\n",
      "======================================================================\n",
      "[Iter 24250 Task segm] Train Loss: 0.8012\n",
      "[Iter 24250 Task norm] Train Loss: 0.9331\n",
      "[Iter 24250 Task dept] Train Loss: 1.2910\n",
      "[Iter 24250 Total] Train Loss: 1.0084\n",
      "======================================================================\n",
      "[Iter 24300 Task segm] Train Loss: 0.8147\n",
      "[Iter 24300 Task norm] Train Loss: 0.9620\n",
      "[Iter 24300 Task dept] Train Loss: 1.3452\n",
      "[Iter 24300 Total] Train Loss: 1.0407\n",
      "======================================================================\n",
      "[Iter 24350 Task segm] Train Loss: 0.8195\n",
      "[Iter 24350 Task norm] Train Loss: 0.9416\n",
      "[Iter 24350 Task dept] Train Loss: 1.3028\n",
      "[Iter 24350 Total] Train Loss: 1.0213\n",
      "======================================================================\n",
      "[Iter 24400 Task segm] Train Loss: 0.8045\n",
      "[Iter 24400 Task norm] Train Loss: 0.9494\n",
      "[Iter 24400 Task dept] Train Loss: 1.3057\n",
      "[Iter 24400 Total] Train Loss: 1.0199\n",
      "======================================================================\n",
      "[Iter 24400 Task segm] Val Loss: 1.5892\n",
      "{'mIoU': 0.2425, 'Pixel Acc': 0.5588, 'cmp': -0.0847}\n",
      "[Iter 24400 Task norm] Val Loss: 0.0665\n",
      "{'Angle Mean': 17.6411, 'Angle Median': 15.3292, 'Angle 11.25': 35.2118, 'Angle 22.5': 70.5029, 'Angle 30': 84.006, 'cmp': -0.0273}\n",
      "[Iter 24400 Task dept] Val Loss: 0.5956\n",
      "{'abs_err': 0.593, 'rel_err': 0.2332, 'sigma_1.25': 60.8502, 'sigma_1.25^2': 87.7042, 'sigma_1.25^3': 96.352, 'cmp': 0.0382}\n",
      "======================================================================\n",
      "[Iter 24450 Task segm] Train Loss: 0.8228\n",
      "[Iter 24450 Task norm] Train Loss: 0.9492\n",
      "[Iter 24450 Task dept] Train Loss: 1.3065\n",
      "[Iter 24450 Total] Train Loss: 1.0262\n",
      "======================================================================\n",
      "[Iter 24500 Task segm] Train Loss: 0.7823\n",
      "[Iter 24500 Task norm] Train Loss: 0.9228\n",
      "[Iter 24500 Task dept] Train Loss: 1.3212\n",
      "[Iter 24500 Total] Train Loss: 1.0088\n",
      "======================================================================\n",
      "[Iter 24550 Task segm] Train Loss: 0.8235\n",
      "[Iter 24550 Task norm] Train Loss: 0.9645\n",
      "[Iter 24550 Task dept] Train Loss: 1.3093\n",
      "[Iter 24550 Total] Train Loss: 1.0325\n",
      "======================================================================\n",
      "[Iter 24600 Task segm] Train Loss: 0.8262\n",
      "[Iter 24600 Task norm] Train Loss: 0.9190\n",
      "[Iter 24600 Task dept] Train Loss: 1.3223\n",
      "[Iter 24600 Total] Train Loss: 1.0225\n",
      "======================================================================\n",
      "[Iter 24600 Task segm] Val Loss: 1.5906\n",
      "{'mIoU': 0.2439, 'Pixel Acc': 0.5587, 'cmp': -0.0823}\n",
      "[Iter 24600 Task norm] Val Loss: 0.0690\n",
      "{'Angle Mean': 17.9384, 'Angle Median': 15.5038, 'Angle 11.25': 34.8611, 'Angle 22.5': 69.6524, 'Angle 30': 83.1463, 'cmp': -0.0395}\n",
      "[Iter 24600 Task dept] Val Loss: 0.5820\n",
      "{'abs_err': 0.5808, 'rel_err': 0.2358, 'sigma_1.25': 61.8746, 'sigma_1.25^2': 88.0851, 'sigma_1.25^3': 96.5203, 'cmp': 0.0448}\n",
      "======================================================================\n",
      "[Iter 24650 Task segm] Train Loss: 0.8061\n",
      "[Iter 24650 Task norm] Train Loss: 0.9378\n",
      "[Iter 24650 Task dept] Train Loss: 1.2842\n",
      "[Iter 24650 Total] Train Loss: 1.0094\n",
      "======================================================================\n",
      "[Iter 24700 Task segm] Train Loss: 0.8177\n",
      "[Iter 24700 Task norm] Train Loss: 0.9484\n",
      "[Iter 24700 Task dept] Train Loss: 1.2803\n",
      "[Iter 24700 Total] Train Loss: 1.0155\n",
      "======================================================================\n",
      "[Iter 24750 Task segm] Train Loss: 0.8229\n",
      "[Iter 24750 Task norm] Train Loss: 0.9333\n",
      "[Iter 24750 Task dept] Train Loss: 1.3496\n",
      "[Iter 24750 Total] Train Loss: 1.0352\n",
      "======================================================================\n",
      "[Iter 24800 Task segm] Train Loss: 0.7960\n",
      "[Iter 24800 Task norm] Train Loss: 0.9412\n",
      "[Iter 24800 Task dept] Train Loss: 1.3269\n",
      "[Iter 24800 Total] Train Loss: 1.0213\n",
      "======================================================================\n",
      "[Iter 24800 Task segm] Val Loss: 1.6017\n",
      "{'mIoU': 0.242, 'Pixel Acc': 0.5541, 'cmp': -0.0896}\n",
      "[Iter 24800 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 17.5957, 'Angle Median': 15.2763, 'Angle 11.25': 35.2636, 'Angle 22.5': 70.8477, 'Angle 30': 84.28, 'cmp': -0.0242}\n",
      "[Iter 24800 Task dept] Val Loss: 0.5884\n",
      "{'abs_err': 0.5854, 'rel_err': 0.2328, 'sigma_1.25': 61.3319, 'sigma_1.25^2': 87.957, 'sigma_1.25^3': 96.5751, 'cmp': 0.0436}\n",
      "======================================================================\n",
      "[Iter 24850 Task segm] Train Loss: 0.8207\n",
      "[Iter 24850 Task norm] Train Loss: 0.9308\n",
      "[Iter 24850 Task dept] Train Loss: 1.3353\n",
      "[Iter 24850 Total] Train Loss: 1.0289\n",
      "======================================================================\n",
      "[Iter 24900 Task segm] Train Loss: 0.8214\n",
      "[Iter 24900 Task norm] Train Loss: 0.9428\n",
      "[Iter 24900 Task dept] Train Loss: 1.3128\n",
      "[Iter 24900 Total] Train Loss: 1.0257\n",
      "======================================================================\n",
      "[Iter 24950 Task segm] Train Loss: 0.7971\n",
      "[Iter 24950 Task norm] Train Loss: 0.9201\n",
      "[Iter 24950 Task dept] Train Loss: 1.3145\n",
      "[Iter 24950 Total] Train Loss: 1.0106\n",
      "======================================================================\n",
      "[Iter 25000 Task segm] Train Loss: 0.8195\n",
      "[Iter 25000 Task norm] Train Loss: 0.9488\n",
      "[Iter 25000 Task dept] Train Loss: 1.3268\n",
      "[Iter 25000 Total] Train Loss: 1.0317\n",
      "======================================================================\n",
      "[Iter 25000 Task segm] Val Loss: 1.5922\n",
      "{'mIoU': 0.2385, 'Pixel Acc': 0.5566, 'cmp': -0.0939}\n",
      "[Iter 25000 Task norm] Val Loss: 0.0668\n",
      "{'Angle Mean': 17.6637, 'Angle Median': 15.3493, 'Angle 11.25': 35.3945, 'Angle 22.5': 70.2458, 'Angle 30': 83.9004, 'cmp': -0.0278}\n",
      "[Iter 25000 Task dept] Val Loss: 0.5902\n",
      "{'abs_err': 0.588, 'rel_err': 0.2342, 'sigma_1.25': 61.3147, 'sigma_1.25^2': 87.8806, 'sigma_1.25^3': 96.4623, 'cmp': 0.0412}\n",
      "======================================================================\n",
      "[Iter 25050 Task segm] Train Loss: 0.7895\n",
      "[Iter 25050 Task norm] Train Loss: 0.9145\n",
      "[Iter 25050 Task dept] Train Loss: 1.3138\n",
      "[Iter 25050 Total] Train Loss: 1.0059\n",
      "======================================================================\n",
      "[Iter 25100 Task segm] Train Loss: 0.7890\n",
      "[Iter 25100 Task norm] Train Loss: 0.9812\n",
      "[Iter 25100 Task dept] Train Loss: 1.3146\n",
      "[Iter 25100 Total] Train Loss: 1.0283\n",
      "======================================================================\n",
      "[Iter 25150 Task segm] Train Loss: 0.7949\n",
      "[Iter 25150 Task norm] Train Loss: 0.9295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 25150 Task dept] Train Loss: 1.3078\n",
      "[Iter 25150 Total] Train Loss: 1.0107\n",
      "======================================================================\n",
      "[Iter 25200 Task segm] Train Loss: 0.7992\n",
      "[Iter 25200 Task norm] Train Loss: 0.9367\n",
      "[Iter 25200 Task dept] Train Loss: 1.2883\n",
      "[Iter 25200 Total] Train Loss: 1.0081\n",
      "======================================================================\n",
      "[Iter 25200 Task segm] Val Loss: 1.5973\n",
      "{'mIoU': 0.2405, 'Pixel Acc': 0.5555, 'cmp': -0.0911}\n",
      "[Iter 25200 Task norm] Val Loss: 0.0652\n",
      "{'Angle Mean': 17.4845, 'Angle Median': 15.1703, 'Angle 11.25': 35.6131, 'Angle 22.5': 71.2231, 'Angle 30': 84.6689, 'cmp': -0.0175}\n",
      "[Iter 25200 Task dept] Val Loss: 0.5906\n",
      "{'abs_err': 0.5881, 'rel_err': 0.2325, 'sigma_1.25': 61.1041, 'sigma_1.25^2': 87.9114, 'sigma_1.25^3': 96.4981, 'cmp': 0.0419}\n",
      "======================================================================\n",
      "[Iter 25250 Task segm] Train Loss: 0.8149\n",
      "[Iter 25250 Task norm] Train Loss: 0.9586\n",
      "[Iter 25250 Task dept] Train Loss: 1.3163\n",
      "[Iter 25250 Total] Train Loss: 1.0299\n",
      "======================================================================\n",
      "[Iter 25300 Task segm] Train Loss: 0.8118\n",
      "[Iter 25300 Task norm] Train Loss: 0.9321\n",
      "[Iter 25300 Task dept] Train Loss: 1.3184\n",
      "[Iter 25300 Total] Train Loss: 1.0208\n",
      "======================================================================\n",
      "[Iter 25350 Task segm] Train Loss: 0.8087\n",
      "[Iter 25350 Task norm] Train Loss: 0.9490\n",
      "[Iter 25350 Task dept] Train Loss: 1.2932\n",
      "[Iter 25350 Total] Train Loss: 1.0169\n",
      "======================================================================\n",
      "[Iter 25400 Task segm] Train Loss: 0.8156\n",
      "[Iter 25400 Task norm] Train Loss: 0.9614\n",
      "[Iter 25400 Task dept] Train Loss: 1.2738\n",
      "[Iter 25400 Total] Train Loss: 1.0169\n",
      "======================================================================\n",
      "[Iter 25400 Task segm] Val Loss: 1.5916\n",
      "{'mIoU': 0.2437, 'Pixel Acc': 0.5591, 'cmp': -0.0824}\n",
      "[Iter 25400 Task norm] Val Loss: 0.0667\n",
      "{'Angle Mean': 17.7128, 'Angle Median': 15.3514, 'Angle 11.25': 34.7404, 'Angle 22.5': 70.7941, 'Angle 30': 84.125, 'cmp': -0.0301}\n",
      "[Iter 25400 Task dept] Val Loss: 0.5897\n",
      "{'abs_err': 0.5863, 'rel_err': 0.2362, 'sigma_1.25': 61.3298, 'sigma_1.25^2': 88.0084, 'sigma_1.25^3': 96.4148, 'cmp': 0.0404}\n",
      "======================================================================\n",
      "[Iter 25450 Task segm] Train Loss: 0.7966\n",
      "[Iter 25450 Task norm] Train Loss: 0.9127\n",
      "[Iter 25450 Task dept] Train Loss: 1.3023\n",
      "[Iter 25450 Total] Train Loss: 1.0039\n",
      "======================================================================\n",
      "[Iter 25500 Task segm] Train Loss: 0.8065\n",
      "[Iter 25500 Task norm] Train Loss: 0.9085\n",
      "[Iter 25500 Task dept] Train Loss: 1.2976\n",
      "[Iter 25500 Total] Train Loss: 1.0042\n",
      "======================================================================\n",
      "[Iter 25550 Task segm] Train Loss: 0.8045\n",
      "[Iter 25550 Task norm] Train Loss: 0.9170\n",
      "[Iter 25550 Task dept] Train Loss: 1.2996\n",
      "[Iter 25550 Total] Train Loss: 1.0070\n",
      "======================================================================\n",
      "[Iter 25600 Task segm] Train Loss: 0.8121\n",
      "[Iter 25600 Task norm] Train Loss: 0.9262\n",
      "[Iter 25600 Task dept] Train Loss: 1.2855\n",
      "[Iter 25600 Total] Train Loss: 1.0079\n",
      "======================================================================\n",
      "[Iter 25600 Task segm] Val Loss: 1.5949\n",
      "{'mIoU': 0.2434, 'Pixel Acc': 0.5555, 'cmp': -0.086}\n",
      "[Iter 25600 Task norm] Val Loss: 0.0676\n",
      "{'Angle Mean': 17.7539, 'Angle Median': 15.3459, 'Angle 11.25': 35.4288, 'Angle 22.5': 70.1241, 'Angle 30': 83.5207, 'cmp': -0.0298}\n",
      "[Iter 25600 Task dept] Val Loss: 0.5889\n",
      "{'abs_err': 0.586, 'rel_err': 0.2344, 'sigma_1.25': 61.2889, 'sigma_1.25^2': 88.015, 'sigma_1.25^3': 96.4621, 'cmp': 0.0419}\n",
      "======================================================================\n",
      "[Iter 25650 Task segm] Train Loss: 0.8038\n",
      "[Iter 25650 Task norm] Train Loss: 0.9613\n",
      "[Iter 25650 Task dept] Train Loss: 1.3078\n",
      "[Iter 25650 Total] Train Loss: 1.0243\n",
      "======================================================================\n",
      "[Iter 25700 Task segm] Train Loss: 0.7944\n",
      "[Iter 25700 Task norm] Train Loss: 0.9203\n",
      "[Iter 25700 Task dept] Train Loss: 1.2880\n",
      "[Iter 25700 Total] Train Loss: 1.0009\n",
      "======================================================================\n",
      "[Iter 25750 Task segm] Train Loss: 0.7797\n",
      "[Iter 25750 Task norm] Train Loss: 0.9392\n",
      "[Iter 25750 Task dept] Train Loss: 1.3139\n",
      "[Iter 25750 Total] Train Loss: 1.0109\n",
      "======================================================================\n",
      "[Iter 25800 Task segm] Train Loss: 0.8125\n",
      "[Iter 25800 Task norm] Train Loss: 0.9406\n",
      "[Iter 25800 Task dept] Train Loss: 1.2789\n",
      "[Iter 25800 Total] Train Loss: 1.0107\n",
      "======================================================================\n",
      "[Iter 25800 Task segm] Val Loss: 1.6012\n",
      "{'mIoU': 0.2394, 'Pixel Acc': 0.5561, 'cmp': -0.0927}\n",
      "[Iter 25800 Task norm] Val Loss: 0.0664\n",
      "{'Angle Mean': 17.6296, 'Angle Median': 15.3272, 'Angle 11.25': 35.115, 'Angle 22.5': 70.591, 'Angle 30': 84.1227, 'cmp': -0.0272}\n",
      "[Iter 25800 Task dept] Val Loss: 0.5896\n",
      "{'abs_err': 0.587, 'rel_err': 0.2363, 'sigma_1.25': 61.1655, 'sigma_1.25^2': 87.7951, 'sigma_1.25^3': 96.4153, 'cmp': 0.039}\n",
      "======================================================================\n",
      "[Iter 25850 Task segm] Train Loss: 0.8017\n",
      "[Iter 25850 Task norm] Train Loss: 0.9027\n",
      "[Iter 25850 Task dept] Train Loss: 1.2896\n",
      "[Iter 25850 Total] Train Loss: 0.9980\n",
      "======================================================================\n",
      "[Iter 25900 Task segm] Train Loss: 0.7993\n",
      "[Iter 25900 Task norm] Train Loss: 0.9325\n",
      "[Iter 25900 Task dept] Train Loss: 1.3128\n",
      "[Iter 25900 Total] Train Loss: 1.0149\n",
      "======================================================================\n",
      "[Iter 25950 Task segm] Train Loss: 0.8024\n",
      "[Iter 25950 Task norm] Train Loss: 0.9358\n",
      "[Iter 25950 Task dept] Train Loss: 1.3000\n",
      "[Iter 25950 Total] Train Loss: 1.0128\n",
      "======================================================================\n",
      "[Iter 26000 Task segm] Train Loss: 0.7914\n",
      "[Iter 26000 Task norm] Train Loss: 0.9382\n",
      "[Iter 26000 Task dept] Train Loss: 1.2696\n",
      "[Iter 26000 Total] Train Loss: 0.9997\n",
      "======================================================================\n",
      "[Iter 26000 Task segm] Val Loss: 1.6061\n",
      "{'mIoU': 0.243, 'Pixel Acc': 0.5547, 'cmp': -0.0872}\n",
      "[Iter 26000 Task norm] Val Loss: 0.0662\n",
      "{'Angle Mean': 17.5317, 'Angle Median': 15.056, 'Angle 11.25': 36.0433, 'Angle 22.5': 71.1053, 'Angle 30': 84.1665, 'cmp': -0.0154}\n",
      "[Iter 26000 Task dept] Val Loss: 0.6040\n",
      "{'abs_err': 0.5991, 'rel_err': 0.23, 'sigma_1.25': 60.5952, 'sigma_1.25^2': 87.5956, 'sigma_1.25^3': 96.3156, 'cmp': 0.0375}\n",
      "======================================================================\n",
      "[Iter 26050 Task segm] Train Loss: 0.7979\n",
      "[Iter 26050 Task norm] Train Loss: 0.9358\n",
      "[Iter 26050 Task dept] Train Loss: 1.2976\n",
      "[Iter 26050 Total] Train Loss: 1.0104\n",
      "======================================================================\n",
      "[Iter 26100 Task segm] Train Loss: 0.7860\n",
      "[Iter 26100 Task norm] Train Loss: 0.9304\n",
      "[Iter 26100 Task dept] Train Loss: 1.2653\n",
      "[Iter 26100 Total] Train Loss: 0.9939\n",
      "======================================================================\n",
      "[Iter 26150 Task segm] Train Loss: 0.8087\n",
      "[Iter 26150 Task norm] Train Loss: 0.9167\n",
      "[Iter 26150 Task dept] Train Loss: 1.2795\n",
      "[Iter 26150 Total] Train Loss: 1.0016\n",
      "======================================================================\n",
      "[Iter 26200 Task segm] Train Loss: 0.8082\n",
      "[Iter 26200 Task norm] Train Loss: 0.9310\n",
      "[Iter 26200 Task dept] Train Loss: 1.2691\n",
      "[Iter 26200 Total] Train Loss: 1.0027\n",
      "======================================================================\n",
      "[Iter 26200 Task segm] Val Loss: 1.5958\n",
      "{'mIoU': 0.2406, 'Pixel Acc': 0.5551, 'cmp': -0.0913}\n",
      "[Iter 26200 Task norm] Val Loss: 0.0682\n",
      "{'Angle Mean': 17.8364, 'Angle Median': 15.4596, 'Angle 11.25': 34.9758, 'Angle 22.5': 69.9794, 'Angle 30': 83.4209, 'cmp': -0.0355}\n",
      "[Iter 26200 Task dept] Val Loss: 0.5881\n",
      "{'abs_err': 0.5873, 'rel_err': 0.2394, 'sigma_1.25': 61.2217, 'sigma_1.25^2': 87.8382, 'sigma_1.25^3': 96.3598, 'cmp': 0.0366}\n",
      "======================================================================\n",
      "[Iter 26250 Task segm] Train Loss: 0.8044\n",
      "[Iter 26250 Task norm] Train Loss: 0.9564\n",
      "[Iter 26250 Task dept] Train Loss: 1.3006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 26250 Total] Train Loss: 1.0204\n",
      "======================================================================\n",
      "[Iter 26300 Task segm] Train Loss: 0.7944\n",
      "[Iter 26300 Task norm] Train Loss: 0.9334\n",
      "[Iter 26300 Task dept] Train Loss: 1.3017\n",
      "[Iter 26300 Total] Train Loss: 1.0098\n",
      "======================================================================\n",
      "[Iter 26350 Task segm] Train Loss: 0.8145\n",
      "[Iter 26350 Task norm] Train Loss: 0.9321\n",
      "[Iter 26350 Task dept] Train Loss: 1.3018\n",
      "[Iter 26350 Total] Train Loss: 1.0161\n",
      "======================================================================\n",
      "[Iter 26400 Task segm] Train Loss: 0.7852\n",
      "[Iter 26400 Task norm] Train Loss: 0.9424\n",
      "[Iter 26400 Task dept] Train Loss: 1.3467\n",
      "[Iter 26400 Total] Train Loss: 1.0247\n",
      "======================================================================\n",
      "[Iter 26400 Task segm] Val Loss: 1.6023\n",
      "{'mIoU': 0.2401, 'Pixel Acc': 0.5543, 'cmp': -0.0929}\n",
      "[Iter 26400 Task norm] Val Loss: 0.0646\n",
      "{'Angle Mean': 17.4075, 'Angle Median': 15.0249, 'Angle 11.25': 35.5617, 'Angle 22.5': 71.8008, 'Angle 30': 84.8269, 'cmp': -0.0129}\n",
      "[Iter 26400 Task dept] Val Loss: 0.5910\n",
      "{'abs_err': 0.5907, 'rel_err': 0.243, 'sigma_1.25': 61.0836, 'sigma_1.25^2': 87.6159, 'sigma_1.25^3': 96.3217, 'cmp': 0.0316}\n",
      "======================================================================\n",
      "[Iter 26450 Task segm] Train Loss: 0.8004\n",
      "[Iter 26450 Task norm] Train Loss: 0.9123\n",
      "[Iter 26450 Task dept] Train Loss: 1.2499\n",
      "[Iter 26450 Total] Train Loss: 0.9875\n",
      "======================================================================\n",
      "[Iter 26500 Task segm] Train Loss: 0.8270\n",
      "[Iter 26500 Task norm] Train Loss: 0.9427\n",
      "[Iter 26500 Task dept] Train Loss: 1.3234\n",
      "[Iter 26500 Total] Train Loss: 1.0311\n",
      "======================================================================\n",
      "[Iter 26550 Task segm] Train Loss: 0.8023\n",
      "[Iter 26550 Task norm] Train Loss: 0.9305\n",
      "[Iter 26550 Task dept] Train Loss: 1.2963\n",
      "[Iter 26550 Total] Train Loss: 1.0097\n",
      "======================================================================\n",
      "[Iter 26600 Task segm] Train Loss: 0.7971\n",
      "[Iter 26600 Task norm] Train Loss: 0.9377\n",
      "[Iter 26600 Task dept] Train Loss: 1.3251\n",
      "[Iter 26600 Total] Train Loss: 1.0200\n",
      "======================================================================\n",
      "[Iter 26600 Task segm] Val Loss: 1.5888\n",
      "{'mIoU': 0.2447, 'Pixel Acc': 0.5595, 'cmp': -0.0801}\n",
      "[Iter 26600 Task norm] Val Loss: 0.0661\n",
      "{'Angle Mean': 17.596, 'Angle Median': 15.271, 'Angle 11.25': 35.4769, 'Angle 22.5': 70.5191, 'Angle 30': 84.0922, 'cmp': -0.0242}\n",
      "[Iter 26600 Task dept] Val Loss: 0.5925\n",
      "{'abs_err': 0.5898, 'rel_err': 0.2368, 'sigma_1.25': 61.0499, 'sigma_1.25^2': 87.7395, 'sigma_1.25^3': 96.4175, 'cmp': 0.0372}\n",
      "======================================================================\n",
      "[Iter 26650 Task segm] Train Loss: 0.8047\n",
      "[Iter 26650 Task norm] Train Loss: 0.9353\n",
      "[Iter 26650 Task dept] Train Loss: 1.3095\n",
      "[Iter 26650 Total] Train Loss: 1.0165\n",
      "======================================================================\n",
      "[Iter 26700 Task segm] Train Loss: 0.7852\n",
      "[Iter 26700 Task norm] Train Loss: 0.9215\n",
      "[Iter 26700 Task dept] Train Loss: 1.3187\n",
      "[Iter 26700 Total] Train Loss: 1.0085\n",
      "======================================================================\n",
      "[Iter 26750 Task segm] Train Loss: 0.7837\n",
      "[Iter 26750 Task norm] Train Loss: 0.9257\n",
      "[Iter 26750 Task dept] Train Loss: 1.3030\n",
      "[Iter 26750 Total] Train Loss: 1.0042\n",
      "======================================================================\n",
      "[Iter 26800 Task segm] Train Loss: 0.8111\n",
      "[Iter 26800 Task norm] Train Loss: 0.9270\n",
      "[Iter 26800 Task dept] Train Loss: 1.2751\n",
      "[Iter 26800 Total] Train Loss: 1.0044\n",
      "======================================================================\n",
      "[Iter 26800 Task segm] Val Loss: 1.5974\n",
      "{'mIoU': 0.2454, 'Pixel Acc': 0.5564, 'cmp': -0.0816}\n",
      "[Iter 26800 Task norm] Val Loss: 0.0652\n",
      "{'Angle Mean': 17.4681, 'Angle Median': 15.0383, 'Angle 11.25': 35.8827, 'Angle 22.5': 71.4241, 'Angle 30': 84.4921, 'cmp': -0.0137}\n",
      "[Iter 26800 Task dept] Val Loss: 0.5908\n",
      "{'abs_err': 0.5886, 'rel_err': 0.2345, 'sigma_1.25': 61.1072, 'sigma_1.25^2': 87.9145, 'sigma_1.25^3': 96.5096, 'cmp': 0.0402}\n",
      "======================================================================\n",
      "[Iter 26850 Task segm] Train Loss: 0.8146\n",
      "[Iter 26850 Task norm] Train Loss: 0.9111\n",
      "[Iter 26850 Task dept] Train Loss: 1.3080\n",
      "[Iter 26850 Total] Train Loss: 1.0112\n",
      "======================================================================\n",
      "[Iter 26900 Task segm] Train Loss: 0.7988\n",
      "[Iter 26900 Task norm] Train Loss: 0.9195\n",
      "[Iter 26900 Task dept] Train Loss: 1.2818\n",
      "[Iter 26900 Total] Train Loss: 1.0000\n",
      "======================================================================\n",
      "[Iter 26950 Task segm] Train Loss: 0.8210\n",
      "[Iter 26950 Task norm] Train Loss: 0.9362\n",
      "[Iter 26950 Task dept] Train Loss: 1.2806\n",
      "[Iter 26950 Total] Train Loss: 1.0126\n",
      "======================================================================\n",
      "[Iter 27000 Task segm] Train Loss: 0.8074\n",
      "[Iter 27000 Task norm] Train Loss: 0.9229\n",
      "[Iter 27000 Task dept] Train Loss: 1.2929\n",
      "[Iter 27000 Total] Train Loss: 1.0077\n",
      "======================================================================\n",
      "[Iter 27000 Task segm] Val Loss: 1.6046\n",
      "{'mIoU': 0.2436, 'Pixel Acc': 0.557, 'cmp': -0.0843}\n",
      "[Iter 27000 Task norm] Val Loss: 0.0654\n",
      "{'Angle Mean': 17.4816, 'Angle Median': 15.0803, 'Angle 11.25': 35.7478, 'Angle 22.5': 71.2822, 'Angle 30': 84.5165, 'cmp': -0.0156}\n",
      "[Iter 27000 Task dept] Val Loss: 0.5838\n",
      "{'abs_err': 0.5815, 'rel_err': 0.2317, 'sigma_1.25': 61.7197, 'sigma_1.25^2': 88.1604, 'sigma_1.25^3': 96.5196, 'cmp': 0.0475}\n",
      "======================================================================\n",
      "[Iter 27050 Task segm] Train Loss: 0.7804\n",
      "[Iter 27050 Task norm] Train Loss: 0.9158\n",
      "[Iter 27050 Task dept] Train Loss: 1.2817\n",
      "[Iter 27050 Total] Train Loss: 0.9926\n",
      "======================================================================\n",
      "[Iter 27100 Task segm] Train Loss: 0.7978\n",
      "[Iter 27100 Task norm] Train Loss: 0.9094\n",
      "[Iter 27100 Task dept] Train Loss: 1.2593\n",
      "[Iter 27100 Total] Train Loss: 0.9888\n",
      "======================================================================\n",
      "[Iter 27150 Task segm] Train Loss: 0.7936\n",
      "[Iter 27150 Task norm] Train Loss: 0.9253\n",
      "[Iter 27150 Task dept] Train Loss: 1.2880\n",
      "[Iter 27150 Total] Train Loss: 1.0023\n",
      "======================================================================\n",
      "[Iter 27200 Task segm] Train Loss: 0.7862\n",
      "[Iter 27200 Task norm] Train Loss: 0.9447\n",
      "[Iter 27200 Task dept] Train Loss: 1.2799\n",
      "[Iter 27200 Total] Train Loss: 1.0036\n",
      "======================================================================\n",
      "[Iter 27200 Task segm] Val Loss: 1.5866\n",
      "{'mIoU': 0.2452, 'Pixel Acc': 0.5598, 'cmp': -0.0789}\n",
      "[Iter 27200 Task norm] Val Loss: 0.0666\n",
      "{'Angle Mean': 17.649, 'Angle Median': 15.3334, 'Angle 11.25': 35.2383, 'Angle 22.5': 70.4952, 'Angle 30': 84.0282, 'cmp': -0.0273}\n",
      "[Iter 27200 Task dept] Val Loss: 0.5880\n",
      "{'abs_err': 0.5853, 'rel_err': 0.2334, 'sigma_1.25': 61.3765, 'sigma_1.25^2': 87.97, 'sigma_1.25^3': 96.5048, 'cmp': 0.0432}\n",
      "======================================================================\n",
      "[Iter 27250 Task segm] Train Loss: 0.7699\n",
      "[Iter 27250 Task norm] Train Loss: 0.9182\n",
      "[Iter 27250 Task dept] Train Loss: 1.2950\n",
      "[Iter 27250 Total] Train Loss: 0.9944\n",
      "======================================================================\n",
      "[Iter 27300 Task segm] Train Loss: 0.7856\n",
      "[Iter 27300 Task norm] Train Loss: 0.9077\n",
      "[Iter 27300 Task dept] Train Loss: 1.2538\n",
      "[Iter 27300 Total] Train Loss: 0.9824\n",
      "======================================================================\n",
      "[Iter 27350 Task segm] Train Loss: 0.8080\n",
      "[Iter 27350 Task norm] Train Loss: 0.9320\n",
      "[Iter 27350 Task dept] Train Loss: 1.3079\n",
      "[Iter 27350 Total] Train Loss: 1.0160\n",
      "======================================================================\n",
      "[Iter 27400 Task segm] Train Loss: 0.7943\n",
      "[Iter 27400 Task norm] Train Loss: 0.9251\n",
      "[Iter 27400 Task dept] Train Loss: 1.2820\n",
      "[Iter 27400 Total] Train Loss: 1.0005\n",
      "======================================================================\n",
      "[Iter 27400 Task segm] Val Loss: 1.5962\n",
      "{'mIoU': 0.243, 'Pixel Acc': 0.5571, 'cmp': -0.0852}\n",
      "[Iter 27400 Task norm] Val Loss: 0.0657\n",
      "{'Angle Mean': 17.5587, 'Angle Median': 15.246, 'Angle 11.25': 35.4108, 'Angle 22.5': 70.8788, 'Angle 30': 84.395, 'cmp': -0.0221}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 27400 Task dept] Val Loss: 0.5911\n",
      "{'abs_err': 0.589, 'rel_err': 0.2365, 'sigma_1.25': 61.0709, 'sigma_1.25^2': 87.8109, 'sigma_1.25^3': 96.3489, 'cmp': 0.0378}\n",
      "======================================================================\n",
      "[Iter 27450 Task segm] Train Loss: 0.7944\n",
      "[Iter 27450 Task norm] Train Loss: 0.9279\n",
      "[Iter 27450 Task dept] Train Loss: 1.2883\n",
      "[Iter 27450 Total] Train Loss: 1.0035\n",
      "======================================================================\n",
      "[Iter 27500 Task segm] Train Loss: 0.7750\n",
      "[Iter 27500 Task norm] Train Loss: 0.9246\n",
      "[Iter 27500 Task dept] Train Loss: 1.2198\n",
      "[Iter 27500 Total] Train Loss: 0.9732\n",
      "======================================================================\n",
      "[Iter 27550 Task segm] Train Loss: 0.8112\n",
      "[Iter 27550 Task norm] Train Loss: 0.9419\n",
      "[Iter 27550 Task dept] Train Loss: 1.3142\n",
      "[Iter 27550 Total] Train Loss: 1.0224\n",
      "======================================================================\n",
      "[Iter 27600 Task segm] Train Loss: 0.7828\n",
      "[Iter 27600 Task norm] Train Loss: 0.9149\n",
      "[Iter 27600 Task dept] Train Loss: 1.2808\n",
      "[Iter 27600 Total] Train Loss: 0.9928\n",
      "======================================================================\n",
      "[Iter 27600 Task segm] Val Loss: 1.6030\n",
      "{'mIoU': 0.2393, 'Pixel Acc': 0.5567, 'cmp': -0.0924}\n",
      "[Iter 27600 Task norm] Val Loss: 0.0655\n",
      "{'Angle Mean': 17.5359, 'Angle Median': 15.2189, 'Angle 11.25': 35.375, 'Angle 22.5': 71.0893, 'Angle 30': 84.4633, 'cmp': -0.021}\n",
      "[Iter 27600 Task dept] Val Loss: 0.5876\n",
      "{'abs_err': 0.5851, 'rel_err': 0.2334, 'sigma_1.25': 61.4748, 'sigma_1.25^2': 87.9201, 'sigma_1.25^3': 96.4607, 'cmp': 0.0434}\n",
      "======================================================================\n",
      "[Iter 27650 Task segm] Train Loss: 0.7859\n",
      "[Iter 27650 Task norm] Train Loss: 0.9088\n",
      "[Iter 27650 Task dept] Train Loss: 1.2704\n",
      "[Iter 27650 Total] Train Loss: 0.9884\n",
      "======================================================================\n",
      "[Iter 27700 Task segm] Train Loss: 0.7812\n",
      "[Iter 27700 Task norm] Train Loss: 0.9205\n",
      "[Iter 27700 Task dept] Train Loss: 1.2565\n",
      "[Iter 27700 Total] Train Loss: 0.9861\n",
      "======================================================================\n",
      "[Iter 27750 Task segm] Train Loss: 0.7791\n",
      "[Iter 27750 Task norm] Train Loss: 0.9087\n",
      "[Iter 27750 Task dept] Train Loss: 1.2782\n",
      "[Iter 27750 Total] Train Loss: 0.9887\n",
      "======================================================================\n",
      "[Iter 27800 Task segm] Train Loss: 0.7675\n",
      "[Iter 27800 Task norm] Train Loss: 0.9108\n",
      "[Iter 27800 Task dept] Train Loss: 1.2912\n",
      "[Iter 27800 Total] Train Loss: 0.9898\n",
      "======================================================================\n",
      "[Iter 27800 Task segm] Val Loss: 1.6052\n",
      "{'mIoU': 0.2396, 'Pixel Acc': 0.556, 'cmp': -0.0924}\n",
      "[Iter 27800 Task norm] Val Loss: 0.0683\n",
      "{'Angle Mean': 17.8284, 'Angle Median': 15.395, 'Angle 11.25': 35.2447, 'Angle 22.5': 69.9292, 'Angle 30': 83.3813, 'cmp': -0.0332}\n",
      "[Iter 27800 Task dept] Val Loss: 0.5890\n",
      "{'abs_err': 0.586, 'rel_err': 0.2298, 'sigma_1.25': 61.2721, 'sigma_1.25^2': 88.1338, 'sigma_1.25^3': 96.5235, 'cmp': 0.046}\n",
      "======================================================================\n",
      "[Iter 27850 Task segm] Train Loss: 0.7847\n",
      "[Iter 27850 Task norm] Train Loss: 0.9206\n",
      "[Iter 27850 Task dept] Train Loss: 1.2723\n",
      "[Iter 27850 Total] Train Loss: 0.9925\n",
      "======================================================================\n",
      "[Iter 27900 Task segm] Train Loss: 0.7763\n",
      "[Iter 27900 Task norm] Train Loss: 0.9387\n",
      "[Iter 27900 Task dept] Train Loss: 1.2775\n",
      "[Iter 27900 Total] Train Loss: 0.9975\n",
      "======================================================================\n",
      "[Iter 27950 Task segm] Train Loss: 0.7973\n",
      "[Iter 27950 Task norm] Train Loss: 0.9368\n",
      "[Iter 27950 Task dept] Train Loss: 1.3007\n",
      "[Iter 27950 Total] Train Loss: 1.0116\n",
      "======================================================================\n",
      "[Iter 28000 Task segm] Train Loss: 0.7892\n",
      "[Iter 28000 Task norm] Train Loss: 0.9212\n",
      "[Iter 28000 Task dept] Train Loss: 1.2673\n",
      "[Iter 28000 Total] Train Loss: 0.9926\n",
      "======================================================================\n",
      "[Iter 28000 Task segm] Val Loss: 1.5896\n",
      "{'mIoU': 0.2454, 'Pixel Acc': 0.5593, 'cmp': -0.079}\n",
      "[Iter 28000 Task norm] Val Loss: 0.0666\n",
      "{'Angle Mean': 17.6145, 'Angle Median': 15.2495, 'Angle 11.25': 35.741, 'Angle 22.5': 70.4218, 'Angle 30': 83.9353, 'cmp': -0.0232}\n",
      "[Iter 28000 Task dept] Val Loss: 0.5863\n",
      "{'abs_err': 0.5845, 'rel_err': 0.2356, 'sigma_1.25': 61.5828, 'sigma_1.25^2': 88.0047, 'sigma_1.25^3': 96.4465, 'cmp': 0.0424}\n",
      "======================================================================\n",
      "[Iter 28050 Task segm] Train Loss: 0.7883\n",
      "[Iter 28050 Task norm] Train Loss: 0.9430\n",
      "[Iter 28050 Task dept] Train Loss: 1.2597\n",
      "[Iter 28050 Total] Train Loss: 0.9970\n",
      "======================================================================\n",
      "[Iter 28100 Task segm] Train Loss: 0.8095\n",
      "[Iter 28100 Task norm] Train Loss: 0.9338\n",
      "[Iter 28100 Task dept] Train Loss: 1.2934\n",
      "[Iter 28100 Total] Train Loss: 1.0122\n",
      "======================================================================\n",
      "[Iter 28150 Task segm] Train Loss: 0.7911\n",
      "[Iter 28150 Task norm] Train Loss: 0.9061\n",
      "[Iter 28150 Task dept] Train Loss: 1.3224\n",
      "[Iter 28150 Total] Train Loss: 1.0065\n",
      "======================================================================\n",
      "[Iter 28200 Task segm] Train Loss: 0.8093\n",
      "[Iter 28200 Task norm] Train Loss: 0.9325\n",
      "[Iter 28200 Task dept] Train Loss: 1.2744\n",
      "[Iter 28200 Total] Train Loss: 1.0054\n",
      "======================================================================\n",
      "[Iter 28200 Task segm] Val Loss: 1.5917\n",
      "{'mIoU': 0.2435, 'Pixel Acc': 0.5576, 'cmp': -0.0839}\n",
      "[Iter 28200 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 17.5915, 'Angle Median': 15.2786, 'Angle 11.25': 35.3425, 'Angle 22.5': 70.7498, 'Angle 30': 84.2857, 'cmp': -0.024}\n",
      "[Iter 28200 Task dept] Val Loss: 0.5882\n",
      "{'abs_err': 0.586, 'rel_err': 0.2348, 'sigma_1.25': 61.383, 'sigma_1.25^2': 87.9765, 'sigma_1.25^3': 96.4793, 'cmp': 0.0418}\n",
      "======================================================================\n",
      "[Iter 28250 Task segm] Train Loss: 0.7939\n",
      "[Iter 28250 Task norm] Train Loss: 0.9175\n",
      "[Iter 28250 Task dept] Train Loss: 1.3104\n",
      "[Iter 28250 Total] Train Loss: 1.0073\n",
      "======================================================================\n",
      "[Iter 28300 Task segm] Train Loss: 0.7949\n",
      "[Iter 28300 Task norm] Train Loss: 0.9300\n",
      "[Iter 28300 Task dept] Train Loss: 1.2759\n",
      "[Iter 28300 Total] Train Loss: 1.0003\n",
      "======================================================================\n",
      "[Iter 28350 Task segm] Train Loss: 0.7816\n",
      "[Iter 28350 Task norm] Train Loss: 0.9155\n",
      "[Iter 28350 Task dept] Train Loss: 1.2419\n",
      "[Iter 28350 Total] Train Loss: 0.9797\n",
      "======================================================================\n",
      "[Iter 28400 Task segm] Train Loss: 0.7842\n",
      "[Iter 28400 Task norm] Train Loss: 0.9275\n",
      "[Iter 28400 Task dept] Train Loss: 1.2587\n",
      "[Iter 28400 Total] Train Loss: 0.9901\n",
      "======================================================================\n",
      "[Iter 28400 Task segm] Val Loss: 1.5993\n",
      "{'mIoU': 0.2395, 'Pixel Acc': 0.5566, 'cmp': -0.092}\n",
      "[Iter 28400 Task norm] Val Loss: 0.0652\n",
      "{'Angle Mean': 17.443, 'Angle Median': 15.0487, 'Angle 11.25': 35.9852, 'Angle 22.5': 71.3032, 'Angle 30': 84.4855, 'cmp': -0.0134}\n",
      "[Iter 28400 Task dept] Val Loss: 0.5887\n",
      "{'abs_err': 0.5859, 'rel_err': 0.2322, 'sigma_1.25': 61.3957, 'sigma_1.25^2': 88.0266, 'sigma_1.25^3': 96.4944, 'cmp': 0.0442}\n",
      "======================================================================\n",
      "[Iter 28450 Task segm] Train Loss: 0.7943\n",
      "[Iter 28450 Task norm] Train Loss: 0.9171\n",
      "[Iter 28450 Task dept] Train Loss: 1.2575\n",
      "[Iter 28450 Total] Train Loss: 0.9897\n",
      "======================================================================\n",
      "[Iter 28500 Task segm] Train Loss: 0.8045\n",
      "[Iter 28500 Task norm] Train Loss: 0.9116\n",
      "[Iter 28500 Task dept] Train Loss: 1.2788\n",
      "[Iter 28500 Total] Train Loss: 0.9983\n",
      "======================================================================\n",
      "[Iter 28550 Task segm] Train Loss: 0.7745\n",
      "[Iter 28550 Task norm] Train Loss: 0.9194\n",
      "[Iter 28550 Task dept] Train Loss: 1.2635\n",
      "[Iter 28550 Total] Train Loss: 0.9858\n",
      "======================================================================\n",
      "[Iter 28600 Task segm] Train Loss: 0.7718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 28600 Task norm] Train Loss: 0.9213\n",
      "[Iter 28600 Task dept] Train Loss: 1.2449\n",
      "[Iter 28600 Total] Train Loss: 0.9793\n",
      "======================================================================\n",
      "[Iter 28600 Task segm] Val Loss: 1.6000\n",
      "{'mIoU': 0.2419, 'Pixel Acc': 0.5567, 'cmp': -0.0876}\n",
      "[Iter 28600 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 17.5902, 'Angle Median': 15.2245, 'Angle 11.25': 35.258, 'Angle 22.5': 70.9686, 'Angle 30': 84.2868, 'cmp': -0.0231}\n",
      "[Iter 28600 Task dept] Val Loss: 0.5911\n",
      "{'abs_err': 0.589, 'rel_err': 0.2357, 'sigma_1.25': 61.1139, 'sigma_1.25^2': 87.7803, 'sigma_1.25^3': 96.4323, 'cmp': 0.0386}\n",
      "======================================================================\n",
      "[Iter 28650 Task segm] Train Loss: 0.7983\n",
      "[Iter 28650 Task norm] Train Loss: 0.9124\n",
      "[Iter 28650 Task dept] Train Loss: 1.2702\n",
      "[Iter 28650 Total] Train Loss: 0.9936\n",
      "======================================================================\n",
      "[Iter 28700 Task segm] Train Loss: 0.7865\n",
      "[Iter 28700 Task norm] Train Loss: 0.9164\n",
      "[Iter 28700 Task dept] Train Loss: 1.2392\n",
      "[Iter 28700 Total] Train Loss: 0.9807\n",
      "======================================================================\n",
      "[Iter 28750 Task segm] Train Loss: 0.7759\n",
      "[Iter 28750 Task norm] Train Loss: 0.9406\n",
      "[Iter 28750 Task dept] Train Loss: 1.2709\n",
      "[Iter 28750 Total] Train Loss: 0.9958\n",
      "======================================================================\n",
      "[Iter 28800 Task segm] Train Loss: 0.7858\n",
      "[Iter 28800 Task norm] Train Loss: 0.9252\n",
      "[Iter 28800 Task dept] Train Loss: 1.2555\n",
      "[Iter 28800 Total] Train Loss: 0.9889\n",
      "======================================================================\n",
      "[Iter 28800 Task segm] Val Loss: 1.6070\n",
      "{'mIoU': 0.2422, 'Pixel Acc': 0.5569, 'cmp': -0.0869}\n",
      "[Iter 28800 Task norm] Val Loss: 0.0665\n",
      "{'Angle Mean': 17.6146, 'Angle Median': 15.1528, 'Angle 11.25': 35.7545, 'Angle 22.5': 70.7285, 'Angle 30': 84.0249, 'cmp': -0.0208}\n",
      "[Iter 28800 Task dept] Val Loss: 0.5882\n",
      "{'abs_err': 0.5873, 'rel_err': 0.2378, 'sigma_1.25': 61.2698, 'sigma_1.25^2': 87.95, 'sigma_1.25^3': 96.4786, 'cmp': 0.0386}\n",
      "======================================================================\n",
      "[Iter 28850 Task segm] Train Loss: 0.8266\n",
      "[Iter 28850 Task norm] Train Loss: 0.9154\n",
      "[Iter 28850 Task dept] Train Loss: 1.2563\n",
      "[Iter 28850 Total] Train Loss: 0.9995\n",
      "======================================================================\n",
      "[Iter 28900 Task segm] Train Loss: 0.7821\n",
      "[Iter 28900 Task norm] Train Loss: 0.9377\n",
      "[Iter 28900 Task dept] Train Loss: 1.3041\n",
      "[Iter 28900 Total] Train Loss: 1.0080\n",
      "======================================================================\n",
      "[Iter 28950 Task segm] Train Loss: 0.7832\n",
      "[Iter 28950 Task norm] Train Loss: 0.9333\n",
      "[Iter 28950 Task dept] Train Loss: 1.2543\n",
      "[Iter 28950 Total] Train Loss: 0.9903\n",
      "======================================================================\n",
      "[Iter 29000 Task segm] Train Loss: 0.7960\n",
      "[Iter 29000 Task norm] Train Loss: 0.9171\n",
      "[Iter 29000 Task dept] Train Loss: 1.2581\n",
      "[Iter 29000 Total] Train Loss: 0.9904\n",
      "======================================================================\n",
      "[Iter 29000 Task segm] Val Loss: 1.5950\n",
      "{'mIoU': 0.2404, 'Pixel Acc': 0.5569, 'cmp': -0.0902}\n",
      "[Iter 29000 Task norm] Val Loss: 0.0675\n",
      "{'Angle Mean': 17.7952, 'Angle Median': 15.4187, 'Angle 11.25': 34.8398, 'Angle 22.5': 70.2822, 'Angle 30': 83.8035, 'cmp': -0.0335}\n",
      "[Iter 29000 Task dept] Val Loss: 0.5880\n",
      "{'abs_err': 0.5859, 'rel_err': 0.2351, 'sigma_1.25': 61.3531, 'sigma_1.25^2': 87.9309, 'sigma_1.25^3': 96.4264, 'cmp': 0.0413}\n",
      "======================================================================\n",
      "[Iter 29050 Task segm] Train Loss: 0.7780\n",
      "[Iter 29050 Task norm] Train Loss: 0.9369\n",
      "[Iter 29050 Task dept] Train Loss: 1.2910\n",
      "[Iter 29050 Total] Train Loss: 1.0020\n",
      "======================================================================\n",
      "[Iter 29100 Task segm] Train Loss: 0.7792\n",
      "[Iter 29100 Task norm] Train Loss: 0.9162\n",
      "[Iter 29100 Task dept] Train Loss: 1.2664\n",
      "[Iter 29100 Total] Train Loss: 0.9873\n",
      "======================================================================\n",
      "[Iter 29150 Task segm] Train Loss: 0.7935\n",
      "[Iter 29150 Task norm] Train Loss: 0.9401\n",
      "[Iter 29150 Task dept] Train Loss: 1.3040\n",
      "[Iter 29150 Total] Train Loss: 1.0125\n",
      "======================================================================\n",
      "[Iter 29200 Task segm] Train Loss: 0.7962\n",
      "[Iter 29200 Task norm] Train Loss: 0.9042\n",
      "[Iter 29200 Task dept] Train Loss: 1.2619\n",
      "[Iter 29200 Total] Train Loss: 0.9874\n",
      "======================================================================\n",
      "[Iter 29200 Task segm] Val Loss: 1.5990\n",
      "{'mIoU': 0.2429, 'Pixel Acc': 0.5571, 'cmp': -0.0853}\n",
      "[Iter 29200 Task norm] Val Loss: 0.0675\n",
      "{'Angle Mean': 17.7447, 'Angle Median': 15.3491, 'Angle 11.25': 35.3277, 'Angle 22.5': 70.2028, 'Angle 30': 83.6604, 'cmp': -0.0297}\n",
      "[Iter 29200 Task dept] Val Loss: 0.5901\n",
      "{'abs_err': 0.5875, 'rel_err': 0.234, 'sigma_1.25': 61.1565, 'sigma_1.25^2': 87.8731, 'sigma_1.25^3': 96.455, 'cmp': 0.041}\n",
      "======================================================================\n",
      "[Iter 29250 Task segm] Train Loss: 0.7928\n",
      "[Iter 29250 Task norm] Train Loss: 0.9214\n",
      "[Iter 29250 Task dept] Train Loss: 1.2768\n",
      "[Iter 29250 Total] Train Loss: 0.9970\n",
      "======================================================================\n",
      "[Iter 29300 Task segm] Train Loss: 0.8170\n",
      "[Iter 29300 Task norm] Train Loss: 0.9334\n",
      "[Iter 29300 Task dept] Train Loss: 1.2349\n",
      "[Iter 29300 Total] Train Loss: 0.9951\n",
      "======================================================================\n",
      "[Iter 29350 Task segm] Train Loss: 0.7997\n",
      "[Iter 29350 Task norm] Train Loss: 0.9122\n",
      "[Iter 29350 Task dept] Train Loss: 1.2867\n",
      "[Iter 29350 Total] Train Loss: 0.9995\n",
      "======================================================================\n",
      "[Iter 29400 Task segm] Train Loss: 0.7804\n",
      "[Iter 29400 Task norm] Train Loss: 0.9275\n",
      "[Iter 29400 Task dept] Train Loss: 1.2407\n",
      "[Iter 29400 Total] Train Loss: 0.9829\n",
      "======================================================================\n",
      "[Iter 29400 Task segm] Val Loss: 1.5964\n",
      "{'mIoU': 0.2429, 'Pixel Acc': 0.5573, 'cmp': -0.0853}\n",
      "[Iter 29400 Task norm] Val Loss: 0.0662\n",
      "{'Angle Mean': 17.5655, 'Angle Median': 15.1377, 'Angle 11.25': 35.8752, 'Angle 22.5': 70.8233, 'Angle 30': 84.1017, 'cmp': -0.0189}\n",
      "[Iter 29400 Task dept] Val Loss: 0.5853\n",
      "{'abs_err': 0.5834, 'rel_err': 0.2359, 'sigma_1.25': 61.5493, 'sigma_1.25^2': 88.0624, 'sigma_1.25^3': 96.4726, 'cmp': 0.0425}\n",
      "======================================================================\n",
      "[Iter 29450 Task segm] Train Loss: 0.7565\n",
      "[Iter 29450 Task norm] Train Loss: 0.9265\n",
      "[Iter 29450 Task dept] Train Loss: 1.2918\n",
      "[Iter 29450 Total] Train Loss: 0.9916\n",
      "======================================================================\n",
      "[Iter 29500 Task segm] Train Loss: 0.7975\n",
      "[Iter 29500 Task norm] Train Loss: 0.9145\n",
      "[Iter 29500 Task dept] Train Loss: 1.2900\n",
      "[Iter 29500 Total] Train Loss: 1.0007\n",
      "======================================================================\n",
      "[Iter 29550 Task segm] Train Loss: 0.7767\n",
      "[Iter 29550 Task norm] Train Loss: 0.9119\n",
      "[Iter 29550 Task dept] Train Loss: 1.2392\n",
      "[Iter 29550 Total] Train Loss: 0.9759\n",
      "======================================================================\n",
      "[Iter 29600 Task segm] Train Loss: 0.7823\n",
      "[Iter 29600 Task norm] Train Loss: 0.9106\n",
      "[Iter 29600 Task dept] Train Loss: 1.2676\n",
      "[Iter 29600 Total] Train Loss: 0.9868\n",
      "======================================================================\n",
      "[Iter 29600 Task segm] Val Loss: 1.5949\n",
      "{'mIoU': 0.2453, 'Pixel Acc': 0.5593, 'cmp': -0.0792}\n",
      "[Iter 29600 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 17.5607, 'Angle Median': 15.2057, 'Angle 11.25': 35.5815, 'Angle 22.5': 70.9673, 'Angle 30': 84.2876, 'cmp': -0.0206}\n",
      "[Iter 29600 Task dept] Val Loss: 0.5895\n",
      "{'abs_err': 0.5864, 'rel_err': 0.2312, 'sigma_1.25': 61.4042, 'sigma_1.25^2': 88.0641, 'sigma_1.25^3': 96.5084, 'cmp': 0.0449}\n",
      "======================================================================\n",
      "[Iter 29650 Task segm] Train Loss: 0.7897\n",
      "[Iter 29650 Task norm] Train Loss: 0.9301\n",
      "[Iter 29650 Task dept] Train Loss: 1.2451\n",
      "[Iter 29650 Total] Train Loss: 0.9883\n",
      "======================================================================\n",
      "[Iter 29700 Task segm] Train Loss: 0.7838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 29700 Task norm] Train Loss: 0.9350\n",
      "[Iter 29700 Task dept] Train Loss: 1.2661\n",
      "[Iter 29700 Total] Train Loss: 0.9950\n",
      "======================================================================\n",
      "[Iter 29750 Task segm] Train Loss: 0.8084\n",
      "[Iter 29750 Task norm] Train Loss: 0.9166\n",
      "[Iter 29750 Task dept] Train Loss: 1.2587\n",
      "[Iter 29750 Total] Train Loss: 0.9946\n",
      "======================================================================\n",
      "[Iter 29800 Task segm] Train Loss: 0.7846\n",
      "[Iter 29800 Task norm] Train Loss: 0.9126\n",
      "[Iter 29800 Task dept] Train Loss: 1.2850\n",
      "[Iter 29800 Total] Train Loss: 0.9941\n",
      "======================================================================\n",
      "[Iter 29800 Task segm] Val Loss: 1.6036\n",
      "{'mIoU': 0.2446, 'Pixel Acc': 0.559, 'cmp': -0.0808}\n",
      "[Iter 29800 Task norm] Val Loss: 0.0669\n",
      "{'Angle Mean': 17.6817, 'Angle Median': 15.3174, 'Angle 11.25': 35.4158, 'Angle 22.5': 70.3578, 'Angle 30': 83.8929, 'cmp': -0.0271}\n",
      "[Iter 29800 Task dept] Val Loss: 0.5870\n",
      "{'abs_err': 0.5847, 'rel_err': 0.2331, 'sigma_1.25': 61.4336, 'sigma_1.25^2': 88.1076, 'sigma_1.25^3': 96.5663, 'cmp': 0.0443}\n",
      "======================================================================\n",
      "[Iter 29850 Task segm] Train Loss: 0.7500\n",
      "[Iter 29850 Task norm] Train Loss: 0.9350\n",
      "[Iter 29850 Task dept] Train Loss: 1.2502\n",
      "[Iter 29850 Total] Train Loss: 0.9784\n",
      "======================================================================\n",
      "[Iter 29900 Task segm] Train Loss: 0.7914\n",
      "[Iter 29900 Task norm] Train Loss: 0.8997\n",
      "[Iter 29900 Task dept] Train Loss: 1.2485\n",
      "[Iter 29900 Total] Train Loss: 0.9799\n",
      "======================================================================\n",
      "[Iter 29950 Task segm] Train Loss: 0.7921\n",
      "[Iter 29950 Task norm] Train Loss: 0.9121\n",
      "[Iter 29950 Task dept] Train Loss: 1.2838\n",
      "[Iter 29950 Total] Train Loss: 0.9960\n",
      "======================================================================\n",
      "[Iter 30000 Task segm] Train Loss: 0.7799\n",
      "[Iter 30000 Task norm] Train Loss: 0.9067\n",
      "[Iter 30000 Task dept] Train Loss: 1.2432\n",
      "[Iter 30000 Total] Train Loss: 0.9766\n",
      "======================================================================\n",
      "[Iter 30000 Task segm] Val Loss: 1.6150\n",
      "{'mIoU': 0.2404, 'Pixel Acc': 0.557, 'cmp': -0.0901}\n",
      "[Iter 30000 Task norm] Val Loss: 0.0659\n",
      "{'Angle Mean': 17.525, 'Angle Median': 15.0891, 'Angle 11.25': 35.9202, 'Angle 22.5': 71.055, 'Angle 30': 84.243, 'cmp': -0.0165}\n",
      "[Iter 30000 Task dept] Val Loss: 0.5880\n",
      "{'abs_err': 0.586, 'rel_err': 0.2354, 'sigma_1.25': 61.3764, 'sigma_1.25^2': 87.9772, 'sigma_1.25^3': 96.4494, 'cmp': 0.0413}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# random_policy_as_AdaShare_seed98\n",
    "loss_lambda = {'segment_semantic': 1, 'normal':20, 'depth_zbuffer': 3}\n",
    "trainer.post_train(iters=30000, lr=0.001, \n",
    "                   decay_lr_freq=4000, decay_lr_rate=0.5,\n",
    "                   loss_lambda=loss_lambda,\n",
    "                   savePath=checkpoint+'NYUv2/', reload='post_train_22800iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTLModel(\n",
       "  (headsDict): ModuleDict(\n",
       "    (segment_semantic): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (normal): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (depth_zbuffer): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (net): ModuleList(\n",
       "    (0): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (normal): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    )\n",
       "    (1): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): PoolNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): AbstractPool(\n",
       "        (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (10): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (11): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (17): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (18): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (24): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (25): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (normal): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (26): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (27): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (28): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (29): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (31): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (32): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (33): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (34): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (35): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (36): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (37): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (38): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (39): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (40): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (41): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (42): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (43): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (44): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (45): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (46): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (47): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (48): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (49): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (50): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (51): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (52): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (53): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (54): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (55): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normal): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (56): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (57): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (58): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (59): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (60): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (61): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (62): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (63): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (64): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (65): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (66): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (67): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (68): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (69): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (70): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (71): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (72): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (73): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (74): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (75): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (76): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (77): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (78): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (79): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (80): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (81): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (82): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (83): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (84): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (85): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (86): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (87): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (88): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (89): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (90): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (91): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (92): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (93): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (94): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (95): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (normal): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (96): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (97): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (98): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (99): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normal): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (100): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (101): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (102): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (103): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (104): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (105): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (106): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (107): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (108): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (109): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (110): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (111): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (112): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (113): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (114): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (115): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (116): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (117): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU(inplace=True)\n",
       "    )\n",
       "    (118): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (normal): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (dsOp): ModuleDict(\n",
       "        (segment_semantic): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (normal): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "        (depth_zbuffer): ModuleList(\n",
       "          (0): LazyLayer()\n",
       "        )\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (119): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (normal): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (normal): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (120): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (121): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (dsOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (inputNode): InputNode()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL and Hard sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerBaselines(Trainer):\n",
    "    def __init__(self, model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters=50, val_iters=2000, save_iters=200, policy_update_iters=100):\n",
    "        super(TrainerBaselines, self).__init__(model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters, val_iters, save_iters, policy_update_iters)\n",
    "        \n",
    "    def stl_hard_sharing(self, iters, lr=0.001, decay_lr_freq=4000, decay_lr_rate=0.5, task=None, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        writer = None\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=0.0001)\n",
    "#         optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        start = 0\n",
    "        if reload is not None and savePath is not None:\n",
    "            state = torch.load(savePath + reload)\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            optimizer.load_state_dict(state['optimizer'])\n",
    "            start = state['iter'] + 1\n",
    "    \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_lr_freq, gamma=decay_lr_rate)\n",
    "        if task is None:\n",
    "            stage = 'hard_sharing'\n",
    "        else:\n",
    "            stage = 'task_specific'\n",
    "        \n",
    "        for i in range(start, iters):\n",
    "            if task is None:\n",
    "                self.train_step(stage, optimizer, scheduler)\n",
    "            else:\n",
    "                self.train_step_task(stage, task, optimizer, scheduler)\n",
    "\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss(i, writer)\n",
    "                self.reset_train_loss()\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                if task is None:\n",
    "                    self.validate(stage, i, writer=writer)\n",
    "                else:\n",
    "                    self.validate_task(stage, i, task, writer=writer)\n",
    "                \n",
    "                self.model.train()\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    state = {'iter': i,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict()}\n",
    "                    self.save_model(state, stage, savePath)\n",
    "\n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss_data_iter()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerBaselines(mtlmodel, trainDataloaderDict, valDataloaderDict, criterionDict, metricDict, \n",
    "                           val_iters=100, print_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 100 Task segm] Train Loss: 3.8205\n",
      "[Iter 100 Task norm] Train Loss: 0.0794\n",
      "[Iter 100 Task dept] Train Loss: 2.3074\n",
      "[Iter 100 Total] Train Loss: 2.0691\n",
      "======================================================================\n",
      "[Iter 100 Task segm] Val Loss: 2.8336\n",
      "{'mIoU': 0.1341, 'Pixel Acc': 0.3166, 'cmp': -0.4875}\n",
      "[Iter 100 Task norm] Val Loss: 0.0731\n",
      "{'Angle Mean': 19.663, 'Angle Median': 16.8682, 'Angle 11.25': 15.5569, 'Angle 22.5': 74.2688, 'Angle 30': 85.5894, 'cmp': -0.1708}\n",
      "[Iter 100 Task dept] Val Loss: 1.2804\n",
      "{'abs_err': 1.2618, 'rel_err': 0.4061, 'sigma_1.25': 19.6811, 'sigma_1.25^2': 41.2963, 'sigma_1.25^3': 64.0148, 'cmp': -0.6339}\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Train Loss: 2.8100\n",
      "[Iter 200 Task norm] Train Loss: 0.0674\n",
      "[Iter 200 Task dept] Train Loss: 1.1729\n",
      "[Iter 200 Total] Train Loss: 1.3501\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 2.8512\n",
      "{'mIoU': 0.121, 'Pixel Acc': 0.3087, 'cmp': -0.518}\n",
      "[Iter 200 Task norm] Val Loss: 0.0688\n",
      "{'Angle Mean': 18.9299, 'Angle Median': 16.5981, 'Angle 11.25': 22.8569, 'Angle 22.5': 71.1708, 'Angle 30': 87.1258, 'cmp': -0.1216}\n",
      "[Iter 200 Task dept] Val Loss: 1.2523\n",
      "{'abs_err': 1.2347, 'rel_err': 0.3997, 'sigma_1.25': 20.5843, 'sigma_1.25^2': 42.3766, 'sigma_1.25^3': 65.9915, 'cmp': -0.6103}\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Train Loss: 2.7327\n",
      "[Iter 300 Task norm] Train Loss: 0.0674\n",
      "[Iter 300 Task dept] Train Loss: 1.1477\n",
      "[Iter 300 Total] Train Loss: 1.3159\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Val Loss: 2.8021\n",
      "{'mIoU': 0.1712, 'Pixel Acc': 0.3313, 'cmp': -0.4075}\n",
      "[Iter 300 Task norm] Val Loss: 0.0684\n",
      "{'Angle Mean': 19.216, 'Angle Median': 17.2363, 'Angle 11.25': 17.2213, 'Angle 22.5': 72.289, 'Angle 30': 87.9987, 'cmp': -0.1611}\n",
      "[Iter 300 Task dept] Val Loss: 1.0955\n",
      "{'abs_err': 1.0783, 'rel_err': 0.3445, 'sigma_1.25': 27.7857, 'sigma_1.25^2': 57.0729, 'sigma_1.25^3': 81.3532, 'cmp': -0.4244}\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Train Loss: 2.6773\n",
      "[Iter 400 Task norm] Train Loss: 0.0677\n",
      "[Iter 400 Task dept] Train Loss: 1.0910\n",
      "[Iter 400 Total] Train Loss: 1.2787\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 2.8247\n",
      "{'mIoU': 0.1004, 'Pixel Acc': 0.2881, 'cmp': -0.5728}\n",
      "[Iter 400 Task norm] Val Loss: 0.0678\n",
      "{'Angle Mean': 18.743, 'Angle Median': 16.3848, 'Angle 11.25': 23.7863, 'Angle 22.5': 71.7479, 'Angle 30': 87.0277, 'cmp': -0.1098}\n",
      "[Iter 400 Task dept] Val Loss: 1.0979\n",
      "{'abs_err': 1.0826, 'rel_err': 0.3471, 'sigma_1.25': 27.3655, 'sigma_1.25^2': 56.3083, 'sigma_1.25^3': 80.3867, 'cmp': -0.4331}\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Train Loss: 2.6747\n",
      "[Iter 500 Task norm] Train Loss: 0.0669\n",
      "[Iter 500 Task dept] Train Loss: 1.0920\n",
      "[Iter 500 Total] Train Loss: 1.2778\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Val Loss: 2.6356\n",
      "{'mIoU': 0.1387, 'Pixel Acc': 0.3373, 'cmp': -0.4615}\n",
      "[Iter 500 Task norm] Val Loss: 0.0684\n",
      "{'Angle Mean': 18.9354, 'Angle Median': 16.1844, 'Angle 11.25': 19.4097, 'Angle 22.5': 73.5167, 'Angle 30': 86.9184, 'cmp': -0.1297}\n",
      "[Iter 500 Task dept] Val Loss: 0.9311\n",
      "{'abs_err': 0.9181, 'rel_err': 0.3192, 'sigma_1.25': 36.518, 'sigma_1.25^2': 69.204, 'sigma_1.25^3': 88.3689, 'cmp': -0.2794}\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Train Loss: 2.6235\n",
      "[Iter 600 Task norm] Train Loss: 0.0663\n",
      "[Iter 600 Task dept] Train Loss: 1.0748\n",
      "[Iter 600 Total] Train Loss: 1.2549\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 2.6717\n",
      "{'mIoU': 0.1292, 'Pixel Acc': 0.326, 'cmp': -0.4883}\n",
      "[Iter 600 Task norm] Val Loss: 0.0686\n",
      "{'Angle Mean': 18.6805, 'Angle Median': 17.6512, 'Angle 11.25': 26.7178, 'Angle 22.5': 68.4193, 'Angle 30': 86.2156, 'cmp': -0.1211}\n",
      "[Iter 600 Task dept] Val Loss: 1.0370\n",
      "{'abs_err': 1.0219, 'rel_err': 0.3348, 'sigma_1.25': 32.1293, 'sigma_1.25^2': 63.1145, 'sigma_1.25^3': 83.9756, 'cmp': -0.3639}\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Train Loss: 2.5680\n",
      "[Iter 700 Task norm] Train Loss: 0.0669\n",
      "[Iter 700 Task dept] Train Loss: 1.0330\n",
      "[Iter 700 Total] Train Loss: 1.2226\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Val Loss: 2.5761\n",
      "{'mIoU': 0.1111, 'Pixel Acc': 0.3475, 'cmp': -0.503}\n",
      "[Iter 700 Task norm] Val Loss: 0.0683\n",
      "{'Angle Mean': 18.8727, 'Angle Median': 16.2452, 'Angle 11.25': 21.2616, 'Angle 22.5': 72.8973, 'Angle 30': 87.0313, 'cmp': -0.1206}\n",
      "[Iter 700 Task dept] Val Loss: 0.9592\n",
      "{'abs_err': 0.9453, 'rel_err': 0.3237, 'sigma_1.25': 34.5023, 'sigma_1.25^2': 67.1183, 'sigma_1.25^3': 87.5921, 'cmp': -0.3052}\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Train Loss: 2.5412\n",
      "[Iter 800 Task norm] Train Loss: 0.0659\n",
      "[Iter 800 Task dept] Train Loss: 1.0321\n",
      "[Iter 800 Total] Train Loss: 1.2131\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 2.5193\n",
      "{'mIoU': 0.1576, 'Pixel Acc': 0.357, 'cmp': -0.4104}\n",
      "[Iter 800 Task norm] Val Loss: 0.0682\n",
      "{'Angle Mean': 18.6263, 'Angle Median': 16.237, 'Angle 11.25': 25.8203, 'Angle 22.5': 71.6044, 'Angle 30': 86.4817, 'cmp': -0.0964}\n",
      "[Iter 800 Task dept] Val Loss: 1.0106\n",
      "{'abs_err': 0.9965, 'rel_err': 0.3291, 'sigma_1.25': 32.2497, 'sigma_1.25^2': 64.0994, 'sigma_1.25^3': 85.3428, 'cmp': -0.3456}\n",
      "======================================================================\n",
      "[Iter 900 Task segm] Train Loss: 2.5806\n",
      "[Iter 900 Task norm] Train Loss: 0.0669\n",
      "[Iter 900 Task dept] Train Loss: 1.0345\n",
      "[Iter 900 Total] Train Loss: 1.2273\n",
      "======================================================================\n",
      "[Iter 900 Task segm] Val Loss: 2.5637\n",
      "{'mIoU': 0.1345, 'Pixel Acc': 0.3538, 'cmp': -0.4552}\n",
      "[Iter 900 Task norm] Val Loss: 0.0681\n",
      "{'Angle Mean': 18.8523, 'Angle Median': 16.8408, 'Angle 11.25': 21.9138, 'Angle 22.5': 72.2588, 'Angle 30': 87.1296, 'cmp': -0.1266}\n",
      "[Iter 900 Task dept] Val Loss: 0.9335\n",
      "{'abs_err': 0.9201, 'rel_err': 0.3197, 'sigma_1.25': 37.1831, 'sigma_1.25^2': 69.597, 'sigma_1.25^3': 88.2622, 'cmp': -0.2774}\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Train Loss: 2.5190\n",
      "[Iter 1000 Task norm] Train Loss: 0.0668\n",
      "[Iter 1000 Task dept] Train Loss: 1.0037\n",
      "[Iter 1000 Total] Train Loss: 1.1965\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 2.6197\n",
      "{'mIoU': 0.1336, 'Pixel Acc': 0.3335, 'cmp': -0.474}\n",
      "[Iter 1000 Task norm] Val Loss: 0.0687\n",
      "{'Angle Mean': 19.078, 'Angle Median': 16.4438, 'Angle 11.25': 16.5463, 'Angle 22.5': 74.9203, 'Angle 30': 86.8939, 'cmp': -0.1476}\n",
      "[Iter 1000 Task dept] Val Loss: 0.9662\n",
      "{'abs_err': 0.9542, 'rel_err': 0.3274, 'sigma_1.25': 36.7864, 'sigma_1.25^2': 67.9576, 'sigma_1.25^3': 86.2972, 'cmp': -0.3039}\n",
      "======================================================================\n",
      "[Iter 1100 Task segm] Train Loss: 2.5448\n",
      "[Iter 1100 Task norm] Train Loss: 0.0664\n",
      "[Iter 1100 Task dept] Train Loss: 1.0299\n",
      "[Iter 1100 Total] Train Loss: 1.2137\n",
      "======================================================================\n",
      "[Iter 1100 Task segm] Val Loss: 2.5915\n",
      "{'mIoU': 0.1301, 'Pixel Acc': 0.3531, 'cmp': -0.4638}\n",
      "[Iter 1100 Task norm] Val Loss: 0.0675\n",
      "{'Angle Mean': 18.7715, 'Angle Median': 17.099, 'Angle 11.25': 23.2278, 'Angle 22.5': 71.6656, 'Angle 30': 87.2, 'cmp': -0.1232}\n",
      "[Iter 1100 Task dept] Val Loss: 0.9379\n",
      "{'abs_err': 0.9267, 'rel_err': 0.3298, 'sigma_1.25': 38.5223, 'sigma_1.25^2': 69.9533, 'sigma_1.25^3': 87.3921, 'cmp': -0.284}\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Train Loss: 2.5339\n",
      "[Iter 1200 Task norm] Train Loss: 0.0669\n",
      "[Iter 1200 Task dept] Train Loss: 1.0263\n",
      "[Iter 1200 Total] Train Loss: 1.2090\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1200 Task segm] Val Loss: 2.4938\n",
      "{'mIoU': 0.1272, 'Pixel Acc': 0.3553, 'cmp': -0.467}\n",
      "[Iter 1200 Task norm] Val Loss: 0.0684\n",
      "{'Angle Mean': 18.5343, 'Angle Median': 16.1101, 'Angle 11.25': 28.7095, 'Angle 22.5': 70.9844, 'Angle 30': 86.3167, 'cmp': -0.0791}\n",
      "[Iter 1200 Task dept] Val Loss: 0.9528\n",
      "{'abs_err': 0.9414, 'rel_err': 0.3278, 'sigma_1.25': 37.6786, 'sigma_1.25^2': 68.9363, 'sigma_1.25^3': 87.0061, 'cmp': -0.2933}\n",
      "======================================================================\n",
      "[Iter 1300 Task segm] Train Loss: 2.4827\n",
      "[Iter 1300 Task norm] Train Loss: 0.0667\n",
      "[Iter 1300 Task dept] Train Loss: 0.9950\n",
      "[Iter 1300 Total] Train Loss: 1.1815\n",
      "======================================================================\n",
      "[Iter 1300 Task segm] Val Loss: 2.5224\n",
      "{'mIoU': 0.1374, 'Pixel Acc': 0.3582, 'cmp': -0.4461}\n",
      "[Iter 1300 Task norm] Val Loss: 0.0686\n",
      "{'Angle Mean': 18.9966, 'Angle Median': 16.6185, 'Angle 11.25': 19.3076, 'Angle 22.5': 73.0075, 'Angle 30': 87.3357, 'cmp': -0.1375}\n",
      "[Iter 1300 Task dept] Val Loss: 0.9695\n",
      "{'abs_err': 0.9572, 'rel_err': 0.3338, 'sigma_1.25': 37.7215, 'sigma_1.25^2': 68.3355, 'sigma_1.25^3': 85.7973, 'cmp': -0.3069}\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Train Loss: 2.3944\n",
      "[Iter 1400 Task norm] Train Loss: 0.0666\n",
      "[Iter 1400 Task dept] Train Loss: 0.9600\n",
      "[Iter 1400 Total] Train Loss: 1.1403\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 2.4119\n",
      "{'mIoU': 0.141, 'Pixel Acc': 0.3734, 'cmp': -0.4267}\n",
      "[Iter 1400 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 18.3307, 'Angle Median': 16.5205, 'Angle 11.25': 25.327, 'Angle 22.5': 72.6351, 'Angle 30': 87.1228, 'cmp': -0.0955}\n",
      "[Iter 1400 Task dept] Val Loss: 0.8781\n",
      "{'abs_err': 0.8679, 'rel_err': 0.321, 'sigma_1.25': 42.1253, 'sigma_1.25^2': 73.5601, 'sigma_1.25^3': 89.3056, 'cmp': -0.2331}\n",
      "======================================================================\n",
      "[Iter 1500 Task segm] Train Loss: 2.3530\n",
      "[Iter 1500 Task norm] Train Loss: 0.0649\n",
      "[Iter 1500 Task dept] Train Loss: 0.9360\n",
      "[Iter 1500 Total] Train Loss: 1.1180\n",
      "======================================================================\n",
      "[Iter 1500 Task segm] Val Loss: 2.4007\n",
      "{'mIoU': 0.1021, 'Pixel Acc': 0.3709, 'cmp': -0.4995}\n",
      "[Iter 1500 Task norm] Val Loss: 0.0683\n",
      "{'Angle Mean': 18.7432, 'Angle Median': 16.197, 'Angle 11.25': 22.4808, 'Angle 22.5': 73.7517, 'Angle 30': 86.7672, 'cmp': -0.1098}\n",
      "[Iter 1500 Task dept] Val Loss: 0.8516\n",
      "{'abs_err': 0.842, 'rel_err': 0.3258, 'sigma_1.25': 43.8661, 'sigma_1.25^2': 74.465, 'sigma_1.25^3': 89.872, 'cmp': -0.2194}\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Train Loss: 2.3644\n",
      "[Iter 1600 Task norm] Train Loss: 0.0659\n",
      "[Iter 1600 Task dept] Train Loss: 0.9665\n",
      "[Iter 1600 Total] Train Loss: 1.1323\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 2.3628\n",
      "{'mIoU': 0.1343, 'Pixel Acc': 0.3848, 'cmp': -0.4292}\n",
      "[Iter 1600 Task norm] Val Loss: 0.0673\n",
      "{'Angle Mean': 18.2666, 'Angle Median': 16.7436, 'Angle 11.25': 26.3353, 'Angle 22.5': 71.5204, 'Angle 30': 86.158, 'cmp': -0.0975}\n",
      "[Iter 1600 Task dept] Val Loss: 0.8971\n",
      "{'abs_err': 0.8855, 'rel_err': 0.3201, 'sigma_1.25': 41.5269, 'sigma_1.25^2': 72.4086, 'sigma_1.25^3': 88.6993, 'cmp': -0.2441}\n",
      "======================================================================\n",
      "[Iter 1700 Task segm] Train Loss: 2.3113\n",
      "[Iter 1700 Task norm] Train Loss: 0.0654\n",
      "[Iter 1700 Task dept] Train Loss: 0.9441\n",
      "[Iter 1700 Total] Train Loss: 1.1069\n",
      "======================================================================\n",
      "[Iter 1700 Task segm] Val Loss: 2.3044\n",
      "{'mIoU': 0.1107, 'Pixel Acc': 0.3798, 'cmp': -0.4763}\n",
      "[Iter 1700 Task norm] Val Loss: 0.0668\n",
      "{'Angle Mean': 18.548, 'Angle Median': 16.6776, 'Angle 11.25': 22.489, 'Angle 22.5': 73.8288, 'Angle 30': 87.392, 'cmp': -0.1126}\n",
      "[Iter 1700 Task dept] Val Loss: 0.7928\n",
      "{'abs_err': 0.7885, 'rel_err': 0.3444, 'sigma_1.25': 48.0643, 'sigma_1.25^2': 76.5557, 'sigma_1.25^3': 90.7504, 'cmp': -0.1957}\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Train Loss: 2.2716\n",
      "[Iter 1800 Task norm] Train Loss: 0.0662\n",
      "[Iter 1800 Task dept] Train Loss: 0.9245\n",
      "[Iter 1800 Total] Train Loss: 1.0874\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 2.3065\n",
      "{'mIoU': 0.1146, 'Pixel Acc': 0.3838, 'cmp': -0.4658}\n",
      "[Iter 1800 Task norm] Val Loss: 0.0676\n",
      "{'Angle Mean': 18.4492, 'Angle Median': 16.2329, 'Angle 11.25': 27.6266, 'Angle 22.5': 71.5686, 'Angle 30': 86.7068, 'cmp': -0.0835}\n",
      "[Iter 1800 Task dept] Val Loss: 0.8301\n",
      "{'abs_err': 0.8202, 'rel_err': 0.3145, 'sigma_1.25': 44.2918, 'sigma_1.25^2': 76.0265, 'sigma_1.25^3': 91.1124, 'cmp': -0.1955}\n",
      "======================================================================\n",
      "[Iter 1900 Task segm] Train Loss: 2.2375\n",
      "[Iter 1900 Task norm] Train Loss: 0.0648\n",
      "[Iter 1900 Task dept] Train Loss: 0.9182\n",
      "[Iter 1900 Total] Train Loss: 1.0735\n",
      "======================================================================\n",
      "[Iter 1900 Task segm] Val Loss: 2.3743\n",
      "{'mIoU': 0.1097, 'Pixel Acc': 0.3761, 'cmp': -0.4814}\n",
      "[Iter 1900 Task norm] Val Loss: 0.0667\n",
      "{'Angle Mean': 18.5653, 'Angle Median': 16.6673, 'Angle 11.25': 22.6914, 'Angle 22.5': 73.872, 'Angle 30': 87.2219, 'cmp': -0.1118}\n",
      "[Iter 1900 Task dept] Val Loss: 0.8490\n",
      "{'abs_err': 0.8402, 'rel_err': 0.3086, 'sigma_1.25': 44.4575, 'sigma_1.25^2': 74.9204, 'sigma_1.25^3': 90.0733, 'cmp': -0.2015}\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Train Loss: 2.2030\n",
      "[Iter 2000 Task norm] Train Loss: 0.0647\n",
      "[Iter 2000 Task dept] Train Loss: 0.9169\n",
      "[Iter 2000 Total] Train Loss: 1.0615\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 2.2063\n",
      "{'mIoU': 0.1167, 'Pixel Acc': 0.4137, 'cmp': -0.4366}\n",
      "[Iter 2000 Task norm] Val Loss: 0.0651\n",
      "{'Angle Mean': 18.189, 'Angle Median': 15.9726, 'Angle 11.25': 24.9916, 'Angle 22.5': 75.0852, 'Angle 30': 87.1204, 'cmp': -0.0814}\n",
      "[Iter 2000 Task dept] Val Loss: 0.8124\n",
      "{'abs_err': 0.8026, 'rel_err': 0.303, 'sigma_1.25': 45.7926, 'sigma_1.25^2': 77.0515, 'sigma_1.25^3': 91.6036, 'cmp': -0.1721}\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Train Loss: 2.2111\n",
      "[Iter 2100 Task norm] Train Loss: 0.0643\n",
      "[Iter 2100 Task dept] Train Loss: 0.8850\n",
      "[Iter 2100 Total] Train Loss: 1.0535\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Val Loss: 2.9595\n",
      "{'mIoU': 0.1087, 'Pixel Acc': 0.3612, 'cmp': -0.4958}\n",
      "[Iter 2100 Task norm] Val Loss: 0.0679\n",
      "{'Angle Mean': 18.7178, 'Angle Median': 16.5148, 'Angle 11.25': 21.9137, 'Angle 22.5': 75.3629, 'Angle 30': 86.8697, 'cmp': -0.1126}\n",
      "[Iter 2100 Task dept] Val Loss: 0.8898\n",
      "{'abs_err': 0.8823, 'rel_err': 0.3519, 'sigma_1.25': 43.0056, 'sigma_1.25^2': 72.8365, 'sigma_1.25^3': 88.7654, 'cmp': -0.2623}\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Train Loss: 2.1415\n",
      "[Iter 2200 Task norm] Train Loss: 0.0637\n",
      "[Iter 2200 Task dept] Train Loss: 0.8936\n",
      "[Iter 2200 Total] Train Loss: 1.0329\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 2.1698\n",
      "{'mIoU': 0.1343, 'Pixel Acc': 0.4214, 'cmp': -0.398}\n",
      "[Iter 2200 Task norm] Val Loss: 0.0663\n",
      "{'Angle Mean': 18.3346, 'Angle Median': 15.7755, 'Angle 11.25': 25.087, 'Angle 22.5': 75.1979, 'Angle 30': 86.6105, 'cmp': -0.0807}\n",
      "[Iter 2200 Task dept] Val Loss: 0.8105\n",
      "{'abs_err': 0.802, 'rel_err': 0.3005, 'sigma_1.25': 46.0083, 'sigma_1.25^2': 77.0882, 'sigma_1.25^3': 91.5851, 'cmp': -0.1691}\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Train Loss: 2.1366\n",
      "[Iter 2300 Task norm] Train Loss: 0.0638\n",
      "[Iter 2300 Task dept] Train Loss: 0.8730\n",
      "[Iter 2300 Total] Train Loss: 1.0245\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Val Loss: 2.1551\n",
      "{'mIoU': 0.1338, 'Pixel Acc': 0.4147, 'cmp': -0.4047}\n",
      "[Iter 2300 Task norm] Val Loss: 0.0657\n",
      "{'Angle Mean': 18.1337, 'Angle Median': 16.6004, 'Angle 11.25': 25.1648, 'Angle 22.5': 73.6151, 'Angle 30': 87.0241, 'cmp': -0.0929}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2300 Task dept] Val Loss: 0.7292\n",
      "{'abs_err': 0.7254, 'rel_err': 0.3141, 'sigma_1.25': 51.9828, 'sigma_1.25^2': 80.1247, 'sigma_1.25^3': 92.3134, 'cmp': -0.126}\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Train Loss: 2.1050\n",
      "[Iter 2400 Task norm] Train Loss: 0.0637\n",
      "[Iter 2400 Task dept] Train Loss: 0.8642\n",
      "[Iter 2400 Total] Train Loss: 1.0109\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 2.1199\n",
      "{'mIoU': 0.1308, 'Pixel Acc': 0.4274, 'cmp': -0.3993}\n",
      "[Iter 2400 Task norm] Val Loss: 0.0656\n",
      "{'Angle Mean': 18.0485, 'Angle Median': 15.9043, 'Angle 11.25': 25.2931, 'Angle 22.5': 75.5451, 'Angle 30': 86.6797, 'cmp': -0.0769}\n",
      "[Iter 2400 Task dept] Val Loss: 0.7923\n",
      "{'abs_err': 0.7846, 'rel_err': 0.3, 'sigma_1.25': 47.8154, 'sigma_1.25^2': 77.6948, 'sigma_1.25^3': 91.5137, 'cmp': -0.1556}\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Train Loss: 2.1118\n",
      "[Iter 2500 Task norm] Train Loss: 0.0636\n",
      "[Iter 2500 Task dept] Train Loss: 0.8546\n",
      "[Iter 2500 Total] Train Loss: 1.0100\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Val Loss: 2.1189\n",
      "{'mIoU': 0.1234, 'Pixel Acc': 0.431, 'cmp': -0.4098}\n",
      "[Iter 2500 Task norm] Val Loss: 0.0658\n",
      "{'Angle Mean': 17.9544, 'Angle Median': 15.7812, 'Angle 11.25': 28.0217, 'Angle 22.5': 74.6036, 'Angle 30': 86.4943, 'cmp': -0.0615}\n",
      "[Iter 2500 Task dept] Val Loss: 0.8052\n",
      "{'abs_err': 0.7954, 'rel_err': 0.2917, 'sigma_1.25': 46.5617, 'sigma_1.25^2': 77.685, 'sigma_1.25^3': 91.8437, 'cmp': -0.1561}\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Train Loss: 2.0686\n",
      "[Iter 2600 Task norm] Train Loss: 0.0637\n",
      "[Iter 2600 Task dept] Train Loss: 0.8469\n",
      "[Iter 2600 Total] Train Loss: 0.9931\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 2.2004\n",
      "{'mIoU': 0.0989, 'Pixel Acc': 0.4063, 'cmp': -0.4752}\n",
      "[Iter 2600 Task norm] Val Loss: 0.0675\n",
      "{'Angle Mean': 18.2289, 'Angle Median': 16.581, 'Angle 11.25': 30.1467, 'Angle 22.5': 69.5165, 'Angle 30': 86.1685, 'cmp': -0.0783}\n",
      "[Iter 2600 Task dept] Val Loss: 0.8440\n",
      "{'abs_err': 0.834, 'rel_err': 0.3018, 'sigma_1.25': 43.8215, 'sigma_1.25^2': 75.359, 'sigma_1.25^3': 90.7817, 'cmp': -0.1937}\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Train Loss: 1.9305\n",
      "[Iter 2700 Task norm] Train Loss: 0.0627\n",
      "[Iter 2700 Task dept] Train Loss: 0.8108\n",
      "[Iter 2700 Total] Train Loss: 0.9347\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Val Loss: 2.0503\n",
      "{'mIoU': 0.1239, 'Pixel Acc': 0.4388, 'cmp': -0.4022}\n",
      "[Iter 2700 Task norm] Val Loss: 0.0660\n",
      "{'Angle Mean': 18.2647, 'Angle Median': 16.2456, 'Angle 11.25': 25.1488, 'Angle 22.5': 75.3986, 'Angle 30': 87.004, 'cmp': -0.0847}\n",
      "[Iter 2700 Task dept] Val Loss: 0.7713\n",
      "{'abs_err': 0.7631, 'rel_err': 0.2815, 'sigma_1.25': 48.6673, 'sigma_1.25^2': 78.8249, 'sigma_1.25^3': 92.7319, 'cmp': -0.1257}\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Train Loss: 1.9291\n",
      "[Iter 2800 Task norm] Train Loss: 0.0626\n",
      "[Iter 2800 Task dept] Train Loss: 0.7925\n",
      "[Iter 2800 Total] Train Loss: 0.9280\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 2.0156\n",
      "{'mIoU': 0.1181, 'Pixel Acc': 0.4431, 'cmp': -0.4092}\n",
      "[Iter 2800 Task norm] Val Loss: 0.0646\n",
      "{'Angle Mean': 17.6181, 'Angle Median': 15.1984, 'Angle 11.25': 31.4882, 'Angle 22.5': 74.8589, 'Angle 30': 86.2603, 'cmp': -0.0294}\n",
      "[Iter 2800 Task dept] Val Loss: 0.7325\n",
      "{'abs_err': 0.7261, 'rel_err': 0.2841, 'sigma_1.25': 50.2781, 'sigma_1.25^2': 80.9925, 'sigma_1.25^3': 93.5725, 'cmp': -0.1035}\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Train Loss: 1.8926\n",
      "[Iter 2900 Task norm] Train Loss: 0.0617\n",
      "[Iter 2900 Task dept] Train Loss: 0.8123\n",
      "[Iter 2900 Total] Train Loss: 0.9222\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Val Loss: 2.0218\n",
      "{'mIoU': 0.1339, 'Pixel Acc': 0.4538, 'cmp': -0.3713}\n",
      "[Iter 2900 Task norm] Val Loss: 0.0651\n",
      "{'Angle Mean': 17.9532, 'Angle Median': 16.0515, 'Angle 11.25': 27.6325, 'Angle 22.5': 74.688, 'Angle 30': 87.0159, 'cmp': -0.066}\n",
      "[Iter 2900 Task dept] Val Loss: 0.7354\n",
      "{'abs_err': 0.7281, 'rel_err': 0.2741, 'sigma_1.25': 50.5899, 'sigma_1.25^2': 80.7612, 'sigma_1.25^3': 93.708, 'cmp': -0.0953}\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Train Loss: 1.8754\n",
      "[Iter 3000 Task norm] Train Loss: 0.0625\n",
      "[Iter 3000 Task dept] Train Loss: 0.7872\n",
      "[Iter 3000 Total] Train Loss: 0.9084\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 2.0136\n",
      "{'mIoU': 0.1233, 'Pixel Acc': 0.4549, 'cmp': -0.3896}\n",
      "[Iter 3000 Task norm] Val Loss: 0.0641\n",
      "{'Angle Mean': 17.8288, 'Angle Median': 16.3392, 'Angle 11.25': 26.7601, 'Angle 22.5': 74.8026, 'Angle 30': 87.4234, 'cmp': -0.0724}\n",
      "[Iter 3000 Task dept] Val Loss: 0.7864\n",
      "{'abs_err': 0.7776, 'rel_err': 0.2759, 'sigma_1.25': 48.1443, 'sigma_1.25^2': 78.2943, 'sigma_1.25^3': 92.3852, 'cmp': -0.1297}\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Train Loss: 1.8513\n",
      "[Iter 3100 Task norm] Train Loss: 0.0621\n",
      "[Iter 3100 Task dept] Train Loss: 0.7789\n",
      "[Iter 3100 Total] Train Loss: 0.8974\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Val Loss: 1.8870\n",
      "{'mIoU': 0.1453, 'Pixel Acc': 0.4755, 'cmp': -0.3321}\n",
      "[Iter 3100 Task norm] Val Loss: 0.0646\n",
      "{'Angle Mean': 17.7741, 'Angle Median': 16.1689, 'Angle 11.25': 27.3202, 'Angle 22.5': 74.4252, 'Angle 30': 86.843, 'cmp': -0.0686}\n",
      "[Iter 3100 Task dept] Val Loss: 0.6707\n",
      "{'abs_err': 0.6659, 'rel_err': 0.2748, 'sigma_1.25': 55.2392, 'sigma_1.25^2': 83.7996, 'sigma_1.25^3': 94.5029, 'cmp': -0.051}\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Train Loss: 1.8222\n",
      "[Iter 3200 Task norm] Train Loss: 0.0621\n",
      "[Iter 3200 Task dept] Train Loss: 0.7821\n",
      "[Iter 3200 Total] Train Loss: 0.8888\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 2.0512\n",
      "{'mIoU': 0.133, 'Pixel Acc': 0.4349, 'cmp': -0.3889}\n",
      "[Iter 3200 Task norm] Val Loss: 0.0641\n",
      "{'Angle Mean': 17.9452, 'Angle Median': 16.2991, 'Angle 11.25': 25.5039, 'Angle 22.5': 75.7454, 'Angle 30': 87.2902, 'cmp': -0.0781}\n",
      "[Iter 3200 Task dept] Val Loss: 0.7449\n",
      "{'abs_err': 0.7361, 'rel_err': 0.2761, 'sigma_1.25': 50.5945, 'sigma_1.25^2': 80.576, 'sigma_1.25^3': 93.5427, 'cmp': -0.1002}\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Train Loss: 1.8567\n",
      "[Iter 3300 Task norm] Train Loss: 0.0616\n",
      "[Iter 3300 Task dept] Train Loss: 0.7581\n",
      "[Iter 3300 Total] Train Loss: 0.8921\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Val Loss: 1.9191\n",
      "{'mIoU': 0.1488, 'Pixel Acc': 0.4642, 'cmp': -0.3355}\n",
      "[Iter 3300 Task norm] Val Loss: 0.0639\n",
      "{'Angle Mean': 17.753, 'Angle Median': 16.0686, 'Angle 11.25': 27.1204, 'Angle 22.5': 75.0085, 'Angle 30': 87.1794, 'cmp': -0.0657}\n",
      "[Iter 3300 Task dept] Val Loss: 0.6696\n",
      "{'abs_err': 0.6659, 'rel_err': 0.2779, 'sigma_1.25': 55.3412, 'sigma_1.25^2': 83.693, 'sigma_1.25^3': 94.4479, 'cmp': -0.0535}\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Train Loss: 1.8002\n",
      "[Iter 3400 Task norm] Train Loss: 0.0617\n",
      "[Iter 3400 Task dept] Train Loss: 0.7474\n",
      "[Iter 3400 Total] Train Loss: 0.8697\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.9230\n",
      "{'mIoU': 0.1264, 'Pixel Acc': 0.4655, 'cmp': -0.3751}\n",
      "[Iter 3400 Task norm] Val Loss: 0.0630\n",
      "{'Angle Mean': 17.5869, 'Angle Median': 16.0478, 'Angle 11.25': 27.6181, 'Angle 22.5': 74.8994, 'Angle 30': 87.1823, 'cmp': -0.0609}\n",
      "[Iter 3400 Task dept] Val Loss: 0.7462\n",
      "{'abs_err': 0.7386, 'rel_err': 0.2801, 'sigma_1.25': 50.5504, 'sigma_1.25^2': 80.5099, 'sigma_1.25^3': 93.3836, 'cmp': -0.1049}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 3500 Task segm] Train Loss: 1.7997\n",
      "[Iter 3500 Task norm] Train Loss: 0.0627\n",
      "[Iter 3500 Task dept] Train Loss: 0.7548\n",
      "[Iter 3500 Total] Train Loss: 0.8724\n",
      "======================================================================\n",
      "[Iter 3500 Task segm] Val Loss: 1.8183\n",
      "{'mIoU': 0.157, 'Pixel Acc': 0.4899, 'cmp': -0.2987}\n",
      "[Iter 3500 Task norm] Val Loss: 0.0632\n",
      "{'Angle Mean': 17.5617, 'Angle Median': 15.7096, 'Angle 11.25': 30.1133, 'Angle 22.5': 75.6642, 'Angle 30': 87.153, 'cmp': -0.0396}\n",
      "[Iter 3500 Task dept] Val Loss: 0.7154\n",
      "{'abs_err': 0.707, 'rel_err': 0.2636, 'sigma_1.25': 52.0422, 'sigma_1.25^2': 82.4904, 'sigma_1.25^3': 94.575, 'cmp': -0.0692}\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Train Loss: 1.7593\n",
      "[Iter 3600 Task norm] Train Loss: 0.0623\n",
      "[Iter 3600 Task dept] Train Loss: 0.7395\n",
      "[Iter 3600 Total] Train Loss: 0.8537\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.9192\n",
      "{'mIoU': 0.1416, 'Pixel Acc': 0.4652, 'cmp': -0.3476}\n",
      "[Iter 3600 Task norm] Val Loss: 0.0645\n",
      "{'Angle Mean': 17.8286, 'Angle Median': 16.4402, 'Angle 11.25': 28.6604, 'Angle 22.5': 73.325, 'Angle 30': 87.2295, 'cmp': -0.0674}\n",
      "[Iter 3600 Task dept] Val Loss: 0.7167\n",
      "{'abs_err': 0.7095, 'rel_err': 0.2732, 'sigma_1.25': 51.9497, 'sigma_1.25^2': 81.7558, 'sigma_1.25^3': 94.0558, 'cmp': -0.0809}\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Train Loss: 1.7299\n",
      "[Iter 3700 Task norm] Train Loss: 0.0614\n",
      "[Iter 3700 Task dept] Train Loss: 0.7118\n",
      "[Iter 3700 Total] Train Loss: 0.8344\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Val Loss: 1.9544\n",
      "{'mIoU': 0.1445, 'Pixel Acc': 0.4604, 'cmp': -0.3464}\n",
      "[Iter 3700 Task norm] Val Loss: 0.0643\n",
      "{'Angle Mean': 17.7303, 'Angle Median': 15.958, 'Angle 11.25': 27.7061, 'Angle 22.5': 75.4382, 'Angle 30': 86.8785, 'cmp': -0.06}\n",
      "[Iter 3700 Task dept] Val Loss: 0.7400\n",
      "{'abs_err': 0.7322, 'rel_err': 0.2682, 'sigma_1.25': 51.0615, 'sigma_1.25^2': 80.3058, 'sigma_1.25^3': 93.4249, 'cmp': -0.0919}\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Train Loss: 1.7265\n",
      "[Iter 3800 Task norm] Train Loss: 0.0629\n",
      "[Iter 3800 Task dept] Train Loss: 0.7455\n",
      "[Iter 3800 Total] Train Loss: 0.8449\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.8497\n",
      "{'mIoU': 0.1515, 'Pixel Acc': 0.4783, 'cmp': -0.3185}\n",
      "[Iter 3800 Task norm] Val Loss: 0.0643\n",
      "{'Angle Mean': 17.8614, 'Angle Median': 16.401, 'Angle 11.25': 26.821, 'Angle 22.5': 74.6723, 'Angle 30': 87.2381, 'cmp': -0.0741}\n",
      "[Iter 3800 Task dept] Val Loss: 0.7273\n",
      "{'abs_err': 0.72, 'rel_err': 0.2708, 'sigma_1.25': 52.2269, 'sigma_1.25^2': 81.4386, 'sigma_1.25^3': 93.7779, 'cmp': -0.0827}\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Train Loss: 1.7245\n",
      "[Iter 3900 Task norm] Train Loss: 0.0609\n",
      "[Iter 3900 Task dept] Train Loss: 0.7264\n",
      "[Iter 3900 Total] Train Loss: 0.8373\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Val Loss: 1.8550\n",
      "{'mIoU': 0.1588, 'Pixel Acc': 0.4785, 'cmp': -0.3052}\n",
      "[Iter 3900 Task norm] Val Loss: 0.0628\n",
      "{'Angle Mean': 17.4917, 'Angle Median': 15.7387, 'Angle 11.25': 30.0158, 'Angle 22.5': 75.7272, 'Angle 30': 87.1653, 'cmp': -0.0395}\n",
      "[Iter 3900 Task dept] Val Loss: 0.7153\n",
      "{'abs_err': 0.7069, 'rel_err': 0.2586, 'sigma_1.25': 52.4293, 'sigma_1.25^2': 82.5367, 'sigma_1.25^3': 94.5604, 'cmp': -0.0638}\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Train Loss: 1.5787\n",
      "[Iter 4000 Task norm] Train Loss: 0.0614\n",
      "[Iter 4000 Task dept] Train Loss: 0.6786\n",
      "[Iter 4000 Total] Train Loss: 0.7729\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.7561\n",
      "{'mIoU': 0.1815, 'Pixel Acc': 0.5, 'cmp': -0.2456}\n",
      "[Iter 4000 Task norm] Val Loss: 0.0626\n",
      "{'Angle Mean': 17.542, 'Angle Median': 16.3228, 'Angle 11.25': 28.2956, 'Angle 22.5': 75.005, 'Angle 30': 87.4621, 'cmp': -0.0595}\n",
      "[Iter 4000 Task dept] Val Loss: 0.7041\n",
      "{'abs_err': 0.6952, 'rel_err': 0.251, 'sigma_1.25': 53.0782, 'sigma_1.25^2': 83.4512, 'sigma_1.25^3': 95.0374, 'cmp': -0.0485}\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Train Loss: 1.5844\n",
      "[Iter 4100 Task norm] Train Loss: 0.0605\n",
      "[Iter 4100 Task dept] Train Loss: 0.6843\n",
      "[Iter 4100 Total] Train Loss: 0.7764\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Val Loss: 1.7970\n",
      "{'mIoU': 0.1633, 'Pixel Acc': 0.4928, 'cmp': -0.2847}\n",
      "[Iter 4100 Task norm] Val Loss: 0.0631\n",
      "{'Angle Mean': 17.7574, 'Angle Median': 16.3214, 'Angle 11.25': 26.5231, 'Angle 22.5': 75.9062, 'Angle 30': 87.652, 'cmp': -0.0692}\n",
      "[Iter 4100 Task dept] Val Loss: 0.6945\n",
      "{'abs_err': 0.685, 'rel_err': 0.2477, 'sigma_1.25': 53.1027, 'sigma_1.25^2': 83.8727, 'sigma_1.25^3': 95.2945, 'cmp': -0.041}\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Train Loss: 1.5321\n",
      "[Iter 4200 Task norm] Train Loss: 0.0603\n",
      "[Iter 4200 Task dept] Train Loss: 0.6621\n",
      "[Iter 4200 Total] Train Loss: 0.7515\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.7299\n",
      "{'mIoU': 0.1759, 'Pixel Acc': 0.5068, 'cmp': -0.25}\n",
      "[Iter 4200 Task norm] Val Loss: 0.0631\n",
      "{'Angle Mean': 17.7963, 'Angle Median': 17.0738, 'Angle 11.25': 26.9647, 'Angle 22.5': 73.1814, 'Angle 30': 87.9965, 'cmp': -0.0843}\n",
      "[Iter 4200 Task dept] Val Loss: 0.6800\n",
      "{'abs_err': 0.6717, 'rel_err': 0.2461, 'sigma_1.25': 55.0185, 'sigma_1.25^2': 84.4786, 'sigma_1.25^3': 95.3571, 'cmp': -0.0273}\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Train Loss: 1.5705\n",
      "[Iter 4300 Task norm] Train Loss: 0.0610\n",
      "[Iter 4300 Task dept] Train Loss: 0.6747\n",
      "[Iter 4300 Total] Train Loss: 0.7688\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Val Loss: 1.7168\n",
      "{'mIoU': 0.1824, 'Pixel Acc': 0.5123, 'cmp': -0.2335}\n",
      "[Iter 4300 Task norm] Val Loss: 0.0625\n",
      "{'Angle Mean': 17.5409, 'Angle Median': 16.4461, 'Angle 11.25': 29.0002, 'Angle 22.5': 74.1556, 'Angle 30': 87.9243, 'cmp': -0.0584}\n",
      "[Iter 4300 Task dept] Val Loss: 0.7049\n",
      "{'abs_err': 0.6965, 'rel_err': 0.2503, 'sigma_1.25': 52.8627, 'sigma_1.25^2': 83.2639, 'sigma_1.25^3': 95.0513, 'cmp': -0.0496}\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Train Loss: 1.5304\n",
      "[Iter 4400 Task norm] Train Loss: 0.0596\n",
      "[Iter 4400 Task dept] Train Loss: 0.6768\n",
      "[Iter 4400 Total] Train Loss: 0.7556\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.7523\n",
      "{'mIoU': 0.1761, 'Pixel Acc': 0.5005, 'cmp': -0.2549}\n",
      "[Iter 4400 Task norm] Val Loss: 0.0620\n",
      "{'Angle Mean': 17.5101, 'Angle Median': 16.0069, 'Angle 11.25': 28.7643, 'Angle 22.5': 76.1139, 'Angle 30': 87.6751, 'cmp': -0.0484}\n",
      "[Iter 4400 Task dept] Val Loss: 0.6623\n",
      "{'abs_err': 0.6558, 'rel_err': 0.2517, 'sigma_1.25': 56.1659, 'sigma_1.25^2': 84.7834, 'sigma_1.25^3': 95.3892, 'cmp': -0.0219}\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Train Loss: 1.5364\n",
      "[Iter 4500 Task norm] Train Loss: 0.0587\n",
      "[Iter 4500 Task dept] Train Loss: 0.6505\n",
      "[Iter 4500 Total] Train Loss: 0.7485\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Val Loss: 1.7190\n",
      "{'mIoU': 0.1791, 'Pixel Acc': 0.5096, 'cmp': -0.2418}\n",
      "[Iter 4500 Task norm] Val Loss: 0.0619\n",
      "{'Angle Mean': 17.4114, 'Angle Median': 15.7818, 'Angle 11.25': 29.8592, 'Angle 22.5': 76.0593, 'Angle 30': 87.55, 'cmp': -0.0383}\n",
      "[Iter 4500 Task dept] Val Loss: 0.6982\n",
      "{'abs_err': 0.6895, 'rel_err': 0.2479, 'sigma_1.25': 53.081, 'sigma_1.25^2': 83.7599, 'sigma_1.25^3': 95.3674, 'cmp': -0.0429}\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Train Loss: 1.4839\n",
      "[Iter 4600 Task norm] Train Loss: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4600 Task dept] Train Loss: 0.6384\n",
      "[Iter 4600 Total] Train Loss: 0.7274\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.7111\n",
      "{'mIoU': 0.1881, 'Pixel Acc': 0.5102, 'cmp': -0.2248}\n",
      "[Iter 4600 Task norm] Val Loss: 0.0635\n",
      "{'Angle Mean': 17.6644, 'Angle Median': 16.17, 'Angle 11.25': 28.808, 'Angle 22.5': 74.9055, 'Angle 30': 87.2412, 'cmp': -0.0566}\n",
      "[Iter 4600 Task dept] Val Loss: 0.6379\n",
      "{'abs_err': 0.6329, 'rel_err': 0.2477, 'sigma_1.25': 57.6017, 'sigma_1.25^2': 85.9804, 'sigma_1.25^3': 95.8147, 'cmp': -0.0026}\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Train Loss: 1.4748\n",
      "[Iter 4700 Task norm] Train Loss: 0.0599\n",
      "[Iter 4700 Task dept] Train Loss: 0.6437\n",
      "[Iter 4700 Total] Train Loss: 0.7262\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Val Loss: 1.6740\n",
      "{'mIoU': 0.1907, 'Pixel Acc': 0.5199, 'cmp': -0.212}\n",
      "[Iter 4700 Task norm] Val Loss: 0.0622\n",
      "{'Angle Mean': 17.5557, 'Angle Median': 16.1079, 'Angle 11.25': 29.2058, 'Angle 22.5': 75.3875, 'Angle 30': 87.7811, 'cmp': -0.0496}\n",
      "[Iter 4700 Task dept] Val Loss: 0.6412\n",
      "{'abs_err': 0.6346, 'rel_err': 0.2464, 'sigma_1.25': 57.0582, 'sigma_1.25^2': 86.0091, 'sigma_1.25^3': 96.0255, 'cmp': -0.0036}\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Train Loss: 1.4843\n",
      "[Iter 4800 Task norm] Train Loss: 0.0598\n",
      "[Iter 4800 Task dept] Train Loss: 0.6499\n",
      "[Iter 4800 Total] Train Loss: 0.7314\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.7468\n",
      "{'mIoU': 0.1849, 'Pixel Acc': 0.5002, 'cmp': -0.2393}\n",
      "[Iter 4800 Task norm] Val Loss: 0.0635\n",
      "{'Angle Mean': 17.574, 'Angle Median': 16.2586, 'Angle 11.25': 30.1937, 'Angle 22.5': 73.1893, 'Angle 30': 86.9096, 'cmp': -0.0543}\n",
      "[Iter 4800 Task dept] Val Loss: 0.6608\n",
      "{'abs_err': 0.6552, 'rel_err': 0.2437, 'sigma_1.25': 55.8469, 'sigma_1.25^2': 85.142, 'sigma_1.25^3': 95.7992, 'cmp': -0.0147}\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Train Loss: 1.4298\n",
      "[Iter 4900 Task norm] Train Loss: 0.0598\n",
      "[Iter 4900 Task dept] Train Loss: 0.6376\n",
      "[Iter 4900 Total] Train Loss: 0.7091\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Val Loss: 1.6860\n",
      "{'mIoU': 0.1956, 'Pixel Acc': 0.5133, 'cmp': -0.2086}\n",
      "[Iter 4900 Task norm] Val Loss: 0.0616\n",
      "{'Angle Mean': 17.46, 'Angle Median': 16.2062, 'Angle 11.25': 28.3799, 'Angle 22.5': 75.6186, 'Angle 30': 87.9199, 'cmp': -0.0537}\n",
      "[Iter 4900 Task dept] Val Loss: 0.6506\n",
      "{'abs_err': 0.6438, 'rel_err': 0.2381, 'sigma_1.25': 57.4691, 'sigma_1.25^2': 85.7524, 'sigma_1.25^3': 95.7903, 'cmp': 0.0004}\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Train Loss: 1.4219\n",
      "[Iter 5000 Task norm] Train Loss: 0.0602\n",
      "[Iter 5000 Task dept] Train Loss: 0.6260\n",
      "[Iter 5000 Total] Train Loss: 0.7027\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.6589\n",
      "{'mIoU': 0.2021, 'Pixel Acc': 0.5216, 'cmp': -0.1898}\n",
      "[Iter 5000 Task norm] Val Loss: 0.0626\n",
      "{'Angle Mean': 17.5897, 'Angle Median': 16.7725, 'Angle 11.25': 28.6958, 'Angle 22.5': 72.7862, 'Angle 30': 87.8313, 'cmp': -0.0692}\n",
      "[Iter 5000 Task dept] Val Loss: 0.6093\n",
      "{'abs_err': 0.604, 'rel_err': 0.2334, 'sigma_1.25': 59.9808, 'sigma_1.25^2': 87.3089, 'sigma_1.25^3': 96.2875, 'cmp': 0.0304}\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Train Loss: 1.4265\n",
      "[Iter 5100 Task norm] Train Loss: 0.0595\n",
      "[Iter 5100 Task dept] Train Loss: 0.6315\n",
      "[Iter 5100 Total] Train Loss: 0.7059\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Val Loss: 1.6985\n",
      "{'mIoU': 0.1814, 'Pixel Acc': 0.5109, 'cmp': -0.2364}\n",
      "[Iter 5100 Task norm] Val Loss: 0.0643\n",
      "{'Angle Mean': 17.6253, 'Angle Median': 16.2181, 'Angle 11.25': 30.8034, 'Angle 22.5': 72.8663, 'Angle 30': 86.677, 'cmp': -0.0522}\n",
      "[Iter 5100 Task dept] Val Loss: 0.6589\n",
      "{'abs_err': 0.6524, 'rel_err': 0.2458, 'sigma_1.25': 56.5021, 'sigma_1.25^2': 85.3857, 'sigma_1.25^3': 95.6132, 'cmp': -0.0131}\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Train Loss: 1.3927\n",
      "[Iter 5200 Task norm] Train Loss: 0.0598\n",
      "[Iter 5200 Task dept] Train Loss: 0.6241\n",
      "[Iter 5200 Total] Train Loss: 0.6922\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 1.7206\n",
      "{'mIoU': 0.1859, 'Pixel Acc': 0.5102, 'cmp': -0.2288}\n",
      "[Iter 5200 Task norm] Val Loss: 0.0648\n",
      "{'Angle Mean': 18.0683, 'Angle Median': 17.6096, 'Angle 11.25': 26.1176, 'Angle 22.5': 71.2056, 'Angle 30': 87.5866, 'cmp': -0.1062}\n",
      "[Iter 5200 Task dept] Val Loss: 0.6626\n",
      "{'abs_err': 0.6541, 'rel_err': 0.2376, 'sigma_1.25': 55.5844, 'sigma_1.25^2': 85.5204, 'sigma_1.25^3': 96.0299, 'cmp': -0.009}\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Train Loss: 1.3338\n",
      "[Iter 5300 Task norm] Train Loss: 0.0582\n",
      "[Iter 5300 Task dept] Train Loss: 0.5888\n",
      "[Iter 5300 Total] Train Loss: 0.6602\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Val Loss: 1.6330\n",
      "{'mIoU': 0.2023, 'Pixel Acc': 0.5274, 'cmp': -0.1845}\n",
      "[Iter 5300 Task norm] Val Loss: 0.0612\n",
      "{'Angle Mean': 17.3236, 'Angle Median': 15.6719, 'Angle 11.25': 29.5647, 'Angle 22.5': 76.1876, 'Angle 30': 87.4644, 'cmp': -0.0373}\n",
      "[Iter 5300 Task dept] Val Loss: 0.6664\n",
      "{'abs_err': 0.6582, 'rel_err': 0.237, 'sigma_1.25': 56.2889, 'sigma_1.25^2': 84.9532, 'sigma_1.25^3': 95.6638, 'cmp': -0.0095}\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Train Loss: 1.3115\n",
      "[Iter 5400 Task norm] Train Loss: 0.0600\n",
      "[Iter 5400 Task dept] Train Loss: 0.5824\n",
      "[Iter 5400 Total] Train Loss: 0.6513\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 1.6145\n",
      "{'mIoU': 0.2072, 'Pixel Acc': 0.5342, 'cmp': -0.1698}\n",
      "[Iter 5400 Task norm] Val Loss: 0.0626\n",
      "{'Angle Mean': 17.4932, 'Angle Median': 16.2718, 'Angle 11.25': 29.7397, 'Angle 22.5': 73.7947, 'Angle 30': 87.2231, 'cmp': -0.0538}\n",
      "[Iter 5400 Task dept] Val Loss: 0.6662\n",
      "{'abs_err': 0.6563, 'rel_err': 0.2374, 'sigma_1.25': 56.2129, 'sigma_1.25^2': 85.6149, 'sigma_1.25^3': 95.7925, 'cmp': -0.0077}\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Train Loss: 1.2886\n",
      "[Iter 5500 Task norm] Train Loss: 0.0577\n",
      "[Iter 5500 Task dept] Train Loss: 0.5893\n",
      "[Iter 5500 Total] Train Loss: 0.6452\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Val Loss: 1.6394\n",
      "{'mIoU': 0.2023, 'Pixel Acc': 0.5251, 'cmp': -0.1864}\n",
      "[Iter 5500 Task norm] Val Loss: 0.0618\n",
      "{'Angle Mean': 17.47, 'Angle Median': 16.5981, 'Angle 11.25': 29.3466, 'Angle 22.5': 73.3061, 'Angle 30': 88.008, 'cmp': -0.0599}\n",
      "[Iter 5500 Task dept] Val Loss: 0.6269\n",
      "{'abs_err': 0.6207, 'rel_err': 0.2314, 'sigma_1.25': 58.9812, 'sigma_1.25^2': 86.9276, 'sigma_1.25^3': 96.3272, 'cmp': 0.0223}\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Train Loss: 1.2898\n",
      "[Iter 5600 Task norm] Train Loss: 0.0584\n",
      "[Iter 5600 Task dept] Train Loss: 0.5711\n",
      "[Iter 5600 Total] Train Loss: 0.6398\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.6362\n",
      "{'mIoU': 0.2156, 'Pixel Acc': 0.5279, 'cmp': -0.1599}\n",
      "[Iter 5600 Task norm] Val Loss: 0.0613\n",
      "{'Angle Mean': 17.3144, 'Angle Median': 15.9216, 'Angle 11.25': 30.6469, 'Angle 22.5': 74.8111, 'Angle 30': 87.5319, 'cmp': -0.0381}\n",
      "[Iter 5600 Task dept] Val Loss: 0.6894\n",
      "{'abs_err': 0.6804, 'rel_err': 0.2376, 'sigma_1.25': 54.7141, 'sigma_1.25^2': 84.2839, 'sigma_1.25^3': 95.4158, 'cmp': -0.0247}\n",
      "======================================================================\n",
      "[Iter 5700 Task segm] Train Loss: 1.2876\n",
      "[Iter 5700 Task norm] Train Loss: 0.0578\n",
      "[Iter 5700 Task dept] Train Loss: 0.5747\n",
      "[Iter 5700 Total] Train Loss: 0.6400\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5700 Task segm] Val Loss: 1.6258\n",
      "{'mIoU': 0.1988, 'Pixel Acc': 0.5296, 'cmp': -0.189}\n",
      "[Iter 5700 Task norm] Val Loss: 0.0623\n",
      "{'Angle Mean': 17.446, 'Angle Median': 16.1145, 'Angle 11.25': 30.8725, 'Angle 22.5': 73.4246, 'Angle 30': 87.5782, 'cmp': -0.0447}\n",
      "[Iter 5700 Task dept] Val Loss: 0.6072\n",
      "{'abs_err': 0.602, 'rel_err': 0.2344, 'sigma_1.25': 60.3592, 'sigma_1.25^2': 87.5059, 'sigma_1.25^3': 96.4805, 'cmp': 0.0324}\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Train Loss: 1.2650\n",
      "[Iter 5800 Task norm] Train Loss: 0.0586\n",
      "[Iter 5800 Task dept] Train Loss: 0.5510\n",
      "[Iter 5800 Total] Train Loss: 0.6249\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.6471\n",
      "{'mIoU': 0.2022, 'Pixel Acc': 0.5231, 'cmp': -0.1883}\n",
      "[Iter 5800 Task norm] Val Loss: 0.0620\n",
      "{'Angle Mean': 17.2614, 'Angle Median': 15.502, 'Angle 11.25': 31.5913, 'Angle 22.5': 75.203, 'Angle 30': 87.0074, 'cmp': -0.0263}\n",
      "[Iter 5800 Task dept] Val Loss: 0.6191\n",
      "{'abs_err': 0.6131, 'rel_err': 0.2336, 'sigma_1.25': 59.3347, 'sigma_1.25^2': 87.2258, 'sigma_1.25^3': 96.372, 'cmp': 0.025}\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Train Loss: 1.2384\n",
      "[Iter 5900 Task norm] Train Loss: 0.0578\n",
      "[Iter 5900 Task dept] Train Loss: 0.5708\n",
      "[Iter 5900 Total] Train Loss: 0.6223\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Val Loss: 1.6523\n",
      "{'mIoU': 0.198, 'Pixel Acc': 0.5262, 'cmp': -0.1933}\n",
      "[Iter 5900 Task norm] Val Loss: 0.0609\n",
      "{'Angle Mean': 17.2453, 'Angle Median': 15.6723, 'Angle 11.25': 30.1241, 'Angle 22.5': 76.1339, 'Angle 30': 87.6849, 'cmp': -0.0328}\n",
      "[Iter 5900 Task dept] Val Loss: 0.6133\n",
      "{'abs_err': 0.6081, 'rel_err': 0.2331, 'sigma_1.25': 60.0128, 'sigma_1.25^2': 87.284, 'sigma_1.25^3': 96.468, 'cmp': 0.0297}\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Train Loss: 1.2559\n",
      "[Iter 6000 Task norm] Train Loss: 0.0585\n",
      "[Iter 6000 Task dept] Train Loss: 0.5725\n",
      "[Iter 6000 Total] Train Loss: 0.6290\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.6240\n",
      "{'mIoU': 0.1996, 'Pixel Acc': 0.5277, 'cmp': -0.1892}\n",
      "[Iter 6000 Task norm] Val Loss: 0.0607\n",
      "{'Angle Mean': 17.3672, 'Angle Median': 16.1227, 'Angle 11.25': 29.609, 'Angle 22.5': 74.7326, 'Angle 30': 87.909, 'cmp': -0.0468}\n",
      "[Iter 6000 Task dept] Val Loss: 0.6429\n",
      "{'abs_err': 0.6353, 'rel_err': 0.2329, 'sigma_1.25': 58.1244, 'sigma_1.25^2': 86.4767, 'sigma_1.25^3': 96.1692, 'cmp': 0.0121}\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Train Loss: 1.2097\n",
      "[Iter 6100 Task norm] Train Loss: 0.0578\n",
      "[Iter 6100 Task dept] Train Loss: 0.5487\n",
      "[Iter 6100 Total] Train Loss: 0.6054\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Val Loss: 1.6652\n",
      "{'mIoU': 0.2009, 'Pixel Acc': 0.5182, 'cmp': -0.1949}\n",
      "[Iter 6100 Task norm] Val Loss: 0.0610\n",
      "{'Angle Mean': 17.352, 'Angle Median': 16.1586, 'Angle 11.25': 29.634, 'Angle 22.5': 74.6578, 'Angle 30': 87.67, 'cmp': -0.0478}\n",
      "[Iter 6100 Task dept] Val Loss: 0.6380\n",
      "{'abs_err': 0.6298, 'rel_err': 0.2315, 'sigma_1.25': 58.3571, 'sigma_1.25^2': 86.5485, 'sigma_1.25^3': 96.3338, 'cmp': 0.0163}\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Train Loss: 1.2257\n",
      "[Iter 6200 Task norm] Train Loss: 0.0587\n",
      "[Iter 6200 Task dept] Train Loss: 0.5677\n",
      "[Iter 6200 Total] Train Loss: 0.6174\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 1.6482\n",
      "{'mIoU': 0.2015, 'Pixel Acc': 0.5288, 'cmp': -0.1847}\n",
      "[Iter 6200 Task norm] Val Loss: 0.0602\n",
      "{'Angle Mean': 17.3258, 'Angle Median': 16.4021, 'Angle 11.25': 29.068, 'Angle 22.5': 74.8007, 'Angle 30': 88.5621, 'cmp': -0.0517}\n",
      "[Iter 6200 Task dept] Val Loss: 0.6211\n",
      "{'abs_err': 0.6145, 'rel_err': 0.2325, 'sigma_1.25': 59.3966, 'sigma_1.25^2': 87.0842, 'sigma_1.25^3': 96.3462, 'cmp': 0.0253}\n",
      "======================================================================\n",
      "[Iter 6300 Task segm] Train Loss: 1.2207\n",
      "[Iter 6300 Task norm] Train Loss: 0.0581\n",
      "[Iter 6300 Task dept] Train Loss: 0.5616\n",
      "[Iter 6300 Total] Train Loss: 0.6135\n",
      "======================================================================\n",
      "[Iter 6300 Task segm] Val Loss: 1.6233\n",
      "{'mIoU': 0.2111, 'Pixel Acc': 0.5331, 'cmp': -0.1636}\n",
      "[Iter 6300 Task norm] Val Loss: 0.0610\n",
      "{'Angle Mean': 17.1951, 'Angle Median': 15.5581, 'Angle 11.25': 31.4955, 'Angle 22.5': 75.5943, 'Angle 30': 87.4292, 'cmp': -0.0249}\n",
      "[Iter 6300 Task dept] Val Loss: 0.6084\n",
      "{'abs_err': 0.6045, 'rel_err': 0.2385, 'sigma_1.25': 60.3889, 'sigma_1.25^2': 87.045, 'sigma_1.25^3': 96.1773, 'cmp': 0.0267}\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Train Loss: 1.2259\n",
      "[Iter 6400 Task norm] Train Loss: 0.0585\n",
      "[Iter 6400 Task dept] Train Loss: 0.5500\n",
      "[Iter 6400 Total] Train Loss: 0.6115\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.6342\n",
      "{'mIoU': 0.2067, 'Pixel Acc': 0.5267, 'cmp': -0.1771}\n",
      "[Iter 6400 Task norm] Val Loss: 0.0611\n",
      "{'Angle Mean': 17.2227, 'Angle Median': 15.6898, 'Angle 11.25': 31.0712, 'Angle 22.5': 75.1819, 'Angle 30': 87.2391, 'cmp': -0.031}\n",
      "[Iter 6400 Task dept] Val Loss: 0.6247\n",
      "{'abs_err': 0.617, 'rel_err': 0.2289, 'sigma_1.25': 59.4627, 'sigma_1.25^2': 86.871, 'sigma_1.25^3': 96.3843, 'cmp': 0.0272}\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Train Loss: 1.1924\n",
      "[Iter 6500 Task norm] Train Loss: 0.0573\n",
      "[Iter 6500 Task dept] Train Loss: 0.5495\n",
      "[Iter 6500 Total] Train Loss: 0.5997\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Val Loss: 1.6272\n",
      "{'mIoU': 0.1995, 'Pixel Acc': 0.5302, 'cmp': -0.1873}\n",
      "[Iter 6500 Task norm] Val Loss: 0.0608\n",
      "{'Angle Mean': 17.215, 'Angle Median': 15.7685, 'Angle 11.25': 31.6814, 'Angle 22.5': 74.8193, 'Angle 30': 87.7328, 'cmp': -0.0284}\n",
      "[Iter 6500 Task dept] Val Loss: 0.6283\n",
      "{'abs_err': 0.6212, 'rel_err': 0.2304, 'sigma_1.25': 58.7353, 'sigma_1.25^2': 86.7833, 'sigma_1.25^3': 96.4923, 'cmp': 0.0221}\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Train Loss: 1.1643\n",
      "[Iter 6600 Task norm] Train Loss: 0.0568\n",
      "[Iter 6600 Task dept] Train Loss: 0.5205\n",
      "[Iter 6600 Total] Train Loss: 0.5806\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.6094\n",
      "{'mIoU': 0.2129, 'Pixel Acc': 0.5381, 'cmp': -0.1561}\n",
      "[Iter 6600 Task norm] Val Loss: 0.0615\n",
      "{'Angle Mean': 17.3609, 'Angle Median': 16.0399, 'Angle 11.25': 30.6788, 'Angle 22.5': 74.467, 'Angle 30': 87.6743, 'cmp': -0.0407}\n",
      "[Iter 6600 Task dept] Val Loss: 0.6362\n",
      "{'abs_err': 0.6288, 'rel_err': 0.2275, 'sigma_1.25': 58.6337, 'sigma_1.25^2': 86.6548, 'sigma_1.25^3': 96.3412, 'cmp': 0.021}\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Train Loss: 1.1269\n",
      "[Iter 6700 Task norm] Train Loss: 0.0572\n",
      "[Iter 6700 Task dept] Train Loss: 0.5359\n",
      "[Iter 6700 Total] Train Loss: 0.5733\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Val Loss: 1.5975\n",
      "{'mIoU': 0.2125, 'Pixel Acc': 0.5391, 'cmp': -0.156}\n",
      "[Iter 6700 Task norm] Val Loss: 0.0607\n",
      "{'Angle Mean': 17.2276, 'Angle Median': 15.8648, 'Angle 11.25': 30.8261, 'Angle 22.5': 74.6433, 'Angle 30': 87.6655, 'cmp': -0.0354}\n",
      "[Iter 6700 Task dept] Val Loss: 0.6411\n",
      "{'abs_err': 0.632, 'rel_err': 0.2301, 'sigma_1.25': 58.1421, 'sigma_1.25^2': 86.5524, 'sigma_1.25^3': 96.3944, 'cmp': 0.0161}\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Train Loss: 1.1304\n",
      "[Iter 6800 Task norm] Train Loss: 0.0580\n",
      "[Iter 6800 Task dept] Train Loss: 0.5309\n",
      "[Iter 6800 Total] Train Loss: 0.5731\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.6263\n",
      "{'mIoU': 0.2097, 'Pixel Acc': 0.5326, 'cmp': -0.1667}\n",
      "[Iter 6800 Task norm] Val Loss: 0.0604\n",
      "{'Angle Mean': 17.2326, 'Angle Median': 16.0386, 'Angle 11.25': 30.0329, 'Angle 22.5': 74.9713, 'Angle 30': 87.9162, 'cmp': -0.041}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6800 Task dept] Val Loss: 0.6186\n",
      "{'abs_err': 0.6117, 'rel_err': 0.2289, 'sigma_1.25': 59.6457, 'sigma_1.25^2': 87.2973, 'sigma_1.25^3': 96.524, 'cmp': 0.0308}\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Train Loss: 1.0915\n",
      "[Iter 6900 Task norm] Train Loss: 0.0567\n",
      "[Iter 6900 Task dept] Train Loss: 0.5334\n",
      "[Iter 6900 Total] Train Loss: 0.5605\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Val Loss: 1.6155\n",
      "{'mIoU': 0.2099, 'Pixel Acc': 0.5371, 'cmp': -0.1623}\n",
      "[Iter 6900 Task norm] Val Loss: 0.0598\n",
      "{'Angle Mean': 17.1266, 'Angle Median': 15.8763, 'Angle 11.25': 31.1659, 'Angle 22.5': 74.7196, 'Angle 30': 88.1039, 'cmp': -0.0313}\n",
      "[Iter 6900 Task dept] Val Loss: 0.6346\n",
      "{'abs_err': 0.6277, 'rel_err': 0.23, 'sigma_1.25': 58.7989, 'sigma_1.25^2': 86.6098, 'sigma_1.25^3': 96.3379, 'cmp': 0.0199}\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Train Loss: 1.1061\n",
      "[Iter 7000 Task norm] Train Loss: 0.0570\n",
      "[Iter 7000 Task dept] Train Loss: 0.5197\n",
      "[Iter 7000 Total] Train Loss: 0.5609\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 1.6263\n",
      "{'mIoU': 0.2122, 'Pixel Acc': 0.5318, 'cmp': -0.1627}\n",
      "[Iter 7000 Task norm] Val Loss: 0.0608\n",
      "{'Angle Mean': 17.1631, 'Angle Median': 15.7003, 'Angle 11.25': 31.8428, 'Angle 22.5': 74.8578, 'Angle 30': 87.5877, 'cmp': -0.0261}\n",
      "[Iter 7000 Task dept] Val Loss: 0.6347\n",
      "{'abs_err': 0.6271, 'rel_err': 0.227, 'sigma_1.25': 58.8026, 'sigma_1.25^2': 86.7317, 'sigma_1.25^3': 96.4448, 'cmp': 0.0229}\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Train Loss: 1.0965\n",
      "[Iter 7100 Task norm] Train Loss: 0.0582\n",
      "[Iter 7100 Task dept] Train Loss: 0.5139\n",
      "[Iter 7100 Total] Train Loss: 0.5562\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Val Loss: 1.6583\n",
      "{'mIoU': 0.2058, 'Pixel Acc': 0.5281, 'cmp': -0.1775}\n",
      "[Iter 7100 Task norm] Val Loss: 0.0597\n",
      "{'Angle Mean': 17.0993, 'Angle Median': 15.8192, 'Angle 11.25': 31.2407, 'Angle 22.5': 74.9559, 'Angle 30': 88.1539, 'cmp': -0.029}\n",
      "[Iter 7100 Task dept] Val Loss: 0.6222\n",
      "{'abs_err': 0.6153, 'rel_err': 0.2264, 'sigma_1.25': 59.5063, 'sigma_1.25^2': 87.1744, 'sigma_1.25^3': 96.6409, 'cmp': 0.0311}\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Train Loss: 1.0984\n",
      "[Iter 7200 Task norm] Train Loss: 0.0582\n",
      "[Iter 7200 Task dept] Train Loss: 0.5157\n",
      "[Iter 7200 Total] Train Loss: 0.5574\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.6290\n",
      "{'mIoU': 0.2085, 'Pixel Acc': 0.5344, 'cmp': -0.1672}\n",
      "[Iter 7200 Task norm] Val Loss: 0.0605\n",
      "{'Angle Mean': 17.1731, 'Angle Median': 15.817, 'Angle 11.25': 31.0068, 'Angle 22.5': 75.0906, 'Angle 30': 87.7776, 'cmp': -0.0316}\n",
      "[Iter 7200 Task dept] Val Loss: 0.6310\n",
      "{'abs_err': 0.6232, 'rel_err': 0.2262, 'sigma_1.25': 59.2192, 'sigma_1.25^2': 87.008, 'sigma_1.25^3': 96.5594, 'cmp': 0.0272}\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Train Loss: 1.0828\n",
      "[Iter 7300 Task norm] Train Loss: 0.0579\n",
      "[Iter 7300 Task dept] Train Loss: 0.5057\n",
      "[Iter 7300 Total] Train Loss: 0.5488\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Val Loss: 1.6153\n",
      "{'mIoU': 0.2113, 'Pixel Acc': 0.5352, 'cmp': -0.1616}\n",
      "[Iter 7300 Task norm] Val Loss: 0.0605\n",
      "{'Angle Mean': 17.2572, 'Angle Median': 16.2701, 'Angle 11.25': 30.6923, 'Angle 22.5': 73.378, 'Angle 30': 88.2301, 'cmp': -0.0444}\n",
      "[Iter 7300 Task dept] Val Loss: 0.6079\n",
      "{'abs_err': 0.6026, 'rel_err': 0.2266, 'sigma_1.25': 60.694, 'sigma_1.25^2': 87.5531, 'sigma_1.25^3': 96.6523, 'cmp': 0.0401}\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Train Loss: 1.0691\n",
      "[Iter 7400 Task norm] Train Loss: 0.0566\n",
      "[Iter 7400 Task dept] Train Loss: 0.5100\n",
      "[Iter 7400 Total] Train Loss: 0.5452\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 1.6110\n",
      "{'mIoU': 0.2145, 'Pixel Acc': 0.5369, 'cmp': -0.1541}\n",
      "[Iter 7400 Task norm] Val Loss: 0.0606\n",
      "{'Angle Mean': 17.0856, 'Angle Median': 15.3964, 'Angle 11.25': 32.6361, 'Angle 22.5': 75.1591, 'Angle 30': 87.2929, 'cmp': -0.0163}\n",
      "[Iter 7400 Task dept] Val Loss: 0.6226\n",
      "{'abs_err': 0.6142, 'rel_err': 0.2259, 'sigma_1.25': 59.7722, 'sigma_1.25^2': 87.3347, 'sigma_1.25^3': 96.631, 'cmp': 0.0331}\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Train Loss: 1.0744\n",
      "[Iter 7500 Task norm] Train Loss: 0.0579\n",
      "[Iter 7500 Task dept] Train Loss: 0.5141\n",
      "[Iter 7500 Total] Train Loss: 0.5488\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Val Loss: 1.6234\n",
      "{'mIoU': 0.2121, 'Pixel Acc': 0.5342, 'cmp': -0.1608}\n",
      "[Iter 7500 Task norm] Val Loss: 0.0606\n",
      "{'Angle Mean': 17.2242, 'Angle Median': 16.073, 'Angle 11.25': 30.816, 'Angle 22.5': 73.7221, 'Angle 30': 87.9287, 'cmp': -0.0403}\n",
      "[Iter 7500 Task dept] Val Loss: 0.6170\n",
      "{'abs_err': 0.6107, 'rel_err': 0.2264, 'sigma_1.25': 60.1654, 'sigma_1.25^2': 87.3581, 'sigma_1.25^3': 96.5485, 'cmp': 0.0351}\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Train Loss: 1.0681\n",
      "[Iter 7600 Task norm] Train Loss: 0.0569\n",
      "[Iter 7600 Task dept] Train Loss: 0.5032\n",
      "[Iter 7600 Total] Train Loss: 0.5427\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.6097\n",
      "{'mIoU': 0.2136, 'Pixel Acc': 0.5367, 'cmp': -0.156}\n",
      "[Iter 7600 Task norm] Val Loss: 0.0612\n",
      "{'Angle Mean': 17.2749, 'Angle Median': 15.7664, 'Angle 11.25': 31.3715, 'Angle 22.5': 74.5322, 'Angle 30': 87.4612, 'cmp': -0.0322}\n",
      "[Iter 7600 Task dept] Val Loss: 0.6242\n",
      "{'abs_err': 0.6179, 'rel_err': 0.2303, 'sigma_1.25': 59.4602, 'sigma_1.25^2': 86.8706, 'sigma_1.25^3': 96.361, 'cmp': 0.0257}\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Train Loss: 1.0581\n",
      "[Iter 7700 Task norm] Train Loss: 0.0572\n",
      "[Iter 7700 Task dept] Train Loss: 0.5074\n",
      "[Iter 7700 Total] Train Loss: 0.5409\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Val Loss: 1.6320\n",
      "{'mIoU': 0.2158, 'Pixel Acc': 0.5356, 'cmp': -0.153}\n",
      "[Iter 7700 Task norm] Val Loss: 0.0615\n",
      "{'Angle Mean': 17.3757, 'Angle Median': 16.0656, 'Angle 11.25': 30.3176, 'Angle 22.5': 73.7764, 'Angle 30': 87.4959, 'cmp': -0.0456}\n",
      "[Iter 7700 Task dept] Val Loss: 0.6377\n",
      "{'abs_err': 0.6308, 'rel_err': 0.2303, 'sigma_1.25': 58.5365, 'sigma_1.25^2': 86.4664, 'sigma_1.25^3': 96.3725, 'cmp': 0.0174}\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Train Loss: 1.0486\n",
      "[Iter 7800 Task norm] Train Loss: 0.0564\n",
      "[Iter 7800 Task dept] Train Loss: 0.5031\n",
      "[Iter 7800 Total] Train Loss: 0.5360\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 1.6131\n",
      "{'mIoU': 0.2142, 'Pixel Acc': 0.5361, 'cmp': -0.1554}\n",
      "[Iter 7800 Task norm] Val Loss: 0.0610\n",
      "{'Angle Mean': 17.1878, 'Angle Median': 15.747, 'Angle 11.25': 32.0522, 'Angle 22.5': 74.0828, 'Angle 30': 87.5624, 'cmp': -0.0281}\n",
      "[Iter 7800 Task dept] Val Loss: 0.6122\n",
      "{'abs_err': 0.6065, 'rel_err': 0.2303, 'sigma_1.25': 60.5251, 'sigma_1.25^2': 87.3274, 'sigma_1.25^3': 96.3749, 'cmp': 0.0341}\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Train Loss: 1.0404\n",
      "[Iter 7900 Task norm] Train Loss: 0.0561\n",
      "[Iter 7900 Task dept] Train Loss: 0.4878\n",
      "[Iter 7900 Total] Train Loss: 0.5281\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Val Loss: 1.6101\n",
      "{'mIoU': 0.2158, 'Pixel Acc': 0.5391, 'cmp': -0.1501}\n",
      "[Iter 7900 Task norm] Val Loss: 0.0608\n",
      "{'Angle Mean': 17.2799, 'Angle Median': 16.1199, 'Angle 11.25': 30.5387, 'Angle 22.5': 73.8396, 'Angle 30': 87.7764, 'cmp': -0.0432}\n",
      "[Iter 7900 Task dept] Val Loss: 0.6321\n",
      "{'abs_err': 0.6247, 'rel_err': 0.2292, 'sigma_1.25': 59.3114, 'sigma_1.25^2': 86.7394, 'sigma_1.25^3': 96.3012, 'cmp': 0.0235}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 8000 Task segm] Train Loss: 1.0147\n",
      "[Iter 8000 Task norm] Train Loss: 0.0564\n",
      "[Iter 8000 Task dept] Train Loss: 0.5041\n",
      "[Iter 8000 Total] Train Loss: 0.5250\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 1.6198\n",
      "{'mIoU': 0.214, 'Pixel Acc': 0.5381, 'cmp': -0.1542}\n",
      "[Iter 8000 Task norm] Val Loss: 0.0613\n",
      "{'Angle Mean': 17.2655, 'Angle Median': 15.9345, 'Angle 11.25': 31.7831, 'Angle 22.5': 73.332, 'Angle 30': 87.4397, 'cmp': -0.0355}\n",
      "[Iter 8000 Task dept] Val Loss: 0.6115\n",
      "{'abs_err': 0.6051, 'rel_err': 0.2242, 'sigma_1.25': 60.6524, 'sigma_1.25^2': 87.5702, 'sigma_1.25^3': 96.6641, 'cmp': 0.0411}\n",
      "======================================================================\n",
      "[Iter 8100 Task segm] Train Loss: 1.0160\n",
      "[Iter 8100 Task norm] Train Loss: 0.0574\n",
      "[Iter 8100 Task dept] Train Loss: 0.4847\n",
      "[Iter 8100 Total] Train Loss: 0.5194\n",
      "======================================================================\n",
      "[Iter 8100 Task segm] Val Loss: 1.6103\n",
      "{'mIoU': 0.2184, 'Pixel Acc': 0.5397, 'cmp': -0.1447}\n",
      "[Iter 8100 Task norm] Val Loss: 0.0607\n",
      "{'Angle Mean': 17.2875, 'Angle Median': 16.1036, 'Angle 11.25': 30.3106, 'Angle 22.5': 74.0638, 'Angle 30': 87.8323, 'cmp': -0.0436}\n",
      "[Iter 8100 Task dept] Val Loss: 0.6223\n",
      "{'abs_err': 0.6156, 'rel_err': 0.2253, 'sigma_1.25': 59.8063, 'sigma_1.25^2': 87.1333, 'sigma_1.25^3': 96.6064, 'cmp': 0.0328}\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 1.0221\n",
      "[Iter 8200 Task norm] Train Loss: 0.0564\n",
      "[Iter 8200 Task dept] Train Loss: 0.4944\n",
      "[Iter 8200 Total] Train Loss: 0.5243\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.6037\n",
      "{'mIoU': 0.2197, 'Pixel Acc': 0.5418, 'cmp': -0.1406}\n",
      "[Iter 8200 Task norm] Val Loss: 0.0608\n",
      "{'Angle Mean': 17.1562, 'Angle Median': 15.731, 'Angle 11.25': 32.1252, 'Angle 22.5': 74.0107, 'Angle 30': 87.493, 'cmp': -0.0274}\n",
      "[Iter 8200 Task dept] Val Loss: 0.6060\n",
      "{'abs_err': 0.6004, 'rel_err': 0.2252, 'sigma_1.25': 61.0187, 'sigma_1.25^2': 87.6995, 'sigma_1.25^3': 96.695, 'cmp': 0.0435}\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Train Loss: 1.0093\n",
      "[Iter 8300 Task norm] Train Loss: 0.0567\n",
      "[Iter 8300 Task dept] Train Loss: 0.4989\n",
      "[Iter 8300 Total] Train Loss: 0.5217\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Val Loss: 1.5948\n",
      "{'mIoU': 0.2203, 'Pixel Acc': 0.5422, 'cmp': -0.1391}\n",
      "[Iter 8300 Task norm] Val Loss: 0.0603\n",
      "{'Angle Mean': 17.1833, 'Angle Median': 15.9713, 'Angle 11.25': 31.2899, 'Angle 22.5': 73.8755, 'Angle 30': 88.0289, 'cmp': -0.035}\n",
      "[Iter 8300 Task dept] Val Loss: 0.6113\n",
      "{'abs_err': 0.6049, 'rel_err': 0.2242, 'sigma_1.25': 60.5497, 'sigma_1.25^2': 87.7328, 'sigma_1.25^3': 96.7327, 'cmp': 0.0413}\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 1.0132\n",
      "[Iter 8400 Task norm] Train Loss: 0.0559\n",
      "[Iter 8400 Task dept] Train Loss: 0.4858\n",
      "[Iter 8400 Total] Train Loss: 0.5183\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 1.5976\n",
      "{'mIoU': 0.2184, 'Pixel Acc': 0.5414, 'cmp': -0.1433}\n",
      "[Iter 8400 Task norm] Val Loss: 0.0604\n",
      "{'Angle Mean': 17.1811, 'Angle Median': 15.9224, 'Angle 11.25': 31.2112, 'Angle 22.5': 74.1419, 'Angle 30': 87.7575, 'cmp': -0.0347}\n",
      "[Iter 8400 Task dept] Val Loss: 0.6078\n",
      "{'abs_err': 0.6008, 'rel_err': 0.2248, 'sigma_1.25': 60.806, 'sigma_1.25^2': 87.7772, 'sigma_1.25^3': 96.7498, 'cmp': 0.0432}\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Train Loss: 0.9938\n",
      "[Iter 8500 Task norm] Train Loss: 0.0570\n",
      "[Iter 8500 Task dept] Train Loss: 0.4907\n",
      "[Iter 8500 Total] Train Loss: 0.5138\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Val Loss: 1.6041\n",
      "{'mIoU': 0.2171, 'Pixel Acc': 0.5413, 'cmp': -0.1458}\n",
      "[Iter 8500 Task norm] Val Loss: 0.0609\n",
      "{'Angle Mean': 17.2659, 'Angle Median': 16.0724, 'Angle 11.25': 31.113, 'Angle 22.5': 73.4559, 'Angle 30': 87.874, 'cmp': -0.0399}\n",
      "[Iter 8500 Task dept] Val Loss: 0.6244\n",
      "{'abs_err': 0.6166, 'rel_err': 0.2249, 'sigma_1.25': 59.403, 'sigma_1.25^2': 87.1677, 'sigma_1.25^3': 96.6927, 'cmp': 0.0316}\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Train Loss: 0.9986\n",
      "[Iter 8600 Task norm] Train Loss: 0.0567\n",
      "[Iter 8600 Task dept] Train Loss: 0.5045\n",
      "[Iter 8600 Total] Train Loss: 0.5199\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 1.6220\n",
      "{'mIoU': 0.2145, 'Pixel Acc': 0.54, 'cmp': -0.1516}\n",
      "[Iter 8600 Task norm] Val Loss: 0.0604\n",
      "{'Angle Mean': 17.1913, 'Angle Median': 16.0233, 'Angle 11.25': 31.3403, 'Angle 22.5': 73.8578, 'Angle 30': 87.9547, 'cmp': -0.0358}\n",
      "[Iter 8600 Task dept] Val Loss: 0.6275\n",
      "{'abs_err': 0.6209, 'rel_err': 0.2279, 'sigma_1.25': 59.3532, 'sigma_1.25^2': 86.7965, 'sigma_1.25^3': 96.3917, 'cmp': 0.0262}\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Train Loss: 1.0151\n",
      "[Iter 8700 Task norm] Train Loss: 0.0565\n",
      "[Iter 8700 Task dept] Train Loss: 0.4949\n",
      "[Iter 8700 Total] Train Loss: 0.5222\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Val Loss: 1.5989\n",
      "{'mIoU': 0.2191, 'Pixel Acc': 0.5417, 'cmp': -0.1417}\n",
      "[Iter 8700 Task norm] Val Loss: 0.0605\n",
      "{'Angle Mean': 17.1994, 'Angle Median': 16.0305, 'Angle 11.25': 31.3177, 'Angle 22.5': 73.6312, 'Angle 30': 87.795, 'cmp': -0.0371}\n",
      "[Iter 8700 Task dept] Val Loss: 0.6347\n",
      "{'abs_err': 0.627, 'rel_err': 0.2247, 'sigma_1.25': 58.5212, 'sigma_1.25^2': 86.8281, 'sigma_1.25^3': 96.6472, 'cmp': 0.0245}\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.9970\n",
      "[Iter 8800 Task norm] Train Loss: 0.0563\n",
      "[Iter 8800 Task dept] Train Loss: 0.4816\n",
      "[Iter 8800 Total] Train Loss: 0.5116\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.6186\n",
      "{'mIoU': 0.2207, 'Pixel Acc': 0.5401, 'cmp': -0.1403}\n",
      "[Iter 8800 Task norm] Val Loss: 0.0600\n",
      "{'Angle Mean': 17.1717, 'Angle Median': 15.7941, 'Angle 11.25': 30.9262, 'Angle 22.5': 75.0541, 'Angle 30': 87.9548, 'cmp': -0.0314}\n",
      "[Iter 8800 Task dept] Val Loss: 0.6187\n",
      "{'abs_err': 0.6122, 'rel_err': 0.2264, 'sigma_1.25': 60.0218, 'sigma_1.25^2': 87.1515, 'sigma_1.25^3': 96.6108, 'cmp': 0.0338}\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Train Loss: 1.0043\n",
      "[Iter 8900 Task norm] Train Loss: 0.0562\n",
      "[Iter 8900 Task dept] Train Loss: 0.4904\n",
      "[Iter 8900 Total] Train Loss: 0.5170\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Val Loss: 1.5883\n",
      "{'mIoU': 0.2213, 'Pixel Acc': 0.5439, 'cmp': -0.136}\n",
      "[Iter 8900 Task norm] Val Loss: 0.0605\n",
      "{'Angle Mean': 17.1515, 'Angle Median': 15.7154, 'Angle 11.25': 31.5081, 'Angle 22.5': 74.6026, 'Angle 30': 87.6988, 'cmp': -0.0286}\n",
      "[Iter 8900 Task dept] Val Loss: 0.6220\n",
      "{'abs_err': 0.615, 'rel_err': 0.2245, 'sigma_1.25': 59.7303, 'sigma_1.25^2': 87.1682, 'sigma_1.25^3': 96.6371, 'cmp': 0.0335}\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.9891\n",
      "[Iter 9000 Task norm] Train Loss: 0.0556\n",
      "[Iter 9000 Task dept] Train Loss: 0.4887\n",
      "[Iter 9000 Total] Train Loss: 0.5111\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 1.5986\n",
      "{'mIoU': 0.2187, 'Pixel Acc': 0.5435, 'cmp': -0.1411}\n",
      "[Iter 9000 Task norm] Val Loss: 0.0610\n",
      "{'Angle Mean': 17.1891, 'Angle Median': 15.9214, 'Angle 11.25': 32.3154, 'Angle 22.5': 73.3455, 'Angle 30': 87.6891, 'cmp': -0.0307}\n",
      "[Iter 9000 Task dept] Val Loss: 0.6034\n",
      "{'abs_err': 0.5987, 'rel_err': 0.2289, 'sigma_1.25': 61.3027, 'sigma_1.25^2': 87.5679, 'sigma_1.25^3': 96.4409, 'cmp': 0.0412}\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Train Loss: 0.9890\n",
      "[Iter 9100 Task norm] Train Loss: 0.0560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9100 Task dept] Train Loss: 0.4840\n",
      "[Iter 9100 Total] Train Loss: 0.5097\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Val Loss: 1.6008\n",
      "{'mIoU': 0.2202, 'Pixel Acc': 0.5446, 'cmp': -0.1373}\n",
      "[Iter 9100 Task norm] Val Loss: 0.0602\n",
      "{'Angle Mean': 17.1699, 'Angle Median': 16.0495, 'Angle 11.25': 31.023, 'Angle 22.5': 74.0263, 'Angle 30': 88.1228, 'cmp': -0.0369}\n",
      "[Iter 9100 Task dept] Val Loss: 0.6041\n",
      "{'abs_err': 0.5985, 'rel_err': 0.2247, 'sigma_1.25': 61.1592, 'sigma_1.25^2': 87.7854, 'sigma_1.25^3': 96.7052, 'cmp': 0.0452}\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.9558\n",
      "[Iter 9200 Task norm] Train Loss: 0.0566\n",
      "[Iter 9200 Task dept] Train Loss: 0.4737\n",
      "[Iter 9200 Total] Train Loss: 0.4954\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 1.5984\n",
      "{'mIoU': 0.2207, 'Pixel Acc': 0.5462, 'cmp': -0.1351}\n",
      "[Iter 9200 Task norm] Val Loss: 0.0613\n",
      "{'Angle Mean': 17.2771, 'Angle Median': 16.0716, 'Angle 11.25': 31.4949, 'Angle 22.5': 73.1185, 'Angle 30': 87.6696, 'cmp': -0.0392}\n",
      "[Iter 9200 Task dept] Val Loss: 0.6211\n",
      "{'abs_err': 0.6138, 'rel_err': 0.2248, 'sigma_1.25': 60.0154, 'sigma_1.25^2': 87.3336, 'sigma_1.25^3': 96.633, 'cmp': 0.035}\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Train Loss: 0.9763\n",
      "[Iter 9300 Task norm] Train Loss: 0.0564\n",
      "[Iter 9300 Task dept] Train Loss: 0.4756\n",
      "[Iter 9300 Total] Train Loss: 0.5027\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Val Loss: 1.6184\n",
      "{'mIoU': 0.2185, 'Pixel Acc': 0.5424, 'cmp': -0.1423}\n",
      "[Iter 9300 Task norm] Val Loss: 0.0601\n",
      "{'Angle Mean': 17.1604, 'Angle Median': 16.0378, 'Angle 11.25': 31.159, 'Angle 22.5': 73.8267, 'Angle 30': 88.1296, 'cmp': -0.0363}\n",
      "[Iter 9300 Task dept] Val Loss: 0.6172\n",
      "{'abs_err': 0.611, 'rel_err': 0.2252, 'sigma_1.25': 60.3778, 'sigma_1.25^2': 87.2505, 'sigma_1.25^3': 96.5611, 'cmp': 0.0365}\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.9889\n",
      "[Iter 9400 Task norm] Train Loss: 0.0553\n",
      "[Iter 9400 Task dept] Train Loss: 0.4735\n",
      "[Iter 9400 Total] Train Loss: 0.5059\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.6047\n",
      "{'mIoU': 0.222, 'Pixel Acc': 0.5436, 'cmp': -0.135}\n",
      "[Iter 9400 Task norm] Val Loss: 0.0605\n",
      "{'Angle Mean': 17.1426, 'Angle Median': 15.8254, 'Angle 11.25': 32.0481, 'Angle 22.5': 73.8171, 'Angle 30': 87.7382, 'cmp': -0.029}\n",
      "[Iter 9400 Task dept] Val Loss: 0.6121\n",
      "{'abs_err': 0.6064, 'rel_err': 0.2256, 'sigma_1.25': 60.5655, 'sigma_1.25^2': 87.4771, 'sigma_1.25^3': 96.6184, 'cmp': 0.039}\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Train Loss: 0.9610\n",
      "[Iter 9500 Task norm] Train Loss: 0.0561\n",
      "[Iter 9500 Task dept] Train Loss: 0.4741\n",
      "[Iter 9500 Total] Train Loss: 0.4971\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Val Loss: 1.6170\n",
      "{'mIoU': 0.2188, 'Pixel Acc': 0.5422, 'cmp': -0.1418}\n",
      "[Iter 9500 Task norm] Val Loss: 0.0608\n",
      "{'Angle Mean': 17.1939, 'Angle Median': 15.857, 'Angle 11.25': 31.6637, 'Angle 22.5': 73.8831, 'Angle 30': 87.6952, 'cmp': -0.0321}\n",
      "[Iter 9500 Task dept] Val Loss: 0.6161\n",
      "{'abs_err': 0.609, 'rel_err': 0.2233, 'sigma_1.25': 60.3652, 'sigma_1.25^2': 87.476, 'sigma_1.25^3': 96.7053, 'cmp': 0.0394}\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Train Loss: 0.9578\n",
      "[Iter 9600 Task norm] Train Loss: 0.0561\n",
      "[Iter 9600 Task dept] Train Loss: 0.4862\n",
      "[Iter 9600 Total] Train Loss: 0.5000\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 1.6071\n",
      "{'mIoU': 0.2216, 'Pixel Acc': 0.545, 'cmp': -0.1345}\n",
      "[Iter 9600 Task norm] Val Loss: 0.0612\n",
      "{'Angle Mean': 17.2721, 'Angle Median': 16.0459, 'Angle 11.25': 31.3941, 'Angle 22.5': 73.2079, 'Angle 30': 87.618, 'cmp': -0.0393}\n",
      "[Iter 9600 Task dept] Val Loss: 0.6186\n",
      "{'abs_err': 0.6118, 'rel_err': 0.223, 'sigma_1.25': 60.0194, 'sigma_1.25^2': 87.3884, 'sigma_1.25^3': 96.7294, 'cmp': 0.0375}\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Train Loss: 0.9755\n",
      "[Iter 9700 Task norm] Train Loss: 0.0554\n",
      "[Iter 9700 Task dept] Train Loss: 0.4738\n",
      "[Iter 9700 Total] Train Loss: 0.5015\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Val Loss: 1.6017\n",
      "{'mIoU': 0.2219, 'Pixel Acc': 0.544, 'cmp': -0.1347}\n",
      "[Iter 9700 Task norm] Val Loss: 0.0606\n",
      "{'Angle Mean': 17.1906, 'Angle Median': 15.7891, 'Angle 11.25': 31.3841, 'Angle 22.5': 74.3164, 'Angle 30': 87.6402, 'cmp': -0.0317}\n",
      "[Iter 9700 Task dept] Val Loss: 0.6116\n",
      "{'abs_err': 0.6057, 'rel_err': 0.2232, 'sigma_1.25': 60.6393, 'sigma_1.25^2': 87.5037, 'sigma_1.25^3': 96.7047, 'cmp': 0.0416}\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.9906\n",
      "[Iter 9800 Task norm] Train Loss: 0.0566\n",
      "[Iter 9800 Task dept] Train Loss: 0.4714\n",
      "[Iter 9800 Total] Train Loss: 0.5062\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 1.6103\n",
      "{'mIoU': 0.2211, 'Pixel Acc': 0.5418, 'cmp': -0.138}\n",
      "[Iter 9800 Task norm] Val Loss: 0.0603\n",
      "{'Angle Mean': 17.1449, 'Angle Median': 15.9144, 'Angle 11.25': 31.7141, 'Angle 22.5': 73.7193, 'Angle 30': 87.9056, 'cmp': -0.0321}\n",
      "[Iter 9800 Task dept] Val Loss: 0.6183\n",
      "{'abs_err': 0.612, 'rel_err': 0.2258, 'sigma_1.25': 60.2113, 'sigma_1.25^2': 87.2153, 'sigma_1.25^3': 96.5556, 'cmp': 0.035}\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Train Loss: 0.9502\n",
      "[Iter 9900 Task norm] Train Loss: 0.0557\n",
      "[Iter 9900 Task dept] Train Loss: 0.4724\n",
      "[Iter 9900 Total] Train Loss: 0.4928\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Val Loss: 1.5935\n",
      "{'mIoU': 0.2217, 'Pixel Acc': 0.5437, 'cmp': -0.1353}\n",
      "[Iter 9900 Task norm] Val Loss: 0.0606\n",
      "{'Angle Mean': 17.1816, 'Angle Median': 15.8235, 'Angle 11.25': 31.4338, 'Angle 22.5': 74.2147, 'Angle 30': 87.5337, 'cmp': -0.0323}\n",
      "[Iter 9900 Task dept] Val Loss: 0.6117\n",
      "{'abs_err': 0.6062, 'rel_err': 0.2246, 'sigma_1.25': 60.6362, 'sigma_1.25^2': 87.4807, 'sigma_1.25^3': 96.6483, 'cmp': 0.0401}\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.9320\n",
      "[Iter 10000 Task norm] Train Loss: 0.0555\n",
      "[Iter 10000 Task dept] Train Loss: 0.4689\n",
      "[Iter 10000 Total] Train Loss: 0.4855\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 1.6034\n",
      "{'mIoU': 0.2228, 'Pixel Acc': 0.5447, 'cmp': -0.1326}\n",
      "[Iter 10000 Task norm] Val Loss: 0.0613\n",
      "{'Angle Mean': 17.2387, 'Angle Median': 15.8098, 'Angle 11.25': 32.2119, 'Angle 22.5': 73.3927, 'Angle 30': 87.3014, 'cmp': -0.0311}\n",
      "[Iter 10000 Task dept] Val Loss: 0.6055\n",
      "{'abs_err': 0.5999, 'rel_err': 0.2248, 'sigma_1.25': 60.9937, 'sigma_1.25^2': 87.7067, 'sigma_1.25^3': 96.7343, 'cmp': 0.044}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hard sharing\n",
    "trainer.stl_hard_sharing(iters=10000, lr=0.001, decay_lr_freq=1300, decay_lr_rate=0.5, savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 100 Task segm] Train Loss: 3.3355\n",
      "[Iter 100 Total] Train Loss: 3.3355\n",
      "======================================================================\n",
      "[Iter 100 Task segm] Val Loss: 3.0377\n",
      "{'mIoU': 0.0859, 'Pixel Acc': 0.2556, 'cmp': -0.6268}\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Train Loss: 3.0537\n",
      "[Iter 200 Total] Train Loss: 3.0537\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 2.9115\n",
      "{'mIoU': 0.1349, 'Pixel Acc': 0.302, 'cmp': -0.4983}\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Train Loss: 2.9652\n",
      "[Iter 300 Total] Train Loss: 2.9652\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Val Loss: 2.8569\n",
      "{'mIoU': 0.1256, 'Pixel Acc': 0.3257, 'cmp': -0.4951}\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Train Loss: 2.9188\n",
      "[Iter 400 Total] Train Loss: 2.9188\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 2.8176\n",
      "{'mIoU': 0.1091, 'Pixel Acc': 0.3304, 'cmp': -0.5212}\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Train Loss: 2.8878\n",
      "[Iter 500 Total] Train Loss: 2.8878\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Val Loss: 2.7900\n",
      "{'mIoU': 0.1162, 'Pixel Acc': 0.332, 'cmp': -0.5069}\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Train Loss: 2.8801\n",
      "[Iter 600 Total] Train Loss: 2.8801\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 2.7687\n",
      "{'mIoU': 0.1251, 'Pixel Acc': 0.3332, 'cmp': -0.4896}\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Train Loss: 2.8471\n",
      "[Iter 700 Total] Train Loss: 2.8471\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Val Loss: 2.7446\n",
      "{'mIoU': 0.1315, 'Pixel Acc': 0.3333, 'cmp': -0.4779}\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-44c5d3193899>\", line 2, in <module>\n",
      "    trainer.stl_hard_sharing(iters=20000, task=tasks[0], lr=0.001, savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/')\n",
      "  File \"<ipython-input-4-ad744181441f>\", line 30, in stl_hard_sharing\n",
      "    self.train_step_task(stage, task, optimizer, scheduler)\n",
      "  File \"/home/lijunzhang/policymtl2/framework/trainer.py\", line 379, in train_step_task\n",
      "    self.loss_list[task].append(loss.item())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# STL\n",
    "trainer.stl_hard_sharing(iters=20000, task=tasks[0], lr=0.001, savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/' + 'alter_train_with_reg_001_19200iter.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_list = {'segment_semantic': [], 'normal':[], 'depth_zbuffer': []}\n",
    "for name, param in mtlmodel.named_parameters():\n",
    "    if 'policy' in name and not torch.eq(param, torch.tensor([0., 0., 0.]).cuda()).all():\n",
    "        policy = param.data.cpu().detach().numpy()\n",
    "        distribution = softmax(policy, axis=-1)\n",
    "        if 'segment_semantic' in name:\n",
    "            policy_list['segment_semantic'].append(distribution)\n",
    "        elif 'depth_zbuffer' in name:\n",
    "            policy_list['depth_zbuffer'].append(distribution)\n",
    "        elif 'normal' in name:\n",
    "            policy_list['normal'].append(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': [array([0.734335  , 0.19044979, 0.07521517], dtype=float32),\n",
       "  array([0.86952895, 0.10286584, 0.02760528], dtype=float32),\n",
       "  array([0.84768635, 0.115229  , 0.03708472], dtype=float32),\n",
       "  array([0.67560846, 0.1743037 , 0.1500878 ], dtype=float32),\n",
       "  array([0.67832726, 0.18074456, 0.14092812], dtype=float32),\n",
       "  array([0.7569295 , 0.15483332, 0.08823713], dtype=float32),\n",
       "  array([0.7194236 , 0.18658282, 0.09399352], dtype=float32),\n",
       "  array([0.79072237, 0.15644178, 0.05283579], dtype=float32),\n",
       "  array([0.7464034 , 0.18454288, 0.06905375], dtype=float32),\n",
       "  array([0.7569612 , 0.19980013, 0.04323869], dtype=float32),\n",
       "  array([0.76374716, 0.17734347, 0.05890945], dtype=float32),\n",
       "  array([0.7519353 , 0.17865568, 0.06940906], dtype=float32),\n",
       "  array([0.7565602 , 0.16842738, 0.07501237], dtype=float32),\n",
       "  array([0.7459976 , 0.18566479, 0.06833763], dtype=float32),\n",
       "  array([0.7025296 , 0.20090285, 0.09656753], dtype=float32),\n",
       "  array([0.6553151 , 0.22585662, 0.11882838], dtype=float32),\n",
       "  array([0.67305076, 0.25660557, 0.07034369], dtype=float32),\n",
       "  array([0.5599009 , 0.40792358, 0.03217553], dtype=float32),\n",
       "  array([0.7448706 , 0.23533894, 0.01979029], dtype=float32),\n",
       "  array([0.55030894, 0.24144217, 0.20824888], dtype=float32),\n",
       "  array([0.5564741 , 0.2464093 , 0.19711669], dtype=float32),\n",
       "  array([0.5217218 , 0.26689395, 0.21138434], dtype=float32),\n",
       "  array([0.51867425, 0.2662279 , 0.2150978 ], dtype=float32),\n",
       "  array([0.4522388 , 0.27911586, 0.26864535], dtype=float32),\n",
       "  array([0.45271006, 0.28150576, 0.26578414], dtype=float32),\n",
       "  array([0.45461214, 0.27571324, 0.26967475], dtype=float32),\n",
       "  array([0.4269625 , 0.2841005 , 0.28893703], dtype=float32),\n",
       "  array([0.41972128, 0.29480723, 0.28547153], dtype=float32),\n",
       "  array([0.41126907, 0.29874766, 0.28998324], dtype=float32),\n",
       "  array([0.3456356 , 0.62408286, 0.03028155], dtype=float32),\n",
       "  array([0.56557363, 0.33291698, 0.1015094 ], dtype=float32),\n",
       "  array([0.42776176, 0.4471775 , 0.12506078], dtype=float32),\n",
       "  array([0.23443264, 0.7455437 , 0.02002364], dtype=float32),\n",
       "  array([0.2759215 , 0.6960868 , 0.02799185], dtype=float32),\n",
       "  array([0.46034035, 0.46353477, 0.07612494], dtype=float32),\n",
       "  array([0.40501007, 0.4977189 , 0.097271  ], dtype=float32)],\n",
       " 'normal': [array([0.6590796 , 0.17202568, 0.16889478], dtype=float32),\n",
       "  array([0.6548795 , 0.17009832, 0.17502213], dtype=float32),\n",
       "  array([0.6346003 , 0.17483996, 0.19055969], dtype=float32),\n",
       "  array([0.623395  , 0.18520078, 0.1914042 ], dtype=float32),\n",
       "  array([0.637958  , 0.17898524, 0.18305665], dtype=float32),\n",
       "  array([0.6153224 , 0.1926927 , 0.19198482], dtype=float32),\n",
       "  array([0.6165455 , 0.19956525, 0.18388927], dtype=float32),\n",
       "  array([0.60059273, 0.18512794, 0.21427941], dtype=float32),\n",
       "  array([0.610594  , 0.19678985, 0.19261616], dtype=float32),\n",
       "  array([0.58075583, 0.2104521 , 0.20879212], dtype=float32),\n",
       "  array([0.5815484 , 0.20681174, 0.21163985], dtype=float32),\n",
       "  array([0.59279704, 0.20184784, 0.20535518], dtype=float32),\n",
       "  array([0.56225806, 0.21967666, 0.21806522], dtype=float32),\n",
       "  array([0.5456679 , 0.22377206, 0.23055999], dtype=float32),\n",
       "  array([0.5314266 , 0.23513481, 0.23343854], dtype=float32),\n",
       "  array([0.5444481 , 0.22406985, 0.231482  ], dtype=float32),\n",
       "  array([0.5122006 , 0.23903547, 0.24876389], dtype=float32),\n",
       "  array([0.5150691 , 0.24091864, 0.2440122 ], dtype=float32),\n",
       "  array([0.5069828 , 0.25097182, 0.24204543], dtype=float32),\n",
       "  array([0.49917534, 0.24634743, 0.2544772 ], dtype=float32),\n",
       "  array([0.49534318, 0.24713324, 0.25752363], dtype=float32),\n",
       "  array([0.48146433, 0.25863934, 0.25989628], dtype=float32),\n",
       "  array([0.4618387, 0.2698273, 0.268334 ], dtype=float32),\n",
       "  array([0.45412907, 0.27349207, 0.2723788 ], dtype=float32),\n",
       "  array([0.44243333, 0.27309576, 0.28447098], dtype=float32),\n",
       "  array([0.4393359 , 0.28503516, 0.2756288 ], dtype=float32),\n",
       "  array([0.41219705, 0.2970702 , 0.29073268], dtype=float32),\n",
       "  array([0.41041246, 0.28617498, 0.3034125 ], dtype=float32),\n",
       "  array([0.39653087, 0.30504313, 0.29842603], dtype=float32),\n",
       "  array([0.38966888, 0.29729745, 0.31303367], dtype=float32),\n",
       "  array([0.38145873, 0.31023774, 0.30830368], dtype=float32),\n",
       "  array([0.37760028, 0.3126206 , 0.3097792 ], dtype=float32),\n",
       "  array([0.35881418, 0.33350775, 0.3076779 ], dtype=float32),\n",
       "  array([0.3562237 , 0.33269766, 0.31107873], dtype=float32),\n",
       "  array([0.3441114 , 0.33175153, 0.32413703], dtype=float32),\n",
       "  array([0.3437869 , 0.3335466 , 0.32266638], dtype=float32)],\n",
       " 'depth_zbuffer': [array([0.7765162 , 0.12449436, 0.09898949], dtype=float32),\n",
       "  array([0.7825476 , 0.14193614, 0.07551627], dtype=float32),\n",
       "  array([0.7564697 , 0.14818996, 0.09534041], dtype=float32),\n",
       "  array([0.63833517, 0.18538971, 0.17627516], dtype=float32),\n",
       "  array([0.65692186, 0.17972538, 0.16335265], dtype=float32),\n",
       "  array([0.68999445, 0.19046046, 0.11954516], dtype=float32),\n",
       "  array([0.68895733, 0.19039528, 0.12064736], dtype=float32),\n",
       "  array([0.73793936, 0.16477574, 0.09728483], dtype=float32),\n",
       "  array([0.7573051 , 0.15063433, 0.09206051], dtype=float32),\n",
       "  array([0.7666556, 0.1587519, 0.0745924], dtype=float32),\n",
       "  array([0.706869  , 0.1758621 , 0.11726884], dtype=float32),\n",
       "  array([0.66260177, 0.20172292, 0.13567536], dtype=float32),\n",
       "  array([0.67927045, 0.20613332, 0.11459626], dtype=float32),\n",
       "  array([0.69301856, 0.20176478, 0.10521667], dtype=float32),\n",
       "  array([0.6223995 , 0.23351823, 0.1440823 ], dtype=float32),\n",
       "  array([0.6264872 , 0.20986712, 0.1636456 ], dtype=float32),\n",
       "  array([0.59870887, 0.24691325, 0.15437791], dtype=float32),\n",
       "  array([0.57263005, 0.36511377, 0.06225609], dtype=float32),\n",
       "  array([0.641035  , 0.28576562, 0.07319942], dtype=float32),\n",
       "  array([0.53966707, 0.26115054, 0.19918245], dtype=float32),\n",
       "  array([0.51135147, 0.25963858, 0.22900996], dtype=float32),\n",
       "  array([0.47681376, 0.2677719 , 0.2554143 ], dtype=float32),\n",
       "  array([0.46969777, 0.26241344, 0.2678888 ], dtype=float32),\n",
       "  array([0.47386178, 0.2866822 , 0.2394561 ], dtype=float32),\n",
       "  array([0.45716748, 0.27063665, 0.2721959 ], dtype=float32),\n",
       "  array([0.45067763, 0.2966206 , 0.25270164], dtype=float32),\n",
       "  array([0.42926392, 0.2747945 , 0.29594153], dtype=float32),\n",
       "  array([0.41502282, 0.27819714, 0.30678   ], dtype=float32),\n",
       "  array([0.41922164, 0.30126742, 0.27951097], dtype=float32),\n",
       "  array([0.43637267, 0.41952378, 0.14410356], dtype=float32),\n",
       "  array([0.45384184, 0.42950782, 0.11665015], dtype=float32),\n",
       "  array([0.43263844, 0.4377451 , 0.12961653], dtype=float32),\n",
       "  array([0.33480948, 0.5786386 , 0.0865519 ], dtype=float32),\n",
       "  array([0.30058274, 0.6239581 , 0.07545922], dtype=float32),\n",
       "  array([0.43029597, 0.41051856, 0.15918542], dtype=float32),\n",
       "  array([0.42357472, 0.41937682, 0.15704846], dtype=float32)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph(comment='Policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make nodes\n",
    "layer_num = len(policy_list['segment_semantic'])\n",
    "for i in range(layer_num):\n",
    "    with dot.subgraph(name='cluster_L'+str(i),node_attr={'rank':'same'}) as c:\n",
    "        c.attr(rankdir='LR')\n",
    "        c.node('L'+str(i)+'B0', 'Shared')\n",
    "        c.node('L'+str(i)+'B1', 'Specific')\n",
    "        c.node('L'+str(i)+'B2', 'Skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make edges\n",
    "colors = {'segment_semantic': 'blue', 'normal':'green', 'depth_zbuffer': 'red'}\n",
    "for task in tasks:\n",
    "    for i in range(layer_num-1):\n",
    "        prev = np.argmax(policy_list[task][i])\n",
    "        nxt = np.argmax(policy_list[task][i+1])\n",
    "        dot.edge('L'+str(i)+'B'+str(prev), 'L'+str(i+1)+'B'+str(nxt), color=colors[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Policy\n",
      "digraph {\n",
      "\tsubgraph cluster_L0 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL0B0 [label=Shared]\n",
      "\t\tL0B1 [label=Specific]\n",
      "\t\tL0B2 [label=Skip]\n",
      "\t\tL0B0 -> L0B1 [style=invis]\n",
      "\t\tL0B1 -> L0B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L1 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL1B0 [label=Shared]\n",
      "\t\tL1B1 [label=Specific]\n",
      "\t\tL1B2 [label=Skip]\n",
      "\t\tL1B0 -> L1B1 [style=invis]\n",
      "\t\tL1B1 -> L1B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L2 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL2B0 [label=Shared]\n",
      "\t\tL2B1 [label=Specific]\n",
      "\t\tL2B2 [label=Skip]\n",
      "\t\tL2B0 -> L2B1 [style=invis]\n",
      "\t\tL2B1 -> L2B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L3 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL3B0 [label=Shared]\n",
      "\t\tL3B1 [label=Specific]\n",
      "\t\tL3B2 [label=Skip]\n",
      "\t\tL3B0 -> L3B1 [style=invis]\n",
      "\t\tL3B1 -> L3B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L4 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL4B0 [label=Shared]\n",
      "\t\tL4B1 [label=Specific]\n",
      "\t\tL4B2 [label=Skip]\n",
      "\t\tL4B0 -> L4B1 [style=invis]\n",
      "\t\tL4B1 -> L4B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L5 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL5B0 [label=Shared]\n",
      "\t\tL5B1 [label=Specific]\n",
      "\t\tL5B2 [label=Skip]\n",
      "\t\tL5B0 -> L5B1 [style=invis]\n",
      "\t\tL5B1 -> L5B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L6 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL6B0 [label=Shared]\n",
      "\t\tL6B1 [label=Specific]\n",
      "\t\tL6B2 [label=Skip]\n",
      "\t\tL6B0 -> L6B1 [style=invis]\n",
      "\t\tL6B1 -> L6B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L7 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL7B0 [label=Shared]\n",
      "\t\tL7B1 [label=Specific]\n",
      "\t\tL7B2 [label=Skip]\n",
      "\t\tL7B0 -> L7B1 [style=invis]\n",
      "\t\tL7B1 -> L7B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L8 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL8B0 [label=Shared]\n",
      "\t\tL8B1 [label=Specific]\n",
      "\t\tL8B2 [label=Skip]\n",
      "\t\tL8B0 -> L8B1 [style=invis]\n",
      "\t\tL8B1 -> L8B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L9 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL9B0 [label=Shared]\n",
      "\t\tL9B1 [label=Specific]\n",
      "\t\tL9B2 [label=Skip]\n",
      "\t\tL9B0 -> L9B1 [style=invis]\n",
      "\t\tL9B1 -> L9B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L10 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL10B0 [label=Shared]\n",
      "\t\tL10B1 [label=Specific]\n",
      "\t\tL10B2 [label=Skip]\n",
      "\t\tL10B0 -> L10B1 [style=invis]\n",
      "\t\tL10B1 -> L10B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L11 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL11B0 [label=Shared]\n",
      "\t\tL11B1 [label=Specific]\n",
      "\t\tL11B2 [label=Skip]\n",
      "\t\tL11B0 -> L11B1 [style=invis]\n",
      "\t\tL11B1 -> L11B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L12 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL12B0 [label=Shared]\n",
      "\t\tL12B1 [label=Specific]\n",
      "\t\tL12B2 [label=Skip]\n",
      "\t\tL12B0 -> L12B1 [style=invis]\n",
      "\t\tL12B1 -> L12B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L13 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL13B0 [label=Shared]\n",
      "\t\tL13B1 [label=Specific]\n",
      "\t\tL13B2 [label=Skip]\n",
      "\t\tL13B0 -> L13B1 [style=invis]\n",
      "\t\tL13B1 -> L13B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L14 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL14B0 [label=Shared]\n",
      "\t\tL14B1 [label=Specific]\n",
      "\t\tL14B2 [label=Skip]\n",
      "\t\tL14B0 -> L14B1 [style=invis]\n",
      "\t\tL14B1 -> L14B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L15 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL15B0 [label=Shared]\n",
      "\t\tL15B1 [label=Specific]\n",
      "\t\tL15B2 [label=Skip]\n",
      "\t\tL15B0 -> L15B1 [style=invis]\n",
      "\t\tL15B1 -> L15B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L16 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL16B0 [label=Shared]\n",
      "\t\tL16B1 [label=Specific]\n",
      "\t\tL16B2 [label=Skip]\n",
      "\t\tL16B0 -> L16B1 [style=invis]\n",
      "\t\tL16B1 -> L16B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L17 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL17B0 [label=Shared]\n",
      "\t\tL17B1 [label=Specific]\n",
      "\t\tL17B2 [label=Skip]\n",
      "\t\tL17B0 -> L17B1 [style=invis]\n",
      "\t\tL17B1 -> L17B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L18 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL18B0 [label=Shared]\n",
      "\t\tL18B1 [label=Specific]\n",
      "\t\tL18B2 [label=Skip]\n",
      "\t\tL18B0 -> L18B1 [style=invis]\n",
      "\t\tL18B1 -> L18B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L19 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL19B0 [label=Shared]\n",
      "\t\tL19B1 [label=Specific]\n",
      "\t\tL19B2 [label=Skip]\n",
      "\t\tL19B0 -> L19B1 [style=invis]\n",
      "\t\tL19B1 -> L19B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L20 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL20B0 [label=Shared]\n",
      "\t\tL20B1 [label=Specific]\n",
      "\t\tL20B2 [label=Skip]\n",
      "\t\tL20B0 -> L20B1 [style=invis]\n",
      "\t\tL20B1 -> L20B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L21 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL21B0 [label=Shared]\n",
      "\t\tL21B1 [label=Specific]\n",
      "\t\tL21B2 [label=Skip]\n",
      "\t\tL21B0 -> L21B1 [style=invis]\n",
      "\t\tL21B1 -> L21B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L22 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL22B0 [label=Shared]\n",
      "\t\tL22B1 [label=Specific]\n",
      "\t\tL22B2 [label=Skip]\n",
      "\t\tL22B0 -> L22B1 [style=invis]\n",
      "\t\tL22B1 -> L22B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L23 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL23B0 [label=Shared]\n",
      "\t\tL23B1 [label=Specific]\n",
      "\t\tL23B2 [label=Skip]\n",
      "\t\tL23B0 -> L23B1 [style=invis]\n",
      "\t\tL23B1 -> L23B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L24 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL24B0 [label=Shared]\n",
      "\t\tL24B1 [label=Specific]\n",
      "\t\tL24B2 [label=Skip]\n",
      "\t\tL24B0 -> L24B1 [style=invis]\n",
      "\t\tL24B1 -> L24B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L25 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL25B0 [label=Shared]\n",
      "\t\tL25B1 [label=Specific]\n",
      "\t\tL25B2 [label=Skip]\n",
      "\t\tL25B0 -> L25B1 [style=invis]\n",
      "\t\tL25B1 -> L25B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L26 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL26B0 [label=Shared]\n",
      "\t\tL26B1 [label=Specific]\n",
      "\t\tL26B2 [label=Skip]\n",
      "\t\tL26B0 -> L26B1 [style=invis]\n",
      "\t\tL26B1 -> L26B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L27 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL27B0 [label=Shared]\n",
      "\t\tL27B1 [label=Specific]\n",
      "\t\tL27B2 [label=Skip]\n",
      "\t\tL27B0 -> L27B1 [style=invis]\n",
      "\t\tL27B1 -> L27B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L28 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL28B0 [label=Shared]\n",
      "\t\tL28B1 [label=Specific]\n",
      "\t\tL28B2 [label=Skip]\n",
      "\t\tL28B0 -> L28B1 [style=invis]\n",
      "\t\tL28B1 -> L28B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L29 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL29B0 [label=Shared]\n",
      "\t\tL29B1 [label=Specific]\n",
      "\t\tL29B2 [label=Skip]\n",
      "\t\tL29B0 -> L29B1 [style=invis]\n",
      "\t\tL29B1 -> L29B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L30 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL30B0 [label=Shared]\n",
      "\t\tL30B1 [label=Specific]\n",
      "\t\tL30B2 [label=Skip]\n",
      "\t\tL30B0 -> L30B1 [style=invis]\n",
      "\t\tL30B1 -> L30B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L31 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL31B0 [label=Shared]\n",
      "\t\tL31B1 [label=Specific]\n",
      "\t\tL31B2 [label=Skip]\n",
      "\t\tL31B0 -> L31B1 [style=invis]\n",
      "\t\tL31B1 -> L31B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L32 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL32B0 [label=Shared]\n",
      "\t\tL32B1 [label=Specific]\n",
      "\t\tL32B2 [label=Skip]\n",
      "\t\tL32B0 -> L32B1 [style=invis]\n",
      "\t\tL32B1 -> L32B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L33 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL33B0 [label=Shared]\n",
      "\t\tL33B1 [label=Specific]\n",
      "\t\tL33B2 [label=Skip]\n",
      "\t\tL33B0 -> L33B1 [style=invis]\n",
      "\t\tL33B1 -> L33B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L34 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL34B0 [label=Shared]\n",
      "\t\tL34B1 [label=Specific]\n",
      "\t\tL34B2 [label=Skip]\n",
      "\t\tL34B0 -> L34B1 [style=invis]\n",
      "\t\tL34B1 -> L34B2 [style=invis]\n",
      "\t}\n",
      "\tsubgraph cluster_L35 {\n",
      "\t\tnode [rank=same rankdir=LR]\n",
      "\t\tL35B0 [label=Shared]\n",
      "\t\tL35B1 [label=Specific]\n",
      "\t\tL35B2 [label=Skip]\n",
      "\t\tL35B0 -> L35B1 [style=invis]\n",
      "\t\tL35B1 -> L35B2 [style=invis]\n",
      "\t}\n",
      "\tL0B1 -> L1B1 [color=blue]\n",
      "\tL1B1 -> L2B0 [color=blue]\n",
      "\tL2B0 -> L3B0 [color=blue]\n",
      "\tL3B0 -> L4B1 [color=blue]\n",
      "\tL4B1 -> L5B1 [color=blue]\n",
      "\tL5B1 -> L6B0 [color=blue]\n",
      "\tL6B0 -> L7B1 [color=blue]\n",
      "\tL7B1 -> L8B1 [color=blue]\n",
      "\tL8B1 -> L9B1 [color=blue]\n",
      "\tL9B1 -> L10B0 [color=blue]\n",
      "\tL10B0 -> L11B0 [color=blue]\n",
      "\tL11B0 -> L12B0 [color=blue]\n",
      "\tL12B0 -> L13B0 [color=blue]\n",
      "\tL13B0 -> L14B0 [color=blue]\n",
      "\tL14B0 -> L15B1 [color=blue]\n",
      "\tL15B1 -> L16B0 [color=blue]\n",
      "\tL16B0 -> L17B1 [color=blue]\n",
      "\tL17B1 -> L18B0 [color=blue]\n",
      "\tL18B0 -> L19B0 [color=blue]\n",
      "\tL19B0 -> L20B1 [color=blue]\n",
      "\tL20B1 -> L21B1 [color=blue]\n",
      "\tL21B1 -> L22B1 [color=blue]\n",
      "\tL22B1 -> L23B1 [color=blue]\n",
      "\tL23B1 -> L24B1 [color=blue]\n",
      "\tL24B1 -> L25B1 [color=blue]\n",
      "\tL25B1 -> L26B0 [color=blue]\n",
      "\tL26B0 -> L27B0 [color=blue]\n",
      "\tL27B0 -> L28B1 [color=blue]\n",
      "\tL28B1 -> L29B0 [color=blue]\n",
      "\tL29B0 -> L30B1 [color=blue]\n",
      "\tL30B1 -> L31B0 [color=blue]\n",
      "\tL31B0 -> L32B0 [color=blue]\n",
      "\tL32B0 -> L33B1 [color=blue]\n",
      "\tL33B1 -> L34B0 [color=blue]\n",
      "\tL34B0 -> L35B1 [color=blue]\n",
      "\tL0B1 -> L1B0 [color=red]\n",
      "\tL1B0 -> L2B0 [color=red]\n",
      "\tL2B0 -> L3B0 [color=red]\n",
      "\tL3B0 -> L4B0 [color=red]\n",
      "\tL4B0 -> L5B1 [color=red]\n",
      "\tL5B1 -> L6B0 [color=red]\n",
      "\tL6B0 -> L7B2 [color=red]\n",
      "\tL7B2 -> L8B0 [color=red]\n",
      "\tL8B0 -> L9B1 [color=red]\n",
      "\tL9B1 -> L10B0 [color=red]\n",
      "\tL10B0 -> L11B0 [color=red]\n",
      "\tL11B0 -> L12B1 [color=red]\n",
      "\tL12B1 -> L13B0 [color=red]\n",
      "\tL13B0 -> L14B1 [color=red]\n",
      "\tL14B1 -> L15B0 [color=red]\n",
      "\tL15B0 -> L16B2 [color=red]\n",
      "\tL16B2 -> L17B0 [color=red]\n",
      "\tL17B0 -> L18B0 [color=red]\n",
      "\tL18B0 -> L19B0 [color=red]\n",
      "\tL19B0 -> L20B1 [color=red]\n",
      "\tL20B1 -> L21B1 [color=red]\n",
      "\tL21B1 -> L22B1 [color=red]\n",
      "\tL22B1 -> L23B1 [color=red]\n",
      "\tL23B1 -> L24B1 [color=red]\n",
      "\tL24B1 -> L25B1 [color=red]\n",
      "\tL25B1 -> L26B0 [color=red]\n",
      "\tL26B0 -> L27B1 [color=red]\n",
      "\tL27B1 -> L28B2 [color=red]\n",
      "\tL28B2 -> L29B2 [color=red]\n",
      "\tL29B2 -> L30B1 [color=red]\n",
      "\tL30B1 -> L31B1 [color=red]\n",
      "\tL31B1 -> L32B0 [color=red]\n",
      "\tL32B0 -> L33B0 [color=red]\n",
      "\tL33B0 -> L34B0 [color=red]\n",
      "\tL34B0 -> L35B0 [color=red]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dot.source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policy/alter_train_with_reg.gv.pdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render('policy/alter_train_with_reg.gv', view=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab6adb3d30>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rgbnorm(rgb):\n",
    "    rgb -= rgb.min()\n",
    "    rgb /= rgb.max()+0.01\n",
    "    return rgb\n",
    "\n",
    "spectrum_list = []\n",
    "for task in tasks:\n",
    "    policies = policy_list[task]    \n",
    "    spectrum = np.stack([rgbnorm(policy) for policy in policies])\n",
    "    spectrum = np.repeat(spectrum[np.newaxis,:,:],1,axis=0)\n",
    "    spectrum_list.append(spectrum)\n",
    "plt.figure(figsize=(16,2))\n",
    "plt.imshow(np.concatenate(spectrum_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab62b3c2b0>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spectrum_list = []\n",
    "for task in tasks:\n",
    "    policies = policy_list[task]   \n",
    "    idx = np.argmax(policies,axis=1)\n",
    "    spectrum = np.zeros([len(idx),3])\n",
    "    spectrum[np.arange(len(idx)),idx] = 1.0\n",
    "    spectrum[np.arange(len(idx)),(idx+1)%3] = 0.2\n",
    "    spectrum = np.repeat(spectrum[np.newaxis,:,:],1,axis=0)\n",
    "    spectrum_list.append(spectrum)\n",
    "\n",
    "plt.figure(figsize=(16,2))\n",
    "plt.imshow(np.concatenate(spectrum_list,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/' + 'alter_train_20000iter.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_list = {'segment_semantic': [], 'normal':[], 'depth_zbuffer': []}\n",
    "name_list = {'segment_semantic': [], 'normal':[], 'depth_zbuffer': []}\n",
    "for name, param in mtlmodel.named_parameters():\n",
    "    if 'policy' in name and not torch.eq(param, torch.tensor([0., 0., 0.]).cuda()).all():\n",
    "        if 'segment_semantic' in name:\n",
    "            policy_list['segment_semantic'].append(param.data.cpu().detach().numpy())\n",
    "            name_list['segment_semantic'].append(name)\n",
    "        elif 'depth_zbuffer' in name:\n",
    "            policy_list['depth_zbuffer'].append(param.data.cpu().detach().numpy())\n",
    "            name_list['depth_zbuffer'].append(name)\n",
    "        elif 'normal' in name:\n",
    "            policy_list['normal'].append(param.data.cpu().detach().numpy())\n",
    "            name_list['normal'].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(98)\n",
    "\n",
    "# shuffle from existed policy randomly\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    temp = policy_list[task].copy()\n",
    "    random.shuffle(temp)\n",
    "    \n",
    "    count = 0\n",
    "    for name in name_list[task]:\n",
    "        random_policy_dict[name] = torch.tensor(temp[count]).cuda()\n",
    "        count += 1\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, 'checkpoints/Cityscapes/' + 'random_policy_as_task_alter_train_13600iter_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(98)\n",
    "\n",
    "# random initilization\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    for name in name_list[task]:\n",
    "        random_policy_dict[name] = torch.rand(3).cuda()\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, 'checkpoints/Cityscapes/' + 'random_policy_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(98)\n",
    "\n",
    "# The first 20 Conv to be shared\n",
    "shared = 20\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    count = 0\n",
    "    for name in name_list[task]:\n",
    "        if count < shared:\n",
    "            random_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        else:\n",
    "            random_policy_dict[name] = torch.rand(3).cuda()\n",
    "        count += 1\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/' + 'random_policy_with_bottom20_shared_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(98)\n",
    "\n",
    "# The first and last Conv to be shared as AdaShare\n",
    "shared = 20\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    count = 0\n",
    "    for name in name_list[task]:\n",
    "        if count in range(0,7):\n",
    "            random_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        elif count in range(14,24):\n",
    "            random_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        elif count in range(30,37):\n",
    "            random_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        else:\n",
    "            random_policy_dict[name] = torch.rand(3).cuda()\n",
    "        count += 1\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/' + 'random_policy_as_AdaShare_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "\n",
    "# sample from trained policy\n",
    "sample_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    for name, policy in zip(name_list[task], policy_list[task]):\n",
    "        distribution = softmax(policy, axis=-1)\n",
    "        choice = np.random.choice((0,1,2), p=distribution)\n",
    "        if choice == 0:\n",
    "            sample_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        elif choice == 1:\n",
    "            sample_policy_dict[name] = torch.tensor([0.0,1.0,0.0]).cuda()\n",
    "        elif choice == 2:\n",
    "            sample_policy_dict[name] = torch.tensor([0.0,0.0,1.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['headsDict.segment_semantic.fc1.conv1.weight', 'headsDict.segment_semantic.fc1.conv1.bias', 'headsDict.segment_semantic.fc1.conv2.weight', 'headsDict.segment_semantic.fc1.conv2.bias', 'headsDict.segment_semantic.fc1.conv3.weight', 'headsDict.segment_semantic.fc1.conv3.bias', 'headsDict.segment_semantic.fc2.conv1.weight', 'headsDict.segment_semantic.fc2.conv1.bias', 'headsDict.segment_semantic.fc2.conv2.weight', 'headsDict.segment_semantic.fc2.conv2.bias', 'headsDict.segment_semantic.fc2.conv3.weight', 'headsDict.segment_semantic.fc2.conv3.bias', 'headsDict.segment_semantic.fc3.conv1.weight', 'headsDict.segment_semantic.fc3.conv1.bias', 'headsDict.segment_semantic.fc3.conv2.weight', 'headsDict.segment_semantic.fc3.conv2.bias', 'headsDict.segment_semantic.fc3.conv3.weight', 'headsDict.segment_semantic.fc3.conv3.bias', 'headsDict.segment_semantic.fc4.conv1.weight', 'headsDict.segment_semantic.fc4.conv1.bias', 'headsDict.segment_semantic.fc4.conv2.weight', 'headsDict.segment_semantic.fc4.conv2.bias', 'headsDict.segment_semantic.fc4.conv3.weight', 'headsDict.segment_semantic.fc4.conv3.bias', 'headsDict.depth_zbuffer.fc1.conv1.weight', 'headsDict.depth_zbuffer.fc1.conv1.bias', 'headsDict.depth_zbuffer.fc1.conv2.weight', 'headsDict.depth_zbuffer.fc1.conv2.bias', 'headsDict.depth_zbuffer.fc1.conv3.weight', 'headsDict.depth_zbuffer.fc1.conv3.bias', 'headsDict.depth_zbuffer.fc2.conv1.weight', 'headsDict.depth_zbuffer.fc2.conv1.bias', 'headsDict.depth_zbuffer.fc2.conv2.weight', 'headsDict.depth_zbuffer.fc2.conv2.bias', 'headsDict.depth_zbuffer.fc2.conv3.weight', 'headsDict.depth_zbuffer.fc2.conv3.bias', 'headsDict.depth_zbuffer.fc3.conv1.weight', 'headsDict.depth_zbuffer.fc3.conv1.bias', 'headsDict.depth_zbuffer.fc3.conv2.weight', 'headsDict.depth_zbuffer.fc3.conv2.bias', 'headsDict.depth_zbuffer.fc3.conv3.weight', 'headsDict.depth_zbuffer.fc3.conv3.bias', 'headsDict.depth_zbuffer.fc4.conv1.weight', 'headsDict.depth_zbuffer.fc4.conv1.bias', 'headsDict.depth_zbuffer.fc4.conv2.weight', 'headsDict.depth_zbuffer.fc4.conv2.bias', 'headsDict.depth_zbuffer.fc4.conv3.weight', 'headsDict.depth_zbuffer.fc4.conv3.bias', 'net.0.taskOp.segment_semantic.weight', 'net.0.taskOp.depth_zbuffer.weight', 'net.0.dsOp.segment_semantic.0.weight', 'net.0.dsOp.segment_semantic.1.weight', 'net.0.dsOp.segment_semantic.1.bias', 'net.0.dsOp.segment_semantic.1.running_mean', 'net.0.dsOp.segment_semantic.1.running_var', 'net.0.dsOp.depth_zbuffer.0.weight', 'net.0.dsOp.depth_zbuffer.1.weight', 'net.0.dsOp.depth_zbuffer.1.bias', 'net.0.dsOp.depth_zbuffer.1.running_mean', 'net.0.dsOp.depth_zbuffer.1.running_var', 'net.0.basicOp.weight', 'net.1.taskOp.segment_semantic.weight', 'net.1.taskOp.segment_semantic.bias', 'net.1.taskOp.segment_semantic.running_mean', 'net.1.taskOp.segment_semantic.running_var', 'net.1.taskOp.depth_zbuffer.weight', 'net.1.taskOp.depth_zbuffer.bias', 'net.1.taskOp.depth_zbuffer.running_mean', 'net.1.taskOp.depth_zbuffer.running_var', 'net.1.policy.segment_semantic', 'net.1.policy.depth_zbuffer', 'net.1.basicOp.weight', 'net.1.basicOp.bias', 'net.1.basicOp.running_mean', 'net.1.basicOp.running_var', 'net.4.taskOp.segment_semantic.weight', 'net.4.taskOp.depth_zbuffer.weight', 'net.4.basicOp.weight', 'net.5.taskOp.segment_semantic.weight', 'net.5.taskOp.segment_semantic.bias', 'net.5.taskOp.segment_semantic.running_mean', 'net.5.taskOp.segment_semantic.running_var', 'net.5.taskOp.depth_zbuffer.weight', 'net.5.taskOp.depth_zbuffer.bias', 'net.5.taskOp.depth_zbuffer.running_mean', 'net.5.taskOp.depth_zbuffer.running_var', 'net.5.policy.segment_semantic', 'net.5.policy.depth_zbuffer', 'net.5.basicOp.weight', 'net.5.basicOp.bias', 'net.5.basicOp.running_mean', 'net.5.basicOp.running_var', 'net.7.taskOp.segment_semantic.weight', 'net.7.taskOp.depth_zbuffer.weight', 'net.7.basicOp.weight', 'net.8.taskOp.segment_semantic.weight', 'net.8.taskOp.segment_semantic.bias', 'net.8.taskOp.segment_semantic.running_mean', 'net.8.taskOp.segment_semantic.running_var', 'net.8.taskOp.depth_zbuffer.weight', 'net.8.taskOp.depth_zbuffer.bias', 'net.8.taskOp.depth_zbuffer.running_mean', 'net.8.taskOp.depth_zbuffer.running_var', 'net.8.policy.segment_semantic', 'net.8.policy.depth_zbuffer', 'net.8.basicOp.weight', 'net.8.basicOp.bias', 'net.8.basicOp.running_mean', 'net.8.basicOp.running_var', 'net.11.taskOp.segment_semantic.weight', 'net.11.taskOp.depth_zbuffer.weight', 'net.11.basicOp.weight', 'net.12.taskOp.segment_semantic.weight', 'net.12.taskOp.segment_semantic.bias', 'net.12.taskOp.segment_semantic.running_mean', 'net.12.taskOp.segment_semantic.running_var', 'net.12.taskOp.depth_zbuffer.weight', 'net.12.taskOp.depth_zbuffer.bias', 'net.12.taskOp.depth_zbuffer.running_mean', 'net.12.taskOp.depth_zbuffer.running_var', 'net.12.policy.segment_semantic', 'net.12.policy.depth_zbuffer', 'net.12.basicOp.weight', 'net.12.basicOp.bias', 'net.12.basicOp.running_mean', 'net.12.basicOp.running_var', 'net.14.taskOp.segment_semantic.weight', 'net.14.taskOp.depth_zbuffer.weight', 'net.14.basicOp.weight', 'net.15.taskOp.segment_semantic.weight', 'net.15.taskOp.segment_semantic.bias', 'net.15.taskOp.segment_semantic.running_mean', 'net.15.taskOp.segment_semantic.running_var', 'net.15.taskOp.depth_zbuffer.weight', 'net.15.taskOp.depth_zbuffer.bias', 'net.15.taskOp.depth_zbuffer.running_mean', 'net.15.taskOp.depth_zbuffer.running_var', 'net.15.policy.segment_semantic', 'net.15.policy.depth_zbuffer', 'net.15.basicOp.weight', 'net.15.basicOp.bias', 'net.15.basicOp.running_mean', 'net.15.basicOp.running_var', 'net.18.taskOp.segment_semantic.weight', 'net.18.taskOp.depth_zbuffer.weight', 'net.18.basicOp.weight', 'net.19.taskOp.segment_semantic.weight', 'net.19.taskOp.segment_semantic.bias', 'net.19.taskOp.segment_semantic.running_mean', 'net.19.taskOp.segment_semantic.running_var', 'net.19.taskOp.depth_zbuffer.weight', 'net.19.taskOp.depth_zbuffer.bias', 'net.19.taskOp.depth_zbuffer.running_mean', 'net.19.taskOp.depth_zbuffer.running_var', 'net.19.policy.segment_semantic', 'net.19.policy.depth_zbuffer', 'net.19.basicOp.weight', 'net.19.basicOp.bias', 'net.19.basicOp.running_mean', 'net.19.basicOp.running_var', 'net.21.taskOp.segment_semantic.weight', 'net.21.taskOp.depth_zbuffer.weight', 'net.21.basicOp.weight', 'net.22.taskOp.segment_semantic.weight', 'net.22.taskOp.segment_semantic.bias', 'net.22.taskOp.segment_semantic.running_mean', 'net.22.taskOp.segment_semantic.running_var', 'net.22.taskOp.depth_zbuffer.weight', 'net.22.taskOp.depth_zbuffer.bias', 'net.22.taskOp.depth_zbuffer.running_mean', 'net.22.taskOp.depth_zbuffer.running_var', 'net.22.policy.segment_semantic', 'net.22.policy.depth_zbuffer', 'net.22.basicOp.weight', 'net.22.basicOp.bias', 'net.22.basicOp.running_mean', 'net.22.basicOp.running_var', 'net.25.taskOp.segment_semantic.weight', 'net.25.taskOp.depth_zbuffer.weight', 'net.25.dsOp.segment_semantic.0.weight', 'net.25.dsOp.segment_semantic.1.weight', 'net.25.dsOp.segment_semantic.1.bias', 'net.25.dsOp.segment_semantic.1.running_mean', 'net.25.dsOp.segment_semantic.1.running_var', 'net.25.dsOp.depth_zbuffer.0.weight', 'net.25.dsOp.depth_zbuffer.1.weight', 'net.25.dsOp.depth_zbuffer.1.bias', 'net.25.dsOp.depth_zbuffer.1.running_mean', 'net.25.dsOp.depth_zbuffer.1.running_var', 'net.25.basicOp.weight', 'net.26.taskOp.segment_semantic.weight', 'net.26.taskOp.segment_semantic.bias', 'net.26.taskOp.segment_semantic.running_mean', 'net.26.taskOp.segment_semantic.running_var', 'net.26.taskOp.depth_zbuffer.weight', 'net.26.taskOp.depth_zbuffer.bias', 'net.26.taskOp.depth_zbuffer.running_mean', 'net.26.taskOp.depth_zbuffer.running_var', 'net.26.policy.segment_semantic', 'net.26.policy.depth_zbuffer', 'net.26.basicOp.weight', 'net.26.basicOp.bias', 'net.26.basicOp.running_mean', 'net.26.basicOp.running_var', 'net.27.taskOp.segment_semantic.weight', 'net.27.taskOp.depth_zbuffer.weight', 'net.27.dsOp.segment_semantic.0.weight', 'net.27.dsOp.segment_semantic.1.weight', 'net.27.dsOp.segment_semantic.1.bias', 'net.27.dsOp.segment_semantic.1.running_mean', 'net.27.dsOp.segment_semantic.1.running_var', 'net.27.dsOp.depth_zbuffer.0.weight', 'net.27.dsOp.depth_zbuffer.1.weight', 'net.27.dsOp.depth_zbuffer.1.bias', 'net.27.dsOp.depth_zbuffer.1.running_mean', 'net.27.dsOp.depth_zbuffer.1.running_var', 'net.27.basicOp.weight', 'net.28.taskOp.segment_semantic.weight', 'net.28.taskOp.segment_semantic.bias', 'net.28.taskOp.segment_semantic.running_mean', 'net.28.taskOp.segment_semantic.running_var', 'net.28.taskOp.depth_zbuffer.weight', 'net.28.taskOp.depth_zbuffer.bias', 'net.28.taskOp.depth_zbuffer.running_mean', 'net.28.taskOp.depth_zbuffer.running_var', 'net.28.policy.segment_semantic', 'net.28.policy.depth_zbuffer', 'net.28.basicOp.weight', 'net.28.basicOp.bias', 'net.28.basicOp.running_mean', 'net.28.basicOp.running_var', 'net.30.taskOp.segment_semantic.weight', 'net.30.taskOp.depth_zbuffer.weight', 'net.30.basicOp.weight', 'net.31.taskOp.segment_semantic.weight', 'net.31.taskOp.segment_semantic.bias', 'net.31.taskOp.segment_semantic.running_mean', 'net.31.taskOp.segment_semantic.running_var', 'net.31.taskOp.depth_zbuffer.weight', 'net.31.taskOp.depth_zbuffer.bias', 'net.31.taskOp.depth_zbuffer.running_mean', 'net.31.taskOp.depth_zbuffer.running_var', 'net.31.policy.segment_semantic', 'net.31.policy.depth_zbuffer', 'net.31.basicOp.weight', 'net.31.basicOp.bias', 'net.31.basicOp.running_mean', 'net.31.basicOp.running_var', 'net.34.taskOp.segment_semantic.weight', 'net.34.taskOp.depth_zbuffer.weight', 'net.34.basicOp.weight', 'net.35.taskOp.segment_semantic.weight', 'net.35.taskOp.segment_semantic.bias', 'net.35.taskOp.segment_semantic.running_mean', 'net.35.taskOp.segment_semantic.running_var', 'net.35.taskOp.depth_zbuffer.weight', 'net.35.taskOp.depth_zbuffer.bias', 'net.35.taskOp.depth_zbuffer.running_mean', 'net.35.taskOp.depth_zbuffer.running_var', 'net.35.policy.segment_semantic', 'net.35.policy.depth_zbuffer', 'net.35.basicOp.weight', 'net.35.basicOp.bias', 'net.35.basicOp.running_mean', 'net.35.basicOp.running_var', 'net.37.taskOp.segment_semantic.weight', 'net.37.taskOp.depth_zbuffer.weight', 'net.37.basicOp.weight', 'net.38.taskOp.segment_semantic.weight', 'net.38.taskOp.segment_semantic.bias', 'net.38.taskOp.segment_semantic.running_mean', 'net.38.taskOp.segment_semantic.running_var', 'net.38.taskOp.depth_zbuffer.weight', 'net.38.taskOp.depth_zbuffer.bias', 'net.38.taskOp.depth_zbuffer.running_mean', 'net.38.taskOp.depth_zbuffer.running_var', 'net.38.policy.segment_semantic', 'net.38.policy.depth_zbuffer', 'net.38.basicOp.weight', 'net.38.basicOp.bias', 'net.38.basicOp.running_mean', 'net.38.basicOp.running_var', 'net.41.taskOp.segment_semantic.weight', 'net.41.taskOp.depth_zbuffer.weight', 'net.41.basicOp.weight', 'net.42.taskOp.segment_semantic.weight', 'net.42.taskOp.segment_semantic.bias', 'net.42.taskOp.segment_semantic.running_mean', 'net.42.taskOp.segment_semantic.running_var', 'net.42.taskOp.depth_zbuffer.weight', 'net.42.taskOp.depth_zbuffer.bias', 'net.42.taskOp.depth_zbuffer.running_mean', 'net.42.taskOp.depth_zbuffer.running_var', 'net.42.policy.segment_semantic', 'net.42.policy.depth_zbuffer', 'net.42.basicOp.weight', 'net.42.basicOp.bias', 'net.42.basicOp.running_mean', 'net.42.basicOp.running_var', 'net.44.taskOp.segment_semantic.weight', 'net.44.taskOp.depth_zbuffer.weight', 'net.44.basicOp.weight', 'net.45.taskOp.segment_semantic.weight', 'net.45.taskOp.segment_semantic.bias', 'net.45.taskOp.segment_semantic.running_mean', 'net.45.taskOp.segment_semantic.running_var', 'net.45.taskOp.depth_zbuffer.weight', 'net.45.taskOp.depth_zbuffer.bias', 'net.45.taskOp.depth_zbuffer.running_mean', 'net.45.taskOp.depth_zbuffer.running_var', 'net.45.policy.segment_semantic', 'net.45.policy.depth_zbuffer', 'net.45.basicOp.weight', 'net.45.basicOp.bias', 'net.45.basicOp.running_mean', 'net.45.basicOp.running_var', 'net.48.taskOp.segment_semantic.weight', 'net.48.taskOp.depth_zbuffer.weight', 'net.48.basicOp.weight', 'net.49.taskOp.segment_semantic.weight', 'net.49.taskOp.segment_semantic.bias', 'net.49.taskOp.segment_semantic.running_mean', 'net.49.taskOp.segment_semantic.running_var', 'net.49.taskOp.depth_zbuffer.weight', 'net.49.taskOp.depth_zbuffer.bias', 'net.49.taskOp.depth_zbuffer.running_mean', 'net.49.taskOp.depth_zbuffer.running_var', 'net.49.policy.segment_semantic', 'net.49.policy.depth_zbuffer', 'net.49.basicOp.weight', 'net.49.basicOp.bias', 'net.49.basicOp.running_mean', 'net.49.basicOp.running_var', 'net.51.taskOp.segment_semantic.weight', 'net.51.taskOp.depth_zbuffer.weight', 'net.51.basicOp.weight', 'net.52.taskOp.segment_semantic.weight', 'net.52.taskOp.segment_semantic.bias', 'net.52.taskOp.segment_semantic.running_mean', 'net.52.taskOp.segment_semantic.running_var', 'net.52.taskOp.depth_zbuffer.weight', 'net.52.taskOp.depth_zbuffer.bias', 'net.52.taskOp.depth_zbuffer.running_mean', 'net.52.taskOp.depth_zbuffer.running_var', 'net.52.policy.segment_semantic', 'net.52.policy.depth_zbuffer', 'net.52.basicOp.weight', 'net.52.basicOp.bias', 'net.52.basicOp.running_mean', 'net.52.basicOp.running_var', 'net.55.taskOp.segment_semantic.weight', 'net.55.taskOp.depth_zbuffer.weight', 'net.55.dsOp.segment_semantic.0.weight', 'net.55.dsOp.segment_semantic.1.weight', 'net.55.dsOp.segment_semantic.1.bias', 'net.55.dsOp.segment_semantic.1.running_mean', 'net.55.dsOp.segment_semantic.1.running_var', 'net.55.dsOp.depth_zbuffer.0.weight', 'net.55.dsOp.depth_zbuffer.1.weight', 'net.55.dsOp.depth_zbuffer.1.bias', 'net.55.dsOp.depth_zbuffer.1.running_mean', 'net.55.dsOp.depth_zbuffer.1.running_var', 'net.55.basicOp.weight', 'net.56.taskOp.segment_semantic.weight', 'net.56.taskOp.segment_semantic.bias', 'net.56.taskOp.segment_semantic.running_mean', 'net.56.taskOp.segment_semantic.running_var', 'net.56.taskOp.depth_zbuffer.weight', 'net.56.taskOp.depth_zbuffer.bias', 'net.56.taskOp.depth_zbuffer.running_mean', 'net.56.taskOp.depth_zbuffer.running_var', 'net.56.policy.segment_semantic', 'net.56.policy.depth_zbuffer', 'net.56.basicOp.weight', 'net.56.basicOp.bias', 'net.56.basicOp.running_mean', 'net.56.basicOp.running_var', 'net.57.taskOp.segment_semantic.weight', 'net.57.taskOp.depth_zbuffer.weight', 'net.57.dsOp.segment_semantic.0.weight', 'net.57.dsOp.segment_semantic.1.weight', 'net.57.dsOp.segment_semantic.1.bias', 'net.57.dsOp.segment_semantic.1.running_mean', 'net.57.dsOp.segment_semantic.1.running_var', 'net.57.dsOp.depth_zbuffer.0.weight', 'net.57.dsOp.depth_zbuffer.1.weight', 'net.57.dsOp.depth_zbuffer.1.bias', 'net.57.dsOp.depth_zbuffer.1.running_mean', 'net.57.dsOp.depth_zbuffer.1.running_var', 'net.57.basicOp.weight', 'net.58.taskOp.segment_semantic.weight', 'net.58.taskOp.segment_semantic.bias', 'net.58.taskOp.segment_semantic.running_mean', 'net.58.taskOp.segment_semantic.running_var', 'net.58.taskOp.depth_zbuffer.weight', 'net.58.taskOp.depth_zbuffer.bias', 'net.58.taskOp.depth_zbuffer.running_mean', 'net.58.taskOp.depth_zbuffer.running_var', 'net.58.policy.segment_semantic', 'net.58.policy.depth_zbuffer', 'net.58.basicOp.weight', 'net.58.basicOp.bias', 'net.58.basicOp.running_mean', 'net.58.basicOp.running_var', 'net.60.taskOp.segment_semantic.weight', 'net.60.taskOp.depth_zbuffer.weight', 'net.60.basicOp.weight', 'net.61.taskOp.segment_semantic.weight', 'net.61.taskOp.segment_semantic.bias', 'net.61.taskOp.segment_semantic.running_mean', 'net.61.taskOp.segment_semantic.running_var', 'net.61.taskOp.depth_zbuffer.weight', 'net.61.taskOp.depth_zbuffer.bias', 'net.61.taskOp.depth_zbuffer.running_mean', 'net.61.taskOp.depth_zbuffer.running_var', 'net.61.policy.segment_semantic', 'net.61.policy.depth_zbuffer', 'net.61.basicOp.weight', 'net.61.basicOp.bias', 'net.61.basicOp.running_mean', 'net.61.basicOp.running_var', 'net.64.taskOp.segment_semantic.weight', 'net.64.taskOp.depth_zbuffer.weight', 'net.64.basicOp.weight', 'net.65.taskOp.segment_semantic.weight', 'net.65.taskOp.segment_semantic.bias', 'net.65.taskOp.segment_semantic.running_mean', 'net.65.taskOp.segment_semantic.running_var', 'net.65.taskOp.depth_zbuffer.weight', 'net.65.taskOp.depth_zbuffer.bias', 'net.65.taskOp.depth_zbuffer.running_mean', 'net.65.taskOp.depth_zbuffer.running_var', 'net.65.policy.segment_semantic', 'net.65.policy.depth_zbuffer', 'net.65.basicOp.weight', 'net.65.basicOp.bias', 'net.65.basicOp.running_mean', 'net.65.basicOp.running_var', 'net.67.taskOp.segment_semantic.weight', 'net.67.taskOp.depth_zbuffer.weight', 'net.67.basicOp.weight', 'net.68.taskOp.segment_semantic.weight', 'net.68.taskOp.segment_semantic.bias', 'net.68.taskOp.segment_semantic.running_mean', 'net.68.taskOp.segment_semantic.running_var', 'net.68.taskOp.depth_zbuffer.weight', 'net.68.taskOp.depth_zbuffer.bias', 'net.68.taskOp.depth_zbuffer.running_mean', 'net.68.taskOp.depth_zbuffer.running_var', 'net.68.policy.segment_semantic', 'net.68.policy.depth_zbuffer', 'net.68.basicOp.weight', 'net.68.basicOp.bias', 'net.68.basicOp.running_mean', 'net.68.basicOp.running_var', 'net.71.taskOp.segment_semantic.weight', 'net.71.taskOp.depth_zbuffer.weight', 'net.71.basicOp.weight', 'net.72.taskOp.segment_semantic.weight', 'net.72.taskOp.segment_semantic.bias', 'net.72.taskOp.segment_semantic.running_mean', 'net.72.taskOp.segment_semantic.running_var', 'net.72.taskOp.depth_zbuffer.weight', 'net.72.taskOp.depth_zbuffer.bias', 'net.72.taskOp.depth_zbuffer.running_mean', 'net.72.taskOp.depth_zbuffer.running_var', 'net.72.policy.segment_semantic', 'net.72.policy.depth_zbuffer', 'net.72.basicOp.weight', 'net.72.basicOp.bias', 'net.72.basicOp.running_mean', 'net.72.basicOp.running_var', 'net.74.taskOp.segment_semantic.weight', 'net.74.taskOp.depth_zbuffer.weight', 'net.74.basicOp.weight', 'net.75.taskOp.segment_semantic.weight', 'net.75.taskOp.segment_semantic.bias', 'net.75.taskOp.segment_semantic.running_mean', 'net.75.taskOp.segment_semantic.running_var', 'net.75.taskOp.depth_zbuffer.weight', 'net.75.taskOp.depth_zbuffer.bias', 'net.75.taskOp.depth_zbuffer.running_mean', 'net.75.taskOp.depth_zbuffer.running_var', 'net.75.policy.segment_semantic', 'net.75.policy.depth_zbuffer', 'net.75.basicOp.weight', 'net.75.basicOp.bias', 'net.75.basicOp.running_mean', 'net.75.basicOp.running_var', 'net.78.taskOp.segment_semantic.weight', 'net.78.taskOp.depth_zbuffer.weight', 'net.78.basicOp.weight', 'net.79.taskOp.segment_semantic.weight', 'net.79.taskOp.segment_semantic.bias', 'net.79.taskOp.segment_semantic.running_mean', 'net.79.taskOp.segment_semantic.running_var', 'net.79.taskOp.depth_zbuffer.weight', 'net.79.taskOp.depth_zbuffer.bias', 'net.79.taskOp.depth_zbuffer.running_mean', 'net.79.taskOp.depth_zbuffer.running_var', 'net.79.policy.segment_semantic', 'net.79.policy.depth_zbuffer', 'net.79.basicOp.weight', 'net.79.basicOp.bias', 'net.79.basicOp.running_mean', 'net.79.basicOp.running_var', 'net.81.taskOp.segment_semantic.weight', 'net.81.taskOp.depth_zbuffer.weight', 'net.81.basicOp.weight', 'net.82.taskOp.segment_semantic.weight', 'net.82.taskOp.segment_semantic.bias', 'net.82.taskOp.segment_semantic.running_mean', 'net.82.taskOp.segment_semantic.running_var', 'net.82.taskOp.depth_zbuffer.weight', 'net.82.taskOp.depth_zbuffer.bias', 'net.82.taskOp.depth_zbuffer.running_mean', 'net.82.taskOp.depth_zbuffer.running_var', 'net.82.policy.segment_semantic', 'net.82.policy.depth_zbuffer', 'net.82.basicOp.weight', 'net.82.basicOp.bias', 'net.82.basicOp.running_mean', 'net.82.basicOp.running_var', 'net.85.taskOp.segment_semantic.weight', 'net.85.taskOp.depth_zbuffer.weight', 'net.85.basicOp.weight', 'net.86.taskOp.segment_semantic.weight', 'net.86.taskOp.segment_semantic.bias', 'net.86.taskOp.segment_semantic.running_mean', 'net.86.taskOp.segment_semantic.running_var', 'net.86.taskOp.depth_zbuffer.weight', 'net.86.taskOp.depth_zbuffer.bias', 'net.86.taskOp.depth_zbuffer.running_mean', 'net.86.taskOp.depth_zbuffer.running_var', 'net.86.policy.segment_semantic', 'net.86.policy.depth_zbuffer', 'net.86.basicOp.weight', 'net.86.basicOp.bias', 'net.86.basicOp.running_mean', 'net.86.basicOp.running_var', 'net.88.taskOp.segment_semantic.weight', 'net.88.taskOp.depth_zbuffer.weight', 'net.88.basicOp.weight', 'net.89.taskOp.segment_semantic.weight', 'net.89.taskOp.segment_semantic.bias', 'net.89.taskOp.segment_semantic.running_mean', 'net.89.taskOp.segment_semantic.running_var', 'net.89.taskOp.depth_zbuffer.weight', 'net.89.taskOp.depth_zbuffer.bias', 'net.89.taskOp.depth_zbuffer.running_mean', 'net.89.taskOp.depth_zbuffer.running_var', 'net.89.policy.segment_semantic', 'net.89.policy.depth_zbuffer', 'net.89.basicOp.weight', 'net.89.basicOp.bias', 'net.89.basicOp.running_mean', 'net.89.basicOp.running_var', 'net.92.taskOp.segment_semantic.weight', 'net.92.taskOp.depth_zbuffer.weight', 'net.92.basicOp.weight', 'net.93.taskOp.segment_semantic.weight', 'net.93.taskOp.segment_semantic.bias', 'net.93.taskOp.segment_semantic.running_mean', 'net.93.taskOp.segment_semantic.running_var', 'net.93.taskOp.depth_zbuffer.weight', 'net.93.taskOp.depth_zbuffer.bias', 'net.93.taskOp.depth_zbuffer.running_mean', 'net.93.taskOp.depth_zbuffer.running_var', 'net.93.policy.segment_semantic', 'net.93.policy.depth_zbuffer', 'net.93.basicOp.weight', 'net.93.basicOp.bias', 'net.93.basicOp.running_mean', 'net.93.basicOp.running_var', 'net.95.taskOp.segment_semantic.weight', 'net.95.taskOp.depth_zbuffer.weight', 'net.95.basicOp.weight', 'net.96.taskOp.segment_semantic.weight', 'net.96.taskOp.segment_semantic.bias', 'net.96.taskOp.segment_semantic.running_mean', 'net.96.taskOp.segment_semantic.running_var', 'net.96.taskOp.depth_zbuffer.weight', 'net.96.taskOp.depth_zbuffer.bias', 'net.96.taskOp.depth_zbuffer.running_mean', 'net.96.taskOp.depth_zbuffer.running_var', 'net.96.policy.segment_semantic', 'net.96.policy.depth_zbuffer', 'net.96.basicOp.weight', 'net.96.basicOp.bias', 'net.96.basicOp.running_mean', 'net.96.basicOp.running_var', 'net.99.taskOp.segment_semantic.weight', 'net.99.taskOp.depth_zbuffer.weight', 'net.99.dsOp.segment_semantic.0.weight', 'net.99.dsOp.segment_semantic.1.weight', 'net.99.dsOp.segment_semantic.1.bias', 'net.99.dsOp.segment_semantic.1.running_mean', 'net.99.dsOp.segment_semantic.1.running_var', 'net.99.dsOp.depth_zbuffer.0.weight', 'net.99.dsOp.depth_zbuffer.1.weight', 'net.99.dsOp.depth_zbuffer.1.bias', 'net.99.dsOp.depth_zbuffer.1.running_mean', 'net.99.dsOp.depth_zbuffer.1.running_var', 'net.99.basicOp.weight', 'net.100.taskOp.segment_semantic.weight', 'net.100.taskOp.segment_semantic.bias', 'net.100.taskOp.segment_semantic.running_mean', 'net.100.taskOp.segment_semantic.running_var', 'net.100.taskOp.depth_zbuffer.weight', 'net.100.taskOp.depth_zbuffer.bias', 'net.100.taskOp.depth_zbuffer.running_mean', 'net.100.taskOp.depth_zbuffer.running_var', 'net.100.policy.segment_semantic', 'net.100.policy.depth_zbuffer', 'net.100.basicOp.weight', 'net.100.basicOp.bias', 'net.100.basicOp.running_mean', 'net.100.basicOp.running_var', 'net.101.taskOp.segment_semantic.weight', 'net.101.taskOp.depth_zbuffer.weight', 'net.101.dsOp.segment_semantic.0.weight', 'net.101.dsOp.segment_semantic.1.weight', 'net.101.dsOp.segment_semantic.1.bias', 'net.101.dsOp.segment_semantic.1.running_mean', 'net.101.dsOp.segment_semantic.1.running_var', 'net.101.dsOp.depth_zbuffer.0.weight', 'net.101.dsOp.depth_zbuffer.1.weight', 'net.101.dsOp.depth_zbuffer.1.bias', 'net.101.dsOp.depth_zbuffer.1.running_mean', 'net.101.dsOp.depth_zbuffer.1.running_var', 'net.101.basicOp.weight', 'net.102.taskOp.segment_semantic.weight', 'net.102.taskOp.segment_semantic.bias', 'net.102.taskOp.segment_semantic.running_mean', 'net.102.taskOp.segment_semantic.running_var', 'net.102.taskOp.depth_zbuffer.weight', 'net.102.taskOp.depth_zbuffer.bias', 'net.102.taskOp.depth_zbuffer.running_mean', 'net.102.taskOp.depth_zbuffer.running_var', 'net.102.policy.segment_semantic', 'net.102.policy.depth_zbuffer', 'net.102.basicOp.weight', 'net.102.basicOp.bias', 'net.102.basicOp.running_mean', 'net.102.basicOp.running_var', 'net.104.taskOp.segment_semantic.weight', 'net.104.taskOp.depth_zbuffer.weight', 'net.104.basicOp.weight', 'net.105.taskOp.segment_semantic.weight', 'net.105.taskOp.segment_semantic.bias', 'net.105.taskOp.segment_semantic.running_mean', 'net.105.taskOp.segment_semantic.running_var', 'net.105.taskOp.depth_zbuffer.weight', 'net.105.taskOp.depth_zbuffer.bias', 'net.105.taskOp.depth_zbuffer.running_mean', 'net.105.taskOp.depth_zbuffer.running_var', 'net.105.policy.segment_semantic', 'net.105.policy.depth_zbuffer', 'net.105.basicOp.weight', 'net.105.basicOp.bias', 'net.105.basicOp.running_mean', 'net.105.basicOp.running_var', 'net.108.taskOp.segment_semantic.weight', 'net.108.taskOp.depth_zbuffer.weight', 'net.108.basicOp.weight', 'net.109.taskOp.segment_semantic.weight', 'net.109.taskOp.segment_semantic.bias', 'net.109.taskOp.segment_semantic.running_mean', 'net.109.taskOp.segment_semantic.running_var', 'net.109.taskOp.depth_zbuffer.weight', 'net.109.taskOp.depth_zbuffer.bias', 'net.109.taskOp.depth_zbuffer.running_mean', 'net.109.taskOp.depth_zbuffer.running_var', 'net.109.policy.segment_semantic', 'net.109.policy.depth_zbuffer', 'net.109.basicOp.weight', 'net.109.basicOp.bias', 'net.109.basicOp.running_mean', 'net.109.basicOp.running_var', 'net.111.taskOp.segment_semantic.weight', 'net.111.taskOp.depth_zbuffer.weight', 'net.111.basicOp.weight', 'net.112.taskOp.segment_semantic.weight', 'net.112.taskOp.segment_semantic.bias', 'net.112.taskOp.segment_semantic.running_mean', 'net.112.taskOp.segment_semantic.running_var', 'net.112.taskOp.depth_zbuffer.weight', 'net.112.taskOp.depth_zbuffer.bias', 'net.112.taskOp.depth_zbuffer.running_mean', 'net.112.taskOp.depth_zbuffer.running_var', 'net.112.policy.segment_semantic', 'net.112.policy.depth_zbuffer', 'net.112.basicOp.weight', 'net.112.basicOp.bias', 'net.112.basicOp.running_mean', 'net.112.basicOp.running_var', 'net.115.taskOp.segment_semantic.weight', 'net.115.taskOp.depth_zbuffer.weight', 'net.115.basicOp.weight', 'net.116.taskOp.segment_semantic.weight', 'net.116.taskOp.segment_semantic.bias', 'net.116.taskOp.segment_semantic.running_mean', 'net.116.taskOp.segment_semantic.running_var', 'net.116.taskOp.depth_zbuffer.weight', 'net.116.taskOp.depth_zbuffer.bias', 'net.116.taskOp.depth_zbuffer.running_mean', 'net.116.taskOp.depth_zbuffer.running_var', 'net.116.policy.segment_semantic', 'net.116.policy.depth_zbuffer', 'net.116.basicOp.weight', 'net.116.basicOp.bias', 'net.116.basicOp.running_mean', 'net.116.basicOp.running_var', 'net.118.taskOp.segment_semantic.weight', 'net.118.taskOp.depth_zbuffer.weight', 'net.118.basicOp.weight', 'net.119.taskOp.segment_semantic.weight', 'net.119.taskOp.segment_semantic.bias', 'net.119.taskOp.segment_semantic.running_mean', 'net.119.taskOp.segment_semantic.running_var', 'net.119.taskOp.depth_zbuffer.weight', 'net.119.taskOp.depth_zbuffer.bias', 'net.119.taskOp.depth_zbuffer.running_mean', 'net.119.taskOp.depth_zbuffer.running_var', 'net.119.policy.segment_semantic', 'net.119.policy.depth_zbuffer', 'net.119.basicOp.weight', 'net.119.basicOp.bias', 'net.119.basicOp.running_mean', 'net.119.basicOp.running_var'], unexpected_keys=[])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "random_state = torch.load('checkpoints/Cityscapes/' + 'random_policy_seed98.model')\n",
    "mtlmodel.load_state_dict(random_state['state_dict'],  strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_dict': OrderedDict([('net.0.policy.segment_semantic',\n",
       "               tensor([0.8013, 0.9743, 0.0132], device='cuda:0')),\n",
       "              ('net.4.policy.segment_semantic',\n",
       "               tensor([0.1849, 0.2576, 0.4162], device='cuda:0')),\n",
       "              ('net.7.policy.segment_semantic',\n",
       "               tensor([0.5283, 0.6112, 0.3682], device='cuda:0')),\n",
       "              ('net.11.policy.segment_semantic',\n",
       "               tensor([0.8037, 0.5521, 0.1797], device='cuda:0')),\n",
       "              ('net.14.policy.segment_semantic',\n",
       "               tensor([0.5865, 0.1435, 0.1253], device='cuda:0')),\n",
       "              ('net.18.policy.segment_semantic',\n",
       "               tensor([0.0908, 0.2993, 0.4109], device='cuda:0')),\n",
       "              ('net.21.policy.segment_semantic',\n",
       "               tensor([0.0246, 0.2858, 0.5702], device='cuda:0')),\n",
       "              ('net.25.policy.segment_semantic',\n",
       "               tensor([0.7914, 0.7014, 0.4357], device='cuda:0')),\n",
       "              ('net.27.policy.segment_semantic',\n",
       "               tensor([0.7049, 0.6594, 0.2567], device='cuda:0')),\n",
       "              ('net.30.policy.segment_semantic',\n",
       "               tensor([0.6766, 0.8575, 0.5775], device='cuda:0')),\n",
       "              ('net.34.policy.segment_semantic',\n",
       "               tensor([0.2790, 0.8382, 0.0333], device='cuda:0')),\n",
       "              ('net.37.policy.segment_semantic',\n",
       "               tensor([0.6352, 0.6431, 0.9880], device='cuda:0')),\n",
       "              ('net.41.policy.segment_semantic',\n",
       "               tensor([0.6996, 0.4078, 0.1015], device='cuda:0')),\n",
       "              ('net.44.policy.segment_semantic',\n",
       "               tensor([0.1410, 0.3959, 0.7326], device='cuda:0')),\n",
       "              ('net.48.policy.segment_semantic',\n",
       "               tensor([0.8880, 0.9432, 0.6873], device='cuda:0')),\n",
       "              ('net.51.policy.segment_semantic',\n",
       "               tensor([0.9427, 0.7679, 0.3888], device='cuda:0')),\n",
       "              ('net.55.policy.segment_semantic',\n",
       "               tensor([0.0136, 0.2464, 0.7609], device='cuda:0')),\n",
       "              ('net.57.policy.segment_semantic',\n",
       "               tensor([0.4940, 0.8463, 0.0324], device='cuda:0')),\n",
       "              ('net.60.policy.segment_semantic',\n",
       "               tensor([0.5068, 0.2518, 0.2477], device='cuda:0')),\n",
       "              ('net.64.policy.segment_semantic',\n",
       "               tensor([0.3053, 0.6100, 0.9996], device='cuda:0')),\n",
       "              ('net.67.policy.segment_semantic',\n",
       "               tensor([0.6072, 0.8496, 0.4890], device='cuda:0')),\n",
       "              ('net.71.policy.segment_semantic',\n",
       "               tensor([0.0961, 0.8070, 0.6575], device='cuda:0')),\n",
       "              ('net.74.policy.segment_semantic',\n",
       "               tensor([0.0041, 0.2041, 0.2028], device='cuda:0')),\n",
       "              ('net.78.policy.segment_semantic',\n",
       "               tensor([0.5338, 0.4242, 0.9883], device='cuda:0')),\n",
       "              ('net.81.policy.segment_semantic',\n",
       "               tensor([0.1981, 0.5251, 0.6922], device='cuda:0')),\n",
       "              ('net.85.policy.segment_semantic',\n",
       "               tensor([0.1511, 0.2406, 0.5841], device='cuda:0')),\n",
       "              ('net.88.policy.segment_semantic',\n",
       "               tensor([0.6771, 0.3479, 0.8644], device='cuda:0')),\n",
       "              ('net.92.policy.segment_semantic',\n",
       "               tensor([0.5812, 0.9064, 0.2832], device='cuda:0')),\n",
       "              ('net.95.policy.segment_semantic',\n",
       "               tensor([0.3638, 0.6208, 0.9081], device='cuda:0')),\n",
       "              ('net.99.policy.segment_semantic',\n",
       "               tensor([0.5171, 0.3676, 0.4089], device='cuda:0')),\n",
       "              ('net.101.policy.segment_semantic',\n",
       "               tensor([0.0201, 0.0684, 0.9333], device='cuda:0')),\n",
       "              ('net.104.policy.segment_semantic',\n",
       "               tensor([0.4210, 0.4657, 0.3852], device='cuda:0')),\n",
       "              ('net.108.policy.segment_semantic',\n",
       "               tensor([0.0853, 0.9036, 0.6229], device='cuda:0')),\n",
       "              ('net.111.policy.segment_semantic',\n",
       "               tensor([0.0791, 0.6441, 0.0496], device='cuda:0')),\n",
       "              ('net.115.policy.segment_semantic',\n",
       "               tensor([0.3585, 0.8501, 0.9563], device='cuda:0')),\n",
       "              ('net.118.policy.segment_semantic',\n",
       "               tensor([0.9398, 0.8635, 0.3529], device='cuda:0')),\n",
       "              ('net.0.policy.depth_zbuffer',\n",
       "               tensor([0.2986, 0.0129, 0.2851], device='cuda:0')),\n",
       "              ('net.4.policy.depth_zbuffer',\n",
       "               tensor([0.2785, 0.5316, 0.9822], device='cuda:0')),\n",
       "              ('net.7.policy.depth_zbuffer',\n",
       "               tensor([0.5180, 0.5230, 0.4106], device='cuda:0')),\n",
       "              ('net.11.policy.depth_zbuffer',\n",
       "               tensor([0.5729, 0.5666, 0.3400], device='cuda:0')),\n",
       "              ('net.14.policy.depth_zbuffer',\n",
       "               tensor([0.0705, 0.8648, 0.1862], device='cuda:0')),\n",
       "              ('net.18.policy.depth_zbuffer',\n",
       "               tensor([0.9367, 0.9191, 0.1087], device='cuda:0')),\n",
       "              ('net.21.policy.depth_zbuffer',\n",
       "               tensor([0.8490, 0.5278, 0.6581], device='cuda:0')),\n",
       "              ('net.25.policy.depth_zbuffer',\n",
       "               tensor([0.5205, 0.8426, 0.7122], device='cuda:0')),\n",
       "              ('net.27.policy.depth_zbuffer',\n",
       "               tensor([0.5586, 0.8733, 0.1552], device='cuda:0')),\n",
       "              ('net.30.policy.depth_zbuffer',\n",
       "               tensor([0.2275, 0.1199, 0.1899], device='cuda:0')),\n",
       "              ('net.34.policy.depth_zbuffer',\n",
       "               tensor([0.4547, 0.5875, 0.7764], device='cuda:0')),\n",
       "              ('net.37.policy.depth_zbuffer',\n",
       "               tensor([0.0707, 0.4299, 0.1713], device='cuda:0')),\n",
       "              ('net.41.policy.depth_zbuffer',\n",
       "               tensor([0.3681, 0.9895, 0.6250], device='cuda:0')),\n",
       "              ('net.44.policy.depth_zbuffer',\n",
       "               tensor([0.9086, 0.8344, 0.0051], device='cuda:0')),\n",
       "              ('net.48.policy.depth_zbuffer',\n",
       "               tensor([0.8104, 0.6201, 0.5329], device='cuda:0')),\n",
       "              ('net.51.policy.depth_zbuffer',\n",
       "               tensor([0.2319, 0.2718, 0.2945], device='cuda:0')),\n",
       "              ('net.55.policy.depth_zbuffer',\n",
       "               tensor([0.9045, 0.3321, 0.4307], device='cuda:0')),\n",
       "              ('net.57.policy.depth_zbuffer',\n",
       "               tensor([0.2477, 0.0208, 0.0551], device='cuda:0')),\n",
       "              ('net.60.policy.depth_zbuffer',\n",
       "               tensor([0.5236, 0.2080, 0.3754], device='cuda:0')),\n",
       "              ('net.64.policy.depth_zbuffer',\n",
       "               tensor([0.6481, 0.7825, 0.1003], device='cuda:0')),\n",
       "              ('net.67.policy.depth_zbuffer',\n",
       "               tensor([0.3755, 0.4327, 0.1096], device='cuda:0')),\n",
       "              ('net.71.policy.depth_zbuffer',\n",
       "               tensor([0.1480, 0.3582, 0.2645], device='cuda:0')),\n",
       "              ('net.74.policy.depth_zbuffer',\n",
       "               tensor([0.0662, 0.2986, 0.4912], device='cuda:0')),\n",
       "              ('net.78.policy.depth_zbuffer',\n",
       "               tensor([0.4837, 0.2779, 0.1885], device='cuda:0')),\n",
       "              ('net.81.policy.depth_zbuffer',\n",
       "               tensor([0.0760, 0.3008, 0.7057], device='cuda:0')),\n",
       "              ('net.85.policy.depth_zbuffer',\n",
       "               tensor([0.8320, 0.5214, 0.9113], device='cuda:0')),\n",
       "              ('net.88.policy.depth_zbuffer',\n",
       "               tensor([0.9624, 0.8612, 0.0973], device='cuda:0')),\n",
       "              ('net.92.policy.depth_zbuffer',\n",
       "               tensor([0.2196, 0.1946, 0.4857], device='cuda:0')),\n",
       "              ('net.95.policy.depth_zbuffer',\n",
       "               tensor([0.8987, 0.0590, 0.7320], device='cuda:0')),\n",
       "              ('net.99.policy.depth_zbuffer',\n",
       "               tensor([0.1820, 0.2932, 0.7846], device='cuda:0')),\n",
       "              ('net.101.policy.depth_zbuffer',\n",
       "               tensor([0.1984, 0.7761, 0.8488], device='cuda:0')),\n",
       "              ('net.104.policy.depth_zbuffer',\n",
       "               tensor([0.7607, 0.1147, 0.9929], device='cuda:0')),\n",
       "              ('net.108.policy.depth_zbuffer',\n",
       "               tensor([0.8426, 0.7638, 0.6738], device='cuda:0')),\n",
       "              ('net.111.policy.depth_zbuffer',\n",
       "               tensor([0.5203, 0.2665, 0.5983], device='cuda:0')),\n",
       "              ('net.115.policy.depth_zbuffer',\n",
       "               tensor([0.8187, 0.9307, 0.8956], device='cuda:0')),\n",
       "              ('net.118.policy.depth_zbuffer',\n",
       "               tensor([0.1201, 0.0644, 0.6865], device='cuda:0'))])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['headsDict.segment_semantic.fc1.conv1.weight', 'headsDict.segment_semantic.fc1.conv1.bias', 'headsDict.segment_semantic.fc1.conv2.weight', 'headsDict.segment_semantic.fc1.conv2.bias', 'headsDict.segment_semantic.fc1.conv3.weight', 'headsDict.segment_semantic.fc1.conv3.bias', 'headsDict.segment_semantic.fc2.conv1.weight', 'headsDict.segment_semantic.fc2.conv1.bias', 'headsDict.segment_semantic.fc2.conv2.weight', 'headsDict.segment_semantic.fc2.conv2.bias', 'headsDict.segment_semantic.fc2.conv3.weight', 'headsDict.segment_semantic.fc2.conv3.bias', 'headsDict.segment_semantic.fc3.conv1.weight', 'headsDict.segment_semantic.fc3.conv1.bias', 'headsDict.segment_semantic.fc3.conv2.weight', 'headsDict.segment_semantic.fc3.conv2.bias', 'headsDict.segment_semantic.fc3.conv3.weight', 'headsDict.segment_semantic.fc3.conv3.bias', 'headsDict.segment_semantic.fc4.conv1.weight', 'headsDict.segment_semantic.fc4.conv1.bias', 'headsDict.segment_semantic.fc4.conv2.weight', 'headsDict.segment_semantic.fc4.conv2.bias', 'headsDict.segment_semantic.fc4.conv3.weight', 'headsDict.segment_semantic.fc4.conv3.bias', 'headsDict.normal.fc1.conv1.weight', 'headsDict.normal.fc1.conv1.bias', 'headsDict.normal.fc1.conv2.weight', 'headsDict.normal.fc1.conv2.bias', 'headsDict.normal.fc1.conv3.weight', 'headsDict.normal.fc1.conv3.bias', 'headsDict.normal.fc2.conv1.weight', 'headsDict.normal.fc2.conv1.bias', 'headsDict.normal.fc2.conv2.weight', 'headsDict.normal.fc2.conv2.bias', 'headsDict.normal.fc2.conv3.weight', 'headsDict.normal.fc2.conv3.bias', 'headsDict.normal.fc3.conv1.weight', 'headsDict.normal.fc3.conv1.bias', 'headsDict.normal.fc3.conv2.weight', 'headsDict.normal.fc3.conv2.bias', 'headsDict.normal.fc3.conv3.weight', 'headsDict.normal.fc3.conv3.bias', 'headsDict.normal.fc4.conv1.weight', 'headsDict.normal.fc4.conv1.bias', 'headsDict.normal.fc4.conv2.weight', 'headsDict.normal.fc4.conv2.bias', 'headsDict.normal.fc4.conv3.weight', 'headsDict.normal.fc4.conv3.bias', 'headsDict.depth_zbuffer.fc1.conv1.weight', 'headsDict.depth_zbuffer.fc1.conv1.bias', 'headsDict.depth_zbuffer.fc1.conv2.weight', 'headsDict.depth_zbuffer.fc1.conv2.bias', 'headsDict.depth_zbuffer.fc1.conv3.weight', 'headsDict.depth_zbuffer.fc1.conv3.bias', 'headsDict.depth_zbuffer.fc2.conv1.weight', 'headsDict.depth_zbuffer.fc2.conv1.bias', 'headsDict.depth_zbuffer.fc2.conv2.weight', 'headsDict.depth_zbuffer.fc2.conv2.bias', 'headsDict.depth_zbuffer.fc2.conv3.weight', 'headsDict.depth_zbuffer.fc2.conv3.bias', 'headsDict.depth_zbuffer.fc3.conv1.weight', 'headsDict.depth_zbuffer.fc3.conv1.bias', 'headsDict.depth_zbuffer.fc3.conv2.weight', 'headsDict.depth_zbuffer.fc3.conv2.bias', 'headsDict.depth_zbuffer.fc3.conv3.weight', 'headsDict.depth_zbuffer.fc3.conv3.bias', 'headsDict.depth_zbuffer.fc4.conv1.weight', 'headsDict.depth_zbuffer.fc4.conv1.bias', 'headsDict.depth_zbuffer.fc4.conv2.weight', 'headsDict.depth_zbuffer.fc4.conv2.bias', 'headsDict.depth_zbuffer.fc4.conv3.weight', 'headsDict.depth_zbuffer.fc4.conv3.bias', 'net.0.taskOp.segment_semantic.weight', 'net.0.taskOp.normal.weight', 'net.0.taskOp.depth_zbuffer.weight', 'net.0.dsOp.segment_semantic.0.weight', 'net.0.dsOp.segment_semantic.1.weight', 'net.0.dsOp.segment_semantic.1.bias', 'net.0.dsOp.segment_semantic.1.running_mean', 'net.0.dsOp.segment_semantic.1.running_var', 'net.0.dsOp.normal.0.weight', 'net.0.dsOp.normal.1.weight', 'net.0.dsOp.normal.1.bias', 'net.0.dsOp.normal.1.running_mean', 'net.0.dsOp.normal.1.running_var', 'net.0.dsOp.depth_zbuffer.0.weight', 'net.0.dsOp.depth_zbuffer.1.weight', 'net.0.dsOp.depth_zbuffer.1.bias', 'net.0.dsOp.depth_zbuffer.1.running_mean', 'net.0.dsOp.depth_zbuffer.1.running_var', 'net.0.basicOp.weight', 'net.1.taskOp.segment_semantic.weight', 'net.1.taskOp.segment_semantic.bias', 'net.1.taskOp.segment_semantic.running_mean', 'net.1.taskOp.segment_semantic.running_var', 'net.1.taskOp.normal.weight', 'net.1.taskOp.normal.bias', 'net.1.taskOp.normal.running_mean', 'net.1.taskOp.normal.running_var', 'net.1.taskOp.depth_zbuffer.weight', 'net.1.taskOp.depth_zbuffer.bias', 'net.1.taskOp.depth_zbuffer.running_mean', 'net.1.taskOp.depth_zbuffer.running_var', 'net.1.policy.segment_semantic', 'net.1.policy.normal', 'net.1.policy.depth_zbuffer', 'net.1.basicOp.weight', 'net.1.basicOp.bias', 'net.1.basicOp.running_mean', 'net.1.basicOp.running_var', 'net.4.taskOp.segment_semantic.weight', 'net.4.taskOp.normal.weight', 'net.4.taskOp.depth_zbuffer.weight', 'net.4.basicOp.weight', 'net.5.taskOp.segment_semantic.weight', 'net.5.taskOp.segment_semantic.bias', 'net.5.taskOp.segment_semantic.running_mean', 'net.5.taskOp.segment_semantic.running_var', 'net.5.taskOp.normal.weight', 'net.5.taskOp.normal.bias', 'net.5.taskOp.normal.running_mean', 'net.5.taskOp.normal.running_var', 'net.5.taskOp.depth_zbuffer.weight', 'net.5.taskOp.depth_zbuffer.bias', 'net.5.taskOp.depth_zbuffer.running_mean', 'net.5.taskOp.depth_zbuffer.running_var', 'net.5.policy.segment_semantic', 'net.5.policy.normal', 'net.5.policy.depth_zbuffer', 'net.5.basicOp.weight', 'net.5.basicOp.bias', 'net.5.basicOp.running_mean', 'net.5.basicOp.running_var', 'net.7.taskOp.segment_semantic.weight', 'net.7.taskOp.normal.weight', 'net.7.taskOp.depth_zbuffer.weight', 'net.7.basicOp.weight', 'net.8.taskOp.segment_semantic.weight', 'net.8.taskOp.segment_semantic.bias', 'net.8.taskOp.segment_semantic.running_mean', 'net.8.taskOp.segment_semantic.running_var', 'net.8.taskOp.normal.weight', 'net.8.taskOp.normal.bias', 'net.8.taskOp.normal.running_mean', 'net.8.taskOp.normal.running_var', 'net.8.taskOp.depth_zbuffer.weight', 'net.8.taskOp.depth_zbuffer.bias', 'net.8.taskOp.depth_zbuffer.running_mean', 'net.8.taskOp.depth_zbuffer.running_var', 'net.8.policy.segment_semantic', 'net.8.policy.normal', 'net.8.policy.depth_zbuffer', 'net.8.basicOp.weight', 'net.8.basicOp.bias', 'net.8.basicOp.running_mean', 'net.8.basicOp.running_var', 'net.11.taskOp.segment_semantic.weight', 'net.11.taskOp.normal.weight', 'net.11.taskOp.depth_zbuffer.weight', 'net.11.basicOp.weight', 'net.12.taskOp.segment_semantic.weight', 'net.12.taskOp.segment_semantic.bias', 'net.12.taskOp.segment_semantic.running_mean', 'net.12.taskOp.segment_semantic.running_var', 'net.12.taskOp.normal.weight', 'net.12.taskOp.normal.bias', 'net.12.taskOp.normal.running_mean', 'net.12.taskOp.normal.running_var', 'net.12.taskOp.depth_zbuffer.weight', 'net.12.taskOp.depth_zbuffer.bias', 'net.12.taskOp.depth_zbuffer.running_mean', 'net.12.taskOp.depth_zbuffer.running_var', 'net.12.policy.segment_semantic', 'net.12.policy.normal', 'net.12.policy.depth_zbuffer', 'net.12.basicOp.weight', 'net.12.basicOp.bias', 'net.12.basicOp.running_mean', 'net.12.basicOp.running_var', 'net.14.taskOp.segment_semantic.weight', 'net.14.taskOp.normal.weight', 'net.14.taskOp.depth_zbuffer.weight', 'net.14.basicOp.weight', 'net.15.taskOp.segment_semantic.weight', 'net.15.taskOp.segment_semantic.bias', 'net.15.taskOp.segment_semantic.running_mean', 'net.15.taskOp.segment_semantic.running_var', 'net.15.taskOp.normal.weight', 'net.15.taskOp.normal.bias', 'net.15.taskOp.normal.running_mean', 'net.15.taskOp.normal.running_var', 'net.15.taskOp.depth_zbuffer.weight', 'net.15.taskOp.depth_zbuffer.bias', 'net.15.taskOp.depth_zbuffer.running_mean', 'net.15.taskOp.depth_zbuffer.running_var', 'net.15.policy.segment_semantic', 'net.15.policy.normal', 'net.15.policy.depth_zbuffer', 'net.15.basicOp.weight', 'net.15.basicOp.bias', 'net.15.basicOp.running_mean', 'net.15.basicOp.running_var', 'net.18.taskOp.segment_semantic.weight', 'net.18.taskOp.normal.weight', 'net.18.taskOp.depth_zbuffer.weight', 'net.18.basicOp.weight', 'net.19.taskOp.segment_semantic.weight', 'net.19.taskOp.segment_semantic.bias', 'net.19.taskOp.segment_semantic.running_mean', 'net.19.taskOp.segment_semantic.running_var', 'net.19.taskOp.normal.weight', 'net.19.taskOp.normal.bias', 'net.19.taskOp.normal.running_mean', 'net.19.taskOp.normal.running_var', 'net.19.taskOp.depth_zbuffer.weight', 'net.19.taskOp.depth_zbuffer.bias', 'net.19.taskOp.depth_zbuffer.running_mean', 'net.19.taskOp.depth_zbuffer.running_var', 'net.19.policy.segment_semantic', 'net.19.policy.normal', 'net.19.policy.depth_zbuffer', 'net.19.basicOp.weight', 'net.19.basicOp.bias', 'net.19.basicOp.running_mean', 'net.19.basicOp.running_var', 'net.21.taskOp.segment_semantic.weight', 'net.21.taskOp.normal.weight', 'net.21.taskOp.depth_zbuffer.weight', 'net.21.basicOp.weight', 'net.22.taskOp.segment_semantic.weight', 'net.22.taskOp.segment_semantic.bias', 'net.22.taskOp.segment_semantic.running_mean', 'net.22.taskOp.segment_semantic.running_var', 'net.22.taskOp.normal.weight', 'net.22.taskOp.normal.bias', 'net.22.taskOp.normal.running_mean', 'net.22.taskOp.normal.running_var', 'net.22.taskOp.depth_zbuffer.weight', 'net.22.taskOp.depth_zbuffer.bias', 'net.22.taskOp.depth_zbuffer.running_mean', 'net.22.taskOp.depth_zbuffer.running_var', 'net.22.policy.segment_semantic', 'net.22.policy.normal', 'net.22.policy.depth_zbuffer', 'net.22.basicOp.weight', 'net.22.basicOp.bias', 'net.22.basicOp.running_mean', 'net.22.basicOp.running_var', 'net.25.taskOp.segment_semantic.weight', 'net.25.taskOp.normal.weight', 'net.25.taskOp.depth_zbuffer.weight', 'net.25.dsOp.segment_semantic.0.weight', 'net.25.dsOp.segment_semantic.1.weight', 'net.25.dsOp.segment_semantic.1.bias', 'net.25.dsOp.segment_semantic.1.running_mean', 'net.25.dsOp.segment_semantic.1.running_var', 'net.25.dsOp.normal.0.weight', 'net.25.dsOp.normal.1.weight', 'net.25.dsOp.normal.1.bias', 'net.25.dsOp.normal.1.running_mean', 'net.25.dsOp.normal.1.running_var', 'net.25.dsOp.depth_zbuffer.0.weight', 'net.25.dsOp.depth_zbuffer.1.weight', 'net.25.dsOp.depth_zbuffer.1.bias', 'net.25.dsOp.depth_zbuffer.1.running_mean', 'net.25.dsOp.depth_zbuffer.1.running_var', 'net.25.basicOp.weight', 'net.26.taskOp.segment_semantic.weight', 'net.26.taskOp.segment_semantic.bias', 'net.26.taskOp.segment_semantic.running_mean', 'net.26.taskOp.segment_semantic.running_var', 'net.26.taskOp.normal.weight', 'net.26.taskOp.normal.bias', 'net.26.taskOp.normal.running_mean', 'net.26.taskOp.normal.running_var', 'net.26.taskOp.depth_zbuffer.weight', 'net.26.taskOp.depth_zbuffer.bias', 'net.26.taskOp.depth_zbuffer.running_mean', 'net.26.taskOp.depth_zbuffer.running_var', 'net.26.policy.segment_semantic', 'net.26.policy.normal', 'net.26.policy.depth_zbuffer', 'net.26.basicOp.weight', 'net.26.basicOp.bias', 'net.26.basicOp.running_mean', 'net.26.basicOp.running_var', 'net.27.taskOp.segment_semantic.weight', 'net.27.taskOp.normal.weight', 'net.27.taskOp.depth_zbuffer.weight', 'net.27.dsOp.segment_semantic.0.weight', 'net.27.dsOp.segment_semantic.1.weight', 'net.27.dsOp.segment_semantic.1.bias', 'net.27.dsOp.segment_semantic.1.running_mean', 'net.27.dsOp.segment_semantic.1.running_var', 'net.27.dsOp.normal.0.weight', 'net.27.dsOp.normal.1.weight', 'net.27.dsOp.normal.1.bias', 'net.27.dsOp.normal.1.running_mean', 'net.27.dsOp.normal.1.running_var', 'net.27.dsOp.depth_zbuffer.0.weight', 'net.27.dsOp.depth_zbuffer.1.weight', 'net.27.dsOp.depth_zbuffer.1.bias', 'net.27.dsOp.depth_zbuffer.1.running_mean', 'net.27.dsOp.depth_zbuffer.1.running_var', 'net.27.basicOp.weight', 'net.28.taskOp.segment_semantic.weight', 'net.28.taskOp.segment_semantic.bias', 'net.28.taskOp.segment_semantic.running_mean', 'net.28.taskOp.segment_semantic.running_var', 'net.28.taskOp.normal.weight', 'net.28.taskOp.normal.bias', 'net.28.taskOp.normal.running_mean', 'net.28.taskOp.normal.running_var', 'net.28.taskOp.depth_zbuffer.weight', 'net.28.taskOp.depth_zbuffer.bias', 'net.28.taskOp.depth_zbuffer.running_mean', 'net.28.taskOp.depth_zbuffer.running_var', 'net.28.policy.segment_semantic', 'net.28.policy.normal', 'net.28.policy.depth_zbuffer', 'net.28.basicOp.weight', 'net.28.basicOp.bias', 'net.28.basicOp.running_mean', 'net.28.basicOp.running_var', 'net.30.taskOp.segment_semantic.weight', 'net.30.taskOp.normal.weight', 'net.30.taskOp.depth_zbuffer.weight', 'net.30.basicOp.weight', 'net.31.taskOp.segment_semantic.weight', 'net.31.taskOp.segment_semantic.bias', 'net.31.taskOp.segment_semantic.running_mean', 'net.31.taskOp.segment_semantic.running_var', 'net.31.taskOp.normal.weight', 'net.31.taskOp.normal.bias', 'net.31.taskOp.normal.running_mean', 'net.31.taskOp.normal.running_var', 'net.31.taskOp.depth_zbuffer.weight', 'net.31.taskOp.depth_zbuffer.bias', 'net.31.taskOp.depth_zbuffer.running_mean', 'net.31.taskOp.depth_zbuffer.running_var', 'net.31.policy.segment_semantic', 'net.31.policy.normal', 'net.31.policy.depth_zbuffer', 'net.31.basicOp.weight', 'net.31.basicOp.bias', 'net.31.basicOp.running_mean', 'net.31.basicOp.running_var', 'net.34.taskOp.segment_semantic.weight', 'net.34.taskOp.normal.weight', 'net.34.taskOp.depth_zbuffer.weight', 'net.34.basicOp.weight', 'net.35.taskOp.segment_semantic.weight', 'net.35.taskOp.segment_semantic.bias', 'net.35.taskOp.segment_semantic.running_mean', 'net.35.taskOp.segment_semantic.running_var', 'net.35.taskOp.normal.weight', 'net.35.taskOp.normal.bias', 'net.35.taskOp.normal.running_mean', 'net.35.taskOp.normal.running_var', 'net.35.taskOp.depth_zbuffer.weight', 'net.35.taskOp.depth_zbuffer.bias', 'net.35.taskOp.depth_zbuffer.running_mean', 'net.35.taskOp.depth_zbuffer.running_var', 'net.35.policy.segment_semantic', 'net.35.policy.normal', 'net.35.policy.depth_zbuffer', 'net.35.basicOp.weight', 'net.35.basicOp.bias', 'net.35.basicOp.running_mean', 'net.35.basicOp.running_var', 'net.37.taskOp.segment_semantic.weight', 'net.37.taskOp.normal.weight', 'net.37.taskOp.depth_zbuffer.weight', 'net.37.basicOp.weight', 'net.38.taskOp.segment_semantic.weight', 'net.38.taskOp.segment_semantic.bias', 'net.38.taskOp.segment_semantic.running_mean', 'net.38.taskOp.segment_semantic.running_var', 'net.38.taskOp.normal.weight', 'net.38.taskOp.normal.bias', 'net.38.taskOp.normal.running_mean', 'net.38.taskOp.normal.running_var', 'net.38.taskOp.depth_zbuffer.weight', 'net.38.taskOp.depth_zbuffer.bias', 'net.38.taskOp.depth_zbuffer.running_mean', 'net.38.taskOp.depth_zbuffer.running_var', 'net.38.policy.segment_semantic', 'net.38.policy.normal', 'net.38.policy.depth_zbuffer', 'net.38.basicOp.weight', 'net.38.basicOp.bias', 'net.38.basicOp.running_mean', 'net.38.basicOp.running_var', 'net.41.taskOp.segment_semantic.weight', 'net.41.taskOp.normal.weight', 'net.41.taskOp.depth_zbuffer.weight', 'net.41.basicOp.weight', 'net.42.taskOp.segment_semantic.weight', 'net.42.taskOp.segment_semantic.bias', 'net.42.taskOp.segment_semantic.running_mean', 'net.42.taskOp.segment_semantic.running_var', 'net.42.taskOp.normal.weight', 'net.42.taskOp.normal.bias', 'net.42.taskOp.normal.running_mean', 'net.42.taskOp.normal.running_var', 'net.42.taskOp.depth_zbuffer.weight', 'net.42.taskOp.depth_zbuffer.bias', 'net.42.taskOp.depth_zbuffer.running_mean', 'net.42.taskOp.depth_zbuffer.running_var', 'net.42.policy.segment_semantic', 'net.42.policy.normal', 'net.42.policy.depth_zbuffer', 'net.42.basicOp.weight', 'net.42.basicOp.bias', 'net.42.basicOp.running_mean', 'net.42.basicOp.running_var', 'net.44.taskOp.segment_semantic.weight', 'net.44.taskOp.normal.weight', 'net.44.taskOp.depth_zbuffer.weight', 'net.44.basicOp.weight', 'net.45.taskOp.segment_semantic.weight', 'net.45.taskOp.segment_semantic.bias', 'net.45.taskOp.segment_semantic.running_mean', 'net.45.taskOp.segment_semantic.running_var', 'net.45.taskOp.normal.weight', 'net.45.taskOp.normal.bias', 'net.45.taskOp.normal.running_mean', 'net.45.taskOp.normal.running_var', 'net.45.taskOp.depth_zbuffer.weight', 'net.45.taskOp.depth_zbuffer.bias', 'net.45.taskOp.depth_zbuffer.running_mean', 'net.45.taskOp.depth_zbuffer.running_var', 'net.45.policy.segment_semantic', 'net.45.policy.normal', 'net.45.policy.depth_zbuffer', 'net.45.basicOp.weight', 'net.45.basicOp.bias', 'net.45.basicOp.running_mean', 'net.45.basicOp.running_var', 'net.48.taskOp.segment_semantic.weight', 'net.48.taskOp.normal.weight', 'net.48.taskOp.depth_zbuffer.weight', 'net.48.basicOp.weight', 'net.49.taskOp.segment_semantic.weight', 'net.49.taskOp.segment_semantic.bias', 'net.49.taskOp.segment_semantic.running_mean', 'net.49.taskOp.segment_semantic.running_var', 'net.49.taskOp.normal.weight', 'net.49.taskOp.normal.bias', 'net.49.taskOp.normal.running_mean', 'net.49.taskOp.normal.running_var', 'net.49.taskOp.depth_zbuffer.weight', 'net.49.taskOp.depth_zbuffer.bias', 'net.49.taskOp.depth_zbuffer.running_mean', 'net.49.taskOp.depth_zbuffer.running_var', 'net.49.policy.segment_semantic', 'net.49.policy.normal', 'net.49.policy.depth_zbuffer', 'net.49.basicOp.weight', 'net.49.basicOp.bias', 'net.49.basicOp.running_mean', 'net.49.basicOp.running_var', 'net.51.taskOp.segment_semantic.weight', 'net.51.taskOp.normal.weight', 'net.51.taskOp.depth_zbuffer.weight', 'net.51.basicOp.weight', 'net.52.taskOp.segment_semantic.weight', 'net.52.taskOp.segment_semantic.bias', 'net.52.taskOp.segment_semantic.running_mean', 'net.52.taskOp.segment_semantic.running_var', 'net.52.taskOp.normal.weight', 'net.52.taskOp.normal.bias', 'net.52.taskOp.normal.running_mean', 'net.52.taskOp.normal.running_var', 'net.52.taskOp.depth_zbuffer.weight', 'net.52.taskOp.depth_zbuffer.bias', 'net.52.taskOp.depth_zbuffer.running_mean', 'net.52.taskOp.depth_zbuffer.running_var', 'net.52.policy.segment_semantic', 'net.52.policy.normal', 'net.52.policy.depth_zbuffer', 'net.52.basicOp.weight', 'net.52.basicOp.bias', 'net.52.basicOp.running_mean', 'net.52.basicOp.running_var', 'net.55.taskOp.segment_semantic.weight', 'net.55.taskOp.normal.weight', 'net.55.taskOp.depth_zbuffer.weight', 'net.55.dsOp.segment_semantic.0.weight', 'net.55.dsOp.segment_semantic.1.weight', 'net.55.dsOp.segment_semantic.1.bias', 'net.55.dsOp.segment_semantic.1.running_mean', 'net.55.dsOp.segment_semantic.1.running_var', 'net.55.dsOp.normal.0.weight', 'net.55.dsOp.normal.1.weight', 'net.55.dsOp.normal.1.bias', 'net.55.dsOp.normal.1.running_mean', 'net.55.dsOp.normal.1.running_var', 'net.55.dsOp.depth_zbuffer.0.weight', 'net.55.dsOp.depth_zbuffer.1.weight', 'net.55.dsOp.depth_zbuffer.1.bias', 'net.55.dsOp.depth_zbuffer.1.running_mean', 'net.55.dsOp.depth_zbuffer.1.running_var', 'net.55.basicOp.weight', 'net.56.taskOp.segment_semantic.weight', 'net.56.taskOp.segment_semantic.bias', 'net.56.taskOp.segment_semantic.running_mean', 'net.56.taskOp.segment_semantic.running_var', 'net.56.taskOp.normal.weight', 'net.56.taskOp.normal.bias', 'net.56.taskOp.normal.running_mean', 'net.56.taskOp.normal.running_var', 'net.56.taskOp.depth_zbuffer.weight', 'net.56.taskOp.depth_zbuffer.bias', 'net.56.taskOp.depth_zbuffer.running_mean', 'net.56.taskOp.depth_zbuffer.running_var', 'net.56.policy.segment_semantic', 'net.56.policy.normal', 'net.56.policy.depth_zbuffer', 'net.56.basicOp.weight', 'net.56.basicOp.bias', 'net.56.basicOp.running_mean', 'net.56.basicOp.running_var', 'net.57.taskOp.segment_semantic.weight', 'net.57.taskOp.normal.weight', 'net.57.taskOp.depth_zbuffer.weight', 'net.57.dsOp.segment_semantic.0.weight', 'net.57.dsOp.segment_semantic.1.weight', 'net.57.dsOp.segment_semantic.1.bias', 'net.57.dsOp.segment_semantic.1.running_mean', 'net.57.dsOp.segment_semantic.1.running_var', 'net.57.dsOp.normal.0.weight', 'net.57.dsOp.normal.1.weight', 'net.57.dsOp.normal.1.bias', 'net.57.dsOp.normal.1.running_mean', 'net.57.dsOp.normal.1.running_var', 'net.57.dsOp.depth_zbuffer.0.weight', 'net.57.dsOp.depth_zbuffer.1.weight', 'net.57.dsOp.depth_zbuffer.1.bias', 'net.57.dsOp.depth_zbuffer.1.running_mean', 'net.57.dsOp.depth_zbuffer.1.running_var', 'net.57.basicOp.weight', 'net.58.taskOp.segment_semantic.weight', 'net.58.taskOp.segment_semantic.bias', 'net.58.taskOp.segment_semantic.running_mean', 'net.58.taskOp.segment_semantic.running_var', 'net.58.taskOp.normal.weight', 'net.58.taskOp.normal.bias', 'net.58.taskOp.normal.running_mean', 'net.58.taskOp.normal.running_var', 'net.58.taskOp.depth_zbuffer.weight', 'net.58.taskOp.depth_zbuffer.bias', 'net.58.taskOp.depth_zbuffer.running_mean', 'net.58.taskOp.depth_zbuffer.running_var', 'net.58.policy.segment_semantic', 'net.58.policy.normal', 'net.58.policy.depth_zbuffer', 'net.58.basicOp.weight', 'net.58.basicOp.bias', 'net.58.basicOp.running_mean', 'net.58.basicOp.running_var', 'net.60.taskOp.segment_semantic.weight', 'net.60.taskOp.normal.weight', 'net.60.taskOp.depth_zbuffer.weight', 'net.60.basicOp.weight', 'net.61.taskOp.segment_semantic.weight', 'net.61.taskOp.segment_semantic.bias', 'net.61.taskOp.segment_semantic.running_mean', 'net.61.taskOp.segment_semantic.running_var', 'net.61.taskOp.normal.weight', 'net.61.taskOp.normal.bias', 'net.61.taskOp.normal.running_mean', 'net.61.taskOp.normal.running_var', 'net.61.taskOp.depth_zbuffer.weight', 'net.61.taskOp.depth_zbuffer.bias', 'net.61.taskOp.depth_zbuffer.running_mean', 'net.61.taskOp.depth_zbuffer.running_var', 'net.61.policy.segment_semantic', 'net.61.policy.normal', 'net.61.policy.depth_zbuffer', 'net.61.basicOp.weight', 'net.61.basicOp.bias', 'net.61.basicOp.running_mean', 'net.61.basicOp.running_var', 'net.64.taskOp.segment_semantic.weight', 'net.64.taskOp.normal.weight', 'net.64.taskOp.depth_zbuffer.weight', 'net.64.basicOp.weight', 'net.65.taskOp.segment_semantic.weight', 'net.65.taskOp.segment_semantic.bias', 'net.65.taskOp.segment_semantic.running_mean', 'net.65.taskOp.segment_semantic.running_var', 'net.65.taskOp.normal.weight', 'net.65.taskOp.normal.bias', 'net.65.taskOp.normal.running_mean', 'net.65.taskOp.normal.running_var', 'net.65.taskOp.depth_zbuffer.weight', 'net.65.taskOp.depth_zbuffer.bias', 'net.65.taskOp.depth_zbuffer.running_mean', 'net.65.taskOp.depth_zbuffer.running_var', 'net.65.policy.segment_semantic', 'net.65.policy.normal', 'net.65.policy.depth_zbuffer', 'net.65.basicOp.weight', 'net.65.basicOp.bias', 'net.65.basicOp.running_mean', 'net.65.basicOp.running_var', 'net.67.taskOp.segment_semantic.weight', 'net.67.taskOp.normal.weight', 'net.67.taskOp.depth_zbuffer.weight', 'net.67.basicOp.weight', 'net.68.taskOp.segment_semantic.weight', 'net.68.taskOp.segment_semantic.bias', 'net.68.taskOp.segment_semantic.running_mean', 'net.68.taskOp.segment_semantic.running_var', 'net.68.taskOp.normal.weight', 'net.68.taskOp.normal.bias', 'net.68.taskOp.normal.running_mean', 'net.68.taskOp.normal.running_var', 'net.68.taskOp.depth_zbuffer.weight', 'net.68.taskOp.depth_zbuffer.bias', 'net.68.taskOp.depth_zbuffer.running_mean', 'net.68.taskOp.depth_zbuffer.running_var', 'net.68.policy.segment_semantic', 'net.68.policy.normal', 'net.68.policy.depth_zbuffer', 'net.68.basicOp.weight', 'net.68.basicOp.bias', 'net.68.basicOp.running_mean', 'net.68.basicOp.running_var', 'net.71.taskOp.segment_semantic.weight', 'net.71.taskOp.normal.weight', 'net.71.taskOp.depth_zbuffer.weight', 'net.71.basicOp.weight', 'net.72.taskOp.segment_semantic.weight', 'net.72.taskOp.segment_semantic.bias', 'net.72.taskOp.segment_semantic.running_mean', 'net.72.taskOp.segment_semantic.running_var', 'net.72.taskOp.normal.weight', 'net.72.taskOp.normal.bias', 'net.72.taskOp.normal.running_mean', 'net.72.taskOp.normal.running_var', 'net.72.taskOp.depth_zbuffer.weight', 'net.72.taskOp.depth_zbuffer.bias', 'net.72.taskOp.depth_zbuffer.running_mean', 'net.72.taskOp.depth_zbuffer.running_var', 'net.72.policy.segment_semantic', 'net.72.policy.normal', 'net.72.policy.depth_zbuffer', 'net.72.basicOp.weight', 'net.72.basicOp.bias', 'net.72.basicOp.running_mean', 'net.72.basicOp.running_var', 'net.74.taskOp.segment_semantic.weight', 'net.74.taskOp.normal.weight', 'net.74.taskOp.depth_zbuffer.weight', 'net.74.basicOp.weight', 'net.75.taskOp.segment_semantic.weight', 'net.75.taskOp.segment_semantic.bias', 'net.75.taskOp.segment_semantic.running_mean', 'net.75.taskOp.segment_semantic.running_var', 'net.75.taskOp.normal.weight', 'net.75.taskOp.normal.bias', 'net.75.taskOp.normal.running_mean', 'net.75.taskOp.normal.running_var', 'net.75.taskOp.depth_zbuffer.weight', 'net.75.taskOp.depth_zbuffer.bias', 'net.75.taskOp.depth_zbuffer.running_mean', 'net.75.taskOp.depth_zbuffer.running_var', 'net.75.policy.segment_semantic', 'net.75.policy.normal', 'net.75.policy.depth_zbuffer', 'net.75.basicOp.weight', 'net.75.basicOp.bias', 'net.75.basicOp.running_mean', 'net.75.basicOp.running_var', 'net.78.taskOp.segment_semantic.weight', 'net.78.taskOp.normal.weight', 'net.78.taskOp.depth_zbuffer.weight', 'net.78.basicOp.weight', 'net.79.taskOp.segment_semantic.weight', 'net.79.taskOp.segment_semantic.bias', 'net.79.taskOp.segment_semantic.running_mean', 'net.79.taskOp.segment_semantic.running_var', 'net.79.taskOp.normal.weight', 'net.79.taskOp.normal.bias', 'net.79.taskOp.normal.running_mean', 'net.79.taskOp.normal.running_var', 'net.79.taskOp.depth_zbuffer.weight', 'net.79.taskOp.depth_zbuffer.bias', 'net.79.taskOp.depth_zbuffer.running_mean', 'net.79.taskOp.depth_zbuffer.running_var', 'net.79.policy.segment_semantic', 'net.79.policy.normal', 'net.79.policy.depth_zbuffer', 'net.79.basicOp.weight', 'net.79.basicOp.bias', 'net.79.basicOp.running_mean', 'net.79.basicOp.running_var', 'net.81.taskOp.segment_semantic.weight', 'net.81.taskOp.normal.weight', 'net.81.taskOp.depth_zbuffer.weight', 'net.81.basicOp.weight', 'net.82.taskOp.segment_semantic.weight', 'net.82.taskOp.segment_semantic.bias', 'net.82.taskOp.segment_semantic.running_mean', 'net.82.taskOp.segment_semantic.running_var', 'net.82.taskOp.normal.weight', 'net.82.taskOp.normal.bias', 'net.82.taskOp.normal.running_mean', 'net.82.taskOp.normal.running_var', 'net.82.taskOp.depth_zbuffer.weight', 'net.82.taskOp.depth_zbuffer.bias', 'net.82.taskOp.depth_zbuffer.running_mean', 'net.82.taskOp.depth_zbuffer.running_var', 'net.82.policy.segment_semantic', 'net.82.policy.normal', 'net.82.policy.depth_zbuffer', 'net.82.basicOp.weight', 'net.82.basicOp.bias', 'net.82.basicOp.running_mean', 'net.82.basicOp.running_var', 'net.85.taskOp.segment_semantic.weight', 'net.85.taskOp.normal.weight', 'net.85.taskOp.depth_zbuffer.weight', 'net.85.basicOp.weight', 'net.86.taskOp.segment_semantic.weight', 'net.86.taskOp.segment_semantic.bias', 'net.86.taskOp.segment_semantic.running_mean', 'net.86.taskOp.segment_semantic.running_var', 'net.86.taskOp.normal.weight', 'net.86.taskOp.normal.bias', 'net.86.taskOp.normal.running_mean', 'net.86.taskOp.normal.running_var', 'net.86.taskOp.depth_zbuffer.weight', 'net.86.taskOp.depth_zbuffer.bias', 'net.86.taskOp.depth_zbuffer.running_mean', 'net.86.taskOp.depth_zbuffer.running_var', 'net.86.policy.segment_semantic', 'net.86.policy.normal', 'net.86.policy.depth_zbuffer', 'net.86.basicOp.weight', 'net.86.basicOp.bias', 'net.86.basicOp.running_mean', 'net.86.basicOp.running_var', 'net.88.taskOp.segment_semantic.weight', 'net.88.taskOp.normal.weight', 'net.88.taskOp.depth_zbuffer.weight', 'net.88.basicOp.weight', 'net.89.taskOp.segment_semantic.weight', 'net.89.taskOp.segment_semantic.bias', 'net.89.taskOp.segment_semantic.running_mean', 'net.89.taskOp.segment_semantic.running_var', 'net.89.taskOp.normal.weight', 'net.89.taskOp.normal.bias', 'net.89.taskOp.normal.running_mean', 'net.89.taskOp.normal.running_var', 'net.89.taskOp.depth_zbuffer.weight', 'net.89.taskOp.depth_zbuffer.bias', 'net.89.taskOp.depth_zbuffer.running_mean', 'net.89.taskOp.depth_zbuffer.running_var', 'net.89.policy.segment_semantic', 'net.89.policy.normal', 'net.89.policy.depth_zbuffer', 'net.89.basicOp.weight', 'net.89.basicOp.bias', 'net.89.basicOp.running_mean', 'net.89.basicOp.running_var', 'net.92.taskOp.segment_semantic.weight', 'net.92.taskOp.normal.weight', 'net.92.taskOp.depth_zbuffer.weight', 'net.92.basicOp.weight', 'net.93.taskOp.segment_semantic.weight', 'net.93.taskOp.segment_semantic.bias', 'net.93.taskOp.segment_semantic.running_mean', 'net.93.taskOp.segment_semantic.running_var', 'net.93.taskOp.normal.weight', 'net.93.taskOp.normal.bias', 'net.93.taskOp.normal.running_mean', 'net.93.taskOp.normal.running_var', 'net.93.taskOp.depth_zbuffer.weight', 'net.93.taskOp.depth_zbuffer.bias', 'net.93.taskOp.depth_zbuffer.running_mean', 'net.93.taskOp.depth_zbuffer.running_var', 'net.93.policy.segment_semantic', 'net.93.policy.normal', 'net.93.policy.depth_zbuffer', 'net.93.basicOp.weight', 'net.93.basicOp.bias', 'net.93.basicOp.running_mean', 'net.93.basicOp.running_var', 'net.95.taskOp.segment_semantic.weight', 'net.95.taskOp.normal.weight', 'net.95.taskOp.depth_zbuffer.weight', 'net.95.basicOp.weight', 'net.96.taskOp.segment_semantic.weight', 'net.96.taskOp.segment_semantic.bias', 'net.96.taskOp.segment_semantic.running_mean', 'net.96.taskOp.segment_semantic.running_var', 'net.96.taskOp.normal.weight', 'net.96.taskOp.normal.bias', 'net.96.taskOp.normal.running_mean', 'net.96.taskOp.normal.running_var', 'net.96.taskOp.depth_zbuffer.weight', 'net.96.taskOp.depth_zbuffer.bias', 'net.96.taskOp.depth_zbuffer.running_mean', 'net.96.taskOp.depth_zbuffer.running_var', 'net.96.policy.segment_semantic', 'net.96.policy.normal', 'net.96.policy.depth_zbuffer', 'net.96.basicOp.weight', 'net.96.basicOp.bias', 'net.96.basicOp.running_mean', 'net.96.basicOp.running_var', 'net.99.taskOp.segment_semantic.weight', 'net.99.taskOp.normal.weight', 'net.99.taskOp.depth_zbuffer.weight', 'net.99.dsOp.segment_semantic.0.weight', 'net.99.dsOp.segment_semantic.1.weight', 'net.99.dsOp.segment_semantic.1.bias', 'net.99.dsOp.segment_semantic.1.running_mean', 'net.99.dsOp.segment_semantic.1.running_var', 'net.99.dsOp.normal.0.weight', 'net.99.dsOp.normal.1.weight', 'net.99.dsOp.normal.1.bias', 'net.99.dsOp.normal.1.running_mean', 'net.99.dsOp.normal.1.running_var', 'net.99.dsOp.depth_zbuffer.0.weight', 'net.99.dsOp.depth_zbuffer.1.weight', 'net.99.dsOp.depth_zbuffer.1.bias', 'net.99.dsOp.depth_zbuffer.1.running_mean', 'net.99.dsOp.depth_zbuffer.1.running_var', 'net.99.basicOp.weight', 'net.100.taskOp.segment_semantic.weight', 'net.100.taskOp.segment_semantic.bias', 'net.100.taskOp.segment_semantic.running_mean', 'net.100.taskOp.segment_semantic.running_var', 'net.100.taskOp.normal.weight', 'net.100.taskOp.normal.bias', 'net.100.taskOp.normal.running_mean', 'net.100.taskOp.normal.running_var', 'net.100.taskOp.depth_zbuffer.weight', 'net.100.taskOp.depth_zbuffer.bias', 'net.100.taskOp.depth_zbuffer.running_mean', 'net.100.taskOp.depth_zbuffer.running_var', 'net.100.policy.segment_semantic', 'net.100.policy.normal', 'net.100.policy.depth_zbuffer', 'net.100.basicOp.weight', 'net.100.basicOp.bias', 'net.100.basicOp.running_mean', 'net.100.basicOp.running_var', 'net.101.taskOp.segment_semantic.weight', 'net.101.taskOp.normal.weight', 'net.101.taskOp.depth_zbuffer.weight', 'net.101.dsOp.segment_semantic.0.weight', 'net.101.dsOp.segment_semantic.1.weight', 'net.101.dsOp.segment_semantic.1.bias', 'net.101.dsOp.segment_semantic.1.running_mean', 'net.101.dsOp.segment_semantic.1.running_var', 'net.101.dsOp.normal.0.weight', 'net.101.dsOp.normal.1.weight', 'net.101.dsOp.normal.1.bias', 'net.101.dsOp.normal.1.running_mean', 'net.101.dsOp.normal.1.running_var', 'net.101.dsOp.depth_zbuffer.0.weight', 'net.101.dsOp.depth_zbuffer.1.weight', 'net.101.dsOp.depth_zbuffer.1.bias', 'net.101.dsOp.depth_zbuffer.1.running_mean', 'net.101.dsOp.depth_zbuffer.1.running_var', 'net.101.basicOp.weight', 'net.102.taskOp.segment_semantic.weight', 'net.102.taskOp.segment_semantic.bias', 'net.102.taskOp.segment_semantic.running_mean', 'net.102.taskOp.segment_semantic.running_var', 'net.102.taskOp.normal.weight', 'net.102.taskOp.normal.bias', 'net.102.taskOp.normal.running_mean', 'net.102.taskOp.normal.running_var', 'net.102.taskOp.depth_zbuffer.weight', 'net.102.taskOp.depth_zbuffer.bias', 'net.102.taskOp.depth_zbuffer.running_mean', 'net.102.taskOp.depth_zbuffer.running_var', 'net.102.policy.segment_semantic', 'net.102.policy.normal', 'net.102.policy.depth_zbuffer', 'net.102.basicOp.weight', 'net.102.basicOp.bias', 'net.102.basicOp.running_mean', 'net.102.basicOp.running_var', 'net.104.taskOp.segment_semantic.weight', 'net.104.taskOp.normal.weight', 'net.104.taskOp.depth_zbuffer.weight', 'net.104.basicOp.weight', 'net.105.taskOp.segment_semantic.weight', 'net.105.taskOp.segment_semantic.bias', 'net.105.taskOp.segment_semantic.running_mean', 'net.105.taskOp.segment_semantic.running_var', 'net.105.taskOp.normal.weight', 'net.105.taskOp.normal.bias', 'net.105.taskOp.normal.running_mean', 'net.105.taskOp.normal.running_var', 'net.105.taskOp.depth_zbuffer.weight', 'net.105.taskOp.depth_zbuffer.bias', 'net.105.taskOp.depth_zbuffer.running_mean', 'net.105.taskOp.depth_zbuffer.running_var', 'net.105.policy.segment_semantic', 'net.105.policy.normal', 'net.105.policy.depth_zbuffer', 'net.105.basicOp.weight', 'net.105.basicOp.bias', 'net.105.basicOp.running_mean', 'net.105.basicOp.running_var', 'net.108.taskOp.segment_semantic.weight', 'net.108.taskOp.normal.weight', 'net.108.taskOp.depth_zbuffer.weight', 'net.108.basicOp.weight', 'net.109.taskOp.segment_semantic.weight', 'net.109.taskOp.segment_semantic.bias', 'net.109.taskOp.segment_semantic.running_mean', 'net.109.taskOp.segment_semantic.running_var', 'net.109.taskOp.normal.weight', 'net.109.taskOp.normal.bias', 'net.109.taskOp.normal.running_mean', 'net.109.taskOp.normal.running_var', 'net.109.taskOp.depth_zbuffer.weight', 'net.109.taskOp.depth_zbuffer.bias', 'net.109.taskOp.depth_zbuffer.running_mean', 'net.109.taskOp.depth_zbuffer.running_var', 'net.109.policy.segment_semantic', 'net.109.policy.normal', 'net.109.policy.depth_zbuffer', 'net.109.basicOp.weight', 'net.109.basicOp.bias', 'net.109.basicOp.running_mean', 'net.109.basicOp.running_var', 'net.111.taskOp.segment_semantic.weight', 'net.111.taskOp.normal.weight', 'net.111.taskOp.depth_zbuffer.weight', 'net.111.basicOp.weight', 'net.112.taskOp.segment_semantic.weight', 'net.112.taskOp.segment_semantic.bias', 'net.112.taskOp.segment_semantic.running_mean', 'net.112.taskOp.segment_semantic.running_var', 'net.112.taskOp.normal.weight', 'net.112.taskOp.normal.bias', 'net.112.taskOp.normal.running_mean', 'net.112.taskOp.normal.running_var', 'net.112.taskOp.depth_zbuffer.weight', 'net.112.taskOp.depth_zbuffer.bias', 'net.112.taskOp.depth_zbuffer.running_mean', 'net.112.taskOp.depth_zbuffer.running_var', 'net.112.policy.segment_semantic', 'net.112.policy.normal', 'net.112.policy.depth_zbuffer', 'net.112.basicOp.weight', 'net.112.basicOp.bias', 'net.112.basicOp.running_mean', 'net.112.basicOp.running_var', 'net.115.taskOp.segment_semantic.weight', 'net.115.taskOp.normal.weight', 'net.115.taskOp.depth_zbuffer.weight', 'net.115.basicOp.weight', 'net.116.taskOp.segment_semantic.weight', 'net.116.taskOp.segment_semantic.bias', 'net.116.taskOp.segment_semantic.running_mean', 'net.116.taskOp.segment_semantic.running_var', 'net.116.taskOp.normal.weight', 'net.116.taskOp.normal.bias', 'net.116.taskOp.normal.running_mean', 'net.116.taskOp.normal.running_var', 'net.116.taskOp.depth_zbuffer.weight', 'net.116.taskOp.depth_zbuffer.bias', 'net.116.taskOp.depth_zbuffer.running_mean', 'net.116.taskOp.depth_zbuffer.running_var', 'net.116.policy.segment_semantic', 'net.116.policy.normal', 'net.116.policy.depth_zbuffer', 'net.116.basicOp.weight', 'net.116.basicOp.bias', 'net.116.basicOp.running_mean', 'net.116.basicOp.running_var', 'net.118.taskOp.segment_semantic.weight', 'net.118.taskOp.normal.weight', 'net.118.taskOp.depth_zbuffer.weight', 'net.118.basicOp.weight', 'net.119.taskOp.segment_semantic.weight', 'net.119.taskOp.segment_semantic.bias', 'net.119.taskOp.segment_semantic.running_mean', 'net.119.taskOp.segment_semantic.running_var', 'net.119.taskOp.normal.weight', 'net.119.taskOp.normal.bias', 'net.119.taskOp.normal.running_mean', 'net.119.taskOp.normal.running_var', 'net.119.taskOp.depth_zbuffer.weight', 'net.119.taskOp.depth_zbuffer.bias', 'net.119.taskOp.depth_zbuffer.running_mean', 'net.119.taskOp.depth_zbuffer.running_var', 'net.119.policy.segment_semantic', 'net.119.policy.normal', 'net.119.policy.depth_zbuffer', 'net.119.basicOp.weight', 'net.119.basicOp.bias', 'net.119.basicOp.running_mean', 'net.119.basicOp.running_var'], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/NYUv2/' + 'sample_bottom20_loss_lambda/20-10/sample_policy_seed10.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['segment_semantic','normal','depth_zbuffer']\n",
    "\n",
    "singleParam = 0\n",
    "mtlParam = 0\n",
    "for node in mtlmodel.net:\n",
    "    if node.taskSp and not node.assumeSp:\n",
    "        shared = False\n",
    "        \n",
    "        params = node.basicOp.weight.data.nelement()\n",
    "        if node.basicOp.bias is not None:\n",
    "            params += node.basicOp.bias.data.nelement()\n",
    "        singleParam += params\n",
    "        \n",
    "        for task in name_list:\n",
    "            policy = node.policy[task].data.cpu().detach().numpy()\n",
    "            if np.array_equal(policy, np.array([1.,0.,0.])):\n",
    "                if not shared:\n",
    "                    mtlParam += params\n",
    "                    shared = True\n",
    "            elif np.array_equal(policy, np.array([0.,1.,0.])):\n",
    "                mtlParam += params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.45198967621305997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlParam / (singleParam * len(name_list)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy layer-wise training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer2(Trainer):\n",
    "    def __init__(self, model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters=50, val_iters=2000, save_iters=200, policy_update_iters=100, next_policy_iters=200):\n",
    "        super(Trainer2, self).__init__(model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters, val_iters, save_iters, policy_update_iters)\n",
    "        self.next_policy_iters = next_policy_iters\n",
    "        \n",
    "    def layerwise_policy_train(self, iters, task_iters=None, policy_lr=0.01, network_lr=0.0001, \n",
    "                               start_tau=5, tau_ratio=0.965,\n",
    "                               policy_scale=6, loss_lambda=1.0,\n",
    "                               writerPath=None, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        if writerPath != None:\n",
    "            writer = SummaryWriter(log_dir=writerPath+'layerwise_policy_train/')\n",
    "        else:\n",
    "            writer = None\n",
    "        \n",
    "        # Step 1: Set optimizer\n",
    "        self.freeze_policy()\n",
    "        optimizer = torch.optim.SGD([{'params': filter(lambda p: p.requires_grad==False, self.model.parameters()), 'lr': policy_lr},\n",
    "                            {'params': filter(lambda p: p.requires_grad, self.model.parameters()), 'lr': network_lr}],\n",
    "                                    momentum=0.9, weight_decay=1e-4)\n",
    "        self.unfreeze_all_weights()\n",
    "        \n",
    "        start = 0\n",
    "        policy_idx = self.model.next_policy_idx(-1)\n",
    "        tau = start_tau\n",
    "        if reload is not None and savePath is not None:\n",
    "            state = torch.load(savePath + reload)\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            if 'layerwise_policy_train' in reload:\n",
    "#                 optimizer.load_state_dict(state['optimizer'])\n",
    "                start = state['iter'] + 1 \n",
    "                policy_idx = state['policy_idx']\n",
    "                tau = state['tau']\n",
    "            \n",
    "        ######################################################################################\n",
    "#         self.model.transfer_weight_after_pretrain() # copy backbone weights to specific weights\n",
    "        ######################################################################################\n",
    "        \n",
    "        # Step 2: Set task training iters and policy_update_iters\n",
    "        if task_iters is None or len(task_iters) != len(self.tasks):\n",
    "            task_iters = tuple([100] * len(self.tasks))\n",
    "#         self.policy_update_iters = sum(task_iters)\n",
    "        \n",
    "        for i in range(start, iters):\n",
    "            # Step 3: Check whether to train the next policy \n",
    "            if tau < 1e-2: # For fixed-layerwise\n",
    "#             if (i+1) % self.next_policy_iters == 0 and policy_idx < self.model.max_policy_idx(): # For Adashare-layerwise\n",
    "                # Fixed the current policy parameters # For fixed-layerwise\n",
    "                self.freeze_layerwise_policy(policy_idx) \n",
    "                print('current policy:')\n",
    "                for task in self.tasks:\n",
    "                    print('task: ' + task)\n",
    "                    print(self.model.current_policy(policy_idx,task))\n",
    "\n",
    "                # Go to the next policy idx\n",
    "                policy_idx = self.model.next_policy_idx(policy_idx)\n",
    "                print('policy_idx change to: ' + str(policy_idx))\n",
    "                # Reset tau\n",
    "                tau = start_tau # For fixed-layerwise\n",
    "            \n",
    "            # Step 4: Train network and policy jointly\n",
    "            #         Train tasks alternatively\n",
    "            task_idx = self.which_task(i, task_iters)\n",
    "            self.train_step_task_with_reg('layerwise_policy_train', self.tasks[task_idx], optimizer,tau=tau, \n",
    "                                          policy_idx=policy_idx, scale=policy_scale, loss_lambda=loss_lambda)\n",
    "\n",
    "            # Step 5: Update tau in policy every self.policy_update_iters\n",
    "            #         If reach the end of the model, don't update anymore\n",
    "            if (i+1) % self.policy_update_iters == 0 and policy_idx < self.model.max_policy_idx(): # For fixed-layerwise\n",
    "#             if (i+1) % self.policy_update_iters == 0 and tau > 1e-6: # For Adashare-layerwise\n",
    "                tau = tau * tau_ratio\n",
    "                print('tau: ' + str(tau))\n",
    "\n",
    "            # Step 6: Print loss\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss_with_reg(i, writer)\n",
    "                self.reset_train_loss()\n",
    "            \n",
    "            # Step 7: Validation\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                self.validate('layerwise_policy_train', i, tau=tau, hard=True, writer=writer, policy_idx=policy_idx)\n",
    "                self.model.train()\n",
    "                \n",
    "            # Step 8: Save model\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    state = {'iter': i,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            'tau': tau,\n",
    "                            'policy_idx': policy_idx}\n",
    "                    self.save_model(state, 'layerwise_policy_train', savePath)\n",
    "                    \n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss_data_iter()\n",
    "        return\n",
    "    \n",
    "    def task_alter_train_with_reg(self, iters, task_iters=None, policy_lr=0.01, network_lr=0.0001, \n",
    "                                   tau=5, tau_ratio=0.965,\n",
    "                                   policy_scale=6, loss_lambda=1.0, \n",
    "                                   writerPath=None, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        if writerPath != None:\n",
    "            writer = SummaryWriter(log_dir=writerPath+'task_alter_train/')\n",
    "        else:\n",
    "            writer = None\n",
    "        \n",
    "        # Step 1: Set optimizer\n",
    "        self.freeze_policy()\n",
    "        optimizer = torch.optim.SGD([{'params': filter(lambda p: p.requires_grad==False, self.model.parameters()), 'lr': policy_lr},\n",
    "                                     {'params': filter(lambda p: p.requires_grad, self.model.parameters()), 'lr': network_lr}],\n",
    "                                      momentum=0.9, weight_decay=1e-4)\n",
    "        self.unfreeze_all_weights()\n",
    "        \n",
    "        start = 0\n",
    "        if reload is not None and savePath is not None:\n",
    "            state = torch.load(savePath + reload)\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            if 'task_alter_train' in reload:\n",
    "#                 optimizer.load_state_dict(state['optimizer'])\n",
    "                tau = state['tau']\n",
    "                start = state['iter'] + 1 \n",
    "        \n",
    "        # Step 2: Set task training iters\n",
    "        if task_iters is None or len(task_iters) != len(self.tasks):\n",
    "            task_iters = tuple([100] * len(self.tasks))\n",
    "        \n",
    "        for i in range(start, iters):\n",
    "            # Step 2-1: Train network and policy jointly\n",
    "            task_idx = self.which_task(i, task_iters)\n",
    "            self.train_step_task_with_reg('mtl', self.tasks[task_idx], optimizer, tau=tau, scale=policy_scale, loss_lambda=loss_lambda)\n",
    "\n",
    "            # Step 3: Update tau in policy every self.policy_update_iters\n",
    "            if (i+1) % self.policy_update_iters == 0 and tau > 1e-6:\n",
    "                tau = tau * 0.965\n",
    "                print('tau: ' + str(tau))\n",
    "                count = 0\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if 'policy' in name and count < 16 and not self.model.net[int(name.split('.')[1])].assumeSp:\n",
    "                        print(name, param)\n",
    "                        count += 1\n",
    "\n",
    "            # Step 4: Print loss\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss_with_reg(i, writer)\n",
    "                self.reset_train_loss()\n",
    "            \n",
    "            # Step 5: Validation\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                self.validate('mtl', i, tau=tau, hard=True, writer=writer)\n",
    "                self.model.train()\n",
    "                \n",
    "            # Step 6: Save model\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    state = {'iter': i,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            'tau': tau}\n",
    "                    self.save_model(state, 'task_alter_train', savePath)\n",
    "                    \n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss_data_iter()\n",
    "        return\n",
    "    \n",
    "    def alter_train_with_reg(self, iters, network_policy_iters=(400,100), policy_lr=0.01, network_lr=0.0001, \n",
    "                             tau=5, tau_ratio=0.965,\n",
    "                             policy_scale=6, loss_lambda=1.0,\n",
    "                             writerPath=None, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        # Key point: set two optimizers, one for the model, one for the policy\n",
    "        if writerPath != None:\n",
    "            writer = SummaryWriter(log_dir=writerPath+'alter_train/')\n",
    "        else:\n",
    "            writer = None\n",
    "        \n",
    "        # Step 1: Get the two optimizers for network and policy respectively\n",
    "        self.freeze_policy()\n",
    "        policy_op = torch.optim.Adam(filter(lambda p: p.requires_grad==False, self.model.parameters()), lr=policy_lr, weight_decay=5*1e-4)\n",
    "        network_op = torch.optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()), lr=network_lr, momentum=0.9, weight_decay=1e-4)\n",
    "        self.unfreeze_all_weights()\n",
    "        start = 0\n",
    "        if reload is not None and savePath is not None:\n",
    "            state = torch.load(savePath + reload)\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            if 'alter_train' in reload:\n",
    "#                 policy_op.load_state_dict(state['policy_op'])\n",
    "#                 network_op.load_state_dict(state['network_op'])\n",
    "                tau = state['tau']\n",
    "                start = state['iter'] + 1       \n",
    "        \n",
    "        # Step 2: Train network and policy alternatively\n",
    "        policy_count = 0\n",
    "        for i in range(start, iters):\n",
    "            # Step 2-1: Train network when the current iter is in the first part of network_policy_iters\n",
    "            if i % (network_policy_iters[0] + network_policy_iters[1]) in range(network_policy_iters[0]):\n",
    "                self.train_step_with_reg('mtl', network_op, tau=tau, scale=policy_scale, loss_lambda=loss_lambda)\n",
    "\n",
    "#                 print('Train Network:')\n",
    "#                 self.print_train_loss(i, writer)\n",
    "\n",
    "            # Step 2-2: Train policy when the current iter is in the second part of network_policy_iters\n",
    "            else:\n",
    "                self.train_step_with_reg('mtl', policy_op, tau=tau,loss_lambda=loss_lambda)\n",
    "                policy_count += 1\n",
    "\n",
    "#                 print('Train Policy:')\n",
    "#                 self.print_train_loss(i, writer)\n",
    "\n",
    "            # Step 3: Update tau in policy every self.policy_update_iters\n",
    "            if policy_count > self.policy_update_iters and tau > 1e-6:\n",
    "                tau = tau * tau_ratio\n",
    "                print('tau: ' + str(tau))\n",
    "                policy_count = 0\n",
    "\n",
    "            # Step 4: Print loss\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss_with_reg(i, writer)\n",
    "                self.reset_train_loss()\n",
    "            \n",
    "            # Step 5: Validation\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                self.validate('mtl', i, tau=tau, writer=writer)\n",
    "                self.model.train()\n",
    "                \n",
    "            # Step 6: Save model\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    state = {'iter': i,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'policy_op': policy_op.state_dict(),\n",
    "                            'network_op': network_op.state_dict(),\n",
    "                            'tau': tau}\n",
    "                    self.save_model(state, 'alter_train', savePath)\n",
    "                    \n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss_data_iter()\n",
    "        return\n",
    "    \n",
    "    # Helper Functions\n",
    "    def train_step_with_reg(self, stage, optimizer, schedular=None, \n",
    "                            tau=1, hard=False, \n",
    "                            policy_idx=None, scale=6, loss_lambda=1.0):\n",
    "        # Function: Train one iter for each task \n",
    "        for task in self.tasks:\n",
    "            try:\n",
    "                data = next(self.train_iter_dict[task])\n",
    "            except StopIteration:\n",
    "                self.train_iter_dict[task] = iter(self.train_dataloader_dict[task])\n",
    "                continue\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            x = data['input'].cuda()\n",
    "            y = data['label'].cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(x, stage, task, tau, hard, policy_idx)\n",
    "            if 'mask' in data:\n",
    "                tloss = self.criterion_dict[task](output, y, data['mask'].cuda())\n",
    "            else:\n",
    "                tloss = self.criterion_dict[task](output, y)\n",
    "            \n",
    "            regloss = self.model.policy_reg(task, policy_idx, tau, scale) # For fixed-layerwise\n",
    "#             regloss = self.model.policy_reg_so_far(task, policy_idx, tau, scale) # For Adashare-layerwise\n",
    "            if isinstance(loss_lambda, dict):\n",
    "                loss = loss_lambda[task] * tloss + loss_lambda['policy'] * regloss\n",
    "            elif isinstance(loss_lambda, float):\n",
    "                loss = tloss + loss_lambda * regloss\n",
    "            else:\n",
    "                sys.exit('Loss weights (lambda) should be in the type of dictionary or float.')\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            self.loss_list[task].append((tloss.item(), regloss.item(), loss.item()))  \n",
    "            \n",
    "        if schedular is not None:\n",
    "            scheduler.step()\n",
    "        return\n",
    "    \n",
    "    def train_step_task_with_reg(self, stage, task, optimizer, schedular=None, \n",
    "                                 tau=1, hard=False, \n",
    "                                 policy_idx=None, scale=6, loss_lambda=1.0):\n",
    "        # Function: Train one iter for one task \n",
    "        try:\n",
    "            data = next(self.train_iter_dict[task])\n",
    "        except StopIteration:\n",
    "            self.train_iter_dict[task] = iter(self.train_dataloader_dict[task])\n",
    "            return\n",
    "        except:\n",
    "            return\n",
    "\n",
    "        x = data['input'].cuda()\n",
    "        y = data['label'].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = self.model(x, stage, task, tau, hard, policy_idx)\n",
    "        if 'mask' in data:\n",
    "            tloss = self.criterion_dict[task](output, y, data['mask'].cuda())\n",
    "        else:\n",
    "            tloss = self.criterion_dict[task](output, y)\n",
    "        \n",
    "        regloss = self.model.policy_reg(task, policy_idx, tau, scale)\n",
    "        if isinstance(loss_lambda, dict):\n",
    "            loss = loss_lambda[task] * tloss + loss_lambda['policy'] * regloss\n",
    "        elif isinstance(loss_lambda, float):\n",
    "            loss = tloss + loss_lambda * regloss\n",
    "        else:\n",
    "            sys.exit('Loss weights (lambda) should be in the type of dictionary or float.')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        self.loss_list[task].append((tloss.item(), regloss.item(), loss.item()))  \n",
    "            \n",
    "        if schedular is not None:\n",
    "            scheduler.step()\n",
    "        return\n",
    "    \n",
    "    def print_train_loss_with_reg(self, it, writer=None):\n",
    "        # Function: Print loss for each task\n",
    "        total_loss = 0\n",
    "        task_num = 0\n",
    "        \n",
    "        for task in self.tasks:\n",
    "            if self.loss_list[task]:\n",
    "                avg_tloss = np.mean([x[0] for x in self.loss_list[task]])\n",
    "                avg_regloss = np.mean([x[1] for x in self.loss_list[task]])\n",
    "                avg_loss = np.mean([x[2] for x in self.loss_list[task]])\n",
    "            else:\n",
    "                continue\n",
    "            total_loss += avg_loss\n",
    "            task_num += 1\n",
    "            if writer != None:\n",
    "                writer.add_scalar('Loss/train/' + task, avg_loss, it)\n",
    "            print('[Iter {} Task {}] Task Loss: {:.4f} Reg Loss: {:.4f} Train Loss: {:.4f}'.format((it+1), task[:4], avg_tloss, avg_regloss, avg_loss), flush=True)\n",
    "        print('[Iter {} Total] Train Loss: {:.4f}'.format((it+1), total_loss/task_num), flush=True)\n",
    "        print('======================================================================', flush=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer2(mtlmodel, trainDataloaderDict, valDataloaderDict, criterionDict, metricDict, \n",
    "                   val_iters=200, print_iters=200, policy_update_iters=100, next_policy_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 4.825\n",
      "tau: 4.656125\n",
      "[Iter 200 Task segm] Task Loss: 0.6813 Reg Loss: 0.2937 Train Loss: 0.6842\n",
      "[Iter 200 Task dept] Task Loss: 0.0209 Reg Loss: 0.2533 Train Loss: 0.0234\n",
      "[Iter 200 Total] Train Loss: 0.3538\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 0.6928\n",
      "{'mIoU': 0.5202, 'Pixel Acc': 0.6935, 'cmp': 0.1113}\n",
      "[Iter 200 Task dept] Val Loss: 0.0296\n",
      "{'abs_err': 0.0344, 'rel_err': 0.41, 'sigma_1.25': 42.4208, 'sigma_1.25^2': 71.2166, 'sigma_1.25^3': 82.9887, 'cmp': -0.3899}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "tau: 4.3359000031249995\n",
      "[Iter 400 Task segm] Task Loss: 0.6980 Reg Loss: 0.2512 Train Loss: 0.7005\n",
      "[Iter 400 Task dept] Task Loss: 0.0211 Reg Loss: 0.2797 Train Loss: 0.0239\n",
      "[Iter 400 Total] Train Loss: 0.3622\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 0.6911\n",
      "{'mIoU': 0.521, 'Pixel Acc': 0.6943, 'cmp': 0.1128}\n",
      "[Iter 400 Task dept] Val Loss: 0.0290\n",
      "{'abs_err': 0.0338, 'rel_err': 0.4015, 'sigma_1.25': 44.237, 'sigma_1.25^2': 72.3982, 'sigma_1.25^3': 84.1059, 'cmp': -0.3671}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "tau: 4.037698480410078\n",
      "[Iter 600 Task segm] Task Loss: 0.7422 Reg Loss: 0.3533 Train Loss: 0.7457\n",
      "[Iter 600 Task dept] Task Loss: 0.0211 Reg Loss: 0.2809 Train Loss: 0.0239\n",
      "[Iter 600 Total] Train Loss: 0.3848\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 0.7191\n",
      "{'mIoU': 0.5129, 'Pixel Acc': 0.6826, 'cmp': 0.0948}\n",
      "[Iter 600 Task dept] Val Loss: 0.0296\n",
      "{'abs_err': 0.0341, 'rel_err': 0.3997, 'sigma_1.25': 43.9492, 'sigma_1.25^2': 73.2933, 'sigma_1.25^3': 85.5164, 'cmp': -0.3655}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "tau: 3.7600057674198744\n",
      "[Iter 800 Task segm] Task Loss: 0.7031 Reg Loss: 0.2815 Train Loss: 0.7059\n",
      "[Iter 800 Task dept] Task Loss: 0.0210 Reg Loss: 0.2498 Train Loss: 0.0235\n",
      "[Iter 800 Total] Train Loss: 0.3647\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 0.6868\n",
      "{'mIoU': 0.5224, 'Pixel Acc': 0.6935, 'cmp': 0.1139}\n",
      "[Iter 800 Task dept] Val Loss: 0.0290\n",
      "{'abs_err': 0.0337, 'rel_err': 0.402, 'sigma_1.25': 44.7916, 'sigma_1.25^2': 71.8295, 'sigma_1.25^3': 83.8584, 'cmp': -0.3661}\n",
      "======================================================================\n",
      "tau: 3.6284055655601786\n",
      "policy_idx change to: 4\n",
      "tau: 3.501411370765572\n",
      "[Iter 1000 Task segm] Task Loss: 0.6449 Reg Loss: 0.2801 Train Loss: 0.6477\n",
      "[Iter 1000 Task dept] Task Loss: 0.0213 Reg Loss: 0.2774 Train Loss: 0.0241\n",
      "[Iter 1000 Total] Train Loss: 0.3359\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 0.6927\n",
      "{'mIoU': 0.52, 'Pixel Acc': 0.6914, 'cmp': 0.1096}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0279\n",
      "{'abs_err': 0.0321, 'rel_err': 0.3911, 'sigma_1.25': 47.9963, 'sigma_1.25^2': 73.6276, 'sigma_1.25^3': 85.3053, 'cmp': -0.3242}\n",
      "======================================================================\n",
      "tau: 3.3788619727887768\n",
      "tau: 3.2606018037411695\n",
      "[Iter 1200 Task segm] Task Loss: 0.7153 Reg Loss: 0.1801 Train Loss: 0.7171\n",
      "[Iter 1200 Task dept] Task Loss: 0.0211 Reg Loss: 0.2603 Train Loss: 0.0237\n",
      "[Iter 1200 Total] Train Loss: 0.3704\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 0.6914\n",
      "{'mIoU': 0.5185, 'Pixel Acc': 0.6926, 'cmp': 0.1085}\n",
      "[Iter 1200 Task dept] Val Loss: 0.0287\n",
      "{'abs_err': 0.0331, 'rel_err': 0.4028, 'sigma_1.25': 45.8408, 'sigma_1.25^2': 71.6629, 'sigma_1.25^3': 83.4777, 'cmp': -0.3583}\n",
      "======================================================================\n",
      "tau: 3.1464807406102286\n",
      "tau: 3.0363539146888705\n",
      "[Iter 1400 Task segm] Task Loss: 0.7062 Reg Loss: 0.3385 Train Loss: 0.7096\n",
      "[Iter 1400 Task dept] Task Loss: 0.0211 Reg Loss: 0.2890 Train Loss: 0.0240\n",
      "[Iter 1400 Total] Train Loss: 0.3668\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 0.7398\n",
      "{'mIoU': 0.5049, 'Pixel Acc': 0.6852, 'cmp': 0.0866}\n",
      "[Iter 1400 Task dept] Val Loss: 0.0269\n",
      "{'abs_err': 0.0311, 'rel_err': 0.3885, 'sigma_1.25': 50.2808, 'sigma_1.25^2': 74.7109, 'sigma_1.25^3': 85.6663, 'cmp': -0.3015}\n",
      "======================================================================\n",
      "tau: 2.93008152767476\n",
      "tau: 2.827528674206143\n",
      "[Iter 1600 Task segm] Task Loss: 0.7010 Reg Loss: 0.3361 Train Loss: 0.7044\n",
      "[Iter 1600 Task dept] Task Loss: 0.0211 Reg Loss: 0.2750 Train Loss: 0.0238\n",
      "[Iter 1600 Total] Train Loss: 0.3641\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 0.6854\n",
      "{'mIoU': 0.5228, 'Pixel Acc': 0.6919, 'cmp': 0.1133}\n",
      "[Iter 1600 Task dept] Val Loss: 0.0292\n",
      "{'abs_err': 0.034, 'rel_err': 0.4046, 'sigma_1.25': 44.1911, 'sigma_1.25^2': 71.2445, 'sigma_1.25^3': 83.2843, 'cmp': -0.3756}\n",
      "======================================================================\n",
      "tau: 2.728565170608928\n",
      "tau: 2.6330653896376153\n",
      "[Iter 1800 Task segm] Task Loss: 0.7236 Reg Loss: 0.2767 Train Loss: 0.7264\n",
      "[Iter 1800 Task dept] Task Loss: 0.0212 Reg Loss: 0.2921 Train Loss: 0.0241\n",
      "[Iter 1800 Total] Train Loss: 0.3752\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 0.7042\n",
      "{'mIoU': 0.5196, 'Pixel Acc': 0.6904, 'cmp': 0.1084}\n",
      "[Iter 1800 Task dept] Val Loss: 0.0265\n",
      "{'abs_err': 0.0306, 'rel_err': 0.3832, 'sigma_1.25': 50.8017, 'sigma_1.25^2': 74.7895, 'sigma_1.25^3': 86.0728, 'cmp': -0.2903}\n",
      "======================================================================\n",
      "tau: 2.5409081010002987\n",
      "policy_idx change to: 7\n",
      "tau: 2.451976317465288\n",
      "[Iter 2000 Task segm] Task Loss: 0.6788 Reg Loss: 0.3281 Train Loss: 0.6821\n",
      "[Iter 2000 Task dept] Task Loss: 0.0212 Reg Loss: 0.2735 Train Loss: 0.0240\n",
      "[Iter 2000 Total] Train Loss: 0.3530\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 0.6846\n",
      "{'mIoU': 0.5259, 'Pixel Acc': 0.6931, 'cmp': 0.118}\n",
      "[Iter 2000 Task dept] Val Loss: 0.0282\n",
      "{'abs_err': 0.0326, 'rel_err': 0.3947, 'sigma_1.25': 46.8602, 'sigma_1.25^2': 72.7259, 'sigma_1.25^3': 84.5498, 'cmp': -0.3395}\n",
      "======================================================================\n",
      "tau: 2.366157146354003\n",
      "tau: 2.2833416462316127\n",
      "[Iter 2200 Task segm] Task Loss: 0.6635 Reg Loss: 0.3458 Train Loss: 0.6670\n",
      "[Iter 2200 Task dept] Task Loss: 0.0207 Reg Loss: 0.3014 Train Loss: 0.0238\n",
      "[Iter 2200 Total] Train Loss: 0.3454\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 0.6911\n",
      "{'mIoU': 0.5213, 'Pixel Acc': 0.6879, 'cmp': 0.1088}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0307\n",
      "{'abs_err': 0.0356, 'rel_err': 0.4199, 'sigma_1.25': 41.2786, 'sigma_1.25^2': 69.1663, 'sigma_1.25^3': 81.4388, 'cmp': -0.4207}\n",
      "======================================================================\n",
      "tau: 2.2034246886135063\n",
      "tau: 2.1263048245120335\n",
      "[Iter 2400 Task segm] Task Loss: 0.7061 Reg Loss: 0.2725 Train Loss: 0.7088\n",
      "[Iter 2400 Task dept] Task Loss: 0.0209 Reg Loss: 0.3208 Train Loss: 0.0242\n",
      "[Iter 2400 Total] Train Loss: 0.3665\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 0.6885\n",
      "{'mIoU': 0.5252, 'Pixel Acc': 0.6919, 'cmp': 0.1164}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0295\n",
      "{'abs_err': 0.0341, 'rel_err': 0.408, 'sigma_1.25': 44.2217, 'sigma_1.25^2': 70.3344, 'sigma_1.25^3': 82.5111, 'cmp': -0.3824}\n",
      "======================================================================\n",
      "tau: 2.051884155654112\n",
      "tau: 1.9800682102062181\n",
      "[Iter 2600 Task segm] Task Loss: 0.6721 Reg Loss: 0.3255 Train Loss: 0.6754\n",
      "[Iter 2600 Task dept] Task Loss: 0.0209 Reg Loss: 0.2725 Train Loss: 0.0236\n",
      "[Iter 2600 Total] Train Loss: 0.3495\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 0.7185\n",
      "{'mIoU': 0.5163, 'Pixel Acc': 0.6821, 'cmp': 0.0987}\n",
      "[Iter 2600 Task dept] Val Loss: 0.0320\n",
      "{'abs_err': 0.0364, 'rel_err': 0.4203, 'sigma_1.25': 40.1762, 'sigma_1.25^2': 69.1105, 'sigma_1.25^3': 81.9767, 'cmp': -0.4329}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 1.9107658228490005\n",
      "tau: 1.8438890190492854\n",
      "[Iter 2800 Task segm] Task Loss: 0.6382 Reg Loss: 0.4251 Train Loss: 0.6425\n",
      "[Iter 2800 Task dept] Task Loss: 0.0212 Reg Loss: 0.3016 Train Loss: 0.0242\n",
      "[Iter 2800 Total] Train Loss: 0.3333\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 0.6963\n",
      "{'mIoU': 0.5236, 'Pixel Acc': 0.6883, 'cmp': 0.112}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0314\n",
      "{'abs_err': 0.0361, 'rel_err': 0.4199, 'sigma_1.25': 40.9986, 'sigma_1.25^2': 68.6831, 'sigma_1.25^3': 81.3958, 'cmp': -0.4283}\n",
      "======================================================================\n",
      "tau: 1.7793529033825604\n",
      "policy_idx change to: 11\n",
      "tau: 1.7170755517641707\n",
      "[Iter 3000 Task segm] Task Loss: 0.6676 Reg Loss: 0.5155 Train Loss: 0.6727\n",
      "[Iter 3000 Task dept] Task Loss: 0.0208 Reg Loss: 0.3087 Train Loss: 0.0239\n",
      "[Iter 3000 Total] Train Loss: 0.3483\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 0.7548\n",
      "{'mIoU': 0.5052, 'Pixel Acc': 0.6714, 'cmp': 0.0777}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0343\n",
      "{'abs_err': 0.0389, 'rel_err': 0.4375, 'sigma_1.25': 35.8847, 'sigma_1.25^2': 66.8012, 'sigma_1.25^3': 80.2697, 'cmp': -0.4939}\n",
      "======================================================================\n",
      "tau: 1.6569779074524247\n",
      "tau: 1.5989836806915898\n",
      "[Iter 3200 Task segm] Task Loss: 0.6578 Reg Loss: 0.3710 Train Loss: 0.6615\n",
      "[Iter 3200 Task dept] Task Loss: 0.0207 Reg Loss: 0.3159 Train Loss: 0.0239\n",
      "[Iter 3200 Total] Train Loss: 0.3427\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 0.6864\n",
      "{'mIoU': 0.5288, 'Pixel Acc': 0.6943, 'cmp': 0.1224}\n",
      "[Iter 3200 Task dept] Val Loss: 0.0299\n",
      "{'abs_err': 0.0346, 'rel_err': 0.4123, 'sigma_1.25': 43.0076, 'sigma_1.25^2': 69.4705, 'sigma_1.25^3': 81.748, 'cmp': -0.3984}\n",
      "======================================================================\n",
      "tau: 1.5430192518673842\n",
      "tau: 1.4890135780520257\n",
      "[Iter 3400 Task segm] Task Loss: 0.6839 Reg Loss: 0.3702 Train Loss: 0.6876\n",
      "[Iter 3400 Task dept] Task Loss: 0.0207 Reg Loss: 0.3172 Train Loss: 0.0239\n",
      "[Iter 3400 Total] Train Loss: 0.3557\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 0.6769\n",
      "{'mIoU': 0.5317, 'Pixel Acc': 0.6958, 'cmp': 0.1271}\n",
      "[Iter 3400 Task dept] Val Loss: 0.0305\n",
      "{'abs_err': 0.0351, 'rel_err': 0.4168, 'sigma_1.25': 42.3436, 'sigma_1.25^2': 69.5007, 'sigma_1.25^3': 81.6476, 'cmp': -0.4086}\n",
      "======================================================================\n",
      "tau: 1.4368981028202048\n",
      "tau: 1.3866066692214976\n",
      "[Iter 3600 Task segm] Task Loss: 0.7023 Reg Loss: 0.2499 Train Loss: 0.7048\n",
      "[Iter 3600 Task dept] Task Loss: 0.0205 Reg Loss: 0.3619 Train Loss: 0.0241\n",
      "[Iter 3600 Total] Train Loss: 0.3645\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 0.7368\n",
      "{'mIoU': 0.5131, 'Pixel Acc': 0.6752, 'cmp': 0.0902}\n",
      "[Iter 3600 Task dept] Val Loss: 0.0330\n",
      "{'abs_err': 0.0377, 'rel_err': 0.4358, 'sigma_1.25': 37.8957, 'sigma_1.25^2': 67.2143, 'sigma_1.25^3': 80.2429, 'cmp': -0.4722}\n",
      "======================================================================\n",
      "tau: 1.338075435798745\n",
      "tau: 1.2912427955457888\n",
      "[Iter 3800 Task segm] Task Loss: 0.7167 Reg Loss: 0.2597 Train Loss: 0.7193\n",
      "[Iter 3800 Task dept] Task Loss: 0.0210 Reg Loss: 0.3220 Train Loss: 0.0242\n",
      "[Iter 3800 Total] Train Loss: 0.3717\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 0.6839\n",
      "{'mIoU': 0.5294, 'Pixel Acc': 0.6931, 'cmp': 0.1224}\n",
      "[Iter 3800 Task dept] Val Loss: 0.0315\n",
      "{'abs_err': 0.0362, 'rel_err': 0.4234, 'sigma_1.25': 40.2913, 'sigma_1.25^2': 68.3534, 'sigma_1.25^3': 80.8882, 'cmp': -0.4365}\n",
      "======================================================================\n",
      "tau: 1.2460492977016862\n",
      "policy_idx change to: 14\n",
      "tau: 1.202437572282127\n",
      "[Iter 4000 Task segm] Task Loss: 0.7569 Reg Loss: 0.2995 Train Loss: 0.7599\n",
      "[Iter 4000 Task dept] Task Loss: 0.0207 Reg Loss: 0.3180 Train Loss: 0.0239\n",
      "[Iter 4000 Total] Train Loss: 0.3919\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 0.6767\n",
      "{'mIoU': 0.5331, 'Pixel Acc': 0.6957, 'cmp': 0.1287}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0315\n",
      "{'abs_err': 0.0362, 'rel_err': 0.4183, 'sigma_1.25': 40.1851, 'sigma_1.25^2': 69.0673, 'sigma_1.25^3': 81.7416, 'cmp': -0.4301}\n",
      "======================================================================\n",
      "tau: 1.1603522572522524\n",
      "tau: 1.1197399282484235\n",
      "[Iter 4200 Task dept] Task Loss: 0.0213 Reg Loss: 0.3362 Train Loss: 0.0246\n",
      "[Iter 4200 Total] Train Loss: 0.0246\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 0.6782\n",
      "{'mIoU': 0.4674, 'Pixel Acc': 0.695, 'cmp': 0.0465}\n",
      "[Iter 4200 Task dept] Val Loss: 0.0328\n",
      "{'abs_err': 0.0377, 'rel_err': 0.4262, 'sigma_1.25': 37.3861, 'sigma_1.25^2': 67.5669, 'sigma_1.25^3': 80.7098, 'cmp': -0.4655}\n",
      "======================================================================\n",
      "tau: 1.0805490307597287\n",
      "tau: 1.0427298146831383\n",
      "[Iter 4400 Task segm] Task Loss: 0.6991 Reg Loss: 0.2573 Train Loss: 0.7017\n",
      "[Iter 4400 Task dept] Task Loss: 0.0206 Reg Loss: 0.3700 Train Loss: 0.0243\n",
      "[Iter 4400 Total] Train Loss: 0.3630\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 0.6655\n",
      "{'mIoU': 0.5386, 'Pixel Acc': 0.6972, 'cmp': 0.1366}\n",
      "[Iter 4400 Task dept] Val Loss: 0.0300\n",
      "{'abs_err': 0.0345, 'rel_err': 0.4086, 'sigma_1.25': 43.04, 'sigma_1.25^2': 70.6673, 'sigma_1.25^3': 83.161, 'cmp': -0.3896}\n",
      "======================================================================\n",
      "tau: 1.0062342711692285\n",
      "tau: 0.9710160716783055\n",
      "[Iter 4600 Task segm] Task Loss: 0.7120 Reg Loss: 0.3710 Train Loss: 0.7157\n",
      "[Iter 4600 Task dept] Task Loss: 0.0208 Reg Loss: 0.3778 Train Loss: 0.0246\n",
      "[Iter 4600 Total] Train Loss: 0.3701\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 0.7027\n",
      "{'mIoU': 0.5256, 'Pixel Acc': 0.6925, 'cmp': 0.1173}\n",
      "[Iter 4600 Task dept] Val Loss: 0.0302\n",
      "{'abs_err': 0.0349, 'rel_err': 0.4138, 'sigma_1.25': 42.6074, 'sigma_1.25^2': 69.4615, 'sigma_1.25^3': 81.7359, 'cmp': -0.4039}\n",
      "======================================================================\n",
      "tau: 0.9370305091695648\n",
      "tau: 0.90423444134863\n",
      "[Iter 4800 Task segm] Task Loss: 0.6500 Reg Loss: 0.4198 Train Loss: 0.6542\n",
      "[Iter 4800 Task dept] Task Loss: 0.0209 Reg Loss: 0.3446 Train Loss: 0.0244\n",
      "[Iter 4800 Total] Train Loss: 0.3393\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 0.6717\n",
      "{'mIoU': 0.5389, 'Pixel Acc': 0.6962, 'cmp': 0.1363}\n",
      "[Iter 4800 Task dept] Val Loss: 0.0302\n",
      "{'abs_err': 0.0348, 'rel_err': 0.4095, 'sigma_1.25': 42.3907, 'sigma_1.25^2': 71.0332, 'sigma_1.25^3': 83.4619, 'cmp': -0.3932}\n",
      "======================================================================\n",
      "tau: 0.8725862359014279\n",
      "policy_idx change to: 18\n",
      "tau: 0.8420457176448779\n",
      "[Iter 5000 Task segm] Task Loss: 0.6369 Reg Loss: 0.5729 Train Loss: 0.6426\n",
      "[Iter 5000 Task dept] Task Loss: 0.0210 Reg Loss: 0.3647 Train Loss: 0.0246\n",
      "[Iter 5000 Total] Train Loss: 0.3336\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 0.6903\n",
      "{'mIoU': 0.4669, 'Pixel Acc': 0.6919, 'cmp': 0.0438}\n",
      "[Iter 5000 Task dept] Val Loss: 0.0318\n",
      "{'abs_err': 0.0365, 'rel_err': 0.4187, 'sigma_1.25': 39.5106, 'sigma_1.25^2': 68.79, 'sigma_1.25^3': 81.6176, 'cmp': -0.4363}\n",
      "======================================================================\n",
      "tau: 0.8125741175273071\n",
      "tau: 0.7841340234138513\n",
      "[Iter 5200 Task segm] Task Loss: 0.6356 Reg Loss: 0.2760 Train Loss: 0.6383\n",
      "[Iter 5200 Task dept] Task Loss: 0.0209 Reg Loss: 0.3660 Train Loss: 0.0246\n",
      "[Iter 5200 Total] Train Loss: 0.3315\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 0.6962\n",
      "{'mIoU': 0.534, 'Pixel Acc': 0.6948, 'cmp': 0.1293}\n",
      "[Iter 5200 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0315, 'rel_err': 0.3888, 'sigma_1.25': 49.0669, 'sigma_1.25^2': 73.9568, 'sigma_1.25^3': 85.5101, 'cmp': -0.3117}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 0.7566893325943664\n",
      "tau: 0.7302052059535636\n",
      "[Iter 5400 Task segm] Task Loss: 0.6720 Reg Loss: 0.4058 Train Loss: 0.6760\n",
      "[Iter 5400 Task dept] Task Loss: 0.0208 Reg Loss: 0.3733 Train Loss: 0.0246\n",
      "[Iter 5400 Total] Train Loss: 0.3503\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 0.6916\n",
      "{'mIoU': 0.5319, 'Pixel Acc': 0.6931, 'cmp': 0.1255}\n",
      "[Iter 5400 Task dept] Val Loss: 0.0265\n",
      "{'abs_err': 0.0307, 'rel_err': 0.3821, 'sigma_1.25': 50.9987, 'sigma_1.25^2': 75.7859, 'sigma_1.25^3': 86.8668, 'cmp': -0.2855}\n",
      "======================================================================\n",
      "tau: 0.7046480237451889\n",
      "tau: 0.6799853429141073\n",
      "[Iter 5600 Task segm] Task Loss: 0.6835 Reg Loss: 0.5117 Train Loss: 0.6886\n",
      "[Iter 5600 Task dept] Task Loss: 0.0210 Reg Loss: 0.3884 Train Loss: 0.0249\n",
      "[Iter 5600 Total] Train Loss: 0.3568\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 0.6874\n",
      "{'mIoU': 0.5326, 'Pixel Acc': 0.6962, 'cmp': 0.1285}\n",
      "[Iter 5600 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0315, 'rel_err': 0.3855, 'sigma_1.25': 49.5003, 'sigma_1.25^2': 75.0749, 'sigma_1.25^3': 86.2862, 'cmp': -0.305}\n",
      "======================================================================\n",
      "tau: 0.6561858559121135\n",
      "tau: 0.6332193509551896\n",
      "[Iter 5800 Task segm] Task Loss: 0.7233 Reg Loss: 0.5853 Train Loss: 0.7291\n",
      "[Iter 5800 Task dept] Task Loss: 0.0209 Reg Loss: 0.3751 Train Loss: 0.0246\n",
      "[Iter 5800 Total] Train Loss: 0.3769\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 0.6728\n",
      "{'mIoU': 0.5387, 'Pixel Acc': 0.6981, 'cmp': 0.1374}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0276\n",
      "{'abs_err': 0.032, 'rel_err': 0.3912, 'sigma_1.25': 47.9921, 'sigma_1.25^2': 74.0608, 'sigma_1.25^3': 85.7155, 'cmp': -0.3216}\n",
      "======================================================================\n",
      "tau: 0.6110566736717579\n",
      "policy_idx change to: 21\n",
      "tau: 0.5896696900932463\n",
      "[Iter 6000 Task segm] Task Loss: 0.6347 Reg Loss: 0.4504 Train Loss: 0.6393\n",
      "[Iter 6000 Task dept] Task Loss: 0.0211 Reg Loss: 0.3925 Train Loss: 0.0250\n",
      "[Iter 6000 Total] Train Loss: 0.3321\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 0.6791\n",
      "{'mIoU': 0.5327, 'Pixel Acc': 0.6947, 'cmp': 0.1275}\n",
      "[Iter 6000 Task dept] Val Loss: 0.0277\n",
      "{'abs_err': 0.032, 'rel_err': 0.3887, 'sigma_1.25': 48.1508, 'sigma_1.25^2': 74.8772, 'sigma_1.25^3': 86.4077, 'cmp': -0.3164}\n",
      "======================================================================\n",
      "tau: 0.5690312509399826\n",
      "tau: 0.5491151571570833\n",
      "[Iter 6200 Task segm] Task Loss: 0.7261 Reg Loss: 0.5009 Train Loss: 0.7311\n",
      "[Iter 6200 Task dept] Task Loss: 0.0208 Reg Loss: 0.3884 Train Loss: 0.0247\n",
      "[Iter 6200 Total] Train Loss: 0.3779\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 0.6767\n",
      "{'mIoU': 0.5332, 'Pixel Acc': 0.6953, 'cmp': 0.1286}\n",
      "[Iter 6200 Task dept] Val Loss: 0.0294\n",
      "{'abs_err': 0.034, 'rel_err': 0.3989, 'sigma_1.25': 43.9547, 'sigma_1.25^2': 72.0454, 'sigma_1.25^3': 84.4484, 'cmp': -0.3684}\n",
      "======================================================================\n",
      "tau: 0.5298961266565854\n",
      "tau: 0.5113497622236048\n",
      "[Iter 6400 Task segm] Task Loss: 0.6823 Reg Loss: 0.5364 Train Loss: 0.6876\n",
      "[Iter 6400 Task dept] Task Loss: 0.0212 Reg Loss: 0.3705 Train Loss: 0.0249\n",
      "[Iter 6400 Total] Train Loss: 0.3563\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 0.6991\n",
      "{'mIoU': 0.4594, 'Pixel Acc': 0.6888, 'cmp': 0.0325}\n",
      "[Iter 6400 Task dept] Val Loss: 0.0308\n",
      "{'abs_err': 0.0354, 'rel_err': 0.4102, 'sigma_1.25': 41.4603, 'sigma_1.25^2': 70.2267, 'sigma_1.25^3': 82.7589, 'cmp': -0.407}\n",
      "======================================================================\n",
      "tau: 0.49345252054577865\n",
      "tau: 0.4761816823266764\n",
      "[Iter 6600 Task segm] Task Loss: 0.6555 Reg Loss: 0.4714 Train Loss: 0.6603\n",
      "[Iter 6600 Task dept] Task Loss: 0.0208 Reg Loss: 0.3700 Train Loss: 0.0245\n",
      "[Iter 6600 Total] Train Loss: 0.3424\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 0.6925\n",
      "{'mIoU': 0.4624, 'Pixel Acc': 0.69, 'cmp': 0.0369}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0322\n",
      "{'abs_err': 0.037, 'rel_err': 0.4237, 'sigma_1.25': 38.2036, 'sigma_1.25^2': 68.2652, 'sigma_1.25^3': 81.0951, 'cmp': -0.4512}\n",
      "======================================================================\n",
      "tau: 0.4595153234452427\n",
      "tau: 0.4434322871246592\n",
      "[Iter 6800 Task segm] Task Loss: 0.6781 Reg Loss: 0.3601 Train Loss: 0.6817\n",
      "[Iter 6800 Task dept] Task Loss: 0.0212 Reg Loss: 0.3923 Train Loss: 0.0251\n",
      "[Iter 6800 Total] Train Loss: 0.3534\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 0.7013\n",
      "{'mIoU': 0.5203, 'Pixel Acc': 0.6864, 'cmp': 0.1066}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0302\n",
      "{'abs_err': 0.0347, 'rel_err': 0.402, 'sigma_1.25': 43.0361, 'sigma_1.25^2': 71.7856, 'sigma_1.25^3': 84.3678, 'cmp': -0.3822}\n",
      "======================================================================\n",
      "tau: 0.4279121570752961\n",
      "policy_idx change to: 25\n",
      "tau: 0.41293523157766077\n",
      "[Iter 7000 Task segm] Task Loss: 0.6691 Reg Loss: 0.4843 Train Loss: 0.6740\n",
      "[Iter 7000 Task dept] Task Loss: 0.0208 Reg Loss: 0.3369 Train Loss: 0.0242\n",
      "[Iter 7000 Total] Train Loss: 0.3491\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 0.6836\n",
      "{'mIoU': 0.4587, 'Pixel Acc': 0.6923, 'cmp': 0.034}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0320\n",
      "{'abs_err': 0.0366, 'rel_err': 0.419, 'sigma_1.25': 39.4649, 'sigma_1.25^2': 68.5252, 'sigma_1.25^3': 80.9911, 'cmp': -0.4397}\n",
      "======================================================================\n",
      "tau: 0.3984824984724426\n",
      "tau: 0.3845356110259071\n",
      "[Iter 7200 Task segm] Task Loss: 0.6457 Reg Loss: 0.3514 Train Loss: 0.6492\n",
      "[Iter 7200 Task dept] Task Loss: 0.0206 Reg Loss: 0.4437 Train Loss: 0.0250\n",
      "[Iter 7200 Total] Train Loss: 0.3371\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 0.6768\n",
      "{'mIoU': 0.5335, 'Pixel Acc': 0.6973, 'cmp': 0.1303}\n",
      "[Iter 7200 Task dept] Val Loss: 0.0293\n",
      "{'abs_err': 0.0338, 'rel_err': 0.399, 'sigma_1.25': 44.4309, 'sigma_1.25^2': 73.0422, 'sigma_1.25^3': 84.6766, 'cmp': -0.3623}\n",
      "======================================================================\n",
      "tau: 0.37107686464000034\n",
      "tau: 0.3580891743776003\n",
      "[Iter 7400 Task segm] Task Loss: 0.6583 Reg Loss: 0.6796 Train Loss: 0.6651\n",
      "[Iter 7400 Task dept] Task Loss: 0.0209 Reg Loss: 0.4637 Train Loss: 0.0256\n",
      "[Iter 7400 Total] Train Loss: 0.3454\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 0.6816\n",
      "{'mIoU': 0.5327, 'Pixel Acc': 0.693, 'cmp': 0.1264}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0298\n",
      "{'abs_err': 0.0344, 'rel_err': 0.4045, 'sigma_1.25': 43.2337, 'sigma_1.25^2': 71.9251, 'sigma_1.25^3': 84.2933, 'cmp': -0.3789}\n",
      "======================================================================\n",
      "tau: 0.34555605327438427\n",
      "tau: 0.3334615914097808\n",
      "[Iter 7600 Task segm] Task Loss: 0.6375 Reg Loss: 0.2735 Train Loss: 0.6402\n",
      "[Iter 7600 Task dept] Task Loss: 0.0208 Reg Loss: 0.3973 Train Loss: 0.0248\n",
      "[Iter 7600 Total] Train Loss: 0.3325\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 0.7426\n",
      "{'mIoU': 0.5087, 'Pixel Acc': 0.673, 'cmp': 0.0832}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0331\n",
      "{'abs_err': 0.0376, 'rel_err': 0.4211, 'sigma_1.25': 36.5154, 'sigma_1.25^2': 69.5719, 'sigma_1.25^3': 82.9862, 'cmp': -0.4551}\n",
      "======================================================================\n",
      "tau: 0.32179043571043847\n",
      "tau: 0.3105277704605731\n",
      "[Iter 7800 Task segm] Task Loss: 0.6867 Reg Loss: 0.4328 Train Loss: 0.6911\n",
      "[Iter 7800 Task dept] Task Loss: 0.0210 Reg Loss: 0.4473 Train Loss: 0.0255\n",
      "[Iter 7800 Total] Train Loss: 0.3583\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 0.6870\n",
      "{'mIoU': 0.5195, 'Pixel Acc': 0.6925, 'cmp': 0.1096}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs_err': 0.0343, 'rel_err': 0.4022, 'sigma_1.25': 43.2896, 'sigma_1.25^2': 72.4604, 'sigma_1.25^3': 84.6234, 'cmp': -0.3744}\n",
      "======================================================================\n",
      "tau: 0.29965929849445305\n",
      "policy_idx change to: 27\n",
      "tau: 0.2891712230471472\n",
      "[Iter 8000 Task segm] Task Loss: 0.6449 Reg Loss: 0.3172 Train Loss: 0.6481\n",
      "[Iter 8000 Task dept] Task Loss: 0.0209 Reg Loss: 0.3684 Train Loss: 0.0246\n",
      "[Iter 8000 Total] Train Loss: 0.3363\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 0.6806\n",
      "{'mIoU': 0.4596, 'Pixel Acc': 0.6922, 'cmp': 0.0349}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0319\n",
      "{'abs_err': 0.0365, 'rel_err': 0.4149, 'sigma_1.25': 38.9431, 'sigma_1.25^2': 69.8393, 'sigma_1.25^3': 82.7661, 'cmp': -0.431}\n",
      "======================================================================\n",
      "tau: 0.279050230240497\n",
      "tau: 0.2692834721820796\n",
      "[Iter 8200 Task segm] Task Loss: 0.6860 Reg Loss: 0.5178 Train Loss: 0.6912\n",
      "[Iter 8200 Task dept] Task Loss: 0.0210 Reg Loss: 0.4125 Train Loss: 0.0251\n",
      "[Iter 8200 Total] Train Loss: 0.3581\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 0.6790\n",
      "{'mIoU': 0.4652, 'Pixel Acc': 0.6942, 'cmp': 0.0432}\n",
      "[Iter 8200 Task dept] Val Loss: 0.0305\n",
      "{'abs_err': 0.0349, 'rel_err': 0.4097, 'sigma_1.25': 42.0322, 'sigma_1.25^2': 71.2219, 'sigma_1.25^3': 83.5824, 'cmp': -0.3951}\n",
      "======================================================================\n",
      "tau: 0.2598585506557068\n",
      "tau: 0.25076350138275705\n",
      "[Iter 8400 Task dept] Task Loss: 0.0206 Reg Loss: 0.3843 Train Loss: 0.0245\n",
      "[Iter 8400 Total] Train Loss: 0.0245\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 0.6954\n",
      "{'mIoU': 0.4594, 'Pixel Acc': 0.6887, 'cmp': 0.0324}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0294\n",
      "{'abs_err': 0.0339, 'rel_err': 0.3979, 'sigma_1.25': 44.3133, 'sigma_1.25^2': 73.4194, 'sigma_1.25^3': 85.4818, 'cmp': -0.3603}\n",
      "======================================================================\n",
      "tau: 0.24198677883436054\n",
      "tau: 0.2335172415751579\n",
      "[Iter 8600 Task segm] Task Loss: 0.6702 Reg Loss: 0.4922 Train Loss: 0.6752\n",
      "[Iter 8600 Task dept] Task Loss: 0.0209 Reg Loss: 0.4894 Train Loss: 0.0258\n",
      "[Iter 8600 Total] Train Loss: 0.3505\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 0.6688\n",
      "{'mIoU': 0.5382, 'Pixel Acc': 0.6957, 'cmp': 0.135}\n",
      "[Iter 8600 Task dept] Val Loss: 0.0308\n",
      "{'abs_err': 0.0353, 'rel_err': 0.413, 'sigma_1.25': 41.0249, 'sigma_1.25^2': 70.8817, 'sigma_1.25^3': 83.2513, 'cmp': -0.4066}\n",
      "======================================================================\n",
      "tau: 0.22534413812002738\n",
      "tau: 0.2174570932858264\n",
      "[Iter 8800 Task segm] Task Loss: 0.7173 Reg Loss: 0.3448 Train Loss: 0.7208\n",
      "[Iter 8800 Task dept] Task Loss: 0.0206 Reg Loss: 0.4604 Train Loss: 0.0252\n",
      "[Iter 8800 Total] Train Loss: 0.3730\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 0.6748\n",
      "{'mIoU': 0.5291, 'Pixel Acc': 0.6972, 'cmp': 0.1247}\n",
      "[Iter 8800 Task dept] Val Loss: 0.0288\n",
      "{'abs_err': 0.0333, 'rel_err': 0.3919, 'sigma_1.25': 45.3859, 'sigma_1.25^2': 74.8247, 'sigma_1.25^3': 86.5211, 'cmp': -0.3408}\n",
      "======================================================================\n",
      "tau: 0.20984609502082247\n",
      "policy_idx change to: 30\n",
      "tau: 0.20250148169509366\n",
      "[Iter 9000 Task segm] Task Loss: 0.6758 Reg Loss: 0.5872 Train Loss: 0.6817\n",
      "[Iter 9000 Task dept] Task Loss: 0.0208 Reg Loss: 0.3932 Train Loss: 0.0248\n",
      "[Iter 9000 Total] Train Loss: 0.3532\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 0.6577\n",
      "{'mIoU': 0.4732, 'Pixel Acc': 0.7001, 'cmp': 0.0571}\n",
      "[Iter 9000 Task dept] Val Loss: 0.0292\n",
      "{'abs_err': 0.0337, 'rel_err': 0.3999, 'sigma_1.25': 44.6691, 'sigma_1.25^2': 72.512, 'sigma_1.25^3': 84.5283, 'cmp': -0.3626}\n",
      "======================================================================\n",
      "tau: 0.1954139298357654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-083f305b849b>\", line 3, in <module>\n",
      "    savePath='checkpoints/Cityscapes_re/', reload='pre_train_24000iter.model')\n",
      "  File \"<ipython-input-4-26b7f59cd536>\", line 67, in layerwise_policy_train\n",
      "    policy_idx=policy_idx, scale=policy_scale, loss_lambda=loss_lambda)\n",
      "  File \"<ipython-input-4-26b7f59cd536>\", line 245, in train_step_task_with_reg\n",
      "    optimizer.step()\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/sgd.py\", line 106, in step\n",
      "    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Adashare style\n",
    "loss_lambda = {'segment_semantic': 1, 'depth_zbuffer': 1, 'policy':0.01}\n",
    "trainer.layerwise_policy_train(iters=50000, task_iters=(10,200), policy_lr=0.01, network_lr=0.0001, tau_ratio=0.965, loss_lambda=loss_lambda,\n",
    "                               savePath='checkpoints/Cityscapes_re/', reload='pre_train_24000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3ac19116e384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'segment_semantic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depth_zbuffer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'policy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer.layerwise_policy_train(iters=50000, task_iters=(10,200),policy_lr=0.01, network_lr=0.0001, tau_ratio=0.965, loss_lambda=loss_lambda,\n\u001b[0;32m----> 4\u001b[0;31m                                savePath='checkpoints/Cityscapes_re2/', reload='pre_train_24000iter.model')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0d4e083a99a7>\u001b[0m in \u001b[0;36mlayerwise_policy_train\u001b[0;34m(self, iters, task_iters, policy_lr, network_lr, start_tau, tau_ratio, policy_scale, loss_lambda, writerPath, savePath, reload)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtask_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             self.train_step_task_with_reg('layerwise_policy_train', self.tasks[task_idx], optimizer,tau=tau, \n\u001b[0;32m---> 67\u001b[0;31m                                           policy_idx=policy_idx, scale=policy_scale, loss_lambda=loss_lambda)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Step 5: Update tau in policy every self.policy_update_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0d4e083a99a7>\u001b[0m in \u001b[0;36mtrain_step_task_with_reg\u001b[0;34m(self, stage, task, optimizer, schedular, tau, hard, policy_idx, scale, loss_lambda)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss weights (lambda) should be in the type of dictionary or float.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fixed policy style\n",
    "loss_lambda = {'segment_semantic': 1, 'depth_zbuffer': 1, 'policy':0.001}\n",
    "trainer.layerwise_policy_train(iters=50000, task_iters=(10,200),policy_lr=0.01, network_lr=0.0001, tau_ratio=0.965, loss_lambda=loss_lambda,\n",
    "                               savePath='checkpoints/Cityscapes_re2/', reload='pre_train_24000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 4.825\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9620, 1.0361], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9792, 1.0190], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9859, 1.0123], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9894, 1.0088], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9871, 1.0111], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9930, 1.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9891, 1.0091], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9974, 1.0008], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([1., 1.], device='cuda:0', requires_grad=True)\n",
      "tau: 4.656125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9588, 1.0374], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9988, 0.9994], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9771, 1.0191], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9991, 0.9991], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9840, 1.0122], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9990, 0.9992], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9875, 1.0086], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9991, 0.9990], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9852, 1.0110], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9990, 0.9991], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9914, 1.0048], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9991, 0.9991], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9873, 1.0089], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9990, 0.9991], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9962, 1.0000], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9991, 0.9991], device='cuda:0', requires_grad=True)\n",
      "[Iter 200 Task segm] Task Loss: 0.4221 Reg Loss: 9.5780 Train Loss: 0.4221\n",
      "[Iter 200 Task dept] Task Loss: 0.0247 Reg Loss: 9.4434 Train Loss: 0.0247\n",
      "[Iter 200 Total] Train Loss: 0.2234\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 4.9951\n",
      "{'mIoU': 0.129, 'Pixel Acc': 0.3786, 'cmp': -0.5861}\n",
      "[Iter 200 Task dept] Val Loss: 0.0343\n",
      "{'abs_err': 0.0357, 'rel_err': 0.5523, 'sigma_1.25': 46.8783, 'sigma_1.25^2': 69.302, 'sigma_1.25^3': 80.9527, 'cmp': -0.4868}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9248, 1.0694], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9978, 0.9984], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9590, 1.0352], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9981, 0.9981], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9731, 1.0211], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9980, 0.9982], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9781, 1.0161], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9981, 0.9981], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9756, 1.0186], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9981, 0.9981], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9851, 1.0091], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9981, 0.9981], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9794, 1.0148], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9980, 0.9982], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9935, 1.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9981, 0.9981], device='cuda:0', requires_grad=True)\n",
      "tau: 4.3359000031249995\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9209, 1.0714], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9967, 0.9975], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9562, 1.0361], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9972, 0.9971], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9713, 1.0209], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9969, 0.9973], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9764, 1.0158], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9972, 0.9970], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9739, 1.0184], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9971, 0.9972], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9836, 1.0087], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9971, 0.9971], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9777, 1.0145], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9970, 0.9972], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9923, 0.9999], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9971, 0.9971], device='cuda:0', requires_grad=True)\n",
      "[Iter 400 Task segm] Task Loss: 0.4129 Reg Loss: 10.1089 Train Loss: 0.4129\n",
      "[Iter 400 Task dept] Task Loss: 0.0241 Reg Loss: 9.7055 Train Loss: 0.0241\n",
      "[Iter 400 Total] Train Loss: 0.2185\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 4.8203\n",
      "{'mIoU': 0.1262, 'Pixel Acc': 0.3763, 'cmp': -0.5912}\n",
      "[Iter 400 Task dept] Val Loss: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs_err': 0.0349, 'rel_err': 0.6381, 'sigma_1.25': 48.298, 'sigma_1.25^2': 68.6314, 'sigma_1.25^3': 79.952, 'cmp': -0.5298}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.8971, 1.0931], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9957, 0.9965], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9375, 1.0528], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9962, 0.9961], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9563, 1.0340], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9959, 0.9963], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9679, 1.0223], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9963, 0.9960], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9642, 1.0260], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9961, 0.9962], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9768, 1.0135], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9961, 0.9961], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9692, 1.0211], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9961, 0.9962], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9895, 1.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9961, 0.9961], device='cuda:0', requires_grad=True)\n",
      "tau: 4.037698480410078\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.8928, 1.0954], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9947, 0.9956], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9346, 1.0537], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9953, 0.9949], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9542, 1.0340], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9948, 0.9955], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9659, 1.0223], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9952, 0.9951], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9622, 1.0261], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9951, 0.9952], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9753, 1.0130], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9952, 0.9951], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9676, 1.0206], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9950, 0.9952], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9883, 0.9999], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9951, 0.9951], device='cuda:0', requires_grad=True)\n",
      "[Iter 600 Task segm] Task Loss: 0.4026 Reg Loss: 10.0187 Train Loss: 0.4026\n",
      "[Iter 600 Task dept] Task Loss: 0.0241 Reg Loss: 9.6905 Train Loss: 0.0241\n",
      "[Iter 600 Total] Train Loss: 0.2134\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 4.9004\n",
      "{'mIoU': 0.1281, 'Pixel Acc': 0.3803, 'cmp': -0.586}\n",
      "[Iter 600 Task dept] Val Loss: 0.0361\n",
      "{'abs_err': 0.0365, 'rel_err': 0.6869, 'sigma_1.25': 46.6098, 'sigma_1.25^2': 67.4965, 'sigma_1.25^3': 78.8067, 'cmp': -0.5881}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.8653, 1.1210], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9936, 0.9946], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9166, 1.0696], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9944, 0.9939], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9422, 1.0440], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9938, 0.9945], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9563, 1.0300], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9942, 0.9941], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9523, 1.0340], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9941, 0.9942], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9675, 1.0187], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9942, 0.9941], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9594, 1.0268], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9940, 0.9942], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9857, 1.0006], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9941, 0.9942], device='cuda:0', requires_grad=True)\n",
      "tau: 3.7600057674198744\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.8618, 1.1225], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9924, 0.9939], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9131, 1.0713], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9936, 0.9927], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9398, 1.0445], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9927, 0.9936], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9546, 1.0297], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9932, 0.9931], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9505, 1.0339], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9931, 0.9932], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9660, 1.0183], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9932, 0.9931], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9576, 1.0267], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9931, 0.9932], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([0.9846, 0.9997], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.9931, 0.9932], device='cuda:0', requires_grad=True)\n",
      "[Iter 800 Task segm] Task Loss: 0.3993 Reg Loss: 10.1029 Train Loss: 0.3993\n",
      "[Iter 800 Task dept] Task Loss: 0.0236 Reg Loss: 9.8581 Train Loss: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 800 Total] Train Loss: 0.2115\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 3.9510\n",
      "{'mIoU': 0.1427, 'Pixel Acc': 0.4138, 'cmp': -0.5456}\n",
      "[Iter 800 Task dept] Val Loss: 0.0535\n",
      "{'abs_err': 0.0502, 'rel_err': 1.1976, 'sigma_1.25': 39.2014, 'sigma_1.25^2': 58.7068, 'sigma_1.25^3': 70.0101, 'cmp': -1.1187}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Task alter-train with reg - on whole training set\n",
    "loss_lambda = {'segment_semantic': 1, 'depth_zbuffer': 1, 'policy':0.00}\n",
    "trainer.task_alter_train_with_reg(iters=20000, task_iters=(100,100),policy_lr=0.01, network_lr=0.0001, \n",
    "                                  tau=5, tau_ratio=0.965, loss_lambda=loss_lambda,\n",
    "                                  savePath='checkpoints/Cityscapes/', reload='pre_train_72000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 4.825\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4541, 0.5450], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.5000, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4783, 0.5208], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.5000, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4927, 0.5064], device='cuda:0', requires_grad=True)\n",
      "tau: 4.656125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4521, 0.5461], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4987, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4764, 0.5217], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4985, 0.5006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4912, 0.5069], device='cuda:0', requires_grad=True)\n",
      "[Iter 200 Task segm] Task Loss: 0.6851 Reg Loss: 9.9181 Train Loss: 0.6851\n",
      "[Iter 200 Task dept] Task Loss: 0.0219 Reg Loss: 9.6551 Train Loss: 0.0219\n",
      "[Iter 200 Total] Train Loss: 0.3535\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 0.8756\n",
      "{'mIoU': 0.4132, 'Pixel Acc': 0.6541, 'cmp': -0.0482}\n",
      "[Iter 200 Task dept] Val Loss: 0.0265\n",
      "{'abs_err': 0.0287, 'rel_err': 0.4057, 'sigma_1.25': 53.4612, 'sigma_1.25^2': 74.6295, 'sigma_1.25^3': 85.5578, 'cmp': -0.275}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4411, 0.5561], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4982, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4686, 0.5285], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4980, 0.5002], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4872, 0.5100], device='cuda:0', requires_grad=True)\n",
      "tau: 4.3359000031249995\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4400, 0.5562], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4968, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4678, 0.5283], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4968, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4868, 0.5094], device='cuda:0', requires_grad=True)\n",
      "[Iter 400 Task segm] Task Loss: 0.6504 Reg Loss: 9.8392 Train Loss: 0.6504\n",
      "[Iter 400 Task dept] Task Loss: 0.0244 Reg Loss: 9.7897 Train Loss: 0.0244\n",
      "[Iter 400 Total] Train Loss: 0.3374\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 0.8307\n",
      "{'mIoU': 0.4276, 'Pixel Acc': 0.6596, 'cmp': -0.0267}\n",
      "[Iter 400 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0276, 'rel_err': 0.4377, 'sigma_1.25': 56.9377, 'sigma_1.25^2': 77.2817, 'sigma_1.25^3': 87.2763, 'cmp': -0.2622}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4258, 0.5694], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4963, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4622, 0.5331], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4963, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4842, 0.5110], device='cuda:0', requires_grad=True)\n",
      "tau: 4.037698480410078\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4246, 0.5696], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4953, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4616, 0.5326], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4952, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4842, 0.5101], device='cuda:0', requires_grad=True)\n",
      "[Iter 600 Task segm] Task Loss: 0.6556 Reg Loss: 9.8948 Train Loss: 0.6556\n",
      "[Iter 600 Task dept] Task Loss: 0.0225 Reg Loss: 9.8335 Train Loss: 0.0225\n",
      "[Iter 600 Total] Train Loss: 0.3391\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 0.8919\n",
      "{'mIoU': 0.427, 'Pixel Acc': 0.6539, 'cmp': -0.0312}\n",
      "[Iter 600 Task dept] Val Loss: 0.0292\n",
      "{'abs_err': 0.0271, 'rel_err': 0.4804, 'sigma_1.25': 59.1231, 'sigma_1.25^2': 78.1143, 'sigma_1.25^3': 87.7408, 'cmp': -0.2731}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4066, 0.5867], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4947, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4551, 0.5382], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4947, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4799, 0.5134], device='cuda:0', requires_grad=True)\n",
      "tau: 3.7600057674198744\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4051, 0.5872], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4938, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4545, 0.5378], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4937, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4794, 0.5129], device='cuda:0', requires_grad=True)\n",
      "[Iter 800 Task segm] Task Loss: 0.6489 Reg Loss: 9.9100 Train Loss: 0.6489\n",
      "[Iter 800 Task dept] Task Loss: 0.0223 Reg Loss: 10.1219 Train Loss: 0.0223\n",
      "[Iter 800 Total] Train Loss: 0.3356\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 0.7892\n",
      "{'mIoU': 0.3945, 'Pixel Acc': 0.6607, 'cmp': -0.0671}\n",
      "[Iter 800 Task dept] Val Loss: 0.0264\n",
      "{'abs_err': 0.026, 'rel_err': 0.4192, 'sigma_1.25': 59.5624, 'sigma_1.25^2': 78.0497, 'sigma_1.25^3': 87.7074, 'cmp': -0.2215}\n",
      "======================================================================\n",
      "tau: 3.6284055655601786\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3828, 0.6085], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4932, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4466, 0.5448], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4932, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4778, 0.5135], device='cuda:0', requires_grad=True)\n",
      "tau: 3.501411370765572\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3814, 0.6090], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4911, 0.5002], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4457, 0.5447], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4917, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4765, 0.5139], device='cuda:0', requires_grad=True)\n",
      "[Iter 1000 Task segm] Task Loss: 0.6390 Reg Loss: 10.0239 Train Loss: 0.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1000 Task dept] Task Loss: 0.0228 Reg Loss: 10.0611 Train Loss: 0.0228\n",
      "[Iter 1000 Total] Train Loss: 0.3309\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 0.8607\n",
      "{'mIoU': 0.3836, 'Pixel Acc': 0.6399, 'cmp': -0.0945}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0264\n",
      "{'abs_err': 0.0277, 'rel_err': 0.4331, 'sigma_1.25': 56.6233, 'sigma_1.25^2': 75.4476, 'sigma_1.25^3': 85.2392, 'cmp': -0.2693}\n",
      "======================================================================\n",
      "tau: 3.3788619727887768\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3683, 0.6211], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4905, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4413, 0.5481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4912, 0.4992], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4754, 0.5140], device='cuda:0', requires_grad=True)\n",
      "tau: 3.2606018037411695\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3667, 0.6218], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4895, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4411, 0.5473], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4900, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4748, 0.5136], device='cuda:0', requires_grad=True)\n",
      "[Iter 1200 Task segm] Task Loss: 0.6376 Reg Loss: 10.3656 Train Loss: 0.6376\n",
      "[Iter 1200 Task dept] Task Loss: 0.0221 Reg Loss: 10.1598 Train Loss: 0.0221\n",
      "[Iter 1200 Total] Train Loss: 0.3298\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 0.9007\n",
      "{'mIoU': 0.38, 'Pixel Acc': 0.6374, 'cmp': -0.1007}\n",
      "[Iter 1200 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0268, 'rel_err': 0.4347, 'sigma_1.25': 58.5188, 'sigma_1.25^2': 77.2117, 'sigma_1.25^3': 86.8642, 'cmp': -0.247}\n",
      "======================================================================\n",
      "tau: 3.1464807406102286\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3593, 0.6282], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4889, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4395, 0.5480], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4894, 0.4990], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4761, 0.5114], device='cuda:0', requires_grad=True)\n",
      "tau: 3.0363539146888705\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3578, 0.6287], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4874, 0.5001], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4388, 0.5477], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4882, 0.4993], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4754, 0.5111], device='cuda:0', requires_grad=True)\n",
      "[Iter 1400 Task segm] Task Loss: 0.6069 Reg Loss: 10.2331 Train Loss: 0.6069\n",
      "[Iter 1400 Task dept] Task Loss: 0.0223 Reg Loss: 10.5570 Train Loss: 0.0223\n",
      "[Iter 1400 Total] Train Loss: 0.3146\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 0.8063\n",
      "{'mIoU': 0.4034, 'Pixel Acc': 0.641, 'cmp': -0.0692}\n",
      "[Iter 1400 Task dept] Val Loss: 0.0258\n",
      "{'abs_err': 0.0259, 'rel_err': 0.4034, 'sigma_1.25': 58.4121, 'sigma_1.25^2': 77.0189, 'sigma_1.25^3': 87.0037, 'cmp': -0.2181}\n",
      "======================================================================\n",
      "tau: 2.93008152767476\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3386, 0.6470], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4869, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4354, 0.5502], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4876, 0.4989], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4751, 0.5105], device='cuda:0', requires_grad=True)\n",
      "tau: 2.827528674206143\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3368, 0.6478], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4859, 0.4997], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4350, 0.5496], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4863, 0.4993], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4750, 0.5096], device='cuda:0', requires_grad=True)\n",
      "[Iter 1600 Task segm] Task Loss: 0.6077 Reg Loss: 10.4720 Train Loss: 0.6077\n",
      "[Iter 1600 Task dept] Task Loss: 0.0226 Reg Loss: 10.4263 Train Loss: 0.0226\n",
      "[Iter 1600 Total] Train Loss: 0.3151\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 0.8703\n",
      "{'mIoU': 0.3772, 'Pixel Acc': 0.6261, 'cmp': -0.1118}\n",
      "[Iter 1600 Task dept] Val Loss: 0.0283\n",
      "{'abs_err': 0.026, 'rel_err': 0.4378, 'sigma_1.25': 60.9126, 'sigma_1.25^2': 79.5495, 'sigma_1.25^3': 88.7087, 'cmp': -0.2238}\n",
      "======================================================================\n",
      "tau: 2.728565170608928\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3236, 0.6601], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4855, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4333, 0.5504], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4858, 0.4988], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4779, 0.5057], device='cuda:0', requires_grad=True)\n",
      "tau: 2.6330653896376153\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3233, 0.6594], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4822, 0.5015], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4330, 0.5497], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4842, 0.4994], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4779, 0.5048], device='cuda:0', requires_grad=True)\n",
      "[Iter 1800 Task segm] Task Loss: 0.5919 Reg Loss: 10.5699 Train Loss: 0.5919\n",
      "[Iter 1800 Task dept] Task Loss: 0.0249 Reg Loss: 10.2650 Train Loss: 0.0249\n",
      "[Iter 1800 Total] Train Loss: 0.3084\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 0.8269\n",
      "{'mIoU': 0.3845, 'Pixel Acc': 0.6371, 'cmp': -0.0953}\n",
      "[Iter 1800 Task dept] Val Loss: 0.0296\n",
      "{'abs_err': 0.0278, 'rel_err': 0.4698, 'sigma_1.25': 58.7575, 'sigma_1.25^2': 76.9149, 'sigma_1.25^3': 86.4506, 'cmp': -0.2808}\n",
      "======================================================================\n",
      "tau: 2.5409081010002987\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3133, 0.6684], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4815, 0.5012], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4338, 0.5479], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4836, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4805, 0.5012], device='cuda:0', requires_grad=True)\n",
      "tau: 2.451976317465288\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3120, 0.6688], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4800, 0.5017], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4329, 0.5479], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4821, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4799, 0.5009], device='cuda:0', requires_grad=True)\n",
      "[Iter 2000 Task segm] Task Loss: 0.5895 Reg Loss: 10.5911 Train Loss: 0.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2000 Task dept] Task Loss: 0.0273 Reg Loss: 10.7401 Train Loss: 0.0273\n",
      "[Iter 2000 Total] Train Loss: 0.3084\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 0.8643\n",
      "{'mIoU': 0.3737, 'Pixel Acc': 0.6264, 'cmp': -0.116}\n",
      "[Iter 2000 Task dept] Val Loss: 0.0307\n",
      "{'abs_err': 0.0284, 'rel_err': 0.4758, 'sigma_1.25': 58.2884, 'sigma_1.25^2': 76.3268, 'sigma_1.25^3': 85.9661, 'cmp': -0.2952}\n",
      "======================================================================\n",
      "tau: 2.366157146354003\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2924, 0.6875], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4796, 0.5012], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4296, 0.5502], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4815, 0.4992], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4792, 0.5006], device='cuda:0', requires_grad=True)\n",
      "tau: 2.2833416462316127\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2927, 0.6861], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4768, 0.5030], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4290, 0.5498], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4795, 0.5003], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4792, 0.4997], device='cuda:0', requires_grad=True)\n",
      "[Iter 2200 Task segm] Task Loss: 0.5966 Reg Loss: 10.7100 Train Loss: 0.5966\n",
      "[Iter 2200 Task dept] Task Loss: 0.0227 Reg Loss: 11.2076 Train Loss: 0.0227\n",
      "[Iter 2200 Total] Train Loss: 0.3096\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 0.8372\n",
      "{'mIoU': 0.3961, 'Pixel Acc': 0.6369, 'cmp': -0.081}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0283\n",
      "{'abs_err': 0.0264, 'rel_err': 0.4129, 'sigma_1.25': 59.1377, 'sigma_1.25^2': 77.8036, 'sigma_1.25^3': 87.7158, 'cmp': -0.2244}\n",
      "======================================================================\n",
      "tau: 2.2034246886135063\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2810, 0.6969], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4762, 0.5026], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4287, 0.5493], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4789, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4804, 0.4975], device='cuda:0', requires_grad=True)\n",
      "tau: 2.1263048245120335\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2795, 0.6975], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4757, 0.5022], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4272, 0.5498], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4774, 0.5005], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4800, 0.4970], device='cuda:0', requires_grad=True)\n",
      "[Iter 2400 Task segm] Task Loss: 0.5818 Reg Loss: 10.8843 Train Loss: 0.5818\n",
      "[Iter 2400 Task dept] Task Loss: 0.0238 Reg Loss: 11.0498 Train Loss: 0.0238\n",
      "[Iter 2400 Total] Train Loss: 0.3028\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 0.8435\n",
      "{'mIoU': 0.389, 'Pixel Acc': 0.6287, 'cmp': -0.0954}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0267\n",
      "{'abs_err': 0.0258, 'rel_err': 0.4198, 'sigma_1.25': 60.3338, 'sigma_1.25^2': 78.4938, 'sigma_1.25^3': 87.8866, 'cmp': -0.216}\n",
      "======================================================================\n",
      "tau: 2.051884155654112\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2699, 0.7061], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4752, 0.5017], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4270, 0.5491], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4769, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4834, 0.4926], device='cuda:0', requires_grad=True)\n",
      "tau: 1.9800682102062181\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2712, 0.7039], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4732, 0.5029], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4261, 0.5490], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4757, 0.5003], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4830, 0.4921], device='cuda:0', requires_grad=True)\n",
      "[Iter 2600 Task segm] Task Loss: 0.5922 Reg Loss: 10.9759 Train Loss: 0.5922\n",
      "[Iter 2600 Task dept] Task Loss: 0.0223 Reg Loss: 11.0413 Train Loss: 0.0223\n",
      "[Iter 2600 Total] Train Loss: 0.3073\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 0.9136\n",
      "{'mIoU': 0.3663, 'Pixel Acc': 0.6212, 'cmp': -0.1286}\n",
      "[Iter 2600 Task dept] Val Loss: 0.0313\n",
      "{'abs_err': 0.029, 'rel_err': 0.5122, 'sigma_1.25': 57.6477, 'sigma_1.25^2': 76.0793, 'sigma_1.25^3': 85.8527, 'cmp': -0.3268}\n",
      "======================================================================\n",
      "tau: 1.9107658228490005\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2600, 0.7141], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4725, 0.5025], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4243, 0.5498], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4752, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4856, 0.4886], device='cuda:0', requires_grad=True)\n",
      "tau: 1.8438890190492854\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2606, 0.7126], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4703, 0.5038], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4241, 0.5490], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4737, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4862, 0.4870], device='cuda:0', requires_grad=True)\n",
      "[Iter 2800 Task segm] Task Loss: 0.5854 Reg Loss: 11.1767 Train Loss: 0.5854\n",
      "[Iter 2800 Task dept] Task Loss: 0.0225 Reg Loss: 11.1607 Train Loss: 0.0225\n",
      "[Iter 2800 Total] Train Loss: 0.3040\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 0.8873\n",
      "{'mIoU': 0.3829, 'Pixel Acc': 0.6253, 'cmp': -0.1052}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0338\n",
      "{'abs_err': 0.0306, 'rel_err': 0.545, 'sigma_1.25': 55.946, 'sigma_1.25^2': 75.0671, 'sigma_1.25^3': 85.1195, 'cmp': -0.3748}\n",
      "======================================================================\n",
      "tau: 1.7793529033825604\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2510, 0.7212], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4698, 0.5034], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4245, 0.5477], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4732, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4908, 0.4814], device='cuda:0', requires_grad=True)\n",
      "tau: 1.7170755517641707\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2476, 0.7237], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4682, 0.5040], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4241, 0.5471], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4715, 0.5008], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4908, 0.4805], device='cuda:0', requires_grad=True)\n",
      "[Iter 3000 Task segm] Task Loss: 0.5783 Reg Loss: 11.3559 Train Loss: 0.5783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3000 Task dept] Task Loss: 0.0251 Reg Loss: 11.3203 Train Loss: 0.0251\n",
      "[Iter 3000 Total] Train Loss: 0.3017\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 1.2400\n",
      "{'mIoU': 0.3149, 'Pixel Acc': 0.5226, 'cmp': -0.2586}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0261\n",
      "{'abs_err': 0.026, 'rel_err': 0.4217, 'sigma_1.25': 59.4553, 'sigma_1.25^2': 77.1608, 'sigma_1.25^3': 86.7288, 'cmp': -0.2274}\n",
      "======================================================================\n",
      "tau: 1.6569779074524247\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2356, 0.7347], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4677, 0.5036], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4176, 0.5527], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4710, 0.5003], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4879, 0.4824], device='cuda:0', requires_grad=True)\n",
      "tau: 1.5989836806915898\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2372, 0.7321], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4656, 0.5047], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4191, 0.5503], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4691, 0.5012], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4874, 0.4820], device='cuda:0', requires_grad=True)\n",
      "[Iter 3200 Task segm] Task Loss: 0.5727 Reg Loss: 11.3814 Train Loss: 0.5727\n",
      "[Iter 3200 Task dept] Task Loss: 0.0238 Reg Loss: 11.6220 Train Loss: 0.0238\n",
      "[Iter 3200 Total] Train Loss: 0.2982\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 0.9398\n",
      "{'mIoU': 0.3564, 'Pixel Acc': 0.5783, 'cmp': -0.1697}\n",
      "[Iter 3200 Task dept] Val Loss: 0.0304\n",
      "{'abs_err': 0.0284, 'rel_err': 0.4806, 'sigma_1.25': 58.3098, 'sigma_1.25^2': 75.7666, 'sigma_1.25^3': 85.2426, 'cmp': -0.3017}\n",
      "======================================================================\n",
      "tau: 1.5430192518673842\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2197, 0.7487], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4649, 0.5045], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4174, 0.5510], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4686, 0.5008], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4905, 0.4779], device='cuda:0', requires_grad=True)\n",
      "tau: 1.4890135780520257\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2169, 0.7506], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4635, 0.5050], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4183, 0.5492], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4670, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4897, 0.4778], device='cuda:0', requires_grad=True)\n",
      "[Iter 3400 Task segm] Task Loss: 0.5680 Reg Loss: 11.7626 Train Loss: 0.5680\n",
      "[Iter 3400 Task dept] Task Loss: 0.0243 Reg Loss: 11.8463 Train Loss: 0.0243\n",
      "[Iter 3400 Total] Train Loss: 0.2962\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.0748\n",
      "{'mIoU': 0.3448, 'Pixel Acc': 0.575, 'cmp': -0.1862}\n",
      "[Iter 3400 Task dept] Val Loss: 0.0299\n",
      "{'abs_err': 0.0285, 'rel_err': 0.4833, 'sigma_1.25': 58.8834, 'sigma_1.25^2': 75.5921, 'sigma_1.25^3': 84.5868, 'cmp': -0.3042}\n",
      "======================================================================\n",
      "tau: 1.4368981028202048\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2109, 0.7556], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4629, 0.5046], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4162, 0.5504], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4665, 0.5010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4943, 0.4722], device='cuda:0', requires_grad=True)\n",
      "tau: 1.3866066692214976\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.2044, 0.7612], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4615, 0.5051], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4145, 0.5511], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4648, 0.5018], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4943, 0.4713], device='cuda:0', requires_grad=True)\n",
      "[Iter 3600 Task segm] Task Loss: 0.5634 Reg Loss: 11.9176 Train Loss: 0.5634\n",
      "[Iter 3600 Task dept] Task Loss: 0.0226 Reg Loss: 12.0098 Train Loss: 0.0226\n",
      "[Iter 3600 Total] Train Loss: 0.2930\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.2266\n",
      "{'mIoU': 0.3177, 'Pixel Acc': 0.5558, 'cmp': -0.2329}\n",
      "[Iter 3600 Task dept] Val Loss: 0.0346\n",
      "{'abs_err': 0.0305, 'rel_err': 0.5047, 'sigma_1.25': 56.6575, 'sigma_1.25^2': 77.5954, 'sigma_1.25^3': 87.2723, 'cmp': -0.337}\n",
      "======================================================================\n",
      "tau: 1.338075435798745\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1967, 0.7679], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4610, 0.5046], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4119, 0.5528], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4642, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4979, 0.4668], device='cuda:0', requires_grad=True)\n",
      "tau: 1.2912427955457888\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1953, 0.7685], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4598, 0.5048], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4116, 0.5521], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4633, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4983, 0.4654], device='cuda:0', requires_grad=True)\n",
      "[Iter 3800 Task segm] Task Loss: 0.5680 Reg Loss: 12.1896 Train Loss: 0.5680\n",
      "[Iter 3800 Task dept] Task Loss: 0.0240 Reg Loss: 12.4566 Train Loss: 0.0240\n",
      "[Iter 3800 Total] Train Loss: 0.2960\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.0326\n",
      "{'mIoU': 0.305, 'Pixel Acc': 0.5686, 'cmp': -0.2401}\n",
      "[Iter 3800 Task dept] Val Loss: 0.0345\n",
      "{'abs_err': 0.0311, 'rel_err': 0.5106, 'sigma_1.25': 56.5408, 'sigma_1.25^2': 76.3245, 'sigma_1.25^3': 85.8461, 'cmp': -0.353}\n",
      "======================================================================\n",
      "tau: 1.2460492977016862\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1865, 0.7762], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4594, 0.5044], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4144, 0.5484], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4627, 0.5010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5015, 0.4613], device='cuda:0', requires_grad=True)\n",
      "tau: 1.202437572282127\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1856, 0.7763], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4572, 0.5056], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4138, 0.5481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4614, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5017, 0.4601], device='cuda:0', requires_grad=True)\n",
      "[Iter 4000 Task segm] Task Loss: 0.5581 Reg Loss: 12.2848 Train Loss: 0.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4000 Task dept] Task Loss: 0.0226 Reg Loss: 12.5245 Train Loss: 0.0226\n",
      "[Iter 4000 Total] Train Loss: 0.2904\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.1975\n",
      "{'mIoU': 0.3152, 'Pixel Acc': 0.5551, 'cmp': -0.2364}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0420\n",
      "{'abs_err': 0.0378, 'rel_err': 0.6206, 'sigma_1.25': 49.8039, 'sigma_1.25^2': 72.0543, 'sigma_1.25^3': 82.3852, 'cmp': -0.5353}\n",
      "======================================================================\n",
      "tau: 1.1603522572522524\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1822, 0.7787], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4567, 0.5052], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4177, 0.5432], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4609, 0.5009], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5066, 0.4543], device='cuda:0', requires_grad=True)\n",
      "tau: 1.1197399282484235\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1801, 0.7799], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4553, 0.5056], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4182, 0.5418], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4599, 0.5010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5072, 0.4528], device='cuda:0', requires_grad=True)\n",
      "[Iter 4200 Task segm] Task Loss: 0.5509 Reg Loss: 11.9532 Train Loss: 0.5509\n",
      "[Iter 4200 Task dept] Task Loss: 0.0225 Reg Loss: 12.9155 Train Loss: 0.0225\n",
      "[Iter 4200 Total] Train Loss: 0.2867\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.1228\n",
      "{'mIoU': 0.3112, 'Pixel Acc': 0.5431, 'cmp': -0.2493}\n",
      "[Iter 4200 Task dept] Val Loss: 0.0327\n",
      "{'abs_err': 0.03, 'rel_err': 0.4907, 'sigma_1.25': 57.356, 'sigma_1.25^2': 76.2566, 'sigma_1.25^3': 85.7536, 'cmp': -0.327}\n",
      "======================================================================\n",
      "tau: 1.0805490307597287\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1777, 0.7814], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4548, 0.5052], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4224, 0.5367], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4594, 0.5006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5119, 0.4471], device='cuda:0', requires_grad=True)\n",
      "tau: 1.0427298146831383\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1776, 0.7805], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4528, 0.5062], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4237, 0.5345], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4575, 0.5016], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5112, 0.4469], device='cuda:0', requires_grad=True)\n",
      "[Iter 4400 Task segm] Task Loss: 0.5435 Reg Loss: 11.7749 Train Loss: 0.5435\n",
      "[Iter 4400 Task dept] Task Loss: 0.0219 Reg Loss: 13.2590 Train Loss: 0.0219\n",
      "[Iter 4400 Total] Train Loss: 0.2827\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.2659\n",
      "{'mIoU': 0.32, 'Pixel Acc': 0.5076, 'cmp': -0.2622}\n",
      "[Iter 4400 Task dept] Val Loss: 0.0282\n",
      "{'abs_err': 0.0275, 'rel_err': 0.4558, 'sigma_1.25': 58.8829, 'sigma_1.25^2': 76.4952, 'sigma_1.25^3': 85.7162, 'cmp': -0.2713}\n",
      "======================================================================\n",
      "tau: 1.0062342711692285\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1724, 0.7848], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4521, 0.5060], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4241, 0.5330], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4569, 0.5012], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5155, 0.4417], device='cuda:0', requires_grad=True)\n",
      "tau: 0.9710160716783055\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1719, 0.7843], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4502, 0.5070], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4238, 0.5324], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4559, 0.5013], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5155, 0.4408], device='cuda:0', requires_grad=True)\n",
      "[Iter 4600 Task segm] Task Loss: 0.5570 Reg Loss: 12.5590 Train Loss: 0.5570\n",
      "[Iter 4600 Task dept] Task Loss: 0.0233 Reg Loss: 12.8313 Train Loss: 0.0233\n",
      "[Iter 4600 Total] Train Loss: 0.2901\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.0177\n",
      "{'mIoU': 0.3434, 'Pixel Acc': 0.5767, 'cmp': -0.1868}\n",
      "[Iter 4600 Task dept] Val Loss: 0.0364\n",
      "{'abs_err': 0.0331, 'rel_err': 0.5644, 'sigma_1.25': 53.8623, 'sigma_1.25^2': 73.5036, 'sigma_1.25^3': 83.4574, 'cmp': -0.4286}\n",
      "======================================================================\n",
      "tau: 0.9370305091695648\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1597, 0.7956], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4496, 0.5067], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4263, 0.5290], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4554, 0.5008], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5219, 0.4334], device='cuda:0', requires_grad=True)\n",
      "tau: 0.90423444134863\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1616, 0.7928], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4430, 0.5123], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4262, 0.5282], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4530, 0.5023], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5212, 0.4331], device='cuda:0', requires_grad=True)\n",
      "[Iter 4800 Task segm] Task Loss: 0.5354 Reg Loss: 12.8180 Train Loss: 0.5354\n",
      "[Iter 4800 Task dept] Task Loss: 0.0227 Reg Loss: 13.4208 Train Loss: 0.0227\n",
      "[Iter 4800 Total] Train Loss: 0.2790\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.4282\n",
      "{'mIoU': 0.2392, 'Pixel Acc': 0.4709, 'cmp': -0.3873}\n",
      "[Iter 4800 Task dept] Val Loss: 0.0352\n",
      "{'abs_err': 0.0321, 'rel_err': 0.5573, 'sigma_1.25': 54.8647, 'sigma_1.25^2': 74.3127, 'sigma_1.25^3': 84.4128, 'cmp': -0.4061}\n",
      "======================================================================\n",
      "tau: 0.8725862359014279\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1454, 0.8081], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4424, 0.5120], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4243, 0.5291], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4524, 0.5019], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5253, 0.4281], device='cuda:0', requires_grad=True)\n",
      "tau: 0.8420457176448779\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1430, 0.8095], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4406, 0.5129], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4227, 0.5299], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4512, 0.5023], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5255, 0.4270], device='cuda:0', requires_grad=True)\n",
      "[Iter 5000 Task segm] Task Loss: 0.5407 Reg Loss: 13.2196 Train Loss: 0.5407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5000 Task dept] Task Loss: 0.0237 Reg Loss: 13.4679 Train Loss: 0.0237\n",
      "[Iter 5000 Total] Train Loss: 0.2822\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.7550\n",
      "{'mIoU': 0.306, 'Pixel Acc': 0.5433, 'cmp': -0.2558}\n",
      "[Iter 5000 Task dept] Val Loss: 0.0268\n",
      "{'abs_err': 0.0266, 'rel_err': 0.4306, 'sigma_1.25': 58.0349, 'sigma_1.25^2': 74.5632, 'sigma_1.25^3': 84.1738, 'cmp': -0.2561}\n",
      "======================================================================\n",
      "tau: 0.8125741175273071\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1454, 0.8062], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4400, 0.5125], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4261, 0.5255], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4507, 0.5018], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5305, 0.4211], device='cuda:0', requires_grad=True)\n",
      "tau: 0.7841340234138513\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1435, 0.8072], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4391, 0.5125], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4268, 0.5239], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4498, 0.5018], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5308, 0.4199], device='cuda:0', requires_grad=True)\n",
      "[Iter 5200 Task segm] Task Loss: 0.5396 Reg Loss: 13.1312 Train Loss: 0.5396\n",
      "[Iter 5200 Task dept] Task Loss: 0.0248 Reg Loss: 13.3440 Train Loss: 0.0248\n",
      "[Iter 5200 Total] Train Loss: 0.2822\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 1.1042\n",
      "{'mIoU': 0.2995, 'Pixel Acc': 0.522, 'cmp': -0.2781}\n",
      "[Iter 5200 Task dept] Val Loss: 0.0308\n",
      "{'abs_err': 0.0279, 'rel_err': 0.4531, 'sigma_1.25': 59.3368, 'sigma_1.25^2': 78.3566, 'sigma_1.25^3': 87.7285, 'cmp': -0.2647}\n",
      "======================================================================\n",
      "tau: 0.7566893325943664\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1340, 0.8157], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4386, 0.5121], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4278, 0.5220], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4494, 0.5013], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5353, 0.4145], device='cuda:0', requires_grad=True)\n",
      "tau: 0.7302052059535636\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1328, 0.8161], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4374, 0.5124], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4276, 0.5212], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4484, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5350, 0.4138], device='cuda:0', requires_grad=True)\n",
      "[Iter 5400 Task segm] Task Loss: 0.5346 Reg Loss: 13.0319 Train Loss: 0.5346\n",
      "[Iter 5400 Task dept] Task Loss: 0.0233 Reg Loss: 14.2658 Train Loss: 0.0233\n",
      "[Iter 5400 Total] Train Loss: 0.2790\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 1.4742\n",
      "{'mIoU': 0.2376, 'Pixel Acc': 0.4748, 'cmp': -0.3867}\n",
      "[Iter 5400 Task dept] Val Loss: 0.0351\n",
      "{'abs_err': 0.0304, 'rel_err': 0.4954, 'sigma_1.25': 56.2965, 'sigma_1.25^2': 77.8901, 'sigma_1.25^3': 87.5964, 'cmp': -0.3298}\n",
      "======================================================================\n",
      "tau: 0.7046480237451889\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1294, 0.8185], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4368, 0.5120], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4280, 0.5199], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4478, 0.5010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5387, 0.4092], device='cuda:0', requires_grad=True)\n",
      "tau: 0.6799853429141073\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1249, 0.8221], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4343, 0.5135], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4297, 0.5173], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4461, 0.5018], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5385, 0.4085], device='cuda:0', requires_grad=True)\n",
      "[Iter 5600 Task segm] Task Loss: 0.5397 Reg Loss: 13.2310 Train Loss: 0.5397\n",
      "[Iter 5600 Task dept] Task Loss: 0.0230 Reg Loss: 14.4315 Train Loss: 0.0230\n",
      "[Iter 5600 Total] Train Loss: 0.2813\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.5026\n",
      "{'mIoU': 0.2487, 'Pixel Acc': 0.4592, 'cmp': -0.3832}\n",
      "[Iter 5600 Task dept] Val Loss: 0.0341\n",
      "{'abs_err': 0.0309, 'rel_err': 0.5024, 'sigma_1.25': 56.8651, 'sigma_1.25^2': 75.761, 'sigma_1.25^3': 85.103, 'cmp': -0.3477}\n",
      "======================================================================\n",
      "tau: 0.6561858559121135\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1102, 0.8359], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4338, 0.5132], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4245, 0.5216], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4456, 0.5014], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5403, 0.4058], device='cuda:0', requires_grad=True)\n",
      "tau: 0.6332193509551896\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.1076, 0.8375], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4320, 0.5141], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4231, 0.5220], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4448, 0.5013], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5405, 0.4046], device='cuda:0', requires_grad=True)\n",
      "[Iter 5800 Task segm] Task Loss: 0.5342 Reg Loss: 13.4865 Train Loss: 0.5342\n",
      "[Iter 5800 Task dept] Task Loss: 0.0235 Reg Loss: 14.5739 Train Loss: 0.0235\n",
      "[Iter 5800 Total] Train Loss: 0.2788\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.4040\n",
      "{'mIoU': 0.2617, 'Pixel Acc': 0.4721, 'cmp': -0.3585}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0345\n",
      "{'abs_err': 0.0316, 'rel_err': 0.5221, 'sigma_1.25': 55.8881, 'sigma_1.25^2': 74.7227, 'sigma_1.25^3': 84.3274, 'cmp': -0.3752}\n",
      "======================================================================\n",
      "tau: 0.6110566736717579\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0963, 0.8479], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4316, 0.5135], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4243, 0.5199], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4443, 0.5008], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5433, 0.4009], device='cuda:0', requires_grad=True)\n",
      "tau: 0.5896696900932463\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0966, 0.8467], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4292, 0.5150], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4237, 0.5195], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4422, 0.5020], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5436, 0.3996], device='cuda:0', requires_grad=True)\n",
      "[Iter 6000 Task segm] Task Loss: 0.5168 Reg Loss: 13.4258 Train Loss: 0.5168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6000 Task dept] Task Loss: 0.0228 Reg Loss: 14.4797 Train Loss: 0.0228\n",
      "[Iter 6000 Total] Train Loss: 0.2698\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.3788\n",
      "{'mIoU': 0.2693, 'Pixel Acc': 0.4947, 'cmp': -0.3339}\n",
      "[Iter 6000 Task dept] Val Loss: 0.0451\n",
      "{'abs_err': 0.0396, 'rel_err': 0.6313, 'sigma_1.25': 46.8049, 'sigma_1.25^2': 72.519, 'sigma_1.25^3': 83.3964, 'cmp': -0.5686}\n",
      "======================================================================\n",
      "tau: 0.5690312509399826\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0848, 0.8575], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4285, 0.5148], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4133, 0.5291], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4417, 0.5016], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5400, 0.4024], device='cuda:0', requires_grad=True)\n",
      "tau: 0.5491151571570833\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0819, 0.8596], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4239, 0.5185], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4134, 0.5280], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4397, 0.5027], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5403, 0.4012], device='cuda:0', requires_grad=True)\n",
      "[Iter 6200 Task segm] Task Loss: 0.5487 Reg Loss: 13.4506 Train Loss: 0.5487\n",
      "[Iter 6200 Task dept] Task Loss: 0.0230 Reg Loss: 14.6504 Train Loss: 0.0230\n",
      "[Iter 6200 Total] Train Loss: 0.2859\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 1.3050\n",
      "{'mIoU': 0.2979, 'Pixel Acc': 0.5074, 'cmp': -0.2899}\n",
      "[Iter 6200 Task dept] Val Loss: 0.0318\n",
      "{'abs_err': 0.0293, 'rel_err': 0.4849, 'sigma_1.25': 57.373, 'sigma_1.25^2': 75.7414, 'sigma_1.25^3': 85.3317, 'cmp': -0.3173}\n",
      "======================================================================\n",
      "tau: 0.5298961266565854\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0870, 0.8535], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4232, 0.5182], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4141, 0.5265], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4392, 0.5023], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5448, 0.3958], device='cuda:0', requires_grad=True)\n",
      "tau: 0.5113497622236048\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0860, 0.8537], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4193, 0.5212], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4112, 0.5284], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4378, 0.5028], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5451, 0.3945], device='cuda:0', requires_grad=True)\n",
      "[Iter 6400 Task segm] Task Loss: 0.5255 Reg Loss: 13.9720 Train Loss: 0.5255\n",
      "[Iter 6400 Task dept] Task Loss: 0.0227 Reg Loss: 15.1351 Train Loss: 0.0227\n",
      "[Iter 6400 Total] Train Loss: 0.2741\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.5418\n",
      "{'mIoU': 0.2449, 'Pixel Acc': 0.4308, 'cmp': -0.4071}\n",
      "[Iter 6400 Task dept] Val Loss: 0.0356\n",
      "{'abs_err': 0.0322, 'rel_err': 0.5369, 'sigma_1.25': 56.0776, 'sigma_1.25^2': 75.0073, 'sigma_1.25^3': 84.3699, 'cmp': -0.39}\n",
      "======================================================================\n",
      "tau: 0.49345252054577865\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0815, 0.8572], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4187, 0.5209], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4171, 0.5217], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4374, 0.5022], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5511, 0.3876], device='cuda:0', requires_grad=True)\n",
      "tau: 0.4761816823266764\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0845, 0.8533], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4142, 0.5245], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4168, 0.5210], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4354, 0.5033], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5518, 0.3859], device='cuda:0', requires_grad=True)\n",
      "[Iter 6600 Task segm] Task Loss: 0.5148 Reg Loss: 13.9613 Train Loss: 0.5148\n",
      "[Iter 6600 Task dept] Task Loss: 0.0226 Reg Loss: 14.8977 Train Loss: 0.0226\n",
      "[Iter 6600 Total] Train Loss: 0.2687\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.2128\n",
      "{'mIoU': 0.3399, 'Pixel Acc': 0.5384, 'cmp': -0.2169}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0411\n",
      "{'abs_err': 0.0359, 'rel_err': 0.6308, 'sigma_1.25': 50.5563, 'sigma_1.25^2': 73.4644, 'sigma_1.25^3': 84.1138, 'cmp': -0.5108}\n",
      "======================================================================\n",
      "tau: 0.4595153234452427\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0812, 0.8557], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4137, 0.5241], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4157, 0.5212], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4349, 0.5029], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5557, 0.3812], device='cuda:0', requires_grad=True)\n",
      "tau: 0.4434322871246592\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0781, 0.8579], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4102, 0.5267], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4159, 0.5201], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4336, 0.5033], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5561, 0.3799], device='cuda:0', requires_grad=True)\n",
      "[Iter 6800 Task segm] Task Loss: 0.5165 Reg Loss: 13.9435 Train Loss: 0.5165\n",
      "[Iter 6800 Task dept] Task Loss: 0.0223 Reg Loss: 15.3524 Train Loss: 0.0223\n",
      "[Iter 6800 Total] Train Loss: 0.2694\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.3771\n",
      "{'mIoU': 0.2901, 'Pixel Acc': 0.4967, 'cmp': -0.3067}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0468\n",
      "{'abs_err': 0.0408, 'rel_err': 0.6973, 'sigma_1.25': 43.4964, 'sigma_1.25^2': 71.0837, 'sigma_1.25^3': 82.584, 'cmp': -0.6369}\n",
      "======================================================================\n",
      "tau: 0.4279121570752961\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0763, 0.8588], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4096, 0.5264], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4178, 0.5172], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4331, 0.5029], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5615, 0.3736], device='cuda:0', requires_grad=True)\n",
      "tau: 0.41293523157766077\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0753, 0.8588], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4077, 0.5274], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4167, 0.5175], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4320, 0.5031], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5611, 0.3730], device='cuda:0', requires_grad=True)\n",
      "[Iter 7000 Task segm] Task Loss: 0.5029 Reg Loss: 13.8747 Train Loss: 0.5029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7000 Task dept] Task Loss: 0.0300 Reg Loss: 15.3846 Train Loss: 0.0300\n",
      "[Iter 7000 Total] Train Loss: 0.2665\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 1.2832\n",
      "{'mIoU': 0.2766, 'Pixel Acc': 0.5183, 'cmp': -0.3091}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0460\n",
      "{'abs_err': 0.0402, 'rel_err': 0.6675, 'sigma_1.25': 45.9831, 'sigma_1.25^2': 71.9005, 'sigma_1.25^3': 83.1178, 'cmp': -0.6023}\n",
      "======================================================================\n",
      "tau: 0.3984824984724426\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0662, 0.8671], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4071, 0.5271], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4139, 0.5193], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4316, 0.5026], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5667, 0.3665], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3845356110259071\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0648, 0.8675], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4009, 0.5323], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4120, 0.5203], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4298, 0.5035], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5650, 0.3673], device='cuda:0', requires_grad=True)\n",
      "[Iter 7200 Task segm] Task Loss: 0.5171 Reg Loss: 14.1057 Train Loss: 0.5171\n",
      "[Iter 7200 Task dept] Task Loss: 0.0230 Reg Loss: 15.6215 Train Loss: 0.0230\n",
      "[Iter 7200 Total] Train Loss: 0.2701\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.5033\n",
      "{'mIoU': 0.2552, 'Pixel Acc': 0.5006, 'cmp': -0.3476}\n",
      "[Iter 7200 Task dept] Val Loss: 0.0411\n",
      "{'abs_err': 0.0373, 'rel_err': 0.5773, 'sigma_1.25': 50.9531, 'sigma_1.25^2': 72.7875, 'sigma_1.25^3': 82.6959, 'cmp': -0.4976}\n",
      "======================================================================\n",
      "tau: 0.37107686464000034\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0662, 0.8653], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4001, 0.5322], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4139, 0.5175], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4293, 0.5030], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5710, 0.3604], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3580891743776003\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0648, 0.8657], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3956, 0.5358], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4122, 0.5183], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4273, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5702, 0.3603], device='cuda:0', requires_grad=True)\n",
      "[Iter 7400 Task segm] Task Loss: 0.4955 Reg Loss: 14.0097 Train Loss: 0.4955\n",
      "[Iter 7400 Task dept] Task Loss: 0.0226 Reg Loss: 15.8435 Train Loss: 0.0226\n",
      "[Iter 7400 Total] Train Loss: 0.2591\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 1.2798\n",
      "{'mIoU': 0.302, 'Pixel Acc': 0.5357, 'cmp': -0.2657}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0359\n",
      "{'abs_err': 0.0325, 'rel_err': 0.5154, 'sigma_1.25': 55.1745, 'sigma_1.25^2': 75.0163, 'sigma_1.25^3': 84.7038, 'cmp': -0.3822}\n",
      "======================================================================\n",
      "tau: 0.34555605327438427\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0598, 0.8698], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3950, 0.5355], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4181, 0.5115], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4269, 0.5036], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5759, 0.3537], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3334615914097808\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0569, 0.8718], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3923, 0.5373], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4175, 0.5112], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4259, 0.5037], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5754, 0.3532], device='cuda:0', requires_grad=True)\n",
      "[Iter 7600 Task segm] Task Loss: 0.5053 Reg Loss: 14.7706 Train Loss: 0.5053\n",
      "[Iter 7600 Task dept] Task Loss: 0.0225 Reg Loss: 15.8758 Train Loss: 0.0225\n",
      "[Iter 7600 Total] Train Loss: 0.2639\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.3284\n",
      "{'mIoU': 0.2943, 'Pixel Acc': 0.5581, 'cmp': -0.2604}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0417\n",
      "{'abs_err': 0.0368, 'rel_err': 0.5708, 'sigma_1.25': 49.8862, 'sigma_1.25^2': 74.1055, 'sigma_1.25^3': 84.915, 'cmp': -0.4837}\n",
      "======================================================================\n",
      "tau: 0.32179043571043847\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0549, 0.8729], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3918, 0.5369], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4195, 0.5083], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4255, 0.5032], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5788, 0.3490], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3105277704605731\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0503, 0.8766], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3882, 0.5396], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4203, 0.5066], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4242, 0.5036], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5783, 0.3486], device='cuda:0', requires_grad=True)\n",
      "[Iter 7800 Task segm] Task Loss: 0.5058 Reg Loss: 14.2057 Train Loss: 0.5058\n",
      "[Iter 7800 Task dept] Task Loss: 0.0232 Reg Loss: 16.4172 Train Loss: 0.0232\n",
      "[Iter 7800 Total] Train Loss: 0.2645\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 1.4085\n",
      "{'mIoU': 0.2572, 'Pixel Acc': 0.5218, 'cmp': -0.3308}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0400\n",
      "{'abs_err': 0.0354, 'rel_err': 0.5625, 'sigma_1.25': 51.7207, 'sigma_1.25^2': 75.1771, 'sigma_1.25^3': 85.6279, 'cmp': -0.4528}\n",
      "======================================================================\n",
      "tau: 0.29965929849445305\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0413, 0.8847], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3878, 0.5391], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4242, 0.5018], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4237, 0.5032], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5859, 0.3401], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2891712230471472\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0394, 0.8857], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3859, 0.5401], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4234, 0.5016], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4222, 0.5038], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5854, 0.3396], device='cuda:0', requires_grad=True)\n",
      "[Iter 8000 Task segm] Task Loss: 0.5149 Reg Loss: 14.1548 Train Loss: 0.5149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8000 Task dept] Task Loss: 0.0232 Reg Loss: 16.1994 Train Loss: 0.0232\n",
      "[Iter 8000 Total] Train Loss: 0.2690\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 1.4531\n",
      "{'mIoU': 0.295, 'Pixel Acc': 0.5221, 'cmp': -0.2836}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0379\n",
      "{'abs_err': 0.0333, 'rel_err': 0.555, 'sigma_1.25': 54.2357, 'sigma_1.25^2': 75.7437, 'sigma_1.25^3': 85.7789, 'cmp': -0.4143}\n",
      "======================================================================\n",
      "tau: 0.279050230240497\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0219, 0.9023], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3854, 0.5397], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4203, 0.5039], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4217, 0.5034], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5861, 0.3380], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2692834721820796\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0210, 0.9023], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3821, 0.5421], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4204, 0.5029], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4201, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5864, 0.3369], device='cuda:0', requires_grad=True)\n",
      "[Iter 8200 Task segm] Task Loss: 0.4914 Reg Loss: 14.4022 Train Loss: 0.4914\n",
      "[Iter 8200 Task dept] Task Loss: 0.0233 Reg Loss: 16.2686 Train Loss: 0.0233\n",
      "[Iter 8200 Total] Train Loss: 0.2573\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.8972\n",
      "{'mIoU': 0.2087, 'Pixel Acc': 0.4694, 'cmp': -0.4263}\n",
      "[Iter 8200 Task dept] Val Loss: 0.0418\n",
      "{'abs_err': 0.0367, 'rel_err': 0.5747, 'sigma_1.25': 49.9741, 'sigma_1.25^2': 74.9416, 'sigma_1.25^3': 85.5573, 'cmp': -0.4808}\n",
      "======================================================================\n",
      "tau: 0.2598585506557068\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0209, 0.9015], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3818, 0.5415], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4228, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4196, 0.5037], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5920, 0.3304], device='cuda:0', requires_grad=True)\n",
      "tau: 0.25076350138275705\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0195, 0.9020], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3787, 0.5437], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4244, 0.4971], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4179, 0.5045], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5917, 0.3298], device='cuda:0', requires_grad=True)\n",
      "[Iter 8400 Task segm] Task Loss: 0.4836 Reg Loss: 14.8994 Train Loss: 0.4836\n",
      "[Iter 8400 Task dept] Task Loss: 0.0232 Reg Loss: 16.4660 Train Loss: 0.0232\n",
      "[Iter 8400 Total] Train Loss: 0.2534\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 2.2020\n",
      "{'mIoU': 0.2106, 'Pixel Acc': 0.4243, 'cmp': -0.4541}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0393\n",
      "{'abs_err': 0.0345, 'rel_err': 0.5519, 'sigma_1.25': 52.1491, 'sigma_1.25^2': 75.4044, 'sigma_1.25^3': 85.6126, 'cmp': -0.434}\n",
      "======================================================================\n",
      "tau: 0.24198677883436054\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0220, 0.8985], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3782, 0.5433], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4247, 0.4959], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4173, 0.5042], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5968, 0.3238], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2335172415751579\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0194, 0.9003], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3748, 0.5458], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4244, 0.4952], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4163, 0.5043], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.5975, 0.3222], device='cuda:0', requires_grad=True)\n",
      "[Iter 8600 Task segm] Task Loss: 0.5097 Reg Loss: 14.3158 Train Loss: 0.5097\n",
      "[Iter 8600 Task dept] Task Loss: 0.0229 Reg Loss: 16.7191 Train Loss: 0.0229\n",
      "[Iter 8600 Total] Train Loss: 0.2663\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 1.5908\n",
      "{'mIoU': 0.2521, 'Pixel Acc': 0.5119, 'cmp': -0.3438}\n",
      "[Iter 8600 Task dept] Val Loss: 0.0423\n",
      "{'abs_err': 0.038, 'rel_err': 0.636, 'sigma_1.25': 50.6153, 'sigma_1.25^2': 72.0805, 'sigma_1.25^3': 82.4, 'cmp': -0.5453}\n",
      "======================================================================\n",
      "tau: 0.22534413812002738\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0249, 0.8939], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3742, 0.5455], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4277, 0.4911], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4159, 0.5038], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6012, 0.3176], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2174570932858264\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0273, 0.8906], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3721, 0.5467], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4273, 0.4906], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4150, 0.5038], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6004, 0.3175], device='cuda:0', requires_grad=True)\n",
      "[Iter 8800 Task segm] Task Loss: 0.4856 Reg Loss: 14.5304 Train Loss: 0.4856\n",
      "[Iter 8800 Task dept] Task Loss: 0.0226 Reg Loss: 16.7823 Train Loss: 0.0226\n",
      "[Iter 8800 Total] Train Loss: 0.2541\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.6872\n",
      "{'mIoU': 0.2718, 'Pixel Acc': 0.5077, 'cmp': -0.3221}\n",
      "[Iter 8800 Task dept] Val Loss: 0.0473\n",
      "{'abs_err': 0.0419, 'rel_err': 0.7362, 'sigma_1.25': 45.5079, 'sigma_1.25^2': 69.8419, 'sigma_1.25^3': 81.2253, 'cmp': -0.6733}\n",
      "======================================================================\n",
      "tau: 0.20984609502082247\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0266, 0.8904], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3716, 0.5463], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4301, 0.4869], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4145, 0.5034], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6096, 0.3074], device='cuda:0', requires_grad=True)\n",
      "tau: 0.20250148169509366\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0237, 0.8924], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3678, 0.5492], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4313, 0.4848], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4129, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6103, 0.3058], device='cuda:0', requires_grad=True)\n",
      "[Iter 9000 Task segm] Task Loss: 0.4838 Reg Loss: 13.9893 Train Loss: 0.4838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9000 Task dept] Task Loss: 0.0241 Reg Loss: 17.5371 Train Loss: 0.0241\n",
      "[Iter 9000 Total] Train Loss: 0.2539\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 2.2614\n",
      "{'mIoU': 0.1844, 'Pixel Acc': 0.3639, 'cmp': -0.5271}\n",
      "[Iter 9000 Task dept] Val Loss: 0.0341\n",
      "{'abs_err': 0.0307, 'rel_err': 0.4837, 'sigma_1.25': 56.6927, 'sigma_1.25^2': 76.3596, 'sigma_1.25^3': 86.0383, 'cmp': -0.3314}\n",
      "======================================================================\n",
      "tau: 0.1954139298357654\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0121, 0.9031], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3671, 0.5490], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4275, 0.4877], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4124, 0.5037], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6106, 0.3046], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1885744422915136\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0128, 0.9015], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3630, 0.5523], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4264, 0.4879], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4106, 0.5047], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6099, 0.3044], device='cuda:0', requires_grad=True)\n",
      "[Iter 9200 Task segm] Task Loss: 0.4993 Reg Loss: 14.5590 Train Loss: 0.4993\n",
      "[Iter 9200 Task dept] Task Loss: 0.0226 Reg Loss: 16.9634 Train Loss: 0.0226\n",
      "[Iter 9200 Total] Train Loss: 0.2610\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 1.3719\n",
      "{'mIoU': 0.2451, 'Pixel Acc': 0.5359, 'cmp': -0.3364}\n",
      "[Iter 9200 Task dept] Val Loss: 0.0434\n",
      "{'abs_err': 0.039, 'rel_err': 0.6164, 'sigma_1.25': 48.3779, 'sigma_1.25^2': 72.363, 'sigma_1.25^3': 83.3941, 'cmp': -0.5483}\n",
      "======================================================================\n",
      "tau: 0.18197433681131062\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0205, 0.8930], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3625, 0.5518], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4352, 0.4782], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4102, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6180, 0.2955], device='cuda:0', requires_grad=True)\n",
      "tau: 0.17560523502291475\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0188, 0.8937], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3597, 0.5538], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4355, 0.4770], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4086, 0.5048], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6179, 0.2946], device='cuda:0', requires_grad=True)\n",
      "[Iter 9400 Task segm] Task Loss: 0.4702 Reg Loss: 14.7193 Train Loss: 0.4702\n",
      "[Iter 9400 Task dept] Task Loss: 0.0233 Reg Loss: 17.4360 Train Loss: 0.0233\n",
      "[Iter 9400 Total] Train Loss: 0.2467\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.6987\n",
      "{'mIoU': 0.2924, 'Pixel Acc': 0.5154, 'cmp': -0.2913}\n",
      "[Iter 9400 Task dept] Val Loss: 0.0439\n",
      "{'abs_err': 0.0389, 'rel_err': 0.6104, 'sigma_1.25': 47.7883, 'sigma_1.25^2': 72.8537, 'sigma_1.25^3': 84.0809, 'cmp': -0.5421}\n",
      "======================================================================\n",
      "tau: 0.16945905179711274\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0269, 0.8848], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3592, 0.5533], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4377, 0.4740], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4081, 0.5044], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6242, 0.2875], device='cuda:0', requires_grad=True)\n",
      "tau: 0.16352798498421378\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0285, 0.8823], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3556, 0.5561], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4364, 0.4744], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4067, 0.5050], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6234, 0.2874], device='cuda:0', requires_grad=True)\n",
      "[Iter 9600 Task segm] Task Loss: 0.4851 Reg Loss: 15.0422 Train Loss: 0.4851\n",
      "[Iter 9600 Task dept] Task Loss: 0.0241 Reg Loss: 16.5349 Train Loss: 0.0241\n",
      "[Iter 9600 Total] Train Loss: 0.2546\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 1.7635\n",
      "{'mIoU': 0.2942, 'Pixel Acc': 0.5028, 'cmp': -0.2975}\n",
      "[Iter 9600 Task dept] Val Loss: 0.0507\n",
      "{'abs_err': 0.0448, 'rel_err': 0.7304, 'sigma_1.25': 41.4414, 'sigma_1.25^2': 69.2138, 'sigma_1.25^3': 81.3802, 'cmp': -0.717}\n",
      "======================================================================\n",
      "tau: 0.1578045055097663\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0260, 0.8839], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3551, 0.5557], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4446, 0.4653], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4063, 0.5045], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6276, 0.2823], device='cuda:0', requires_grad=True)\n",
      "tau: 0.15228134781692448\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0273, 0.8817], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3524, 0.5574], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4443, 0.4647], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4053, 0.5045], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6283, 0.2807], device='cuda:0', requires_grad=True)\n",
      "[Iter 9800 Task segm] Task Loss: 0.4727 Reg Loss: 14.7487 Train Loss: 0.4727\n",
      "[Iter 9800 Task dept] Task Loss: 0.0237 Reg Loss: 17.5469 Train Loss: 0.0237\n",
      "[Iter 9800 Total] Train Loss: 0.2482\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 2.0185\n",
      "{'mIoU': 0.2371, 'Pixel Acc': 0.4784, 'cmp': -0.3849}\n",
      "[Iter 9800 Task dept] Val Loss: 0.0553\n",
      "{'abs_err': 0.0497, 'rel_err': 0.7545, 'sigma_1.25': 38.2143, 'sigma_1.25^2': 66.1818, 'sigma_1.25^3': 79.3, 'cmp': -0.81}\n",
      "======================================================================\n",
      "tau: 0.14695150064333212\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0194, 0.8887], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3518, 0.5572], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4432, 0.4649], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4049, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6324, 0.2757], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1418081981208155\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0161, 0.8911], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3489, 0.5592], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4420, 0.4653], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4043, 0.5038], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6327, 0.2746], device='cuda:0', requires_grad=True)\n",
      "[Iter 10000 Task segm] Task Loss: 0.4790 Reg Loss: 14.7951 Train Loss: 0.4790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10000 Task dept] Task Loss: 0.0224 Reg Loss: 17.2741 Train Loss: 0.0224\n",
      "[Iter 10000 Total] Train Loss: 0.2507\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 2.3582\n",
      "{'mIoU': 0.2104, 'Pixel Acc': 0.4331, 'cmp': -0.4484}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0401\n",
      "{'abs_err': 0.0368, 'rel_err': 0.609, 'sigma_1.25': 51.6962, 'sigma_1.25^2': 72.2032, 'sigma_1.25^3': 82.6108, 'cmp': -0.5107}\n",
      "======================================================================\n",
      "tau: 0.13684491118658695\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0184, 0.8879], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3484, 0.5588], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4504, 0.4560], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4039, 0.5033], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6373, 0.2691], device='cuda:0', requires_grad=True)\n",
      "tau: 0.13205533929505642\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0201, 0.8853], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3456, 0.5607], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4507, 0.4547], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4023, 0.5041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6365, 0.2689], device='cuda:0', requires_grad=True)\n",
      "[Iter 10200 Task segm] Task Loss: 0.4749 Reg Loss: 14.7035 Train Loss: 0.4749\n",
      "[Iter 10200 Task dept] Task Loss: 0.0217 Reg Loss: 17.1532 Train Loss: 0.0217\n",
      "[Iter 10200 Total] Train Loss: 0.2483\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Val Loss: 1.6903\n",
      "{'mIoU': 0.2152, 'Pixel Acc': 0.4726, 'cmp': -0.416}\n",
      "[Iter 10200 Task dept] Val Loss: 0.0405\n",
      "{'abs_err': 0.036, 'rel_err': 0.5717, 'sigma_1.25': 51.1793, 'sigma_1.25^2': 73.7153, 'sigma_1.25^3': 84.2349, 'cmp': -0.4735}\n",
      "======================================================================\n",
      "tau: 0.12743340241972945\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0159, 0.8887], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3451, 0.5604], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4511, 0.4535], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4018, 0.5036], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6414, 0.2632], device='cuda:0', requires_grad=True)\n",
      "tau: 0.12297323333503891\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0145, 0.8892], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3440, 0.5606], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4512, 0.4525], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4003, 0.5043], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6427, 0.2610], device='cuda:0', requires_grad=True)\n",
      "[Iter 10400 Task segm] Task Loss: 0.4732 Reg Loss: 14.1593 Train Loss: 0.4732\n",
      "[Iter 10400 Task dept] Task Loss: 0.0232 Reg Loss: 17.1687 Train Loss: 0.0232\n",
      "[Iter 10400 Total] Train Loss: 0.2482\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Val Loss: 2.3435\n",
      "{'mIoU': 0.2563, 'Pixel Acc': 0.4463, 'cmp': -0.3824}\n",
      "[Iter 10400 Task dept] Val Loss: 0.0387\n",
      "{'abs_err': 0.035, 'rel_err': 0.5693, 'sigma_1.25': 52.2088, 'sigma_1.25^2': 73.3757, 'sigma_1.25^3': 84.0639, 'cmp': -0.4581}\n",
      "======================================================================\n",
      "tau: 0.11866917016831255\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0166, 0.8862], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3435, 0.5602], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4540, 0.4488], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3998, 0.5039], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6512, 0.2516], device='cuda:0', requires_grad=True)\n",
      "tau: 0.11451574921242161\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0180, 0.8840], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3403, 0.5625], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4564, 0.4456], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3984, 0.5044], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6521, 0.2498], device='cuda:0', requires_grad=True)\n",
      "[Iter 10600 Task segm] Task Loss: 0.4669 Reg Loss: 14.3858 Train Loss: 0.4669\n",
      "[Iter 10600 Task dept] Task Loss: 0.0235 Reg Loss: 17.3155 Train Loss: 0.0235\n",
      "[Iter 10600 Total] Train Loss: 0.2452\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Val Loss: 1.9094\n",
      "{'mIoU': 0.1518, 'Pixel Acc': 0.4274, 'cmp': -0.5251}\n",
      "[Iter 10600 Task dept] Val Loss: 0.0369\n",
      "{'abs_err': 0.0329, 'rel_err': 0.5204, 'sigma_1.25': 54.0513, 'sigma_1.25^2': 75.3207, 'sigma_1.25^3': 85.5934, 'cmp': -0.3903}\n",
      "======================================================================\n",
      "tau: 0.11050769798998684\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0234, 0.8776], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3398, 0.5621], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4605, 0.4405], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3980, 0.5039], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6587, 0.2423], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1066399285603373\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0218, 0.8784], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3360, 0.5651], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4597, 0.4405], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3966, 0.5044], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6589, 0.2413], device='cuda:0', requires_grad=True)\n",
      "[Iter 10800 Task segm] Task Loss: 0.4692 Reg Loss: 14.5820 Train Loss: 0.4692\n",
      "[Iter 10800 Task dept] Task Loss: 0.0227 Reg Loss: 17.6486 Train Loss: 0.0227\n",
      "[Iter 10800 Total] Train Loss: 0.2460\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Val Loss: 1.6226\n",
      "{'mIoU': 0.1723, 'Pixel Acc': 0.4699, 'cmp': -0.4712}\n",
      "[Iter 10800 Task dept] Val Loss: 0.0425\n",
      "{'abs_err': 0.0377, 'rel_err': 0.6079, 'sigma_1.25': 49.7793, 'sigma_1.25^2': 72.7475, 'sigma_1.25^3': 83.7711, 'cmp': -0.5216}\n",
      "======================================================================\n",
      "tau: 0.10290753106072549\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0227, 0.8766], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3355, 0.5647], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4671, 0.4322], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3962, 0.5040], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6636, 0.2357], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 0.09930576747360009\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0199, 0.8785], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3324, 0.5670], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4700, 0.4285], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3949, 0.5044], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6643, 0.2341], device='cuda:0', requires_grad=True)\n",
      "[Iter 11000 Task segm] Task Loss: 0.4705 Reg Loss: 14.9264 Train Loss: 0.4705\n",
      "[Iter 11000 Task dept] Task Loss: 0.0241 Reg Loss: 17.5897 Train Loss: 0.0241\n",
      "[Iter 11000 Total] Train Loss: 0.2473\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 1.8577\n",
      "{'mIoU': 0.1624, 'Pixel Acc': 0.4249, 'cmp': -0.5136}\n",
      "[Iter 11000 Task dept] Val Loss: 0.0347\n",
      "{'abs_err': 0.0316, 'rel_err': 0.5079, 'sigma_1.25': 55.1799, 'sigma_1.25^2': 74.9656, 'sigma_1.25^3': 85.0342, 'cmp': -0.3665}\n",
      "======================================================================\n",
      "tau: 0.09583006561202409\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0146, 0.8830], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3319, 0.5665], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4678, 0.4298], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3944, 0.5040], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6693, 0.2282], device='cuda:0', requires_grad=True)\n",
      "tau: 0.09247601331560325\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0105, 0.8862], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3295, 0.5680], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4673, 0.4293], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3933, 0.5042], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6699, 0.2267], device='cuda:0', requires_grad=True)\n",
      "[Iter 11200 Task segm] Task Loss: 0.4786 Reg Loss: 14.5593 Train Loss: 0.4786\n",
      "[Iter 11200 Task dept] Task Loss: 0.0223 Reg Loss: 17.3478 Train Loss: 0.0223\n",
      "[Iter 11200 Total] Train Loss: 0.2504\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Val Loss: 1.4447\n",
      "{'mIoU': 0.1981, 'Pixel Acc': 0.524, 'cmp': -0.4029}\n",
      "[Iter 11200 Task dept] Val Loss: 0.0333\n",
      "{'abs_err': 0.0307, 'rel_err': 0.5121, 'sigma_1.25': 56.7252, 'sigma_1.25^2': 74.4523, 'sigma_1.25^3': 84.0478, 'cmp': -0.357}\n",
      "======================================================================\n",
      "tau: 0.08923935284955713\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0144, 0.8815], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3289, 0.5678], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4696, 0.4262], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3930, 0.5037], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6711, 0.2247], device='cuda:0', requires_grad=True)\n",
      "tau: 0.08611597549982263\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0128, 0.8822], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3271, 0.5687], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4679, 0.4270], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3923, 0.5036], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6723, 0.2226], device='cuda:0', requires_grad=True)\n",
      "[Iter 11400 Task segm] Task Loss: 0.4630 Reg Loss: 14.7714 Train Loss: 0.4630\n",
      "[Iter 11400 Task dept] Task Loss: 0.0221 Reg Loss: 17.3609 Train Loss: 0.0221\n",
      "[Iter 11400 Total] Train Loss: 0.2426\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Val Loss: 1.5412\n",
      "{'mIoU': 0.2014, 'Pixel Acc': 0.5033, 'cmp': -0.4126}\n",
      "[Iter 11400 Task dept] Val Loss: 0.0362\n",
      "{'abs_err': 0.0326, 'rel_err': 0.5608, 'sigma_1.25': 55.2435, 'sigma_1.25^2': 74.7003, 'sigma_1.25^3': 84.67, 'cmp': -0.4113}\n",
      "======================================================================\n",
      "tau: 0.08310191635732883\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0112, 0.8828], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3265, 0.5684], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4701, 0.4240], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3918, 0.5031], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6790, 0.2150], device='cuda:0', requires_grad=True)\n",
      "tau: 0.08019334928482232\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0102, 0.8830], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3233, 0.5708], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4682, 0.4249], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3910, 0.5031], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6779, 0.2153], device='cuda:0', requires_grad=True)\n",
      "[Iter 11600 Task segm] Task Loss: 0.4589 Reg Loss: 14.4610 Train Loss: 0.4589\n",
      "[Iter 11600 Task dept] Task Loss: 0.0225 Reg Loss: 17.6120 Train Loss: 0.0225\n",
      "[Iter 11600 Total] Train Loss: 0.2407\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Val Loss: 1.7916\n",
      "{'mIoU': 0.17, 'Pixel Acc': 0.455, 'cmp': -0.484}\n",
      "[Iter 11600 Task dept] Val Loss: 0.0413\n",
      "{'abs_err': 0.037, 'rel_err': 0.6076, 'sigma_1.25': 50.9642, 'sigma_1.25^2': 72.7606, 'sigma_1.25^3': 83.3073, 'cmp': -0.5116}\n",
      "======================================================================\n",
      "tau: 0.07738658205985353\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0117, 0.8807], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3228, 0.5704], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4741, 0.4182], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3906, 0.5026], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6816, 0.2107], device='cuda:0', requires_grad=True)\n",
      "tau: 0.07467805168775866\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0135, 0.8779], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3211, 0.5712], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4741, 0.4173], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3892, 0.5031], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6817, 0.2098], device='cuda:0', requires_grad=True)\n",
      "[Iter 11800 Task segm] Task Loss: 0.4530 Reg Loss: 14.1106 Train Loss: 0.4530\n",
      "[Iter 11800 Task dept] Task Loss: 0.0229 Reg Loss: 17.2970 Train Loss: 0.0229\n",
      "[Iter 11800 Total] Train Loss: 0.2380\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Val Loss: 2.0649\n",
      "{'mIoU': 0.1515, 'Pixel Acc': 0.4476, 'cmp': -0.512}\n",
      "[Iter 11800 Task dept] Val Loss: 0.0500\n",
      "{'abs_err': 0.0446, 'rel_err': 0.718, 'sigma_1.25': 42.9189, 'sigma_1.25^2': 67.5475, 'sigma_1.25^3': 80.3405, 'cmp': -0.7089}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 0.07206431987868711\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0143, 0.8763], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3205, 0.5710], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4780, 0.4126], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3888, 0.5027], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6872, 0.2034], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06954206868293306\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0140, 0.8757], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3175, 0.5731], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4779, 0.4118], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3880, 0.5025], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6871, 0.2026], device='cuda:0', requires_grad=True)\n",
      "[Iter 12000 Task segm] Task Loss: 0.4591 Reg Loss: 14.6233 Train Loss: 0.4591\n",
      "[Iter 12000 Task dept] Task Loss: 0.0253 Reg Loss: 18.0675 Train Loss: 0.0253\n",
      "[Iter 12000 Total] Train Loss: 0.2422\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 1.5821\n",
      "{'mIoU': 0.1804, 'Pixel Acc': 0.5143, 'cmp': -0.4313}\n",
      "[Iter 12000 Task dept] Val Loss: 0.0507\n",
      "{'abs_err': 0.0457, 'rel_err': 0.7156, 'sigma_1.25': 41.9722, 'sigma_1.25^2': 67.4003, 'sigma_1.25^3': 80.0502, 'cmp': -0.7241}\n",
      "======================================================================\n",
      "tau: 0.0671080962790304\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0061, 0.8828], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3172, 0.5725], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4813, 0.4076], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3876, 0.5021], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6917, 0.1972], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06475931290926433\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0093, 0.8786], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3139, 0.5749], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4802, 0.4078], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3869, 0.5020], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6911, 0.1969], device='cuda:0', requires_grad=True)\n",
      "[Iter 12200 Task segm] Task Loss: 0.4550 Reg Loss: 14.4941 Train Loss: 0.4550\n",
      "[Iter 12200 Task dept] Task Loss: 0.0221 Reg Loss: 18.0614 Train Loss: 0.0221\n",
      "[Iter 12200 Total] Train Loss: 0.2386\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Val Loss: 1.6665\n",
      "{'mIoU': 0.1822, 'Pixel Acc': 0.4937, 'cmp': -0.443}\n",
      "[Iter 12200 Task dept] Val Loss: 0.0486\n",
      "{'abs_err': 0.0432, 'rel_err': 0.6695, 'sigma_1.25': 44.1644, 'sigma_1.25^2': 69.7749, 'sigma_1.25^3': 81.825, 'cmp': -0.6518}\n",
      "======================================================================\n",
      "tau: 0.06249273695744008\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0048, 0.8823], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3137, 0.5743], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4833, 0.4038], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3865, 0.5015], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6957, 0.1914], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06030549116392967\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.0058, 0.8804], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3103, 0.5768], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4849, 0.4013], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3861, 0.5010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6958, 0.1905], device='cuda:0', requires_grad=True)\n",
      "[Iter 12400 Task segm] Task Loss: 0.4596 Reg Loss: 13.9116 Train Loss: 0.4596\n",
      "[Iter 12400 Task dept] Task Loss: 0.0224 Reg Loss: 18.0984 Train Loss: 0.0224\n",
      "[Iter 12400 Total] Train Loss: 0.2410\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Val Loss: 1.6350\n",
      "{'mIoU': 0.1913, 'Pixel Acc': 0.4605, 'cmp': -0.4538}\n",
      "[Iter 12400 Task dept] Val Loss: 0.0467\n",
      "{'abs_err': 0.0418, 'rel_err': 0.6606, 'sigma_1.25': 45.8927, 'sigma_1.25^2': 69.7268, 'sigma_1.25^3': 81.6159, 'cmp': -0.6254}\n",
      "======================================================================\n",
      "tau: 0.05819479897319213\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0039,  0.8893], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3099, 0.5764], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4806, 0.4048], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3857, 0.5006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6976, 0.1878], device='cuda:0', requires_grad=True)\n",
      "tau: 0.0561579810091304\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0066,  0.8911], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3095, 0.5759], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4792, 0.4053], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3845, 0.5009], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6976, 0.1870], device='cuda:0', requires_grad=True)\n",
      "[Iter 12600 Task segm] Task Loss: 0.4516 Reg Loss: 14.0343 Train Loss: 0.4516\n",
      "[Iter 12600 Task dept] Task Loss: 0.0228 Reg Loss: 17.2778 Train Loss: 0.0228\n",
      "[Iter 12600 Total] Train Loss: 0.2372\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Val Loss: 2.5373\n",
      "{'mIoU': 0.1443, 'Pixel Acc': 0.3503, 'cmp': -0.5861}\n",
      "[Iter 12600 Task dept] Val Loss: 0.0565\n",
      "{'abs_err': 0.0505, 'rel_err': 0.7754, 'sigma_1.25': 37.0026, 'sigma_1.25^2': 66.455, 'sigma_1.25^3': 79.6934, 'cmp': -0.8334}\n",
      "======================================================================\n",
      "tau: 0.054192451673810836\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0091,  0.8927], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3094, 0.5752], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4782, 0.4054], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3841, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7007, 0.1830], device='cuda:0', requires_grad=True)\n",
      "tau: 0.05229571586522745\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0052,  0.8880], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3051, 0.5786], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4790, 0.4038], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3831, 0.5006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7009, 0.1819], device='cuda:0', requires_grad=True)\n",
      "[Iter 12800 Task segm] Task Loss: 0.4506 Reg Loss: 14.1640 Train Loss: 0.4506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12800 Task dept] Task Loss: 0.0237 Reg Loss: 17.4788 Train Loss: 0.0237\n",
      "[Iter 12800 Total] Train Loss: 0.2371\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Val Loss: 2.3640\n",
      "{'mIoU': 0.1436, 'Pixel Acc': 0.3869, 'cmp': -0.5625}\n",
      "[Iter 12800 Task dept] Val Loss: 0.0435\n",
      "{'abs_err': 0.039, 'rel_err': 0.627, 'sigma_1.25': 48.1616, 'sigma_1.25^2': 70.6057, 'sigma_1.25^3': 82.0529, 'cmp': -0.5624}\n",
      "======================================================================\n",
      "tau: 0.05046536580994449\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0036,  0.8855], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3042, 0.5786], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4825, 0.3995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3826, 0.5002], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7047, 0.1773], device='cuda:0', requires_grad=True)\n",
      "tau: 0.04869907800659643\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0034,  0.8845], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3018, 0.5802], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4816, 0.3995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3816, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7040, 0.1771], device='cuda:0', requires_grad=True)\n",
      "[Iter 13000 Task segm] Task Loss: 0.4470 Reg Loss: 14.3205 Train Loss: 0.4470\n",
      "[Iter 13000 Task dept] Task Loss: 0.0218 Reg Loss: 18.0418 Train Loss: 0.0218\n",
      "[Iter 13000 Total] Train Loss: 0.2344\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Val Loss: 1.8800\n",
      "{'mIoU': 0.1582, 'Pixel Acc': 0.4535, 'cmp': -0.4997}\n",
      "[Iter 13000 Task dept] Val Loss: 0.0469\n",
      "{'abs_err': 0.0419, 'rel_err': 0.6829, 'sigma_1.25': 46.3675, 'sigma_1.25^2': 69.0959, 'sigma_1.25^3': 80.7754, 'cmp': -0.6419}\n",
      "======================================================================\n",
      "tau: 0.046994610276365555\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0048,  0.8850], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3011, 0.5799], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4811, 0.3992], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3811, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7079, 0.1723], device='cuda:0', requires_grad=True)\n",
      "tau: 0.04534979891669276\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0049,  0.8843], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2969, 0.5833], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4806, 0.3988], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3798, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7081, 0.1713], device='cuda:0', requires_grad=True)\n",
      "[Iter 13200 Task segm] Task Loss: 0.4545 Reg Loss: 14.0197 Train Loss: 0.4545\n",
      "[Iter 13200 Task dept] Task Loss: 0.0228 Reg Loss: 18.5354 Train Loss: 0.0228\n",
      "[Iter 13200 Total] Train Loss: 0.2386\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Val Loss: 1.8745\n",
      "{'mIoU': 0.1757, 'Pixel Acc': 0.453, 'cmp': -0.4782}\n",
      "[Iter 13200 Task dept] Val Loss: 0.0493\n",
      "{'abs_err': 0.0441, 'rel_err': 0.727, 'sigma_1.25': 43.0739, 'sigma_1.25^2': 67.9494, 'sigma_1.25^3': 80.5022, 'cmp': -0.707}\n",
      "======================================================================\n",
      "tau: 0.04376255595460851\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0074,  0.8859], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2964, 0.5830], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4847, 0.3938], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3793, 0.5001], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7114, 0.1671], device='cuda:0', requires_grad=True)\n",
      "tau: 0.042230866496197214\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0076,  0.8852], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2927, 0.5858], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4847, 0.3929], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3784, 0.5001], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7119, 0.1658], device='cuda:0', requires_grad=True)\n",
      "[Iter 13400 Task segm] Task Loss: 0.4591 Reg Loss: 14.1985 Train Loss: 0.4591\n",
      "[Iter 13400 Task dept] Task Loss: 0.0214 Reg Loss: 17.7241 Train Loss: 0.0214\n",
      "[Iter 13400 Total] Train Loss: 0.2403\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Val Loss: 1.8630\n",
      "{'mIoU': 0.158, 'Pixel Acc': 0.4199, 'cmp': -0.5224}\n",
      "[Iter 13400 Task dept] Val Loss: 0.0566\n",
      "{'abs_err': 0.051, 'rel_err': 0.854, 'sigma_1.25': 37.8824, 'sigma_1.25^2': 63.9246, 'sigma_1.25^3': 76.9044, 'cmp': -0.8965}\n",
      "======================================================================\n",
      "tau: 0.04075278616883031\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0147,  0.8915], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2920, 0.5857], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4756, 0.4012], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3779, 0.4997], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7124, 0.1644], device='cuda:0', requires_grad=True)\n",
      "tau: 0.03932643865292125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0133,  0.8892], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2899, 0.5869], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4759, 0.4000], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3770, 0.4998], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7125, 0.1635], device='cuda:0', requires_grad=True)\n",
      "[Iter 13600 Task segm] Task Loss: 0.4534 Reg Loss: 13.9975 Train Loss: 0.4534\n",
      "[Iter 13600 Task dept] Task Loss: 0.0238 Reg Loss: 18.0995 Train Loss: 0.0238\n",
      "[Iter 13600 Total] Train Loss: 0.2386\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Val Loss: 2.1118\n",
      "{'mIoU': 0.1501, 'Pixel Acc': 0.4037, 'cmp': -0.543}\n",
      "[Iter 13600 Task dept] Val Loss: 0.0472\n",
      "{'abs_err': 0.0422, 'rel_err': 0.7034, 'sigma_1.25': 45.7375, 'sigma_1.25^2': 69.152, 'sigma_1.25^3': 80.9558, 'cmp': -0.6585}\n",
      "======================================================================\n",
      "tau: 0.037950013300069\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0142,  0.8893], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2892, 0.5867], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4762, 0.3989], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3767, 0.4993], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7176, 0.1575], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 0.036621762834566585\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0108,  0.8850], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2862, 0.5889], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4767, 0.3976], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3761, 0.4990], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7178, 0.1564], device='cuda:0', requires_grad=True)\n",
      "[Iter 13800 Task segm] Task Loss: 0.4508 Reg Loss: 14.3659 Train Loss: 0.4508\n",
      "[Iter 13800 Task dept] Task Loss: 0.0231 Reg Loss: 18.4989 Train Loss: 0.0231\n",
      "[Iter 13800 Total] Train Loss: 0.2370\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Val Loss: 1.7402\n",
      "{'mIoU': 0.162, 'Pixel Acc': 0.4734, 'cmp': -0.4816}\n",
      "[Iter 13800 Task dept] Val Loss: 0.0410\n",
      "{'abs_err': 0.0372, 'rel_err': 0.67, 'sigma_1.25': 51.3423, 'sigma_1.25^2': 70.5665, 'sigma_1.25^3': 81.2781, 'cmp': -0.5599}\n",
      "======================================================================\n",
      "tau: 0.035340001135356756\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0196,  0.8930], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2857, 0.5885], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4778, 0.3956], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3757, 0.4986], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7197, 0.1537], device='cuda:0', requires_grad=True)\n",
      "tau: 0.034103101095619266\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0193,  0.8918], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2834, 0.5900], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4776, 0.3950], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3749, 0.4985], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7195, 0.1531], device='cuda:0', requires_grad=True)\n",
      "[Iter 14000 Task segm] Task Loss: 0.4449 Reg Loss: 13.7908 Train Loss: 0.4449\n",
      "[Iter 14000 Task dept] Task Loss: 0.0229 Reg Loss: 18.7113 Train Loss: 0.0229\n",
      "[Iter 14000 Total] Train Loss: 0.2339\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Val Loss: 1.7336\n",
      "{'mIoU': 0.1766, 'Pixel Acc': 0.4789, 'cmp': -0.4598}\n",
      "[Iter 14000 Task dept] Val Loss: 0.0445\n",
      "{'abs_err': 0.0401, 'rel_err': 0.6904, 'sigma_1.25': 48.2129, 'sigma_1.25^2': 70.1817, 'sigma_1.25^3': 81.4706, 'cmp': -0.6157}\n",
      "======================================================================\n",
      "tau: 0.03290949255727259\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0203,  0.8920], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2833, 0.5892], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4834, 0.3883], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3745, 0.4981], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7234, 0.1483], device='cuda:0', requires_grad=True)\n",
      "tau: 0.03175766031776805\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0208,  0.8917], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2815, 0.5902], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4845, 0.3864], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3737, 0.4981], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7229, 0.1479], device='cuda:0', requires_grad=True)\n",
      "[Iter 14200 Task segm] Task Loss: 0.4524 Reg Loss: 14.2184 Train Loss: 0.4524\n",
      "[Iter 14200 Task dept] Task Loss: 0.0243 Reg Loss: 18.3573 Train Loss: 0.0243\n",
      "[Iter 14200 Total] Train Loss: 0.2384\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Val Loss: 3.0199\n",
      "{'mIoU': 0.14, 'Pixel Acc': 0.3535, 'cmp': -0.5892}\n",
      "[Iter 14200 Task dept] Val Loss: 0.0393\n",
      "{'abs_err': 0.035, 'rel_err': 0.5585, 'sigma_1.25': 51.6621, 'sigma_1.25^2': 75.1115, 'sigma_1.25^3': 85.8571, 'cmp': -0.4448}\n",
      "======================================================================\n",
      "tau: 0.030646142206646167\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0227,  0.8927], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2813, 0.5896], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4848, 0.3852], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3731, 0.4977], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7278, 0.1422], device='cuda:0', requires_grad=True)\n",
      "tau: 0.02957352722941355\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0220,  0.8911], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2786, 0.5914], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4850, 0.3841], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3723, 0.4977], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7283, 0.1408], device='cuda:0', requires_grad=True)\n",
      "[Iter 14400 Task segm] Task Loss: 0.4314 Reg Loss: 13.7992 Train Loss: 0.4314\n",
      "[Iter 14400 Task dept] Task Loss: 0.0212 Reg Loss: 18.5602 Train Loss: 0.0212\n",
      "[Iter 14400 Total] Train Loss: 0.2263\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Val Loss: 2.1590\n",
      "{'mIoU': 0.1541, 'Pixel Acc': 0.4162, 'cmp': -0.5298}\n",
      "[Iter 14400 Task dept] Val Loss: 0.0524\n",
      "{'abs_err': 0.0469, 'rel_err': 0.787, 'sigma_1.25': 42.5883, 'sigma_1.25^2': 65.9506, 'sigma_1.25^3': 78.2121, 'cmp': -0.787}\n",
      "======================================================================\n",
      "tau: 0.028538453776384073\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0156,  0.8839], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2780, 0.5912], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4889, 0.3794], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3719, 0.4973], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7325, 0.1358], device='cuda:0', requires_grad=True)\n",
      "tau: 0.02753960789421063\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0220,  0.8895], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2760, 0.5923], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4831, 0.3844], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3704, 0.4979], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7321, 0.1354], device='cuda:0', requires_grad=True)\n",
      "[Iter 14600 Task segm] Task Loss: 0.4326 Reg Loss: 14.3494 Train Loss: 0.4326\n",
      "[Iter 14600 Task dept] Task Loss: 0.0253 Reg Loss: 18.6744 Train Loss: 0.0253\n",
      "[Iter 14600 Total] Train Loss: 0.2290\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Val Loss: 2.4226\n",
      "{'mIoU': 0.1377, 'Pixel Acc': 0.4132, 'cmp': -0.5521}\n",
      "[Iter 14600 Task dept] Val Loss: 0.0521\n",
      "{'abs_err': 0.0463, 'rel_err': 0.8391, 'sigma_1.25': 41.2056, 'sigma_1.25^2': 65.7688, 'sigma_1.25^3': 78.27, 'cmp': -0.8159}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 0.026575721617913255\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1290,  0.9956], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2757, 0.5918], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4416, 0.4250], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3698, 0.4976], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7181, 0.1485], device='cuda:0', requires_grad=True)\n",
      "tau: 0.02564557136128629\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1424,  1.0082], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2719, 0.5947], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4367, 0.4291], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3679, 0.4987], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7126, 0.1531], device='cuda:0', requires_grad=True)\n",
      "[Iter 14800 Task segm] Task Loss: 0.4830 Reg Loss: 13.9861 Train Loss: 0.4830\n",
      "[Iter 14800 Task dept] Task Loss: 0.0252 Reg Loss: 18.2600 Train Loss: 0.0252\n",
      "[Iter 14800 Total] Train Loss: 0.2541\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Val Loss: 3.0594\n",
      "{'mIoU': 0.1437, 'Pixel Acc': 0.4064, 'cmp': -0.5492}\n",
      "[Iter 14800 Task dept] Val Loss: 0.0380\n",
      "{'abs_err': 0.0344, 'rel_err': 0.594, 'sigma_1.25': 51.4591, 'sigma_1.25^2': 71.6762, 'sigma_1.25^3': 83.1704, 'cmp': -0.4741}\n",
      "======================================================================\n",
      "tau: 0.02474797636364127\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1507,  1.0156], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2714, 0.5943], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4283, 0.4367], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3675, 0.4983], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7046, 0.1604], device='cuda:0', requires_grad=True)\n",
      "tau: 0.023881797190913826\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1504,  1.0145], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2678, 0.5971], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4281, 0.4360], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3661, 0.4988], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7034, 0.1606], device='cuda:0', requires_grad=True)\n",
      "[Iter 15000 Task segm] Task Loss: 0.4700 Reg Loss: 14.3400 Train Loss: 0.4700\n",
      "[Iter 15000 Task dept] Task Loss: 0.0229 Reg Loss: 18.6369 Train Loss: 0.0229\n",
      "[Iter 15000 Total] Train Loss: 0.2464\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Val Loss: 1.7891\n",
      "{'mIoU': 0.1988, 'Pixel Acc': 0.4616, 'cmp': -0.4437}\n",
      "[Iter 15000 Task dept] Val Loss: 0.0377\n",
      "{'abs_err': 0.0345, 'rel_err': 0.5759, 'sigma_1.25': 52.0059, 'sigma_1.25^2': 72.524, 'sigma_1.25^3': 83.7223, 'cmp': -0.4596}\n",
      "======================================================================\n",
      "tau: 0.02304593428923184\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1677,  1.0309], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2673, 0.5968], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4151, 0.4481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3655, 0.4986], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7005, 0.1628], device='cuda:0', requires_grad=True)\n",
      "tau: 0.022239326589108724\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1656,  1.0280], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2639, 0.5993], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4160, 0.4464], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3645, 0.4987], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.6991, 0.1633], device='cuda:0', requires_grad=True)\n",
      "[Iter 15200 Task segm] Task Loss: 0.4563 Reg Loss: 14.1919 Train Loss: 0.4563\n",
      "[Iter 15200 Task dept] Task Loss: 0.0226 Reg Loss: 17.7997 Train Loss: 0.0226\n",
      "[Iter 15200 Total] Train Loss: 0.2394\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Val Loss: 1.9968\n",
      "{'mIoU': 0.173, 'Pixel Acc': 0.4106, 'cmp': -0.51}\n",
      "[Iter 15200 Task dept] Val Loss: 0.0472\n",
      "{'abs_err': 0.0421, 'rel_err': 0.7303, 'sigma_1.25': 45.5682, 'sigma_1.25^2': 67.878, 'sigma_1.25^3': 80.1097, 'cmp': -0.6798}\n",
      "======================================================================\n",
      "tau: 0.02146095015848992\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1643,  1.0259], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2632, 0.5992], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4193, 0.4422], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3641, 0.4983], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7046, 0.1569], device='cuda:0', requires_grad=True)\n",
      "tau: 0.02070981690294277\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1626,  1.0233], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2589, 0.6027], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4196, 0.4411], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3630, 0.4986], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7050, 0.1557], device='cuda:0', requires_grad=True)\n",
      "[Iter 15400 Task segm] Task Loss: 0.4405 Reg Loss: 14.3640 Train Loss: 0.4405\n",
      "[Iter 15400 Task dept] Task Loss: 0.0218 Reg Loss: 18.1186 Train Loss: 0.0218\n",
      "[Iter 15400 Total] Train Loss: 0.2311\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Val Loss: 2.3603\n",
      "{'mIoU': 0.1445, 'Pixel Acc': 0.3847, 'cmp': -0.5627}\n",
      "[Iter 15400 Task dept] Val Loss: 0.0421\n",
      "{'abs_err': 0.0375, 'rel_err': 0.6704, 'sigma_1.25': 50.3967, 'sigma_1.25^2': 70.4155, 'sigma_1.25^3': 81.4807, 'cmp': -0.5665}\n",
      "======================================================================\n",
      "tau: 0.019984973311339773\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1420,  1.0019], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2583, 0.6025], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4242, 0.4357], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3626, 0.4981], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7100, 0.1499], device='cuda:0', requires_grad=True)\n",
      "tau: 0.01928549924544288\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1361,  0.9952], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2547, 0.6052], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4255, 0.4336], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3619, 0.4980], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7112, 0.1479], device='cuda:0', requires_grad=True)\n",
      "[Iter 15600 Task segm] Task Loss: 0.4399 Reg Loss: 13.6702 Train Loss: 0.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 15600 Task dept] Task Loss: 0.0221 Reg Loss: 17.7045 Train Loss: 0.0221\n",
      "[Iter 15600 Total] Train Loss: 0.2310\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Val Loss: 2.1046\n",
      "{'mIoU': 0.144, 'Pixel Acc': 0.3908, 'cmp': -0.5594}\n",
      "[Iter 15600 Task dept] Val Loss: 0.0434\n",
      "{'abs_err': 0.0389, 'rel_err': 0.6696, 'sigma_1.25': 49.5054, 'sigma_1.25^2': 70.4515, 'sigma_1.25^3': 81.7663, 'cmp': -0.5841}\n",
      "======================================================================\n",
      "tau: 0.018610506771852376\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1282,  0.9864], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2543, 0.6048], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4318, 0.4264], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3616, 0.4975], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7138, 0.1445], device='cuda:0', requires_grad=True)\n",
      "tau: 0.01795913903483754\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1245,  0.9819], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2507, 0.6075], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4326, 0.4248], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3608, 0.4974], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7144, 0.1430], device='cuda:0', requires_grad=True)\n",
      "[Iter 15800 Task segm] Task Loss: 0.4204 Reg Loss: 14.3027 Train Loss: 0.4204\n",
      "[Iter 15800 Task dept] Task Loss: 0.0216 Reg Loss: 18.9584 Train Loss: 0.0216\n",
      "[Iter 15800 Total] Train Loss: 0.2210\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Val Loss: 1.8180\n",
      "{'mIoU': 0.1475, 'Pixel Acc': 0.4433, 'cmp': -0.5198}\n",
      "[Iter 15800 Task dept] Val Loss: 0.0463\n",
      "{'abs_err': 0.0418, 'rel_err': 0.7207, 'sigma_1.25': 46.9172, 'sigma_1.25^2': 68.6293, 'sigma_1.25^3': 80.3394, 'cmp': -0.6633}\n",
      "======================================================================\n",
      "tau: 0.017330569168618228\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1249,  0.9814], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2503, 0.6070], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4374, 0.4191], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3603, 0.4970], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7202, 0.1363], device='cuda:0', requires_grad=True)\n",
      "tau: 0.01672399924771659\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1261,  0.9818], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2478, 0.6087], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4387, 0.4170], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3588, 0.4977], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7208, 0.1349], device='cuda:0', requires_grad=True)\n",
      "[Iter 16000 Task segm] Task Loss: 0.4313 Reg Loss: 14.2913 Train Loss: 0.4313\n",
      "[Iter 16000 Task dept] Task Loss: 0.0216 Reg Loss: 18.5102 Train Loss: 0.0216\n",
      "[Iter 16000 Total] Train Loss: 0.2265\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Val Loss: 2.1664\n",
      "{'mIoU': 0.1261, 'Pixel Acc': 0.4222, 'cmp': -0.5605}\n",
      "[Iter 16000 Task dept] Val Loss: 0.0430\n",
      "{'abs_err': 0.0386, 'rel_err': 0.6886, 'sigma_1.25': 48.4753, 'sigma_1.25^2': 69.2065, 'sigma_1.25^3': 80.8448, 'cmp': -0.6001}\n",
      "======================================================================\n",
      "tau: 0.016138659274046507\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1145,  0.9694], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2474, 0.6083], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4349, 0.4200], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3585, 0.4972], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7230, 0.1319], device='cuda:0', requires_grad=True)\n",
      "tau: 0.015573806199454879\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1155,  0.9695], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2433, 0.6115], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4363, 0.4177], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3577, 0.4972], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7240, 0.1300], device='cuda:0', requires_grad=True)\n",
      "[Iter 16200 Task segm] Task Loss: 0.4274 Reg Loss: 13.9246 Train Loss: 0.4274\n",
      "[Iter 16200 Task dept] Task Loss: 0.0219 Reg Loss: 18.6707 Train Loss: 0.0219\n",
      "[Iter 16200 Total] Train Loss: 0.2247\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Val Loss: 1.9182\n",
      "{'mIoU': 0.16, 'Pixel Acc': 0.4349, 'cmp': -0.5099}\n",
      "[Iter 16200 Task dept] Val Loss: 0.0427\n",
      "{'abs_err': 0.0386, 'rel_err': 0.7003, 'sigma_1.25': 49.2404, 'sigma_1.25^2': 69.1151, 'sigma_1.25^3': 80.4522, 'cmp': -0.6054}\n",
      "======================================================================\n",
      "tau: 0.015028722982473958\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1202,  0.9734], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2430, 0.6111], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4437, 0.4095], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3574, 0.4967], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7307, 0.1225], device='cuda:0', requires_grad=True)\n",
      "tau: 0.01450271767808737\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1222,  0.9746], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2401, 0.6131], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4422, 0.4102], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3563, 0.4969], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7303, 0.1221], device='cuda:0', requires_grad=True)\n",
      "[Iter 16400 Task segm] Task Loss: 0.4266 Reg Loss: 13.9889 Train Loss: 0.4266\n",
      "[Iter 16400 Task dept] Task Loss: 0.0264 Reg Loss: 18.6070 Train Loss: 0.0264\n",
      "[Iter 16400 Total] Train Loss: 0.2265\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Val Loss: 2.0581\n",
      "{'mIoU': 0.1775, 'Pixel Acc': 0.4528, 'cmp': -0.4761}\n",
      "[Iter 16400 Task dept] Val Loss: 0.0445\n",
      "{'abs_err': 0.04, 'rel_err': 0.7699, 'sigma_1.25': 48.2204, 'sigma_1.25^2': 67.5903, 'sigma_1.25^3': 78.822, 'cmp': -0.6739}\n",
      "======================================================================\n",
      "tau: 0.013995122559354312\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1126,  0.9642], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2394, 0.6130], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4453, 0.4062], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3559, 0.4965], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7336, 0.1179], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 0.01350529326977691\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1070,  0.9577], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2349, 0.6166], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4437, 0.4070], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3555, 0.4960], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7331, 0.1176], device='cuda:0', requires_grad=True)\n",
      "[Iter 16600 Task segm] Task Loss: 0.4324 Reg Loss: 14.2352 Train Loss: 0.4324\n",
      "[Iter 16600 Task dept] Task Loss: 0.0239 Reg Loss: 18.2314 Train Loss: 0.0239\n",
      "[Iter 16600 Total] Train Loss: 0.2281\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Val Loss: 2.2769\n",
      "{'mIoU': 0.1519, 'Pixel Acc': 0.4066, 'cmp': -0.5389}\n",
      "[Iter 16600 Task dept] Val Loss: 0.0485\n",
      "{'abs_err': 0.0435, 'rel_err': 0.7514, 'sigma_1.25': 44.9405, 'sigma_1.25^2': 67.1878, 'sigma_1.25^3': 79.2767, 'cmp': -0.714}\n",
      "======================================================================\n",
      "tau: 0.013032608005334718\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.1010,  0.9509], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2344, 0.6163], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4532, 0.3967], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3553, 0.4954], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7398, 0.1101], device='cuda:0', requires_grad=True)\n",
      "tau: 0.012576466725148002\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0999,  0.9490], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2311, 0.6188], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4539, 0.3951], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3547, 0.4952], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7399, 0.1092], device='cuda:0', requires_grad=True)\n",
      "[Iter 16800 Task segm] Task Loss: 0.4245 Reg Loss: 13.7040 Train Loss: 0.4245\n",
      "[Iter 16800 Task dept] Task Loss: 0.0241 Reg Loss: 18.7542 Train Loss: 0.0241\n",
      "[Iter 16800 Total] Train Loss: 0.2243\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Val Loss: 2.0805\n",
      "{'mIoU': 0.1318, 'Pixel Acc': 0.4158, 'cmp': -0.5577}\n",
      "[Iter 16800 Task dept] Val Loss: 0.0462\n",
      "{'abs_err': 0.0415, 'rel_err': 0.706, 'sigma_1.25': 46.0334, 'sigma_1.25^2': 68.6056, 'sigma_1.25^3': 80.5256, 'cmp': -0.6531}\n",
      "======================================================================\n",
      "tau: 0.012136290389767821\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0915,  0.9397], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2307, 0.6183], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4565, 0.3917], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3542, 0.4949], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7452, 0.1031], device='cuda:0', requires_grad=True)\n",
      "tau: 0.011711520226125947\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0881,  0.9355], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2266, 0.6216], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4566, 0.3908], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3527, 0.4955], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7448, 0.1026], device='cuda:0', requires_grad=True)\n",
      "[Iter 17000 Task segm] Task Loss: 0.4186 Reg Loss: 13.7016 Train Loss: 0.4186\n",
      "[Iter 17000 Task dept] Task Loss: 0.0221 Reg Loss: 18.7030 Train Loss: 0.0221\n",
      "[Iter 17000 Total] Train Loss: 0.2203\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Val Loss: 2.4388\n",
      "{'mIoU': 0.1302, 'Pixel Acc': 0.39, 'cmp': -0.577}\n",
      "[Iter 17000 Task dept] Val Loss: 0.0597\n",
      "{'abs_err': 0.0535, 'rel_err': 0.8582, 'sigma_1.25': 37.6105, 'sigma_1.25^2': 62.6055, 'sigma_1.25^3': 75.8786, 'cmp': -0.9351}\n",
      "======================================================================\n",
      "tau: 0.011301617018211538\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0850,  0.9316], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2262, 0.6212], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4628, 0.3838], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3525, 0.4949], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7524, 0.0941], device='cuda:0', requires_grad=True)\n",
      "tau: 0.010906060422574134\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0862,  0.9320], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2235, 0.6230], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4643, 0.3814], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3510, 0.4956], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7514, 0.0943], device='cuda:0', requires_grad=True)\n",
      "[Iter 17200 Task segm] Task Loss: 0.4191 Reg Loss: 13.5284 Train Loss: 0.4191\n",
      "[Iter 17200 Task dept] Task Loss: 0.0211 Reg Loss: 18.4567 Train Loss: 0.0211\n",
      "[Iter 17200 Total] Train Loss: 0.2201\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Val Loss: 2.1422\n",
      "{'mIoU': 0.1279, 'Pixel Acc': 0.4274, 'cmp': -0.5549}\n",
      "[Iter 17200 Task dept] Val Loss: 0.0406\n",
      "{'abs_err': 0.0367, 'rel_err': 0.6265, 'sigma_1.25': 50.9903, 'sigma_1.25^2': 71.3019, 'sigma_1.25^3': 82.3635, 'cmp': -0.5245}\n",
      "======================================================================\n",
      "tau: 0.010524348307784039\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0791,  0.9240], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2233, 0.6224], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4675, 0.3774], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3505, 0.4953], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7543, 0.0906], device='cuda:0', requires_grad=True)\n",
      "tau: 0.010155996117011597\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0747,  0.9188], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2194, 0.6255], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4661, 0.3781], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3492, 0.4957], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7536, 0.0905], device='cuda:0', requires_grad=True)\n",
      "[Iter 17400 Task segm] Task Loss: 0.4370 Reg Loss: 13.7812 Train Loss: 0.4370\n",
      "[Iter 17400 Task dept] Task Loss: 0.0217 Reg Loss: 17.8853 Train Loss: 0.0217\n",
      "[Iter 17400 Total] Train Loss: 0.2293\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Val Loss: 2.1038\n",
      "{'mIoU': 0.1832, 'Pixel Acc': 0.4278, 'cmp': -0.4857}\n",
      "[Iter 17400 Task dept] Val Loss: 0.0599\n",
      "{'abs_err': 0.0535, 'rel_err': 0.8937, 'sigma_1.25': 35.0814, 'sigma_1.25^2': 62.3013, 'sigma_1.25^3': 75.7338, 'cmp': -0.9645}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "tau: 0.00980053625291619\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0920,  0.9353], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2189, 0.6252], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4645, 0.3787], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3488, 0.4953], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7554, 0.0879], device='cuda:0', requires_grad=True)\n",
      "tau: 0.009457517484064122\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0935,  0.9360], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2174, 0.6259], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4640, 0.3784], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3475, 0.4958], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7546, 0.0879], device='cuda:0', requires_grad=True)\n",
      "[Iter 17600 Task segm] Task Loss: 0.4301 Reg Loss: 13.8909 Train Loss: 0.4301\n",
      "[Iter 17600 Task dept] Task Loss: 0.0238 Reg Loss: 18.2785 Train Loss: 0.0238\n",
      "[Iter 17600 Total] Train Loss: 0.2270\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Val Loss: 2.1239\n",
      "{'mIoU': 0.1392, 'Pixel Acc': 0.4449, 'cmp': -0.529}\n",
      "[Iter 17600 Task dept] Val Loss: 0.0452\n",
      "{'abs_err': 0.0407, 'rel_err': 0.7067, 'sigma_1.25': 48.2321, 'sigma_1.25^2': 68.89, 'sigma_1.25^3': 80.3729, 'cmp': -0.6382}\n",
      "======================================================================\n",
      "tau: 0.009126504372121877\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0886,  0.9303], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2171, 0.6254], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4647, 0.3769], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3472, 0.4953], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7583, 0.0833], device='cuda:0', requires_grad=True)\n",
      "tau: 0.008807076719097612\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0838,  0.9247], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2147, 0.6269], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4656, 0.3752], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3456, 0.4960], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7580, 0.0829], device='cuda:0', requires_grad=True)\n",
      "[Iter 17800 Task segm] Task Loss: 0.4182 Reg Loss: 13.3790 Train Loss: 0.4182\n",
      "[Iter 17800 Task dept] Task Loss: 0.0266 Reg Loss: 18.5938 Train Loss: 0.0266\n",
      "[Iter 17800 Total] Train Loss: 0.2224\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Val Loss: 2.2225\n",
      "{'mIoU': 0.1418, 'Pixel Acc': 0.3851, 'cmp': -0.5659}\n",
      "[Iter 17800 Task dept] Val Loss: 0.0591\n",
      "{'abs_err': 0.0532, 'rel_err': 0.8853, 'sigma_1.25': 36.1937, 'sigma_1.25^2': 62.0211, 'sigma_1.25^3': 75.6246, 'cmp': -0.9537}\n",
      "======================================================================\n",
      "tau: 0.008498829033929196\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0827,  0.9228], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2144, 0.6265], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4634, 0.3766], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3452, 0.4957], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7614, 0.0786], device='cuda:0', requires_grad=True)\n",
      "tau: 0.008201370017741674\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0803,  0.9195], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2115, 0.6285], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4622, 0.3770], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3454, 0.4946], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7607, 0.0785], device='cuda:0', requires_grad=True)\n",
      "[Iter 18000 Task segm] Task Loss: 0.4155 Reg Loss: 13.6677 Train Loss: 0.4155\n",
      "[Iter 18000 Task dept] Task Loss: 0.0229 Reg Loss: 18.6829 Train Loss: 0.0229\n",
      "[Iter 18000 Total] Train Loss: 0.2192\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Val Loss: 2.0597\n",
      "{'mIoU': 0.1622, 'Pixel Acc': 0.4326, 'cmp': -0.5087}\n",
      "[Iter 18000 Task dept] Val Loss: 0.0625\n",
      "{'abs_err': 0.0566, 'rel_err': 0.9809, 'sigma_1.25': 36.5175, 'sigma_1.25^2': 60.0039, 'sigma_1.25^3': 73.1586, 'cmp': -1.0605}\n",
      "======================================================================\n",
      "tau: 0.007914322067120715\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0828,  0.9211], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2110, 0.6282], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4645, 0.3739], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3451, 0.4941], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7632, 0.0752], device='cuda:0', requires_grad=True)\n",
      "tau: 0.0076373207947714895\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0803,  0.9178], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2099, 0.6285], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4637, 0.3738], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3438, 0.4946], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7625, 0.0750], device='cuda:0', requires_grad=True)\n",
      "[Iter 18200 Task segm] Task Loss: 0.4133 Reg Loss: 13.5150 Train Loss: 0.4133\n",
      "[Iter 18200 Task dept] Task Loss: 0.0208 Reg Loss: 18.2839 Train Loss: 0.0208\n",
      "[Iter 18200 Total] Train Loss: 0.2170\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Val Loss: 2.0887\n",
      "{'mIoU': 0.1445, 'Pixel Acc': 0.4449, 'cmp': -0.5225}\n",
      "[Iter 18200 Task dept] Val Loss: 0.0517\n",
      "{'abs_err': 0.0462, 'rel_err': 0.8216, 'sigma_1.25': 43.5968, 'sigma_1.25^2': 65.4606, 'sigma_1.25^3': 77.8613, 'cmp': -0.7989}\n",
      "======================================================================\n",
      "tau: 0.007370014566954487\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0807,  0.9175], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2095, 0.6281], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4709, 0.3659], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3434, 0.4941], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7707, 0.0661], device='cuda:0', requires_grad=True)\n",
      "tau: 0.00711206405711108\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0862,  0.9221], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2081, 0.6286], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4722, 0.3637], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3425, 0.4943], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7701, 0.0659], device='cuda:0', requires_grad=True)\n",
      "[Iter 18400 Task segm] Task Loss: 0.4184 Reg Loss: 13.3706 Train Loss: 0.4184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 18400 Task dept] Task Loss: 0.0208 Reg Loss: 18.4511 Train Loss: 0.0208\n",
      "[Iter 18400 Total] Train Loss: 0.2196\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Val Loss: 1.9122\n",
      "{'mIoU': 0.157, 'Pixel Acc': 0.4758, 'cmp': -0.4862}\n",
      "[Iter 18400 Task dept] Val Loss: 0.0508\n",
      "{'abs_err': 0.0464, 'rel_err': 0.7909, 'sigma_1.25': 43.4313, 'sigma_1.25^2': 65.0917, 'sigma_1.25^3': 77.644, 'cmp': -0.7844}\n",
      "======================================================================\n",
      "tau: 0.006863141815112192\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0944,  0.9295], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2080, 0.6279], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4660, 0.3691], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3420, 0.4939], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7689, 0.0662], device='cuda:0', requires_grad=True)\n",
      "tau: 0.006622931851583265\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0932,  0.9275], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2068, 0.6283], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4672, 0.3671], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3395, 0.4956], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7686, 0.0657], device='cuda:0', requires_grad=True)\n",
      "[Iter 18600 Task segm] Task Loss: 0.4212 Reg Loss: 12.7909 Train Loss: 0.4212\n",
      "[Iter 18600 Task dept] Task Loss: 0.0215 Reg Loss: 18.5109 Train Loss: 0.0215\n",
      "[Iter 18600 Total] Train Loss: 0.2213\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Val Loss: 1.8561\n",
      "{'mIoU': 0.1602, 'Pixel Acc': 0.4413, 'cmp': -0.5053}\n",
      "[Iter 18600 Task dept] Val Loss: 0.0654\n",
      "{'abs_err': 0.0592, 'rel_err': 0.9949, 'sigma_1.25': 33.0872, 'sigma_1.25^2': 59.2184, 'sigma_1.25^3': 73.011, 'cmp': -1.1114}\n",
      "======================================================================\n",
      "tau: 0.0063911292367778505\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0985,  0.9320], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2064, 0.6279], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4760, 0.3575], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3391, 0.4952], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7727, 0.0608], device='cuda:0', requires_grad=True)\n",
      "tau: 0.006167439713490625\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0983,  0.9310], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2049, 0.6286], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4757, 0.3570], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3386, 0.4949], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7729, 0.0598], device='cuda:0', requires_grad=True)\n",
      "[Iter 18800 Task segm] Task Loss: 0.4136 Reg Loss: 13.8661 Train Loss: 0.4136\n",
      "[Iter 18800 Task dept] Task Loss: 0.0213 Reg Loss: 18.4671 Train Loss: 0.0213\n",
      "[Iter 18800 Total] Train Loss: 0.2174\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Val Loss: 1.9476\n",
      "{'mIoU': 0.1523, 'Pixel Acc': 0.4265, 'cmp': -0.5251}\n",
      "[Iter 18800 Task dept] Val Loss: 0.0570\n",
      "{'abs_err': 0.0517, 'rel_err': 0.8777, 'sigma_1.25': 38.539, 'sigma_1.25^2': 61.7218, 'sigma_1.25^3': 75.2299, 'cmp': -0.9266}\n",
      "======================================================================\n",
      "tau: 0.005951579323518454\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0900,  0.9218], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2045, 0.6282], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4804, 0.3515], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3382, 0.4945], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7782, 0.0537], device='cuda:0', requires_grad=True)\n",
      "tau: 0.005743274047195307\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0831,  0.9142], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2021, 0.6298], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4812, 0.3498], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3365, 0.4954], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7773, 0.0537], device='cuda:0', requires_grad=True)\n",
      "[Iter 19000 Task segm] Task Loss: 0.4021 Reg Loss: 13.2950 Train Loss: 0.4021\n",
      "[Iter 19000 Task dept] Task Loss: 0.0220 Reg Loss: 18.8133 Train Loss: 0.0220\n",
      "[Iter 19000 Total] Train Loss: 0.2121\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Val Loss: 2.1551\n",
      "{'mIoU': 0.1445, 'Pixel Acc': 0.4338, 'cmp': -0.5299}\n",
      "[Iter 19000 Task dept] Val Loss: 0.0703\n",
      "{'abs_err': 0.0647, 'rel_err': 1.0479, 'sigma_1.25': 30.309, 'sigma_1.25^2': 55.2169, 'sigma_1.25^3': 70.3256, 'cmp': -1.2311}\n",
      "======================================================================\n",
      "tau: 0.005542259455543471\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0834,  0.9137], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.2017, 0.6293], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4789, 0.3513], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3361, 0.4950], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7809, 0.0493], device='cuda:0', requires_grad=True)\n",
      "tau: 0.005348280374599449\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0809,  0.9103], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1994, 0.6308], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4799, 0.3495], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3355, 0.4948], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7811, 0.0484], device='cuda:0', requires_grad=True)\n",
      "[Iter 19200 Task segm] Task Loss: 0.4137 Reg Loss: 13.3214 Train Loss: 0.4137\n",
      "[Iter 19200 Task dept] Task Loss: 0.0232 Reg Loss: 18.1891 Train Loss: 0.0232\n",
      "[Iter 19200 Total] Train Loss: 0.2184\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Val Loss: 2.1356\n",
      "{'mIoU': 0.1302, 'Pixel Acc': 0.3946, 'cmp': -0.5739}\n",
      "[Iter 19200 Task dept] Val Loss: 0.0571\n",
      "{'abs_err': 0.0516, 'rel_err': 0.8823, 'sigma_1.25': 38.5152, 'sigma_1.25^2': 62.71, 'sigma_1.25^3': 75.8273, 'cmp': -0.9249}\n",
      "======================================================================\n",
      "tau: 0.005161090561488468\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0801,  0.9087], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1990, 0.6304], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4819, 0.3467], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3351, 0.4943], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7842, 0.0444], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 0.004980452391836371\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0771,  0.9049], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1942, 0.6344], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4820, 0.3459], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3348, 0.4938], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7839, 0.0440], device='cuda:0', requires_grad=True)\n",
      "[Iter 19400 Task segm] Task Loss: 0.4167 Reg Loss: 13.4304 Train Loss: 0.4167\n",
      "[Iter 19400 Task dept] Task Loss: 0.0224 Reg Loss: 18.7502 Train Loss: 0.0224\n",
      "[Iter 19400 Total] Train Loss: 0.2195\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Val Loss: 2.9060\n",
      "{'mIoU': 0.113, 'Pixel Acc': 0.3387, 'cmp': -0.6327}\n",
      "[Iter 19400 Task dept] Val Loss: 0.0607\n",
      "{'abs_err': 0.055, 'rel_err': 0.8961, 'sigma_1.25': 35.5244, 'sigma_1.25^2': 61.1512, 'sigma_1.25^3': 75.0925, 'cmp': -0.9862}\n",
      "======================================================================\n",
      "tau: 0.004806136558122098\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0798,  0.9068], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1938, 0.6340], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4862, 0.3408], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3345, 0.4933], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7884, 0.0386], device='cuda:0', requires_grad=True)\n",
      "tau: 0.004637921778587824\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0765,  0.9027], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1868, 0.6402], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4853, 0.3409], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3315, 0.4955], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7868, 0.0394], device='cuda:0', requires_grad=True)\n",
      "[Iter 19600 Task segm] Task Loss: 0.4111 Reg Loss: 13.0661 Train Loss: 0.4111\n",
      "[Iter 19600 Task dept] Task Loss: 0.0222 Reg Loss: 18.7416 Train Loss: 0.0222\n",
      "[Iter 19600 Total] Train Loss: 0.2166\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Val Loss: 2.8164\n",
      "{'mIoU': 0.1081, 'Pixel Acc': 0.3739, 'cmp': -0.6153}\n",
      "[Iter 19600 Task dept] Val Loss: 0.0578\n",
      "{'abs_err': 0.0531, 'rel_err': 0.9441, 'sigma_1.25': 38.499, 'sigma_1.25^2': 60.8389, 'sigma_1.25^3': 74.0451, 'cmp': -0.9875}\n",
      "======================================================================\n",
      "tau: 0.00447559451633725\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0814,  0.9068], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1864, 0.6398], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4885, 0.3369], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3312, 0.4951], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7884, 0.0370], device='cuda:0', requires_grad=True)\n",
      "tau: 0.004318948708265446\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0799,  0.9045], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1855, 0.6399], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4862, 0.3384], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3299, 0.4955], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7870, 0.0376], device='cuda:0', requires_grad=True)\n",
      "[Iter 19800 Task segm] Task Loss: 0.4036 Reg Loss: 12.8485 Train Loss: 0.4036\n",
      "[Iter 19800 Task dept] Task Loss: 0.0213 Reg Loss: 18.1797 Train Loss: 0.0213\n",
      "[Iter 19800 Total] Train Loss: 0.2124\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Val Loss: 2.2400\n",
      "{'mIoU': 0.134, 'Pixel Acc': 0.3619, 'cmp': -0.5911}\n",
      "[Iter 19800 Task dept] Val Loss: 0.0519\n",
      "{'abs_err': 0.0469, 'rel_err': 0.781, 'sigma_1.25': 41.8575, 'sigma_1.25^2': 64.6027, 'sigma_1.25^3': 77.4034, 'cmp': -0.7904}\n",
      "======================================================================\n",
      "tau: 0.004167785503476155\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0780,  0.9018], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1854, 0.6392], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4849, 0.3389], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3295, 0.4951], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7902, 0.0336], device='cuda:0', requires_grad=True)\n",
      "tau: 0.004021913010854489\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([-0.0759,  0.8989], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.1824, 0.6414], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4837, 0.3393], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.3287, 0.4951], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.7900, 0.0330], device='cuda:0', requires_grad=True)\n",
      "[Iter 20000 Task segm] Task Loss: 0.4040 Reg Loss: 13.1729 Train Loss: 0.4040\n",
      "[Iter 20000 Task dept] Task Loss: 0.0214 Reg Loss: 18.6913 Train Loss: 0.0214\n",
      "[Iter 20000 Total] Train Loss: 0.2127\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Val Loss: 2.1104\n",
      "{'mIoU': 0.1522, 'Pixel Acc': 0.4228, 'cmp': -0.5277}\n",
      "[Iter 20000 Task dept] Val Loss: 0.0440\n",
      "{'abs_err': 0.04, 'rel_err': 0.7162, 'sigma_1.25': 48.2696, 'sigma_1.25^2': 68.078, 'sigma_1.25^3': 79.6985, 'cmp': -0.6382}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Task alter-train with reg - on training set 2, only has 595 inputs\n",
    "loss_lambda = {'segment_semantic': 1, 'depth_zbuffer': 20, 'policy':0.00}\n",
    "trainer.task_alter_train_with_reg(iters=20000, task_iters=(100,100),policy_lr=0.01, network_lr=0.001, \n",
    "                                  tau=5, tau_ratio=0.965, loss_lambda=loss_lambda,\n",
    "                                  savePath='checkpoints/Cityscapes_re/', reload='pre_train_24000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 4.825\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4541, 0.5450], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.5000, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4783, 0.5208], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.5000, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4927, 0.5064], device='cuda:0', requires_grad=True)\n",
      "tau: 4.656125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4521, 0.5461], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4987, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4764, 0.5217], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4985, 0.5006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4912, 0.5069], device='cuda:0', requires_grad=True)\n",
      "[Iter 200 Task segm] Task Loss: 0.6851 Reg Loss: 9.9181 Train Loss: 0.6851\n",
      "[Iter 200 Task dept] Task Loss: 0.0219 Reg Loss: 9.6551 Train Loss: 0.0219\n",
      "[Iter 200 Total] Train Loss: 0.3535\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 0.8756\n",
      "{'mIoU': 0.4132, 'Pixel Acc': 0.6541, 'cmp': -0.0482}\n",
      "[Iter 200 Task dept] Val Loss: 0.0265\n",
      "{'abs_err': 0.0287, 'rel_err': 0.4057, 'sigma_1.25': 53.4612, 'sigma_1.25^2': 74.6295, 'sigma_1.25^3': 85.5578, 'cmp': -0.275}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4411, 0.5561], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4982, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4686, 0.5285], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4980, 0.5002], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4872, 0.5100], device='cuda:0', requires_grad=True)\n",
      "tau: 4.3359000031249995\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4400, 0.5562], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4968, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4678, 0.5283], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4968, 0.5004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4868, 0.5094], device='cuda:0', requires_grad=True)\n",
      "[Iter 400 Task segm] Task Loss: 0.6504 Reg Loss: 9.8392 Train Loss: 0.6504\n",
      "[Iter 400 Task dept] Task Loss: 0.0244 Reg Loss: 9.7897 Train Loss: 0.0244\n",
      "[Iter 400 Total] Train Loss: 0.3374\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 0.8307\n",
      "{'mIoU': 0.4276, 'Pixel Acc': 0.6596, 'cmp': -0.0267}\n",
      "[Iter 400 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0276, 'rel_err': 0.4377, 'sigma_1.25': 56.9377, 'sigma_1.25^2': 77.2817, 'sigma_1.25^3': 87.2763, 'cmp': -0.2622}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4258, 0.5694], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4963, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4622, 0.5331], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4963, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4842, 0.5110], device='cuda:0', requires_grad=True)\n",
      "tau: 4.037698480410078\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4246, 0.5696], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4953, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4616, 0.5326], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4952, 0.5000], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4842, 0.5101], device='cuda:0', requires_grad=True)\n",
      "[Iter 600 Task segm] Task Loss: 0.6556 Reg Loss: 9.8948 Train Loss: 0.6556\n",
      "[Iter 600 Task dept] Task Loss: 0.0225 Reg Loss: 9.8335 Train Loss: 0.0225\n",
      "[Iter 600 Total] Train Loss: 0.3391\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 0.8919\n",
      "{'mIoU': 0.427, 'Pixel Acc': 0.6539, 'cmp': -0.0312}\n",
      "[Iter 600 Task dept] Val Loss: 0.0292\n",
      "{'abs_err': 0.0271, 'rel_err': 0.4804, 'sigma_1.25': 59.1231, 'sigma_1.25^2': 78.1143, 'sigma_1.25^3': 87.7408, 'cmp': -0.2731}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4066, 0.5867], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4947, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4551, 0.5382], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4947, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4799, 0.5134], device='cuda:0', requires_grad=True)\n",
      "tau: 3.7600057674198744\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4051, 0.5872], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4938, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4545, 0.5378], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4937, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4794, 0.5129], device='cuda:0', requires_grad=True)\n",
      "[Iter 800 Task segm] Task Loss: 0.6489 Reg Loss: 9.9100 Train Loss: 0.6489\n",
      "[Iter 800 Task dept] Task Loss: 0.0223 Reg Loss: 10.1219 Train Loss: 0.0223\n",
      "[Iter 800 Total] Train Loss: 0.3356\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 0.7892\n",
      "{'mIoU': 0.3945, 'Pixel Acc': 0.6607, 'cmp': -0.0671}\n",
      "[Iter 800 Task dept] Val Loss: 0.0264\n",
      "{'abs_err': 0.026, 'rel_err': 0.4192, 'sigma_1.25': 59.5624, 'sigma_1.25^2': 78.0497, 'sigma_1.25^3': 87.7074, 'cmp': -0.2215}\n",
      "======================================================================\n",
      "tau: 3.6284055655601786\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3828, 0.6085], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4932, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4466, 0.5448], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4932, 0.4991], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4778, 0.5135], device='cuda:0', requires_grad=True)\n",
      "tau: 3.501411370765572\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3814, 0.6090], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4911, 0.5002], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4457, 0.5447], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4917, 0.4996], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4765, 0.5139], device='cuda:0', requires_grad=True)\n",
      "[Iter 1000 Task segm] Task Loss: 0.6390 Reg Loss: 10.0239 Train Loss: 0.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1000 Task dept] Task Loss: 0.0228 Reg Loss: 10.0611 Train Loss: 0.0228\n",
      "[Iter 1000 Total] Train Loss: 0.3309\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 0.8607\n",
      "{'mIoU': 0.3836, 'Pixel Acc': 0.6399, 'cmp': -0.0945}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0264\n",
      "{'abs_err': 0.0277, 'rel_err': 0.4331, 'sigma_1.25': 56.6233, 'sigma_1.25^2': 75.4476, 'sigma_1.25^3': 85.2392, 'cmp': -0.2693}\n",
      "======================================================================\n",
      "tau: 3.3788619727887768\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3683, 0.6211], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4905, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4413, 0.5481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4912, 0.4992], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4754, 0.5140], device='cuda:0', requires_grad=True)\n",
      "tau: 3.2606018037411695\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([0.3667, 0.6218], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4895, 0.4999], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4411, 0.5473], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0.4900, 0.4995], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([0.4748, 0.5136], device='cuda:0', requires_grad=True)\n",
      "[Iter 1200 Task segm] Task Loss: 0.6376 Reg Loss: 10.3656 Train Loss: 0.6376\n",
      "[Iter 1200 Task dept] Task Loss: 0.0221 Reg Loss: 10.1598 Train Loss: 0.0221\n",
      "[Iter 1200 Total] Train Loss: 0.3298\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 0.9007\n",
      "{'mIoU': 0.38, 'Pixel Acc': 0.6374, 'cmp': -0.1007}\n",
      "[Iter 1200 Task dept] Val Loss: 0.0272\n",
      "{'abs_err': 0.0268, 'rel_err': 0.4347, 'sigma_1.25': 58.5188, 'sigma_1.25^2': 77.2117, 'sigma_1.25^3': 86.8642, 'cmp': -0.247}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Task alter-train with reg - on training set 2, only has 595 inputs, reg=0.01\n",
    "loss_lambda = {'segment_semantic': 1, 'depth_zbuffer': 1, 'policy':0.01}\n",
    "trainer.task_alter_train_with_reg(iters=20000, task_iters=(100,100),policy_lr=0.01, network_lr=0.001, \n",
    "                                  tau=5, tau_ratio=0.965, loss_lambda=loss_lambda,\n",
    "                                  savePath='checkpoints/Cityscapes_re2/', reload='pre_train_24000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Policy:\n",
      "OrderedDict([('net.0.policy.segment_semantic', tensor([-0.0759,  0.8989], device='cuda:0')), ('net.0.policy.depth_zbuffer', tensor([0.1824, 0.6414], device='cuda:0')), ('net.1.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.1.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.4.policy.segment_semantic', tensor([0.4837, 0.3393], device='cuda:0')), ('net.4.policy.depth_zbuffer', tensor([0.3287, 0.4951], device='cuda:0')), ('net.5.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.5.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.7.policy.segment_semantic', tensor([0.7900, 0.0330], device='cuda:0')), ('net.7.policy.depth_zbuffer', tensor([0.3413, 0.4825], device='cuda:0')), ('net.8.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.8.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.11.policy.segment_semantic', tensor([0.6922, 0.1308], device='cuda:0')), ('net.11.policy.depth_zbuffer', tensor([0.3577, 0.4661], device='cuda:0')), ('net.12.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.12.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.14.policy.segment_semantic', tensor([0.7051, 0.1179], device='cuda:0')), ('net.14.policy.depth_zbuffer', tensor([0.3680, 0.4558], device='cuda:0')), ('net.15.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.15.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.18.policy.segment_semantic', tensor([0.6549, 0.1681], device='cuda:0')), ('net.18.policy.depth_zbuffer', tensor([0.4001, 0.4237], device='cuda:0')), ('net.19.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.19.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.21.policy.segment_semantic', tensor([0.6599, 0.1631], device='cuda:0')), ('net.21.policy.depth_zbuffer', tensor([0.3863, 0.4375], device='cuda:0')), ('net.22.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.22.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.25.policy.segment_semantic', tensor([0.4563, 0.3667], device='cuda:0')), ('net.25.policy.depth_zbuffer', tensor([0.4099, 0.4139], device='cuda:0')), ('net.26.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.26.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.27.policy.segment_semantic', tensor([0.7671, 0.0559], device='cuda:0')), ('net.27.policy.depth_zbuffer', tensor([0.3879, 0.4359], device='cuda:0')), ('net.28.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.28.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.30.policy.segment_semantic', tensor([ 0.9678, -0.1448], device='cuda:0')), ('net.30.policy.depth_zbuffer', tensor([0.3490, 0.4748], device='cuda:0')), ('net.31.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.31.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.34.policy.segment_semantic', tensor([ 0.8577, -0.0347], device='cuda:0')), ('net.34.policy.depth_zbuffer', tensor([0.3645, 0.4593], device='cuda:0')), ('net.35.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.35.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.37.policy.segment_semantic', tensor([ 0.8384, -0.0154], device='cuda:0')), ('net.37.policy.depth_zbuffer', tensor([0.3665, 0.4573], device='cuda:0')), ('net.38.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.38.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.41.policy.segment_semantic', tensor([0.7615, 0.0615], device='cuda:0')), ('net.41.policy.depth_zbuffer', tensor([0.3749, 0.4489], device='cuda:0')), ('net.42.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.42.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.44.policy.segment_semantic', tensor([0.7181, 0.1049], device='cuda:0')), ('net.44.policy.depth_zbuffer', tensor([0.3899, 0.4339], device='cuda:0')), ('net.45.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.45.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.48.policy.segment_semantic', tensor([0.6767, 0.1463], device='cuda:0')), ('net.48.policy.depth_zbuffer', tensor([0.3859, 0.4379], device='cuda:0')), ('net.49.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.49.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.51.policy.segment_semantic', tensor([0.6489, 0.1741], device='cuda:0')), ('net.51.policy.depth_zbuffer', tensor([0.3950, 0.4288], device='cuda:0')), ('net.52.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.52.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.55.policy.segment_semantic', tensor([0.5103, 0.3127], device='cuda:0')), ('net.55.policy.depth_zbuffer', tensor([0.4062, 0.4176], device='cuda:0')), ('net.56.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.56.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.57.policy.segment_semantic', tensor([0.7810, 0.0420], device='cuda:0')), ('net.57.policy.depth_zbuffer', tensor([0.3766, 0.4472], device='cuda:0')), ('net.58.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.58.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.60.policy.segment_semantic', tensor([ 0.9652, -0.1422], device='cuda:0')), ('net.60.policy.depth_zbuffer', tensor([0.3406, 0.4832], device='cuda:0')), ('net.61.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.61.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.64.policy.segment_semantic', tensor([ 0.8444, -0.0214], device='cuda:0')), ('net.64.policy.depth_zbuffer', tensor([0.3565, 0.4673], device='cuda:0')), ('net.65.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.65.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.67.policy.segment_semantic', tensor([0.7528, 0.0702], device='cuda:0')), ('net.67.policy.depth_zbuffer', tensor([0.3742, 0.4496], device='cuda:0')), ('net.68.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.68.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.71.policy.segment_semantic', tensor([0.7165, 0.1065], device='cuda:0')), ('net.71.policy.depth_zbuffer', tensor([0.3804, 0.4434], device='cuda:0')), ('net.72.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.72.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.74.policy.segment_semantic', tensor([0.6574, 0.1656], device='cuda:0')), ('net.74.policy.depth_zbuffer', tensor([0.3848, 0.4390], device='cuda:0')), ('net.75.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.75.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.78.policy.segment_semantic', tensor([0.6398, 0.1832], device='cuda:0')), ('net.78.policy.depth_zbuffer', tensor([0.3893, 0.4345], device='cuda:0')), ('net.79.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.79.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.81.policy.segment_semantic', tensor([0.6229, 0.2001], device='cuda:0')), ('net.81.policy.depth_zbuffer', tensor([0.3897, 0.4341], device='cuda:0')), ('net.82.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.82.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.85.policy.segment_semantic', tensor([0.5992, 0.2238], device='cuda:0')), ('net.85.policy.depth_zbuffer', tensor([0.3939, 0.4299], device='cuda:0')), ('net.86.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.86.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.88.policy.segment_semantic', tensor([0.5726, 0.2504], device='cuda:0')), ('net.88.policy.depth_zbuffer', tensor([0.3944, 0.4294], device='cuda:0')), ('net.89.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.89.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.92.policy.segment_semantic', tensor([0.5959, 0.2271], device='cuda:0')), ('net.92.policy.depth_zbuffer', tensor([0.3932, 0.4306], device='cuda:0')), ('net.93.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.93.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.95.policy.segment_semantic', tensor([0.5700, 0.2530], device='cuda:0')), ('net.95.policy.depth_zbuffer', tensor([0.3929, 0.4309], device='cuda:0')), ('net.96.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.96.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.99.policy.segment_semantic', tensor([0.5709, 0.2521], device='cuda:0')), ('net.99.policy.depth_zbuffer', tensor([0.3929, 0.4309], device='cuda:0')), ('net.100.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.100.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.101.policy.segment_semantic', tensor([0.6911, 0.1319], device='cuda:0')), ('net.101.policy.depth_zbuffer', tensor([0.3821, 0.4417], device='cuda:0')), ('net.102.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.102.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.104.policy.segment_semantic', tensor([0.8058, 0.0172], device='cuda:0')), ('net.104.policy.depth_zbuffer', tensor([0.3618, 0.4620], device='cuda:0')), ('net.105.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.105.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.108.policy.segment_semantic', tensor([ 0.9294, -0.1064], device='cuda:0')), ('net.108.policy.depth_zbuffer', tensor([0.3592, 0.4646], device='cuda:0')), ('net.109.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.109.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.111.policy.segment_semantic', tensor([ 0.8673, -0.0443], device='cuda:0')), ('net.111.policy.depth_zbuffer', tensor([0.3659, 0.4579], device='cuda:0')), ('net.112.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.112.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.115.policy.segment_semantic', tensor([ 0.9027, -0.0797], device='cuda:0')), ('net.115.policy.depth_zbuffer', tensor([0.3760, 0.4478], device='cuda:0')), ('net.116.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.116.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0')), ('net.118.policy.segment_semantic', tensor([ 0.8958, -0.0728], device='cuda:0')), ('net.118.policy.depth_zbuffer', tensor([0.3858, 0.4380], device='cuda:0')), ('net.119.policy.segment_semantic', tensor([0.5000, 0.5000], device='cuda:0')), ('net.119.policy.depth_zbuffer', tensor([0.5000, 0.5000], device='cuda:0'))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 200 Task segm] Train Loss: 14.0750\n",
      "[Iter 200 Task dept] Train Loss: 32.1798\n",
      "[Iter 200 Total] Train Loss: 23.1274\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 1.2232\n",
      "{'mIoU': 0.3422, 'Pixel Acc': 0.5155, 'cmp': -0.2294}\n",
      "[Iter 200 Task dept] Val Loss: 0.1125\n",
      "{'abs_err': 0.1139, 'rel_err': 1.6609, 'sigma_1.25': 26.323, 'sigma_1.25^2': 48.2532, 'sigma_1.25^3': 64.6886, 'cmp': -2.221}\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Train Loss: 4.3372\n",
      "[Iter 400 Task dept] Train Loss: 2.1692\n",
      "[Iter 400 Total] Train Loss: 3.2532\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 1.2581\n",
      "{'mIoU': 0.3878, 'Pixel Acc': 0.5094, 'cmp': -0.1767}\n",
      "[Iter 400 Task dept] Val Loss: 0.1731\n",
      "{'abs_err': 0.1926, 'rel_err': 5.6378, 'sigma_1.25': 21.8971, 'sigma_1.25^2': 34.3948, 'sigma_1.25^3': 51.0403, 'cmp': -5.6311}\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Train Loss: 1.4119\n",
      "[Iter 600 Task dept] Train Loss: 0.1388\n",
      "[Iter 600 Total] Train Loss: 0.7754\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 1.2667\n",
      "{'mIoU': 0.2563, 'Pixel Acc': 0.51, 'cmp': -0.3399}\n",
      "[Iter 600 Task dept] Val Loss: 0.0540\n",
      "{'abs_err': 0.053, 'rel_err': 0.9385, 'sigma_1.25': 30.4319, 'sigma_1.25^2': 58.1434, 'sigma_1.25^3': 72.4101, 'cmp': -1.0156}\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Train Loss: 1.2406\n",
      "[Iter 800 Task dept] Train Loss: 0.1783\n",
      "[Iter 800 Total] Train Loss: 0.7095\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 1.1168\n",
      "{'mIoU': 0.422, 'Pixel Acc': 0.5714, 'cmp': -0.0927}\n",
      "[Iter 800 Task dept] Val Loss: 0.0550\n",
      "{'abs_err': 0.0548, 'rel_err': 0.6079, 'sigma_1.25': 27.9495, 'sigma_1.25^2': 52.8845, 'sigma_1.25^3': 74.018, 'cmp': -0.8523}\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Train Loss: 1.1265\n",
      "[Iter 1000 Task dept] Train Loss: 0.1025\n",
      "[Iter 1000 Total] Train Loss: 0.6145\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 1.1127\n",
      "{'mIoU': 0.3747, 'Pixel Acc': 0.5755, 'cmp': -0.1487}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0507\n",
      "{'abs_err': 0.0496, 'rel_err': 0.7115, 'sigma_1.25': 33.0003, 'sigma_1.25^2': 61.8608, 'sigma_1.25^3': 76.3591, 'cmp': -0.8135}\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Train Loss: 1.1473\n",
      "[Iter 1200 Task dept] Train Loss: 0.0731\n",
      "[Iter 1200 Total] Train Loss: 0.6102\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 1.0433\n",
      "{'mIoU': 0.4449, 'Pixel Acc': 0.5674, 'cmp': -0.0668}\n",
      "[Iter 1200 Task dept] Val Loss: 0.1171\n",
      "{'abs_err': 0.1172, 'rel_err': 1.3968, 'sigma_1.25': 31.927, 'sigma_1.25^2': 59.1845, 'sigma_1.25^3': 72.7683, 'cmp': -2.0411}\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Train Loss: 1.1045\n",
      "[Iter 1400 Task dept] Train Loss: 0.0887\n",
      "[Iter 1400 Total] Train Loss: 0.5966\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 1.0915\n",
      "{'mIoU': 0.4313, 'Pixel Acc': 0.5405, 'cmp': -0.1018}\n",
      "[Iter 1400 Task dept] Val Loss: 0.0536\n",
      "{'abs_err': 0.0513, 'rel_err': 1.0257, 'sigma_1.25': 31.8062, 'sigma_1.25^2': 59.8386, 'sigma_1.25^3': 73.1046, 'cmp': -1.0388}\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-4a7a9a392f2a>\", line 3, in <module>\n",
      "    savePath='checkpoints/Cityscapes_re/', reload='task_alter_train_20000iter.model')\n",
      "  File \"/home/lijunzhang/policymtl/framework/trainer.py\", line 312, in post_train\n",
      "    task_idx = self.which_task(i, task_iters)\n",
      "  File \"/home/lijunzhang/policymtl/framework/trainer.py\", line 380, in train_step_task\n",
      "    loss.backward()\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/adam.py\", line 96, in step\n",
      "    grad = grad.add(p, alpha=group['weight_decay'])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Post-train on whole training set\n",
    "trainer.post_train(iters=20000, lr=0.01, task_iters=(100,100),\n",
    "                   savePath='checkpoints/Cityscapes_re/', reload='task_alter_train_20000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the policy saved in pre_train_24000 from [1.0, 1.0] to [0.5, 0.5]\n",
    "a = torch.load('checkpoints/Cityscapes_re/pre_train_24000iter.model')\n",
    "for key in a['state_dict']:\n",
    "    if 'policy' in key:\n",
    "        a['state_dict'][key] = a['state_dict'][key] - torch.tensor([0.5,0.5]).cuda()\n",
    "torch.save(a, 'checkpoints/Cityscapes_re/pre_train_24000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  )\n",
      "  (1): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (3): PoolNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): AbstractPool(\n",
      "      (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (5): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (6): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (7): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (8): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (9): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (10): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (11): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (12): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (13): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (14): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (15): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (16): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (17): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (18): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (19): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (20): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (21): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (22): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (23): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (24): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (25): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (26): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (27): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (28): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (29): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (30): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (31): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (32): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (33): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (34): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (35): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (36): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (37): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (38): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (39): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (40): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (41): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (42): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (43): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (44): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (45): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (46): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (47): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (48): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (49): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (50): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (51): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (52): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (53): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (54): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (55): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (56): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (57): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (58): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (59): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (60): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "      (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "  )\n",
      "  (61): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (62): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (63): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (64): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (65): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (66): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (67): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (68): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (69): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (70): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (71): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (72): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (73): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (74): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (75): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (76): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (77): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (78): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (79): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (80): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (81): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (82): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (83): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (84): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (85): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (86): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (87): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (88): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (89): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (90): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (91): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (92): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (93): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (94): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (95): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (96): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (97): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (98): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (99): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (100): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (101): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (102): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (103): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (104): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "      (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "  )\n",
      "  (105): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (106): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (107): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (108): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (109): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (110): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (111): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (112): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (113): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (114): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (115): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (116): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (117): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      "  (118): Conv2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (119): BN2dNode(\n",
      "    (taskOp): ModuleDict(\n",
      "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (policy): ParameterDict(\n",
      "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "    )\n",
      "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (120): EltNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): EltwiseOp(op=1)\n",
      "  )\n",
      "  (121): ReLUNode(\n",
      "    (taskOp): ModuleDict()\n",
      "    (policy): ParameterDict()\n",
      "    (basicOp): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mtlmodel.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegModel, self).__init__()\n",
    "        self.policy = nn.Parameter(torch.tensor([1.0,1.0]))\n",
    "        \n",
    "    def forward(self):\n",
    "        possiblity = nn.functional.gumbel_softmax(self.policy, tau=5, hard=False)\n",
    "        weight = torch.sigmoid((possiblity[1]-possiblity[0])*6).detach()\n",
    "        print(self.policy)\n",
    "        print(possiblity)\n",
    "        print(weight)\n",
    "        reg = weight * possiblity[1]\n",
    "        return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regM = RegModel()\n",
    "optimizer = torch.optim.SGD(regM.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1.], requires_grad=True)\n",
      "tensor([0.3235, 0.6765], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6765276789665222\n",
      "Parameter containing:\n",
      "tensor([1.0044, 0.9956], requires_grad=True)\n",
      "tensor([0.6942, 0.3058], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3636e-17)\n",
      "output:4.170253392062628e-18\n",
      "Parameter containing:\n",
      "tensor([1.0044, 0.9956], requires_grad=True)\n",
      "tensor([0.4358, 0.5642], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5641503930091858\n",
      "Parameter containing:\n",
      "tensor([1.0093, 0.9907], requires_grad=True)\n",
      "tensor([0.5315, 0.4685], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0018)\n",
      "output:0.0008641324820928276\n",
      "Parameter containing:\n",
      "tensor([1.0093, 0.9907], requires_grad=True)\n",
      "tensor([0.6719, 0.3281], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1800e-15)\n",
      "output:3.871833129920322e-16\n",
      "Parameter containing:\n",
      "tensor([1.0093, 0.9907], requires_grad=True)\n",
      "tensor([0.5066, 0.4934], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2104)\n",
      "output:0.10381978005170822\n",
      "Parameter containing:\n",
      "tensor([1.0104, 0.9896], requires_grad=True)\n",
      "tensor([0.5253, 0.4747], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0064)\n",
      "output:0.003021758981049061\n",
      "Parameter containing:\n",
      "tensor([1.0104, 0.9896], requires_grad=True)\n",
      "tensor([0.6796, 0.3204], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5322e-16)\n",
      "output:8.114205719526264e-17\n",
      "Parameter containing:\n",
      "tensor([1.0104, 0.9896], requires_grad=True)\n",
      "tensor([0.3904, 0.6096], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.609561026096344\n",
      "Parameter containing:\n",
      "tensor([1.0151, 0.9849], requires_grad=True)\n",
      "tensor([0.7886, 0.2114], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.6423e-26)\n",
      "output:1.8273888913734874e-26\n",
      "Parameter containing:\n",
      "tensor([1.0151, 0.9849], requires_grad=True)\n",
      "tensor([0.5047, 0.4953], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2817)\n",
      "output:0.1395329385995865\n",
      "Parameter containing:\n",
      "tensor([1.0166, 0.9834], requires_grad=True)\n",
      "tensor([0.5461, 0.4539], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.9856e-05)\n",
      "output:4.532884486252442e-05\n",
      "Parameter containing:\n",
      "tensor([1.0166, 0.9834], requires_grad=True)\n",
      "tensor([0.4530, 0.5470], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5469732880592346\n",
      "Parameter containing:\n",
      "tensor([1.0215, 0.9785], requires_grad=True)\n",
      "tensor([0.4566, 0.5434], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.543300449848175\n",
      "Parameter containing:\n",
      "tensor([1.0265, 0.9735], requires_grad=True)\n",
      "tensor([0.5294, 0.4706], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0028)\n",
      "output:0.0013223693240433931\n",
      "Parameter containing:\n",
      "tensor([1.0265, 0.9735], requires_grad=True)\n",
      "tensor([0.3493, 0.6507], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6506637334823608\n",
      "Parameter containing:\n",
      "tensor([1.0310, 0.9690], requires_grad=True)\n",
      "tensor([0.7020, 0.2980], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8304e-18)\n",
      "output:8.433801176692662e-19\n",
      "Parameter containing:\n",
      "tensor([1.0310, 0.9690], requires_grad=True)\n",
      "tensor([0.4310, 0.5690], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5690488815307617\n",
      "Parameter containing:\n",
      "tensor([1.0359, 0.9641], requires_grad=True)\n",
      "tensor([0.3420, 0.6580], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.658002495765686\n",
      "Parameter containing:\n",
      "tensor([1.0404, 0.9596], requires_grad=True)\n",
      "tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7307e-05)\n",
      "output:3.0420680559473112e-05\n",
      "Parameter containing:\n",
      "tensor([1.0404, 0.9596], requires_grad=True)\n",
      "tensor([0.4797, 0.5203], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9829)\n",
      "output:0.5113417506217957\n",
      "Parameter containing:\n",
      "tensor([1.0453, 0.9547], requires_grad=True)\n",
      "tensor([0.5383, 0.4617], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0005)\n",
      "output:0.00021719682263210416\n",
      "Parameter containing:\n",
      "tensor([1.0453, 0.9547], requires_grad=True)\n",
      "tensor([0.6292, 0.3708], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.9710e-12)\n",
      "output:2.213911562756743e-12\n",
      "Parameter containing:\n",
      "tensor([1.0453, 0.9547], requires_grad=True)\n",
      "tensor([0.6416, 0.3584], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0226e-13)\n",
      "output:1.8001056103621876e-13\n",
      "Parameter containing:\n",
      "tensor([1.0453, 0.9547], requires_grad=True)\n",
      "tensor([0.4223, 0.5777], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5777007937431335\n",
      "Parameter containing:\n",
      "tensor([1.0502, 0.9498], requires_grad=True)\n",
      "tensor([0.5281, 0.4719], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0036)\n",
      "output:0.001693924656137824\n",
      "Parameter containing:\n",
      "tensor([1.0502, 0.9498], requires_grad=True)\n",
      "tensor([0.4761, 0.5239], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9916)\n",
      "output:0.5194566249847412\n",
      "Parameter containing:\n",
      "tensor([1.0552, 0.9448], requires_grad=True)\n",
      "tensor([0.6171, 0.3829], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7558e-11)\n",
      "output:2.5868649236593377e-11\n",
      "Parameter containing:\n",
      "tensor([1.0552, 0.9448], requires_grad=True)\n",
      "tensor([0.4177, 0.5823], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5823209285736084\n",
      "Parameter containing:\n",
      "tensor([1.0601, 0.9399], requires_grad=True)\n",
      "tensor([0.3689, 0.6311], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.631068229675293\n",
      "Parameter containing:\n",
      "tensor([1.0647, 0.9353], requires_grad=True)\n",
      "tensor([0.4362, 0.5638], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5638135671615601\n",
      "Parameter containing:\n",
      "tensor([1.0696, 0.9304], requires_grad=True)\n",
      "tensor([0.3595, 0.6405], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6404874920845032\n",
      "Parameter containing:\n",
      "tensor([1.0742, 0.9258], requires_grad=True)\n",
      "tensor([0.5320, 0.4680], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0017)\n",
      "output:0.0007830046233721077\n",
      "Parameter containing:\n",
      "tensor([1.0742, 0.9258], requires_grad=True)\n",
      "tensor([0.5071, 0.4929], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1932)\n",
      "output:0.09523066133260727\n",
      "Parameter containing:\n",
      "tensor([1.0752, 0.9248], requires_grad=True)\n",
      "tensor([0.4196, 0.5804], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5804358124732971\n",
      "Parameter containing:\n",
      "tensor([1.0801, 0.9199], requires_grad=True)\n",
      "tensor([0.6428, 0.3572], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9223e-13)\n",
      "output:1.4009084690902451e-13\n",
      "Parameter containing:\n",
      "tensor([1.0801, 0.9199], requires_grad=True)\n",
      "tensor([0.4720, 0.5280], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9963)\n",
      "output:0.5260300040245056\n",
      "Parameter containing:\n",
      "tensor([1.0850, 0.9150], requires_grad=True)\n",
      "tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9634)\n",
      "output:0.4974311590194702\n",
      "Parameter containing:\n",
      "tensor([1.0899, 0.9101], requires_grad=True)\n",
      "tensor([0.5336, 0.4664], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0012)\n",
      "output:0.0005591366207227111\n",
      "Parameter containing:\n",
      "tensor([1.0899, 0.9101], requires_grad=True)\n",
      "tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9633)\n",
      "output:0.49738436937332153\n",
      "Parameter containing:\n",
      "tensor([1.0947, 0.9053], requires_grad=True)\n",
      "tensor([0.4539, 0.5461], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.54600590467453\n",
      "Parameter containing:\n",
      "tensor([1.0996, 0.9004], requires_grad=True)\n",
      "tensor([0.4198, 0.5802], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.580226719379425\n",
      "Parameter containing:\n",
      "tensor([1.1045, 0.8955], requires_grad=True)\n",
      "tensor([0.4883, 0.5117], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9122)\n",
      "output:0.4667893648147583\n",
      "Parameter containing:\n",
      "tensor([1.1091, 0.8909], requires_grad=True)\n",
      "tensor([0.5515, 0.4485], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3358e-05)\n",
      "output:1.4959795407776255e-05\n",
      "Parameter containing:\n",
      "tensor([1.1091, 0.8909], requires_grad=True)\n",
      "tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0692e-12)\n",
      "output:3.872477425531651e-13\n",
      "Parameter containing:\n",
      "tensor([1.1091, 0.8909], requires_grad=True)\n",
      "tensor([0.5059, 0.4941], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2357)\n",
      "output:0.11648418009281158\n",
      "Parameter containing:\n",
      "tensor([1.1102, 0.8898], requires_grad=True)\n",
      "tensor([0.5198, 0.4802], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0188)\n",
      "output:0.009039657190442085\n",
      "Parameter containing:\n",
      "tensor([1.1103, 0.8897], requires_grad=True)\n",
      "tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8001e-11)\n",
      "output:6.773702692502992e-12\n",
      "Parameter containing:\n",
      "tensor([1.1103, 0.8897], requires_grad=True)\n",
      "tensor([0.4539, 0.5461], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.546066403388977\n",
      "Parameter containing:\n",
      "tensor([1.1153, 0.8847], requires_grad=True)\n",
      "tensor([0.5805, 0.4195], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0221e-07)\n",
      "output:4.2878234296495066e-08\n",
      "Parameter containing:\n",
      "tensor([1.1153, 0.8847], requires_grad=True)\n",
      "tensor([0.4967, 0.5033], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.6577)\n",
      "output:0.3309999704360962\n",
      "Parameter containing:\n",
      "tensor([1.1186, 0.8814], requires_grad=True)\n",
      "tensor([0.5210, 0.4790], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0148)\n",
      "output:0.007078610360622406\n",
      "Parameter containing:\n",
      "tensor([1.1187, 0.8813], requires_grad=True)\n",
      "tensor([0.3279, 0.6721], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6720555424690247\n",
      "Parameter containing:\n",
      "tensor([1.1231, 0.8769], requires_grad=True)\n",
      "tensor([0.6090, 0.3910], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4031e-10)\n",
      "output:1.330591609116638e-10\n",
      "Parameter containing:\n",
      "tensor([1.1231, 0.8769], requires_grad=True)\n",
      "tensor([0.5784, 0.4216], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5627e-07)\n",
      "output:6.588999923451411e-08\n",
      "Parameter containing:\n",
      "tensor([1.1231, 0.8769], requires_grad=True)\n",
      "tensor([0.5482, 0.4518], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.4497e-05)\n",
      "output:2.9136832381482236e-05\n",
      "Parameter containing:\n",
      "tensor([1.1231, 0.8769], requires_grad=True)\n",
      "tensor([0.5856, 0.4144], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.6823e-08)\n",
      "output:1.5259852048643552e-08\n",
      "Parameter containing:\n",
      "tensor([1.1231, 0.8769], requires_grad=True)\n",
      "tensor([0.4712, 0.5288], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9969)\n",
      "output:0.52717125415802\n",
      "Parameter containing:\n",
      "tensor([1.1280, 0.8720], requires_grad=True)\n",
      "tensor([0.3682, 0.6318], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6318033337593079\n",
      "Parameter containing:\n",
      "tensor([1.1327, 0.8673], requires_grad=True)\n",
      "tensor([0.5671, 0.4329], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4966e-06)\n",
      "output:6.479404532910849e-07\n",
      "Parameter containing:\n",
      "tensor([1.1327, 0.8673], requires_grad=True)\n",
      "tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1071e-10)\n",
      "output:4.266479183834271e-11\n",
      "Parameter containing:\n",
      "tensor([1.1327, 0.8673], requires_grad=True)\n",
      "tensor([0.4794, 0.5206], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9841)\n",
      "output:0.5123503804206848\n",
      "Parameter containing:\n",
      "tensor([1.1376, 0.8624], requires_grad=True)\n",
      "tensor([0.5880, 0.4120], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2684e-08)\n",
      "output:9.345604290444953e-09\n",
      "Parameter containing:\n",
      "tensor([1.1376, 0.8624], requires_grad=True)\n",
      "tensor([0.3392, 0.6608], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6607628464698792\n",
      "Parameter containing:\n",
      "tensor([1.1421, 0.8579], requires_grad=True)\n",
      "tensor([0.5147, 0.4853], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0503)\n",
      "output:0.024429328739643097\n",
      "Parameter containing:\n",
      "tensor([1.1423, 0.8577], requires_grad=True)\n",
      "tensor([0.4399, 0.5601], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5600575804710388\n",
      "Parameter containing:\n",
      "tensor([1.1473, 0.8527], requires_grad=True)\n",
      "tensor([0.5240, 0.4760], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0082)\n",
      "output:0.0039076004177331924\n",
      "Parameter containing:\n",
      "tensor([1.1473, 0.8527], requires_grad=True)\n",
      "tensor([0.6243, 0.3757], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6038e-11)\n",
      "output:6.0256305153827405e-12\n",
      "Parameter containing:\n",
      "tensor([1.1473, 0.8527], requires_grad=True)\n",
      "tensor([0.5629, 0.4371], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4463e-06)\n",
      "output:1.5064068747960846e-06\n",
      "Parameter containing:\n",
      "tensor([1.1473, 0.8527], requires_grad=True)\n",
      "tensor([0.4809, 0.5191], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9786)\n",
      "output:0.507977306842804\n",
      "Parameter containing:\n",
      "tensor([1.1522, 0.8478], requires_grad=True)\n",
      "tensor([0.6094, 0.3906], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1657e-10)\n",
      "output:1.2366407897701492e-10\n",
      "Parameter containing:\n",
      "tensor([1.1522, 0.8478], requires_grad=True)\n",
      "tensor([0.4619, 0.5381], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9995)\n",
      "output:0.5378181338310242\n",
      "Parameter containing:\n",
      "tensor([1.1572, 0.8428], requires_grad=True)\n",
      "tensor([0.5844, 0.4156], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7084e-08)\n",
      "output:1.9570197906659814e-08\n",
      "Parameter containing:\n",
      "tensor([1.1572, 0.8428], requires_grad=True)\n",
      "tensor([0.5575, 0.4425], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0101e-05)\n",
      "output:4.469337000045925e-06\n",
      "Parameter containing:\n",
      "tensor([1.1572, 0.8428], requires_grad=True)\n",
      "tensor([0.4989, 0.5011], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5525)\n",
      "output:0.27682170271873474\n",
      "Parameter containing:\n",
      "tensor([1.1599, 0.8401], requires_grad=True)\n",
      "tensor([0.4149, 0.5851], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5850894451141357\n",
      "Parameter containing:\n",
      "tensor([1.1648, 0.8352], requires_grad=True)\n",
      "tensor([0.4726, 0.5274], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9958)\n",
      "output:0.5251978635787964\n",
      "Parameter containing:\n",
      "tensor([1.1697, 0.8303], requires_grad=True)\n",
      "tensor([0.4715, 0.5285], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9967)\n",
      "output:0.5267531275749207\n",
      "Parameter containing:\n",
      "tensor([1.1747, 0.8253], requires_grad=True)\n",
      "tensor([0.5733, 0.4267], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3161e-07)\n",
      "output:1.8417740932363813e-07\n",
      "Parameter containing:\n",
      "tensor([1.1747, 0.8253], requires_grad=True)\n",
      "tensor([0.4953, 0.5047], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.7206)\n",
      "output:0.3637154698371887\n",
      "Parameter containing:\n",
      "tensor([1.1783, 0.8217], requires_grad=True)\n",
      "tensor([0.5151, 0.4849], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0464)\n",
      "output:0.022502750158309937\n",
      "Parameter containing:\n",
      "tensor([1.1785, 0.8215], requires_grad=True)\n",
      "tensor([0.3600, 0.6400], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6400150656700134\n",
      "Parameter containing:\n",
      "tensor([1.1831, 0.8169], requires_grad=True)\n",
      "tensor([0.7041, 0.2959], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8717e-18)\n",
      "output:5.538505664586086e-19\n",
      "Parameter containing:\n",
      "tensor([1.1831, 0.8169], requires_grad=True)\n",
      "tensor([0.5177, 0.4823], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0280)\n",
      "output:0.013495117425918579\n",
      "Parameter containing:\n",
      "tensor([1.1833, 0.8167], requires_grad=True)\n",
      "tensor([0.5643, 0.4357], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5926e-06)\n",
      "output:1.129556039813906e-06\n",
      "Parameter containing:\n",
      "tensor([1.1833, 0.8167], requires_grad=True)\n",
      "tensor([0.6745, 0.3255], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9418e-16)\n",
      "output:2.259413799988747e-16\n",
      "Parameter containing:\n",
      "tensor([1.1833, 0.8167], requires_grad=True)\n",
      "tensor([0.5927, 0.4073], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8106e-09)\n",
      "output:3.588222607930902e-09\n",
      "Parameter containing:\n",
      "tensor([1.1833, 0.8167], requires_grad=True)\n",
      "tensor([0.4548, 0.5452], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5451733469963074\n",
      "Parameter containing:\n",
      "tensor([1.1882, 0.8118], requires_grad=True)\n",
      "tensor([0.4032, 0.5968], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5967844128608704\n",
      "Parameter containing:\n",
      "tensor([1.1931, 0.8069], requires_grad=True)\n",
      "tensor([0.4651, 0.5349], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9991)\n",
      "output:0.5343920588493347\n",
      "Parameter containing:\n",
      "tensor([1.1980, 0.8020], requires_grad=True)\n",
      "tensor([0.4524, 0.5476], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5475982427597046\n",
      "Parameter containing:\n",
      "tensor([1.2030, 0.7970], requires_grad=True)\n",
      "tensor([0.4885, 0.5115], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9086)\n",
      "output:0.46475648880004883\n",
      "Parameter containing:\n",
      "tensor([1.2075, 0.7925], requires_grad=True)\n",
      "tensor([0.4768, 0.5232], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9905)\n",
      "output:0.5182669758796692\n",
      "Parameter containing:\n",
      "tensor([1.2125, 0.7875], requires_grad=True)\n",
      "tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0824e-11)\n",
      "output:4.045561195070713e-12\n",
      "Parameter containing:\n",
      "tensor([1.2125, 0.7875], requires_grad=True)\n",
      "tensor([0.5017, 0.4983], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4179)\n",
      "output:0.2082635760307312\n",
      "Parameter containing:\n",
      "tensor([1.2146, 0.7854], requires_grad=True)\n",
      "tensor([0.4241, 0.5759], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5758965611457825\n",
      "Parameter containing:\n",
      "tensor([1.2194, 0.7806], requires_grad=True)\n",
      "tensor([0.4452, 0.5548], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5547617673873901\n",
      "Parameter containing:\n",
      "tensor([1.2244, 0.7756], requires_grad=True)\n",
      "tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0059e-11)\n",
      "output:2.2961927498288404e-11\n",
      "Parameter containing:\n",
      "tensor([1.2244, 0.7756], requires_grad=True)\n",
      "tensor([0.5488, 0.4512], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7191e-05)\n",
      "output:2.5801953597692773e-05\n",
      "Parameter containing:\n",
      "tensor([1.2244, 0.7756], requires_grad=True)\n",
      "tensor([0.4887, 0.5113], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9062)\n",
      "output:0.4633893072605133\n",
      "Parameter containing:\n",
      "tensor([1.2289, 0.7711], requires_grad=True)\n",
      "tensor([0.5266, 0.4734], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0049)\n",
      "output:0.002305240137502551\n",
      "Parameter containing:\n",
      "tensor([1.2289, 0.7711], requires_grad=True)\n",
      "tensor([0.6406, 0.3594], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0826e-13)\n",
      "output:2.1858380448540327e-13\n",
      "Parameter containing:\n",
      "tensor([1.2289, 0.7711], requires_grad=True)\n",
      "tensor([0.4130, 0.5870], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.587020218372345\n",
      "Parameter containing:\n",
      "tensor([1.2338, 0.7662], requires_grad=True)\n",
      "tensor([0.6002, 0.3998], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9882e-09)\n",
      "output:7.949269020812721e-10\n",
      "Parameter containing:\n",
      "tensor([1.2338, 0.7662], requires_grad=True)\n",
      "tensor([0.4314, 0.5686], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5685943961143494\n",
      "Parameter containing:\n",
      "tensor([1.2387, 0.7613], requires_grad=True)\n",
      "tensor([0.7323, 0.2677], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.6247e-21)\n",
      "output:1.773323570071497e-21\n",
      "Parameter containing:\n",
      "tensor([1.2387, 0.7613], requires_grad=True)\n",
      "tensor([0.5515, 0.4485], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3371e-05)\n",
      "output:1.4965379705245141e-05\n",
      "Parameter containing:\n",
      "tensor([1.2387, 0.7613], requires_grad=True)\n",
      "tensor([0.6407, 0.3593], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0682e-13)\n",
      "output:2.1805858984799698e-13\n",
      "Parameter containing:\n",
      "tensor([1.2387, 0.7613], requires_grad=True)\n",
      "tensor([0.4589, 0.5411], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9997)\n",
      "output:0.5409260988235474\n",
      "Parameter containing:\n",
      "tensor([1.2436, 0.7564], requires_grad=True)\n",
      "tensor([0.5910, 0.4090], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2505e-08)\n",
      "output:5.114899170877152e-09\n",
      "Parameter containing:\n",
      "tensor([1.2436, 0.7564], requires_grad=True)\n",
      "tensor([0.3843, 0.6157], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6156871318817139\n",
      "Parameter containing:\n",
      "tensor([1.2484, 0.7516], requires_grad=True)\n",
      "tensor([0.4229, 0.5771], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5771186947822571\n",
      "Parameter containing:\n",
      "tensor([1.2533, 0.7467], requires_grad=True)\n",
      "tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6066e-10)\n",
      "output:6.221573256581792e-11\n",
      "Parameter containing:\n",
      "tensor([1.2533, 0.7467], requires_grad=True)\n",
      "tensor([0.4714, 0.5286], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9967)\n",
      "output:0.5268511772155762\n",
      "Parameter containing:\n",
      "tensor([1.2582, 0.7418], requires_grad=True)\n",
      "tensor([0.5540, 0.4460], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0426e-05)\n",
      "output:9.110300197789911e-06\n",
      "Parameter containing:\n",
      "tensor([1.2582, 0.7418], requires_grad=True)\n",
      "tensor([0.4739, 0.5261], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9946)\n",
      "output:0.5231950283050537\n",
      "Parameter containing:\n",
      "tensor([1.2632, 0.7368], requires_grad=True)\n",
      "tensor([0.5395, 0.4605], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0004)\n",
      "output:0.00017022121755871922\n",
      "Parameter containing:\n",
      "tensor([1.2632, 0.7368], requires_grad=True)\n",
      "tensor([0.5182, 0.4818], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0257)\n",
      "output:0.012368062511086464\n",
      "Parameter containing:\n",
      "tensor([1.2633, 0.7367], requires_grad=True)\n",
      "tensor([0.5079, 0.4921], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1718)\n",
      "output:0.08454433083534241\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.5835, 0.4165], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5708e-08)\n",
      "output:2.320159531166155e-08\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.5459, 0.4541], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:4.6831519284751266e-05\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.5466, 0.4534], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.9963e-05)\n",
      "output:4.079117570654489e-05\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.6450, 0.3550], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5466e-13)\n",
      "output:9.040498520152332e-14\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.5768, 0.4232], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1139e-07)\n",
      "output:8.945010421257393e-08\n",
      "Parameter containing:\n",
      "tensor([1.2642, 0.7358], requires_grad=True)\n",
      "tensor([0.4805, 0.5195], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9801)\n",
      "output:0.5091355443000793\n",
      "Parameter containing:\n",
      "tensor([1.2691, 0.7309], requires_grad=True)\n",
      "tensor([0.4424, 0.5576], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.557572066783905\n",
      "Parameter containing:\n",
      "tensor([1.2740, 0.7260], requires_grad=True)\n",
      "tensor([0.6375, 0.3625], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1406e-12)\n",
      "output:4.134588721740884e-13\n",
      "Parameter containing:\n",
      "tensor([1.2740, 0.7260], requires_grad=True)\n",
      "tensor([0.5279, 0.4721], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0038)\n",
      "output:0.0017797962063923478\n",
      "Parameter containing:\n",
      "tensor([1.2740, 0.7260], requires_grad=True)\n",
      "tensor([0.5267, 0.4733], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0047)\n",
      "output:0.002247674623504281\n",
      "Parameter containing:\n",
      "tensor([1.2740, 0.7260], requires_grad=True)\n",
      "tensor([0.6351, 0.3649], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8591e-12)\n",
      "output:6.784695418329822e-13\n",
      "Parameter containing:\n",
      "tensor([1.2740, 0.7260], requires_grad=True)\n",
      "tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0135)\n",
      "output:0.0064544677734375\n",
      "Parameter containing:\n",
      "tensor([1.2741, 0.7259], requires_grad=True)\n",
      "tensor([0.4637, 0.5363], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9993)\n",
      "output:0.5359291434288025\n",
      "Parameter containing:\n",
      "tensor([1.2791, 0.7209], requires_grad=True)\n",
      "tensor([0.5290, 0.4710], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0030)\n",
      "output:0.001428165240213275\n",
      "Parameter containing:\n",
      "tensor([1.2791, 0.7209], requires_grad=True)\n",
      "tensor([0.5421, 0.4579], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:0.00010010736878030002\n",
      "Parameter containing:\n",
      "tensor([1.2791, 0.7209], requires_grad=True)\n",
      "tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.5063e-09)\n",
      "output:1.820138595398646e-09\n",
      "Parameter containing:\n",
      "tensor([1.2791, 0.7209], requires_grad=True)\n",
      "tensor([0.5240, 0.4760], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0082)\n",
      "output:0.0039054066874086857\n",
      "Parameter containing:\n",
      "tensor([1.2791, 0.7209], requires_grad=True)\n",
      "tensor([0.4906, 0.5094], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8667)\n",
      "output:0.44144195318222046\n",
      "Parameter containing:\n",
      "tensor([1.2835, 0.7165], requires_grad=True)\n",
      "tensor([0.3724, 0.6276], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6275622844696045\n",
      "Parameter containing:\n",
      "tensor([1.2881, 0.7119], requires_grad=True)\n",
      "tensor([0.4425, 0.5575], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5574888586997986\n",
      "Parameter containing:\n",
      "tensor([1.2931, 0.7069], requires_grad=True)\n",
      "tensor([0.5793, 0.4207], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2908e-07)\n",
      "output:5.430271698969591e-08\n",
      "Parameter containing:\n",
      "tensor([1.2931, 0.7069], requires_grad=True)\n",
      "tensor([0.4547, 0.5453], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5452203750610352\n",
      "Parameter containing:\n",
      "tensor([1.2980, 0.7020], requires_grad=True)\n",
      "tensor([0.3903, 0.6097], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6096552610397339\n",
      "Parameter containing:\n",
      "tensor([1.3028, 0.6972], requires_grad=True)\n",
      "tensor([0.6004, 0.3996], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8860e-09)\n",
      "output:7.535637114308713e-10\n",
      "Parameter containing:\n",
      "tensor([1.3028, 0.6972], requires_grad=True)\n",
      "tensor([0.5427, 0.4573], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.958119724411517e-05\n",
      "Parameter containing:\n",
      "tensor([1.3028, 0.6972], requires_grad=True)\n",
      "tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1001e-08)\n",
      "output:1.7013549680200413e-08\n",
      "Parameter containing:\n",
      "tensor([1.3028, 0.6972], requires_grad=True)\n",
      "tensor([0.5144, 0.4856], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0536)\n",
      "output:0.026046188548207283\n",
      "Parameter containing:\n",
      "tensor([1.3031, 0.6969], requires_grad=True)\n",
      "tensor([0.6961, 0.3039], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.2574e-18)\n",
      "output:2.8132642175548455e-18\n",
      "Parameter containing:\n",
      "tensor([1.3031, 0.6969], requires_grad=True)\n",
      "tensor([0.5669, 0.4331], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5595e-06)\n",
      "output:6.754790433660673e-07\n",
      "Parameter containing:\n",
      "tensor([1.3031, 0.6969], requires_grad=True)\n",
      "tensor([0.4635, 0.5365], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9993)\n",
      "output:0.5361645817756653\n",
      "Parameter containing:\n",
      "tensor([1.3080, 0.6920], requires_grad=True)\n",
      "tensor([0.4563, 0.5437], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5436466932296753\n",
      "Parameter containing:\n",
      "tensor([1.3130, 0.6870], requires_grad=True)\n",
      "tensor([0.5019, 0.4981], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4053)\n",
      "output:0.20188048481941223\n",
      "Parameter containing:\n",
      "tensor([1.3150, 0.6850], requires_grad=True)\n",
      "tensor([0.6053, 0.3947], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.1833e-10)\n",
      "output:2.835476298201911e-10\n",
      "Parameter containing:\n",
      "tensor([1.3150, 0.6850], requires_grad=True)\n",
      "tensor([0.6174, 0.3826], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.3272e-11)\n",
      "output:2.4206884760569203e-11\n",
      "Parameter containing:\n",
      "tensor([1.3150, 0.6850], requires_grad=True)\n",
      "tensor([0.5570, 0.4430], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1170e-05)\n",
      "output:4.948185505782021e-06\n",
      "Parameter containing:\n",
      "tensor([1.3150, 0.6850], requires_grad=True)\n",
      "tensor([0.5249, 0.4751], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0068)\n",
      "output:0.003252730006352067\n",
      "Parameter containing:\n",
      "tensor([1.3151, 0.6849], requires_grad=True)\n",
      "tensor([0.5459, 0.4541], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:4.701246143667959e-05\n",
      "Parameter containing:\n",
      "tensor([1.3151, 0.6849], requires_grad=True)\n",
      "tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.2300e-09)\n",
      "output:1.7072167013409967e-09\n",
      "Parameter containing:\n",
      "tensor([1.3151, 0.6849], requires_grad=True)\n",
      "tensor([0.5341, 0.4659], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0011)\n",
      "output:0.0005104845040477812\n",
      "Parameter containing:\n",
      "tensor([1.3151, 0.6849], requires_grad=True)\n",
      "tensor([0.4520, 0.5480], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5479214787483215\n",
      "Parameter containing:\n",
      "tensor([1.3200, 0.6800], requires_grad=True)\n",
      "tensor([0.6402, 0.3598], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7056e-13)\n",
      "output:2.412994120921247e-13\n",
      "Parameter containing:\n",
      "tensor([1.3200, 0.6800], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6083, 0.3917], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8982e-10)\n",
      "output:1.526840598398138e-10\n",
      "Parameter containing:\n",
      "tensor([1.3200, 0.6800], requires_grad=True)\n",
      "tensor([0.5614, 0.4386], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6813e-06)\n",
      "output:2.0534157556539867e-06\n",
      "Parameter containing:\n",
      "tensor([1.3200, 0.6800], requires_grad=True)\n",
      "tensor([0.6052, 0.3948], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.2228e-10)\n",
      "output:2.8512489591570045e-10\n",
      "Parameter containing:\n",
      "tensor([1.3200, 0.6800], requires_grad=True)\n",
      "tensor([0.5114, 0.4886], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0928)\n",
      "output:0.04532612860202789\n",
      "Parameter containing:\n",
      "tensor([1.3205, 0.6795], requires_grad=True)\n",
      "tensor([0.3524, 0.6476], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6476355195045471\n",
      "Parameter containing:\n",
      "tensor([1.3250, 0.6750], requires_grad=True)\n",
      "tensor([0.5472, 0.4528], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.8806e-05)\n",
      "output:3.568007014109753e-05\n",
      "Parameter containing:\n",
      "tensor([1.3250, 0.6750], requires_grad=True)\n",
      "tensor([0.5370, 0.4630], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0006)\n",
      "output:0.0002819758665282279\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.7044, 0.2956], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7783e-18)\n",
      "output:5.257370755821922e-19\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3830e-19)\n",
      "output:6.805732533591458e-20\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.5344, 0.4656], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0010)\n",
      "output:0.00048099024570547044\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.6762, 0.3238], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0038e-16)\n",
      "output:1.620459260787794e-16\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.5456, 0.4544], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:4.979193181497976e-05\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.5372, 0.4628], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0006)\n",
      "output:0.00027155247516930103\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.6688, 0.3312], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1814e-15)\n",
      "output:7.22485222690028e-16\n",
      "Parameter containing:\n",
      "tensor([1.3251, 0.6749], requires_grad=True)\n",
      "tensor([0.4575, 0.5425], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5423505902290344\n",
      "Parameter containing:\n",
      "tensor([1.3300, 0.6700], requires_grad=True)\n",
      "tensor([0.5209, 0.4791], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0151)\n",
      "output:0.007227841764688492\n",
      "Parameter containing:\n",
      "tensor([1.3301, 0.6699], requires_grad=True)\n",
      "tensor([0.4913, 0.5087], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8502)\n",
      "output:0.43250590562820435\n",
      "Parameter containing:\n",
      "tensor([1.3343, 0.6657], requires_grad=True)\n",
      "tensor([0.4385, 0.5615], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5615242719650269\n",
      "Parameter containing:\n",
      "tensor([1.3393, 0.6607], requires_grad=True)\n",
      "tensor([0.5314, 0.4686], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0019)\n",
      "output:0.0008814373868517578\n",
      "Parameter containing:\n",
      "tensor([1.3393, 0.6607], requires_grad=True)\n",
      "tensor([0.4834, 0.5166], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9652)\n",
      "output:0.4986046850681305\n",
      "Parameter containing:\n",
      "tensor([1.3441, 0.6559], requires_grad=True)\n",
      "tensor([0.4793, 0.5207], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9844)\n",
      "output:0.5125683546066284\n",
      "Parameter containing:\n",
      "tensor([1.3490, 0.6510], requires_grad=True)\n",
      "tensor([0.5882, 0.4118], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1892e-08)\n",
      "output:9.015233892739616e-09\n",
      "Parameter containing:\n",
      "tensor([1.3490, 0.6510], requires_grad=True)\n",
      "tensor([0.3558, 0.6442], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6441707611083984\n",
      "Parameter containing:\n",
      "tensor([1.3536, 0.6464], requires_grad=True)\n",
      "tensor([0.4712, 0.5288], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9968)\n",
      "output:0.5270829796791077\n",
      "Parameter containing:\n",
      "tensor([1.3586, 0.6414], requires_grad=True)\n",
      "tensor([0.5433, 0.4567], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:7.850729889469221e-05\n",
      "Parameter containing:\n",
      "tensor([1.3586, 0.6414], requires_grad=True)\n",
      "tensor([0.2915, 0.7085], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.7085247039794922\n",
      "Parameter containing:\n",
      "tensor([1.3627, 0.6373], requires_grad=True)\n",
      "tensor([0.5302, 0.4698], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0024)\n",
      "output:0.0011086659505963326\n",
      "Parameter containing:\n",
      "tensor([1.3627, 0.6373], requires_grad=True)\n",
      "tensor([0.5027, 0.4973], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3703)\n",
      "output:0.18415383994579315\n",
      "Parameter containing:\n",
      "tensor([1.3646, 0.6354], requires_grad=True)\n",
      "tensor([0.4914, 0.5086], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8487)\n",
      "output:0.4316553771495819\n",
      "Parameter containing:\n",
      "tensor([1.3688, 0.6312], requires_grad=True)\n",
      "tensor([0.6196, 0.3804], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1284e-11)\n",
      "output:1.5706396253034605e-11\n",
      "Parameter containing:\n",
      "tensor([1.3688, 0.6312], requires_grad=True)\n",
      "tensor([0.4149, 0.5851], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5850669145584106\n",
      "Parameter containing:\n",
      "tensor([1.3737, 0.6263], requires_grad=True)\n",
      "tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8037e-09)\n",
      "output:7.202802798644825e-10\n",
      "Parameter containing:\n",
      "tensor([1.3737, 0.6263], requires_grad=True)\n",
      "tensor([0.5849, 0.4151], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1859e-08)\n",
      "output:1.737377353094871e-08\n",
      "Parameter containing:\n",
      "tensor([1.3737, 0.6263], requires_grad=True)\n",
      "tensor([0.6079, 0.3921], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.2346e-10)\n",
      "output:1.660314247198258e-10\n",
      "Parameter containing:\n",
      "tensor([1.3737, 0.6263], requires_grad=True)\n",
      "tensor([0.5503, 0.4497], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3104e-05)\n",
      "output:1.9385426639928482e-05\n",
      "Parameter containing:\n",
      "tensor([1.3737, 0.6263], requires_grad=True)\n",
      "tensor([0.4547, 0.5453], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5451908707618713\n",
      "Parameter containing:\n",
      "tensor([1.3786, 0.6214], requires_grad=True)\n",
      "tensor([0.4063, 0.5937], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5937350392341614\n",
      "Parameter containing:\n",
      "tensor([1.3834, 0.6166], requires_grad=True)\n",
      "tensor([0.5356, 0.4644], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0008)\n",
      "output:0.00037429342046380043\n",
      "Parameter containing:\n",
      "tensor([1.3834, 0.6166], requires_grad=True)\n",
      "tensor([0.5513, 0.4487], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4915e-05)\n",
      "output:1.566612809256185e-05\n",
      "Parameter containing:\n",
      "tensor([1.3834, 0.6166], requires_grad=True)\n",
      "tensor([0.6486, 0.3514], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2451e-13)\n",
      "output:4.3754726946655664e-14\n",
      "Parameter containing:\n",
      "tensor([1.3834, 0.6166], requires_grad=True)\n",
      "tensor([0.5086, 0.4914], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1514)\n",
      "output:0.0743735209107399\n",
      "Parameter containing:\n",
      "tensor([1.3842, 0.6158], requires_grad=True)\n",
      "tensor([0.6482, 0.3518], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3414e-13)\n",
      "output:4.7189052524484326e-14\n",
      "Parameter containing:\n",
      "tensor([1.3842, 0.6158], requires_grad=True)\n",
      "tensor([0.7313, 0.2687], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.1480e-21)\n",
      "output:2.1895153755303616e-21\n",
      "Parameter containing:\n",
      "tensor([1.3842, 0.6158], requires_grad=True)\n",
      "tensor([0.5986, 0.4014], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7030e-09)\n",
      "output:1.0848645315419958e-09\n",
      "Parameter containing:\n",
      "tensor([1.3842, 0.6158], requires_grad=True)\n",
      "tensor([0.4500, 0.5500], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5499786734580994\n",
      "Parameter containing:\n",
      "tensor([1.3892, 0.6108], requires_grad=True)\n",
      "tensor([0.5116, 0.4884], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0896)\n",
      "output:0.043736834079027176\n",
      "Parameter containing:\n",
      "tensor([1.3896, 0.6104], requires_grad=True)\n",
      "tensor([0.5521, 0.4479], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.9889e-05)\n",
      "output:1.3387434592004865e-05\n",
      "Parameter containing:\n",
      "tensor([1.3896, 0.6104], requires_grad=True)\n",
      "tensor([0.5112, 0.4888], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0963)\n",
      "output:0.04707825556397438\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.5741, 0.4259], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.6402e-07)\n",
      "output:1.5502706673942157e-07\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.6013, 0.3987], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6042e-09)\n",
      "output:6.396718710277582e-10\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.5287, 0.4713], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0032)\n",
      "output:0.001523345592431724\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.2623e-16)\n",
      "output:3.028068141655647e-16\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0192e-14)\n",
      "output:2.093453787600265e-14\n",
      "Parameter containing:\n",
      "tensor([1.3901, 0.6099], requires_grad=True)\n",
      "tensor([0.4058, 0.5942], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5941669940948486\n",
      "Parameter containing:\n",
      "tensor([1.3949, 0.6051], requires_grad=True)\n",
      "tensor([0.4545, 0.5455], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5454347729682922\n",
      "Parameter containing:\n",
      "tensor([1.3999, 0.6001], requires_grad=True)\n",
      "tensor([0.4728, 0.5272], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9957)\n",
      "output:0.5249395966529846\n",
      "Parameter containing:\n",
      "tensor([1.4048, 0.5952], requires_grad=True)\n",
      "tensor([0.5553, 0.4447], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5628e-05)\n",
      "output:6.949306680326117e-06\n",
      "Parameter containing:\n",
      "tensor([1.4048, 0.5952], requires_grad=True)\n",
      "tensor([0.6142, 0.3858], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2139e-10)\n",
      "output:4.6835410549839196e-11\n",
      "Parameter containing:\n",
      "tensor([1.4048, 0.5952], requires_grad=True)\n",
      "tensor([0.5128, 0.4872], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0715)\n",
      "output:0.034848518669605255\n",
      "Parameter containing:\n",
      "tensor([1.4052, 0.5948], requires_grad=True)\n",
      "tensor([0.5507, 0.4493], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9259e-05)\n",
      "output:1.763789805409033e-05\n",
      "Parameter containing:\n",
      "tensor([1.4052, 0.5948], requires_grad=True)\n",
      "tensor([0.4423, 0.5577], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5576882362365723\n",
      "Parameter containing:\n",
      "tensor([1.4101, 0.5899], requires_grad=True)\n",
      "tensor([0.7258, 0.2742], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4274e-20)\n",
      "output:6.655276700441802e-21\n",
      "Parameter containing:\n",
      "tensor([1.4101, 0.5899], requires_grad=True)\n",
      "tensor([0.5977, 0.4023], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2636e-09)\n",
      "output:1.3129556331037406e-09\n",
      "Parameter containing:\n",
      "tensor([1.4101, 0.5899], requires_grad=True)\n",
      "tensor([0.5917, 0.4083], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0859e-08)\n",
      "output:4.433863942665539e-09\n",
      "Parameter containing:\n",
      "tensor([1.4101, 0.5899], requires_grad=True)\n",
      "tensor([0.6135, 0.3865], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3819e-10)\n",
      "output:5.340986333757236e-11\n",
      "Parameter containing:\n",
      "tensor([1.4101, 0.5899], requires_grad=True)\n",
      "tensor([0.3667, 0.6333], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.633320152759552\n",
      "Parameter containing:\n",
      "tensor([1.4148, 0.5852], requires_grad=True)\n",
      "tensor([0.5683, 0.4317], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1702e-06)\n",
      "output:5.05191906086111e-07\n",
      "Parameter containing:\n",
      "tensor([1.4148, 0.5852], requires_grad=True)\n",
      "tensor([0.4275, 0.5725], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5725411772727966\n",
      "Parameter containing:\n",
      "tensor([1.4197, 0.5803], requires_grad=True)\n",
      "tensor([0.5914, 0.4086], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1549e-08)\n",
      "output:4.719279189657755e-09\n",
      "Parameter containing:\n",
      "tensor([1.4197, 0.5803], requires_grad=True)\n",
      "tensor([0.6032, 0.3968], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0926e-09)\n",
      "output:4.335755920958917e-10\n",
      "Parameter containing:\n",
      "tensor([1.4197, 0.5803], requires_grad=True)\n",
      "tensor([0.5861, 0.4139], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2936e-08)\n",
      "output:1.3630735651304349e-08\n",
      "Parameter containing:\n",
      "tensor([1.4197, 0.5803], requires_grad=True)\n",
      "tensor([0.8346, 0.1654], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.6755e-30)\n",
      "output:1.4350506504895016e-30\n",
      "Parameter containing:\n",
      "tensor([1.4197, 0.5803], requires_grad=True)\n",
      "tensor([0.4896, 0.5104], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8888)\n",
      "output:0.45363378524780273\n",
      "Parameter containing:\n",
      "tensor([1.4241, 0.5759], requires_grad=True)\n",
      "tensor([0.5982, 0.4018], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.9585e-09)\n",
      "output:1.1887616446770721e-09\n",
      "Parameter containing:\n",
      "tensor([1.4241, 0.5759], requires_grad=True)\n",
      "tensor([0.4783, 0.5217], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9870)\n",
      "output:0.514893651008606\n",
      "Parameter containing:\n",
      "tensor([1.4290, 0.5710], requires_grad=True)\n",
      "tensor([0.5077, 0.4923], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1770)\n",
      "output:0.0871201604604721\n",
      "Parameter containing:\n",
      "tensor([1.4299, 0.5701], requires_grad=True)\n",
      "tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3807e-14)\n",
      "output:4.700279844971258e-15\n",
      "Parameter containing:\n",
      "tensor([1.4299, 0.5701], requires_grad=True)\n",
      "tensor([0.5407, 0.4593], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00013402116019278765\n",
      "Parameter containing:\n",
      "tensor([1.4299, 0.5701], requires_grad=True)\n",
      "tensor([0.2796, 0.7204], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.7204329967498779\n",
      "Parameter containing:\n",
      "tensor([1.4340, 0.5660], requires_grad=True)\n",
      "tensor([0.4995, 0.5005], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5254)\n",
      "output:0.2629847526550293\n",
      "Parameter containing:\n",
      "tensor([1.4366, 0.5634], requires_grad=True)\n",
      "tensor([0.6114, 0.3886], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1124e-10)\n",
      "output:8.209165985872957e-11\n",
      "Parameter containing:\n",
      "tensor([1.4366, 0.5634], requires_grad=True)\n",
      "tensor([0.6000, 0.4000], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0434e-09)\n",
      "output:8.172550414187185e-10\n",
      "Parameter containing:\n",
      "tensor([1.4366, 0.5634], requires_grad=True)\n",
      "tensor([0.5850, 0.4150], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1245e-08)\n",
      "output:1.7115795003519452e-08\n",
      "Parameter containing:\n",
      "tensor([1.4366, 0.5634], requires_grad=True)\n",
      "tensor([0.5007, 0.4993], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4673)\n",
      "output:0.2333473265171051\n",
      "Parameter containing:\n",
      "tensor([1.4389, 0.5611], requires_grad=True)\n",
      "tensor([0.4626, 0.5374], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9994)\n",
      "output:0.5370952486991882\n",
      "Parameter containing:\n",
      "tensor([1.4439, 0.5561], requires_grad=True)\n",
      "tensor([0.7585, 0.2415], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5196e-23)\n",
      "output:8.499630732679915e-24\n",
      "Parameter containing:\n",
      "tensor([1.4439, 0.5561], requires_grad=True)\n",
      "tensor([0.5686, 0.4314], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0952e-06)\n",
      "output:4.7245896439562785e-07\n",
      "Parameter containing:\n",
      "tensor([1.4439, 0.5561], requires_grad=True)\n",
      "tensor([0.2756, 0.7244], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.7244111895561218\n",
      "Parameter containing:\n",
      "tensor([1.4479, 0.5521], requires_grad=True)\n",
      "tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0657e-14)\n",
      "output:3.614079098246707e-15\n",
      "Parameter containing:\n",
      "tensor([1.4479, 0.5521], requires_grad=True)\n",
      "tensor([0.4883, 0.5117], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9113)\n",
      "output:0.46629032492637634\n",
      "Parameter containing:\n",
      "tensor([1.4524, 0.5476], requires_grad=True)\n",
      "tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8998e-07)\n",
      "output:3.829922547993192e-07\n",
      "Parameter containing:\n",
      "tensor([1.4524, 0.5476], requires_grad=True)\n",
      "tensor([0.5810, 0.4190], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.2988e-08)\n",
      "output:3.89660783639556e-08\n",
      "Parameter containing:\n",
      "tensor([1.4524, 0.5476], requires_grad=True)\n",
      "tensor([0.4526, 0.5474], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5473117828369141\n",
      "Parameter containing:\n",
      "tensor([1.4574, 0.5426], requires_grad=True)\n",
      "tensor([0.5601, 0.4399], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0731e-06)\n",
      "output:2.671812126209261e-06\n",
      "Parameter containing:\n",
      "tensor([1.4574, 0.5426], requires_grad=True)\n",
      "tensor([0.5310, 0.4690], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0020)\n",
      "output:0.0009569677640683949\n",
      "Parameter containing:\n",
      "tensor([1.4574, 0.5426], requires_grad=True)\n",
      "tensor([0.5564, 0.4436], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2704e-05)\n",
      "output:5.63600224268157e-06\n",
      "Parameter containing:\n",
      "tensor([1.4574, 0.5426], requires_grad=True)\n",
      "tensor([0.3918, 0.6082], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6081891059875488\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.5817, 0.4183], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.0219e-08)\n",
      "output:3.35563576925324e-08\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7551e-12)\n",
      "output:1.0108760616772683e-12\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.5652, 0.4348], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1594e-06)\n",
      "output:9.388665489495907e-07\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8951e-05)\n",
      "output:8.445230378129054e-06\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.5430, 0.4570], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.497099042870104e-05\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.6168, 0.3832], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.2197e-11)\n",
      "output:2.7668834237659645e-11\n",
      "Parameter containing:\n",
      "tensor([1.4622, 0.5378], requires_grad=True)\n",
      "tensor([0.5180, 0.4820], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0267)\n",
      "output:0.012872271239757538\n",
      "Parameter containing:\n",
      "tensor([1.4623, 0.5377], requires_grad=True)\n",
      "tensor([0.4778, 0.5222], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9883)\n",
      "output:0.5160694718360901\n",
      "Parameter containing:\n",
      "tensor([1.4672, 0.5328], requires_grad=True)\n",
      "tensor([0.5766, 0.4234], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2235e-07)\n",
      "output:9.414429058551832e-08\n",
      "Parameter containing:\n",
      "tensor([1.4672, 0.5328], requires_grad=True)\n",
      "tensor([0.4997, 0.5003], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5139)\n",
      "output:0.25708794593811035\n",
      "Parameter containing:\n",
      "tensor([1.4698, 0.5302], requires_grad=True)\n",
      "tensor([0.5537, 0.4463], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1568e-05)\n",
      "output:9.625116945244372e-06\n",
      "Parameter containing:\n",
      "tensor([1.4698, 0.5302], requires_grad=True)\n",
      "tensor([0.3090, 0.6910], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6910319328308105\n",
      "Parameter containing:\n",
      "tensor([1.4741, 0.5259], requires_grad=True)\n",
      "tensor([0.5094, 0.4906], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1333)\n",
      "output:0.06540659070014954\n",
      "Parameter containing:\n",
      "tensor([1.4747, 0.5253], requires_grad=True)\n",
      "tensor([0.4398, 0.5602], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5602445602416992\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.5644, 0.4356], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5237e-06)\n",
      "output:1.0992204124704585e-06\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.5928, 0.4072], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.7659e-09)\n",
      "output:3.5698139999595924e-09\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.5632, 0.4368], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2290e-06)\n",
      "output:1.4103699186307495e-06\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.5965, 0.4035], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1708e-09)\n",
      "output:1.6830213889207357e-09\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.6731, 0.3269], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.1497e-16)\n",
      "output:2.9906893717867027e-16\n",
      "Parameter containing:\n",
      "tensor([1.4797, 0.5203], requires_grad=True)\n",
      "tensor([0.4573, 0.5427], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5425849556922913\n",
      "Parameter containing:\n",
      "tensor([1.4846, 0.5154], requires_grad=True)\n",
      "tensor([0.5577, 0.4423], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.7035e-06)\n",
      "output:4.291722689231392e-06\n",
      "Parameter containing:\n",
      "tensor([1.4846, 0.5154], requires_grad=True)\n",
      "tensor([0.4513, 0.5487], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5486412644386292\n",
      "Parameter containing:\n",
      "tensor([1.4896, 0.5104], requires_grad=True)\n",
      "tensor([0.5598, 0.4402], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.3351e-06)\n",
      "output:2.7884109385922784e-06\n",
      "Parameter containing:\n",
      "tensor([1.4896, 0.5104], requires_grad=True)\n",
      "tensor([0.5166, 0.4834], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0346)\n",
      "output:0.016736913472414017\n",
      "Parameter containing:\n",
      "tensor([1.4898, 0.5102], requires_grad=True)\n",
      "tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4526e-08)\n",
      "output:1.4297008910091336e-08\n",
      "Parameter containing:\n",
      "tensor([1.4898, 0.5102], requires_grad=True)\n",
      "tensor([0.4960, 0.5040], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.6901)\n",
      "output:0.34779906272888184\n",
      "Parameter containing:\n",
      "tensor([1.4932, 0.5068], requires_grad=True)\n",
      "tensor([0.5286, 0.4714], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0033)\n",
      "output:0.001533790142275393\n",
      "Parameter containing:\n",
      "tensor([1.4932, 0.5068], requires_grad=True)\n",
      "tensor([0.5797, 0.4203], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1912e-07)\n",
      "output:5.006625514170082e-08\n",
      "Parameter containing:\n",
      "tensor([1.4932, 0.5068], requires_grad=True)\n",
      "tensor([0.4919, 0.5081], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8345)\n",
      "output:0.42402613162994385\n",
      "Parameter containing:\n",
      "tensor([1.4974, 0.5026], requires_grad=True)\n",
      "tensor([0.5097, 0.4903], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1250)\n",
      "output:0.0612793006002903\n",
      "Parameter containing:\n",
      "tensor([1.4980, 0.5020], requires_grad=True)\n",
      "tensor([0.4893, 0.5107], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8939)\n",
      "output:0.4564571976661682\n",
      "Parameter containing:\n",
      "tensor([1.5025, 0.4975], requires_grad=True)\n",
      "tensor([0.5098, 0.4902], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1244)\n",
      "output:0.06097634136676788\n",
      "Parameter containing:\n",
      "tensor([1.5031, 0.4969], requires_grad=True)\n",
      "tensor([0.6071, 0.3929], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0188e-10)\n",
      "output:1.9720734767414427e-10\n",
      "Parameter containing:\n",
      "tensor([1.5031, 0.4969], requires_grad=True)\n",
      "tensor([0.5991, 0.4009], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4664e-09)\n",
      "output:9.887898277938234e-10\n",
      "Parameter containing:\n",
      "tensor([1.5031, 0.4969], requires_grad=True)\n",
      "tensor([0.5776, 0.4224], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8096e-07)\n",
      "output:7.64341336889629e-08\n",
      "Parameter containing:\n",
      "tensor([1.5031, 0.4969], requires_grad=True)\n",
      "tensor([0.4063, 0.5937], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5936638712882996\n",
      "Parameter containing:\n",
      "tensor([1.5079, 0.4921], requires_grad=True)\n",
      "tensor([0.5046, 0.4954], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2854)\n",
      "output:0.14140859246253967\n",
      "Parameter containing:\n",
      "tensor([1.5094, 0.4906], requires_grad=True)\n",
      "tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8071e-09)\n",
      "output:7.216614528182674e-10\n",
      "Parameter containing:\n",
      "tensor([1.5094, 0.4906], requires_grad=True)\n",
      "tensor([0.6985, 0.3015], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7096e-18)\n",
      "output:1.7213240806316372e-18\n",
      "Parameter containing:\n",
      "tensor([1.5094, 0.4906], requires_grad=True)\n",
      "tensor([0.5565, 0.4435], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2490e-05)\n",
      "output:5.5397781579813454e-06\n",
      "Parameter containing:\n",
      "tensor([1.5094, 0.4906], requires_grad=True)\n",
      "tensor([0.4588, 0.5412], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9997)\n",
      "output:0.5410401821136475\n",
      "Parameter containing:\n",
      "tensor([1.5143, 0.4857], requires_grad=True)\n",
      "tensor([0.4939, 0.5061], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.7730)\n",
      "output:0.39121100306510925\n",
      "Parameter containing:\n",
      "tensor([1.5182, 0.4818], requires_grad=True)\n",
      "tensor([0.5427, 0.4573], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.989821799332276e-05\n",
      "Parameter containing:\n",
      "tensor([1.5182, 0.4818], requires_grad=True)\n",
      "tensor([0.5104, 0.4896], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1118)\n",
      "output:0.054764747619628906\n",
      "Parameter containing:\n",
      "tensor([1.5187, 0.4813], requires_grad=True)\n",
      "tensor([0.5419, 0.4581], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:0.0001053323139785789\n",
      "Parameter containing:\n",
      "tensor([1.5187, 0.4813], requires_grad=True)\n",
      "tensor([0.5621, 0.4379], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.0505e-06)\n",
      "output:1.7737851294441498e-06\n",
      "Parameter containing:\n",
      "tensor([1.5187, 0.4813], requires_grad=True)\n",
      "tensor([0.6144, 0.3856], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1500e-10)\n",
      "output:4.433971592665564e-11\n",
      "Parameter containing:\n",
      "tensor([1.5187, 0.4813], requires_grad=True)\n",
      "tensor([0.4979, 0.5021], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.6027)\n",
      "output:0.3026279807090759\n",
      "Parameter containing:\n",
      "tensor([1.5218, 0.4782], requires_grad=True)\n",
      "tensor([0.6704, 0.3296], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5971e-15)\n",
      "output:5.264751283109233e-16\n",
      "Parameter containing:\n",
      "tensor([1.5218, 0.4782], requires_grad=True)\n",
      "tensor([0.5481, 0.4519], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.6454e-05)\n",
      "output:3.00306983262999e-05\n",
      "Parameter containing:\n",
      "tensor([1.5218, 0.4782], requires_grad=True)\n",
      "tensor([0.6010, 0.3990], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6897e-09)\n",
      "output:6.742177927065995e-10\n",
      "Parameter containing:\n",
      "tensor([1.5218, 0.4782], requires_grad=True)\n",
      "tensor([0.4988, 0.5012], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5615)\n",
      "output:0.2814388573169708\n",
      "Parameter containing:\n",
      "tensor([1.5246, 0.4754], requires_grad=True)\n",
      "tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7593e-12)\n",
      "output:6.41558204131365e-13\n",
      "Parameter containing:\n",
      "tensor([1.5246, 0.4754], requires_grad=True)\n",
      "tensor([0.6017, 0.3983], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4621e-09)\n",
      "output:5.823378446123684e-10\n",
      "Parameter containing:\n",
      "tensor([1.5246, 0.4754], requires_grad=True)\n",
      "tensor([0.5844, 0.4156], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6926e-08)\n",
      "output:1.9503671566667435e-08\n",
      "Parameter containing:\n",
      "tensor([1.5246, 0.4754], requires_grad=True)\n",
      "tensor([0.5973, 0.4027], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5182e-09)\n",
      "output:1.4166741113541548e-09\n",
      "Parameter containing:\n",
      "tensor([1.5246, 0.4754], requires_grad=True)\n",
      "tensor([0.4550, 0.5450], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5449180006980896\n",
      "Parameter containing:\n",
      "tensor([1.5295, 0.4705], requires_grad=True)\n",
      "tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2282e-09)\n",
      "output:1.2985231778728235e-09\n",
      "Parameter containing:\n",
      "tensor([1.5295, 0.4705], requires_grad=True)\n",
      "tensor([0.4854, 0.5146], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9490)\n",
      "output:0.4884006083011627\n",
      "Parameter containing:\n",
      "tensor([1.5343, 0.4657], requires_grad=True)\n",
      "tensor([0.6604, 0.3396], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1692e-14)\n",
      "output:3.970761707720177e-15\n",
      "Parameter containing:\n",
      "tensor([1.5343, 0.4657], requires_grad=True)\n",
      "tensor([0.5312, 0.4688], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0020)\n",
      "output:0.000920297869015485\n",
      "Parameter containing:\n",
      "tensor([1.5343, 0.4657], requires_grad=True)\n",
      "tensor([0.5471, 0.4529], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.1337e-05)\n",
      "output:3.683895920403302e-05\n",
      "Parameter containing:\n",
      "tensor([1.5343, 0.4657], requires_grad=True)\n",
      "tensor([0.3887, 0.6113], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.611303448677063\n",
      "Parameter containing:\n",
      "tensor([1.5390, 0.4610], requires_grad=True)\n",
      "tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6133e-15)\n",
      "output:5.319119681015526e-16\n",
      "Parameter containing:\n",
      "tensor([1.5390, 0.4610], requires_grad=True)\n",
      "tensor([0.6303, 0.3697], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.8567e-12)\n",
      "output:1.795757119393837e-12\n",
      "Parameter containing:\n",
      "tensor([1.5390, 0.4610], requires_grad=True)\n",
      "tensor([0.4519, 0.5481], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5480661392211914\n",
      "Parameter containing:\n",
      "tensor([1.5440, 0.4560], requires_grad=True)\n",
      "tensor([0.4771, 0.5229], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9898)\n",
      "output:0.5175414681434631\n",
      "Parameter containing:\n",
      "tensor([1.5489, 0.4511], requires_grad=True)\n",
      "tensor([0.5414, 0.4586], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00011676341091515496\n",
      "Parameter containing:\n",
      "tensor([1.5489, 0.4511], requires_grad=True)\n",
      "tensor([0.4274, 0.5726], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5726061463356018\n",
      "Parameter containing:\n",
      "tensor([1.5538, 0.4462], requires_grad=True)\n",
      "tensor([0.4907, 0.5093], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8643)\n",
      "output:0.4401482045650482\n",
      "Parameter containing:\n",
      "tensor([1.5581, 0.4419], requires_grad=True)\n",
      "tensor([0.6572, 0.3428], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2250e-14)\n",
      "output:7.62774598936063e-15\n",
      "Parameter containing:\n",
      "tensor([1.5581, 0.4419], requires_grad=True)\n",
      "tensor([0.5126, 0.4874], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0747)\n",
      "output:0.03638816624879837\n",
      "Parameter containing:\n",
      "tensor([1.5585, 0.4415], requires_grad=True)\n",
      "tensor([0.5594, 0.4406], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9756e-06)\n",
      "output:3.073673269682331e-06\n",
      "Parameter containing:\n",
      "tensor([1.5585, 0.4415], requires_grad=True)\n",
      "tensor([0.4696, 0.5304], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9977)\n",
      "output:0.5291335582733154\n",
      "Parameter containing:\n",
      "tensor([1.5635, 0.4365], requires_grad=True)\n",
      "tensor([0.5902, 0.4098], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4735e-08)\n",
      "output:6.038805899777344e-09\n",
      "Parameter containing:\n",
      "tensor([1.5635, 0.4365], requires_grad=True)\n",
      "tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.7932e-07)\n",
      "output:3.7835457078472245e-07\n",
      "Parameter containing:\n",
      "tensor([1.5635, 0.4365], requires_grad=True)\n",
      "tensor([0.5949, 0.4051], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7148e-09)\n",
      "output:2.3150572570074246e-09\n",
      "Parameter containing:\n",
      "tensor([1.5635, 0.4365], requires_grad=True)\n",
      "tensor([0.5128, 0.4872], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0715)\n",
      "output:0.03483877703547478\n",
      "Parameter containing:\n",
      "tensor([1.5638, 0.4362], requires_grad=True)\n",
      "tensor([0.6651, 0.3349], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.5421e-15)\n",
      "output:1.5210329452523081e-15\n",
      "Parameter containing:\n",
      "tensor([1.5638, 0.4362], requires_grad=True)\n",
      "tensor([0.5313, 0.4687], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0019)\n",
      "output:0.0009022802114486694\n",
      "Parameter containing:\n",
      "tensor([1.5638, 0.4362], requires_grad=True)\n",
      "tensor([0.4591, 0.5409], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9997)\n",
      "output:0.5407308340072632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1.5688, 0.4312], requires_grad=True)\n",
      "tensor([0.5184, 0.4816], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0247)\n",
      "output:0.011879169382154942\n",
      "Parameter containing:\n",
      "tensor([1.5689, 0.4311], requires_grad=True)\n",
      "tensor([0.4619, 0.5381], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9995)\n",
      "output:0.5378110408782959\n",
      "Parameter containing:\n",
      "tensor([1.5739, 0.4261], requires_grad=True)\n",
      "tensor([0.4823, 0.5177], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9717)\n",
      "output:0.5030204653739929\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5957, 0.4043], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.9028e-09)\n",
      "output:1.9823438446309183e-09\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5563, 0.4437], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2982e-05)\n",
      "output:5.760784915764816e-06\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.6314, 0.3686], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8246e-12)\n",
      "output:1.4095608361075485e-12\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5257, 0.4743], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0058)\n",
      "output:0.002773441607132554\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5288, 0.4712], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0031)\n",
      "output:0.0014765012310817838\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5408, 0.4592], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00013233257050160319\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.6125, 0.3875], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6779e-10)\n",
      "output:6.501061494690319e-11\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5480, 0.4520], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7701e-05)\n",
      "output:3.0600567697547376e-05\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5604, 0.4396], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.6585e-06)\n",
      "output:2.487400934114703e-06\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.6451, 0.3549], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5005e-13)\n",
      "output:8.874780250966996e-14\n",
      "Parameter containing:\n",
      "tensor([1.5788, 0.4212], requires_grad=True)\n",
      "tensor([0.5117, 0.4883], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0881)\n",
      "output:0.04304269328713417\n",
      "Parameter containing:\n",
      "tensor([1.5792, 0.4208], requires_grad=True)\n",
      "tensor([0.4485, 0.5515], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5514811277389526\n",
      "Parameter containing:\n",
      "tensor([1.5842, 0.4158], requires_grad=True)\n",
      "tensor([0.5879, 0.4121], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3011e-08)\n",
      "output:9.48191924976527e-09\n",
      "Parameter containing:\n",
      "tensor([1.5842, 0.4158], requires_grad=True)\n",
      "tensor([0.4831, 0.5169], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9673)\n",
      "output:0.5000370740890503\n",
      "Parameter containing:\n",
      "tensor([1.5890, 0.4110], requires_grad=True)\n",
      "tensor([0.6462, 0.3538], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9916e-13)\n",
      "output:7.045970388088255e-14\n",
      "Parameter containing:\n",
      "tensor([1.5890, 0.4110], requires_grad=True)\n",
      "tensor([0.4304, 0.5696], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5696238875389099\n",
      "Parameter containing:\n",
      "tensor([1.5939, 0.4061], requires_grad=True)\n",
      "tensor([0.5056, 0.4944], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2445)\n",
      "output:0.1208951324224472\n",
      "Parameter containing:\n",
      "tensor([1.5951, 0.4049], requires_grad=True)\n",
      "tensor([0.4780, 0.5220], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9878)\n",
      "output:0.5155760049819946\n",
      "Parameter containing:\n",
      "tensor([1.6001, 0.3999], requires_grad=True)\n",
      "tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8820e-05)\n",
      "output:8.386092304135673e-06\n",
      "Parameter containing:\n",
      "tensor([1.6001, 0.3999], requires_grad=True)\n",
      "tensor([0.5371, 0.4629], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0006)\n",
      "output:0.00027706564287655056\n",
      "Parameter containing:\n",
      "tensor([1.6001, 0.3999], requires_grad=True)\n",
      "tensor([0.5053, 0.4947], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2587)\n",
      "output:0.1279793083667755\n",
      "Parameter containing:\n",
      "tensor([1.6014, 0.3986], requires_grad=True)\n",
      "tensor([0.6107, 0.3893], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4233e-10)\n",
      "output:9.433968189975772e-11\n",
      "Parameter containing:\n",
      "tensor([1.6014, 0.3986], requires_grad=True)\n",
      "tensor([0.5165, 0.4835], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0353)\n",
      "output:0.01708676852285862\n",
      "Parameter containing:\n",
      "tensor([1.6016, 0.3984], requires_grad=True)\n",
      "tensor([0.6533, 0.3467], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.8281e-14)\n",
      "output:1.6738617870243333e-14\n",
      "Parameter containing:\n",
      "tensor([1.6016, 0.3984], requires_grad=True)\n",
      "tensor([0.4510, 0.5490], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5489718317985535\n",
      "Parameter containing:\n",
      "tensor([1.6065, 0.3935], requires_grad=True)\n",
      "tensor([0.6114, 0.3886], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1167e-10)\n",
      "output:8.225834596808923e-11\n",
      "Parameter containing:\n",
      "tensor([1.6065, 0.3935], requires_grad=True)\n",
      "tensor([0.4922, 0.5078], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8272)\n",
      "output:0.42009857296943665\n",
      "Parameter containing:\n",
      "tensor([1.6106, 0.3894], requires_grad=True)\n",
      "tensor([0.4718, 0.5282], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9964)\n",
      "output:0.5262979865074158\n",
      "Parameter containing:\n",
      "tensor([1.6156, 0.3844], requires_grad=True)\n",
      "tensor([0.5845, 0.4155], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6156e-08)\n",
      "output:1.9179687171799742e-08\n",
      "Parameter containing:\n",
      "tensor([1.6156, 0.3844], requires_grad=True)\n",
      "tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9956)\n",
      "output:0.5247544646263123\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.6108, 0.3892], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3827e-10)\n",
      "output:9.27367141412283e-11\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.5940, 0.4060], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.8031e-09)\n",
      "output:2.7618534126361283e-09\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.7386e-11)\n",
      "output:1.4204768437886539e-11\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.6412, 0.3588], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.3952e-13)\n",
      "output:1.9355871072601616e-13\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.6277, 0.3724], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.1745e-12)\n",
      "output:3.043777686492777e-12\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.6465, 0.3535], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8897e-13)\n",
      "output:6.680215462826627e-14\n",
      "Parameter containing:\n",
      "tensor([1.6206, 0.3794], requires_grad=True)\n",
      "tensor([0.3622, 0.6378], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6378260850906372\n",
      "Parameter containing:\n",
      "tensor([1.6252, 0.3748], requires_grad=True)\n",
      "tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6677e-06)\n",
      "output:7.229027119137754e-07\n",
      "Parameter containing:\n",
      "tensor([1.6252, 0.3748], requires_grad=True)\n",
      "tensor([0.5792, 0.4208], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3099e-07)\n",
      "output:5.5114895758379134e-08\n",
      "Parameter containing:\n",
      "tensor([1.6252, 0.3748], requires_grad=True)\n",
      "tensor([0.5448, 0.4552], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:5.899356983718462e-05\n",
      "Parameter containing:\n",
      "tensor([1.6252, 0.3748], requires_grad=True)\n",
      "tensor([0.5106, 0.4894], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1080)\n",
      "output:0.05285952240228653\n",
      "Parameter containing:\n",
      "tensor([1.6257, 0.3743], requires_grad=True)\n",
      "tensor([0.3934, 0.6066], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6066299080848694\n",
      "Parameter containing:\n",
      "tensor([1.6305, 0.3695], requires_grad=True)\n",
      "tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4588e-12)\n",
      "output:5.306251857177535e-13\n",
      "Parameter containing:\n",
      "tensor([1.6305, 0.3695], requires_grad=True)\n",
      "tensor([0.4909, 0.5091], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8617)\n",
      "output:0.4387311041355133\n",
      "Parameter containing:\n",
      "tensor([1.6348, 0.3652], requires_grad=True)\n",
      "tensor([0.6124, 0.3876], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7149e-10)\n",
      "output:6.646319605785322e-11\n",
      "Parameter containing:\n",
      "tensor([1.6348, 0.3652], requires_grad=True)\n",
      "tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.9212e-10)\n",
      "output:1.933243842788812e-10\n",
      "Parameter containing:\n",
      "tensor([1.6348, 0.3652], requires_grad=True)\n",
      "tensor([0.5971, 0.4029], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.6710e-09)\n",
      "output:1.4789853786112417e-09\n",
      "Parameter containing:\n",
      "tensor([1.6348, 0.3652], requires_grad=True)\n",
      "tensor([0.4481, 0.5519], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5518772006034851\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.7242, 0.2758], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3488e-20)\n",
      "output:9.235526469117106e-21\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6311e-11)\n",
      "output:6.129725199643943e-12\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.5906, 0.4094], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3495e-08)\n",
      "output:5.524947610524578e-09\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.7337, 0.2663], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0491e-21)\n",
      "output:1.3446893203009586e-21\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.6473, 0.3527], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6055e-13)\n",
      "output:5.662531465315361e-14\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.7064, 0.2936], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1823e-18)\n",
      "output:3.4714019933313833e-19\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.5555, 0.4445], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4986e-05)\n",
      "output:6.6607185544853564e-06\n",
      "Parameter containing:\n",
      "tensor([1.6398, 0.3602], requires_grad=True)\n",
      "tensor([0.3691, 0.6309], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6308645009994507\n",
      "Parameter containing:\n",
      "tensor([1.6444, 0.3556], requires_grad=True)\n",
      "tensor([0.5240, 0.4760], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0082)\n",
      "output:0.003910144791007042\n",
      "Parameter containing:\n",
      "tensor([1.6445, 0.3555], requires_grad=True)\n",
      "tensor([0.3796, 0.6204], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6204003691673279\n",
      "Parameter containing:\n",
      "tensor([1.6492, 0.3508], requires_grad=True)\n",
      "tensor([0.5930, 0.4070], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.4059e-09)\n",
      "output:3.4214342470306747e-09\n",
      "Parameter containing:\n",
      "tensor([1.6492, 0.3508], requires_grad=True)\n",
      "tensor([0.4035, 0.5965], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5964890718460083\n",
      "Parameter containing:\n",
      "tensor([1.6540, 0.3460], requires_grad=True)\n",
      "tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2539e-13)\n",
      "output:1.15914547925422e-13\n",
      "Parameter containing:\n",
      "tensor([1.6540, 0.3460], requires_grad=True)\n",
      "tensor([0.4033, 0.5967], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5967264771461487\n",
      "Parameter containing:\n",
      "tensor([1.6588, 0.3412], requires_grad=True)\n",
      "tensor([0.5614, 0.4386], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6739e-06)\n",
      "output:2.0501124708971474e-06\n",
      "Parameter containing:\n",
      "tensor([1.6588, 0.3412], requires_grad=True)\n",
      "tensor([0.5024, 0.4976], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3820)\n",
      "output:0.19008170068264008\n",
      "Parameter containing:\n",
      "tensor([1.6607, 0.3393], requires_grad=True)\n",
      "tensor([0.6718, 0.3282], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1957e-15)\n",
      "output:3.9243536725126207e-16\n",
      "Parameter containing:\n",
      "tensor([1.6607, 0.3393], requires_grad=True)\n",
      "tensor([0.5113, 0.4887], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0943)\n",
      "output:0.04607951268553734\n",
      "Parameter containing:\n",
      "tensor([1.6612, 0.3388], requires_grad=True)\n",
      "tensor([0.5330, 0.4670], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0014)\n",
      "output:0.0006371149211190641\n",
      "Parameter containing:\n",
      "tensor([1.6612, 0.3388], requires_grad=True)\n",
      "tensor([0.4938, 0.5062], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.7752)\n",
      "output:0.3923770487308502\n",
      "Parameter containing:\n",
      "tensor([1.6651, 0.3349], requires_grad=True)\n",
      "tensor([0.5562, 0.4438], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3194e-05)\n",
      "output:5.8558134696795605e-06\n",
      "Parameter containing:\n",
      "tensor([1.6651, 0.3349], requires_grad=True)\n",
      "tensor([0.6253, 0.3747], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3013e-11)\n",
      "output:4.875618572069973e-12\n",
      "Parameter containing:\n",
      "tensor([1.6651, 0.3349], requires_grad=True)\n",
      "tensor([0.4513, 0.5487], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5486382842063904\n",
      "Parameter containing:\n",
      "tensor([1.6700, 0.3300], requires_grad=True)\n",
      "tensor([0.3322, 0.6678], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.667790412902832\n",
      "Parameter containing:\n",
      "tensor([1.6744, 0.3256], requires_grad=True)\n",
      "tensor([0.5454, 0.4546], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:5.1491701015038416e-05\n",
      "Parameter containing:\n",
      "tensor([1.6744, 0.3256], requires_grad=True)\n",
      "tensor([0.7129, 0.2871], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2302e-19)\n",
      "output:9.274424637422412e-20\n",
      "Parameter containing:\n",
      "tensor([1.6744, 0.3256], requires_grad=True)\n",
      "tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0163)\n",
      "output:0.007837842218577862\n",
      "Parameter containing:\n",
      "tensor([1.6745, 0.3255], requires_grad=True)\n",
      "tensor([0.5388, 0.4612], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0004)\n",
      "output:0.00019475712906569242\n",
      "Parameter containing:\n",
      "tensor([1.6745, 0.3255], requires_grad=True)\n",
      "tensor([0.6051, 0.3949], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.3641e-10)\n",
      "output:2.9077548702183265e-10\n",
      "Parameter containing:\n",
      "tensor([1.6745, 0.3255], requires_grad=True)\n",
      "tensor([0.3834, 0.6166], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6166311502456665\n",
      "Parameter containing:\n",
      "tensor([1.6793, 0.3207], requires_grad=True)\n",
      "tensor([0.4980, 0.5020], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5972)\n",
      "output:0.29979828000068665\n",
      "Parameter containing:\n",
      "tensor([1.6822, 0.3178], requires_grad=True)\n",
      "tensor([0.4777, 0.5223], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9885)\n",
      "output:0.5162742137908936\n",
      "Parameter containing:\n",
      "tensor([1.6872, 0.3128], requires_grad=True)\n",
      "tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1788e-09)\n",
      "output:1.278389949455061e-09\n",
      "Parameter containing:\n",
      "tensor([1.6872, 0.3128], requires_grad=True)\n",
      "tensor([0.4895, 0.5105], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8917)\n",
      "output:0.4552561044692993\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.5975, 0.4025], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4141e-09)\n",
      "output:1.3742601501220975e-09\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.5992, 0.4008], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4107e-09)\n",
      "output:9.661804689642395e-10\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.6023, 0.3977], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3081e-09)\n",
      "output:5.202848152308093e-10\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5649, 0.4351], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2847e-06)\n",
      "output:9.93984826891392e-07\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.6695, 0.3305], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8817e-15)\n",
      "output:6.218563850672371e-16\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.6043, 0.3957], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.6729e-10)\n",
      "output:3.4316063879380465e-10\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.6535, 0.3465], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6803e-14)\n",
      "output:1.6218980097761765e-14\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.7062, 0.2938], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2356e-18)\n",
      "output:3.6305355165622176e-19\n",
      "Parameter containing:\n",
      "tensor([1.6916, 0.3084], requires_grad=True)\n",
      "tensor([0.4312, 0.5688], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5687633156776428\n",
      "Parameter containing:\n",
      "tensor([1.6965, 0.3035], requires_grad=True)\n",
      "tensor([0.6714, 0.3286], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3008e-15)\n",
      "output:4.274710586996437e-16\n",
      "Parameter containing:\n",
      "tensor([1.6965, 0.3035], requires_grad=True)\n",
      "tensor([0.8025, 0.1975], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.3399e-27)\n",
      "output:1.0547705859686576e-27\n",
      "Parameter containing:\n",
      "tensor([1.6965, 0.3035], requires_grad=True)\n",
      "tensor([0.6046, 0.3954], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.2675e-10)\n",
      "output:3.2692432094805213e-10\n",
      "Parameter containing:\n",
      "tensor([1.6965, 0.3035], requires_grad=True)\n",
      "tensor([0.4782, 0.5218], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9874)\n",
      "output:0.5151925683021545\n",
      "Parameter containing:\n",
      "tensor([1.7015, 0.2985], requires_grad=True)\n",
      "tensor([0.4831, 0.5169], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9670)\n",
      "output:0.49982747435569763\n",
      "Parameter containing:\n",
      "tensor([1.7063, 0.2937], requires_grad=True)\n",
      "tensor([0.5190, 0.4810], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0218)\n",
      "output:0.010473896749317646\n",
      "Parameter containing:\n",
      "tensor([1.7064, 0.2936], requires_grad=True)\n",
      "tensor([0.5868, 0.4132], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8714e-08)\n",
      "output:1.186394182894901e-08\n",
      "Parameter containing:\n",
      "tensor([1.7064, 0.2936], requires_grad=True)\n",
      "tensor([0.5680, 0.4320], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2471e-06)\n",
      "output:5.387860255723353e-07\n",
      "Parameter containing:\n",
      "tensor([1.7064, 0.2936], requires_grad=True)\n",
      "tensor([0.4598, 0.5402], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9997)\n",
      "output:0.5400623083114624\n",
      "Parameter containing:\n",
      "tensor([1.7114, 0.2886], requires_grad=True)\n",
      "tensor([0.5419, 0.4581], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:0.0001053926462191157\n",
      "Parameter containing:\n",
      "tensor([1.7114, 0.2886], requires_grad=True)\n",
      "tensor([0.4096, 0.5904], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5904014706611633\n",
      "Parameter containing:\n",
      "tensor([1.7162, 0.2838], requires_grad=True)\n",
      "tensor([0.4580, 0.5420], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5418543219566345\n",
      "Parameter containing:\n",
      "tensor([1.7212, 0.2788], requires_grad=True)\n",
      "tensor([0.6257, 0.3743], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2022e-11)\n",
      "output:4.4996619277815064e-12\n",
      "Parameter containing:\n",
      "tensor([1.7212, 0.2788], requires_grad=True)\n",
      "tensor([0.5894, 0.4106], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7084e-08)\n",
      "output:7.014219871592786e-09\n",
      "Parameter containing:\n",
      "tensor([1.7212, 0.2788], requires_grad=True)\n",
      "tensor([0.5859, 0.4141], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4529e-08)\n",
      "output:1.42983598294677e-08\n",
      "Parameter containing:\n",
      "tensor([1.7212, 0.2788], requires_grad=True)\n",
      "tensor([0.4901, 0.5099], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8784)\n",
      "output:0.4478977918624878\n",
      "Parameter containing:\n",
      "tensor([1.7256, 0.2744], requires_grad=True)\n",
      "tensor([0.5523, 0.4477], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8588e-05)\n",
      "output:1.2798282114090398e-05\n",
      "Parameter containing:\n",
      "tensor([1.7256, 0.2744], requires_grad=True)\n",
      "tensor([0.7402, 0.2598], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3686e-21)\n",
      "output:3.555706595483395e-22\n",
      "Parameter containing:\n",
      "tensor([1.7256, 0.2744], requires_grad=True)\n",
      "tensor([0.6739, 0.3261], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.8631e-16)\n",
      "output:2.564204312377222e-16\n",
      "Parameter containing:\n",
      "tensor([1.7256, 0.2744], requires_grad=True)\n",
      "tensor([0.3367, 0.6633], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6632829904556274\n",
      "Parameter containing:\n",
      "tensor([1.7300, 0.2700], requires_grad=True)\n",
      "tensor([0.5070, 0.4930], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1989)\n",
      "output:0.09808341413736343\n",
      "Parameter containing:\n",
      "tensor([1.7310, 0.2690], requires_grad=True)\n",
      "tensor([0.6365, 0.3635], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3937e-12)\n",
      "output:5.066234432839212e-13\n",
      "Parameter containing:\n",
      "tensor([1.7310, 0.2690], requires_grad=True)\n",
      "tensor([0.6270, 0.3730], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.3778e-12)\n",
      "output:3.4982782729647832e-12\n",
      "Parameter containing:\n",
      "tensor([1.7310, 0.2690], requires_grad=True)\n",
      "tensor([0.5130, 0.4870], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0691)\n",
      "output:0.03363804891705513\n",
      "Parameter containing:\n",
      "tensor([1.7314, 0.2686], requires_grad=True)\n",
      "tensor([0.5706, 0.4294], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.3299e-07)\n",
      "output:3.1472225714423985e-07\n",
      "Parameter containing:\n",
      "tensor([1.7314, 0.2686], requires_grad=True)\n",
      "tensor([0.4213, 0.5787], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5786691904067993\n",
      "Parameter containing:\n",
      "tensor([1.7362, 0.2638], requires_grad=True)\n",
      "tensor([0.3129, 0.6871], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6871418952941895\n",
      "Parameter containing:\n",
      "tensor([1.7405, 0.2595], requires_grad=True)\n",
      "tensor([0.5873, 0.4127], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6242e-08)\n",
      "output:1.0830721208776595e-08\n",
      "Parameter containing:\n",
      "tensor([1.7405, 0.2595], requires_grad=True)\n",
      "tensor([0.3536, 0.6464], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6463680267333984\n",
      "Parameter containing:\n",
      "tensor([1.7451, 0.2549], requires_grad=True)\n",
      "tensor([0.5670, 0.4330], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5245e-06)\n",
      "output:6.601648578907771e-07\n",
      "Parameter containing:\n",
      "tensor([1.7451, 0.2549], requires_grad=True)\n",
      "tensor([0.6136, 0.3864], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3655e-10)\n",
      "output:5.2767686054000507e-11\n",
      "Parameter containing:\n",
      "tensor([1.7451, 0.2549], requires_grad=True)\n",
      "tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9193e-08)\n",
      "output:2.8892731762653057e-08\n",
      "Parameter containing:\n",
      "tensor([1.7451, 0.2549], requires_grad=True)\n",
      "tensor([0.3254, 0.6746], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6746193170547485\n",
      "Parameter containing:\n",
      "tensor([1.7495, 0.2505], requires_grad=True)\n",
      "tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.5489e-12)\n",
      "output:2.8078227676947565e-12\n",
      "Parameter containing:\n",
      "tensor([1.7495, 0.2505], requires_grad=True)\n",
      "tensor([0.6952, 0.3048], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1079e-17)\n",
      "output:3.3767810098565956e-18\n",
      "Parameter containing:\n",
      "tensor([1.7495, 0.2505], requires_grad=True)\n",
      "tensor([0.4765, 0.5235], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9910)\n",
      "output:0.518804132938385\n",
      "Parameter containing:\n",
      "tensor([1.7544, 0.2456], requires_grad=True)\n",
      "tensor([0.6194, 0.3806], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.2152e-11)\n",
      "output:1.6041164924152085e-11\n",
      "Parameter containing:\n",
      "tensor([1.7544, 0.2456], requires_grad=True)\n",
      "tensor([0.6287, 0.3713], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.6605e-12)\n",
      "output:2.4732290868079154e-12\n",
      "Parameter containing:\n",
      "tensor([1.7544, 0.2456], requires_grad=True)\n",
      "tensor([0.4501, 0.5499], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5499204397201538\n",
      "Parameter containing:\n",
      "tensor([1.7594, 0.2406], requires_grad=True)\n",
      "tensor([0.5085, 0.4915], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1542)\n",
      "output:0.07579166442155838\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.5718, 0.4282], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.8514e-07)\n",
      "output:2.505824170384585e-07\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3975e-24)\n",
      "output:7.807693617009336e-25\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.5747, 0.4253], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2196e-07)\n",
      "output:1.3691561662199092e-07\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.7510, 0.2490], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5941e-22)\n",
      "output:3.9700904958305614e-23\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.5416, 0.4584], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:0.00011269590322626755\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.7010, 0.2990], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4969e-18)\n",
      "output:1.0456689976254873e-18\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.5711, 0.4289], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.6081e-07)\n",
      "output:2.8338919833004184e-07\n",
      "Parameter containing:\n",
      "tensor([1.7602, 0.2398], requires_grad=True)\n",
      "tensor([0.4786, 0.5214], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9864)\n",
      "output:0.5142965912818909\n",
      "Parameter containing:\n",
      "tensor([1.7651, 0.2349], requires_grad=True)\n",
      "tensor([0.4396, 0.5604], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5603493452072144\n",
      "Parameter containing:\n",
      "tensor([1.7700, 0.2300], requires_grad=True)\n",
      "tensor([0.6473, 0.3527], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5907e-13)\n",
      "output:5.609589873232894e-14\n",
      "Parameter containing:\n",
      "tensor([1.7700, 0.2300], requires_grad=True)\n",
      "tensor([0.2991, 0.7009], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.7008815407752991\n",
      "Parameter containing:\n",
      "tensor([1.7742, 0.2258], requires_grad=True)\n",
      "tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0089e-28)\n",
      "output:1.7926199324390126e-29\n",
      "Parameter containing:\n",
      "tensor([1.7742, 0.2258], requires_grad=True)\n",
      "tensor([0.5152, 0.4848], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0455)\n",
      "output:0.0220388974994421\n",
      "Parameter containing:\n",
      "tensor([1.7744, 0.2256], requires_grad=True)\n",
      "tensor([0.5709, 0.4291], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9112e-07)\n",
      "output:2.96543305466912e-07\n",
      "Parameter containing:\n",
      "tensor([1.7744, 0.2256], requires_grad=True)\n",
      "tensor([0.3906, 0.6094], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6094250082969666\n",
      "Parameter containing:\n",
      "tensor([1.7792, 0.2208], requires_grad=True)\n",
      "tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5778e-14)\n",
      "output:1.9377887830593007e-14\n",
      "Parameter containing:\n",
      "tensor([1.7792, 0.2208], requires_grad=True)\n",
      "tensor([0.3927, 0.6073], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6073369979858398\n",
      "Parameter containing:\n",
      "tensor([1.7840, 0.2160], requires_grad=True)\n",
      "tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3785e-13)\n",
      "output:1.2041450193726877e-13\n",
      "Parameter containing:\n",
      "tensor([1.7840, 0.2160], requires_grad=True)\n",
      "tensor([0.6059, 0.3941], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.3029e-10)\n",
      "output:2.4838200940457966e-10\n",
      "Parameter containing:\n",
      "tensor([1.7840, 0.2160], requires_grad=True)\n",
      "tensor([0.4454, 0.5546], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5545626878738403\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.6215, 0.3785], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8021e-11)\n",
      "output:1.0606320509365386e-11\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6474e-12)\n",
      "output:6.002118832330872e-13\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.5360, 0.4640], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0008)\n",
      "output:0.00034857389982789755\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.6022, 0.3978], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3362e-09)\n",
      "output:5.315979323405884e-10\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.6823, 0.3177], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4780e-16)\n",
      "output:4.696165726537105e-17\n",
      "Parameter containing:\n",
      "tensor([1.7889, 0.2111], requires_grad=True)\n",
      "tensor([0.4761, 0.5239], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9916)\n",
      "output:0.519466757774353\n",
      "Parameter containing:\n",
      "tensor([1.7939, 0.2061], requires_grad=True)\n",
      "tensor([0.5429, 0.4571], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.635564154246822e-05\n",
      "Parameter containing:\n",
      "tensor([1.7939, 0.2061], requires_grad=True)\n",
      "tensor([0.6116, 0.3884], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0256e-10)\n",
      "output:7.867269335992688e-11\n",
      "Parameter containing:\n",
      "tensor([1.7939, 0.2061], requires_grad=True)\n",
      "tensor([0.4740, 0.5260], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9945)\n",
      "output:0.5230945348739624\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0568e-14)\n",
      "output:2.106691218499955e-14\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.6198, 0.3802], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9015e-11)\n",
      "output:1.4832288175448127e-11\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5215e-11)\n",
      "output:9.531006192609048e-12\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.5802, 0.4198], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0765e-07)\n",
      "output:4.518728857760834e-08\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.3486e-21)\n",
      "output:1.6980626551294593e-21\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.6589, 0.3411], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5806e-14)\n",
      "output:5.391657359156898e-15\n",
      "Parameter containing:\n",
      "tensor([1.7988, 0.2012], requires_grad=True)\n",
      "tensor([0.3062, 0.6938], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6938443779945374\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.6047, 0.3953], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.9987e-10)\n",
      "output:3.1616251283672625e-10\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5283, 0.4717], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0035)\n",
      "output:0.0016491287387907505\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5928, 0.4072], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.7844e-09)\n",
      "output:3.5774456730308657e-09\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.6070, 0.3930], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0530e-10)\n",
      "output:1.9856889743596895e-10\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.6161e-23)\n",
      "output:8.737504638901165e-24\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5731, 0.4269], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4420e-07)\n",
      "output:1.8961384284921223e-07\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5989, 0.4011], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5809e-09)\n",
      "output:1.035246111058541e-09\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4530e-09)\n",
      "output:1.7983597944137841e-09\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5380, 0.4620], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0005)\n",
      "output:0.00023134065850172192\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5658, 0.4342], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9091e-06)\n",
      "output:8.288585036098084e-07\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.7159, 0.2841], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7615e-19)\n",
      "output:5.00426789941793e-20\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9117e-18)\n",
      "output:2.09031828835085e-18\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.5520, 0.4480], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0348e-05)\n",
      "output:1.3595467862614896e-05\n",
      "Parameter containing:\n",
      "tensor([1.8031, 0.1969], requires_grad=True)\n",
      "tensor([0.4941, 0.5059], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.7637)\n",
      "output:0.38633397221565247\n",
      "Parameter containing:\n",
      "tensor([1.8069, 0.1931], requires_grad=True)\n",
      "tensor([0.5837, 0.4163], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.3630e-08)\n",
      "output:2.2325849613480386e-08\n",
      "Parameter containing:\n",
      "tensor([1.8069, 0.1931], requires_grad=True)\n",
      "tensor([0.4116, 0.5884], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5884386897087097\n",
      "Parameter containing:\n",
      "tensor([1.8117, 0.1883], requires_grad=True)\n",
      "tensor([0.5021, 0.4979], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3979)\n",
      "output:0.19814729690551758\n",
      "Parameter containing:\n",
      "tensor([1.8137, 0.1863], requires_grad=True)\n",
      "tensor([0.6320, 0.3680], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4509e-12)\n",
      "output:1.270078118197071e-12\n",
      "Parameter containing:\n",
      "tensor([1.8137, 0.1863], requires_grad=True)\n",
      "tensor([0.4691, 0.5309], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9979)\n",
      "output:0.5298153162002563\n",
      "Parameter containing:\n",
      "tensor([1.8187, 0.1813], requires_grad=True)\n",
      "tensor([0.6779, 0.3221], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5555e-16)\n",
      "output:1.145359274766245e-16\n",
      "Parameter containing:\n",
      "tensor([1.8187, 0.1813], requires_grad=True)\n",
      "tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0893e-11)\n",
      "output:4.0718257758587395e-12\n",
      "Parameter containing:\n",
      "tensor([1.8187, 0.1813], requires_grad=True)\n",
      "tensor([0.4856, 0.5144], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9467)\n",
      "output:0.48698917031288147\n",
      "Parameter containing:\n",
      "tensor([1.8234, 0.1766], requires_grad=True)\n",
      "tensor([0.5344, 0.4656], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0010)\n",
      "output:0.0004825603391509503\n",
      "Parameter containing:\n",
      "tensor([1.8234, 0.1766], requires_grad=True)\n",
      "tensor([0.6123, 0.3877], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7781e-10)\n",
      "output:6.894419757319525e-11\n",
      "Parameter containing:\n",
      "tensor([1.8234, 0.1766], requires_grad=True)\n",
      "tensor([0.4583, 0.5417], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5415799617767334\n",
      "Parameter containing:\n",
      "tensor([1.8284, 0.1716], requires_grad=True)\n",
      "tensor([0.6220, 0.3780], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5435e-11)\n",
      "output:9.615036197785365e-12\n",
      "Parameter containing:\n",
      "tensor([1.8284, 0.1716], requires_grad=True)\n",
      "tensor([0.5894, 0.4106], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7215e-08)\n",
      "output:7.0687056208385e-09\n",
      "Parameter containing:\n",
      "tensor([1.8284, 0.1716], requires_grad=True)\n",
      "tensor([0.6096, 0.3904], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0158e-10)\n",
      "output:1.1773544639215316e-10\n",
      "Parameter containing:\n",
      "tensor([1.8284, 0.1716], requires_grad=True)\n",
      "tensor([0.4142, 0.5858], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5857608318328857\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5824, 0.4176], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.0276e-08)\n",
      "output:2.9350612607004223e-08\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n",
      "tensor([0.6385, 0.3615], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.4188e-13)\n",
      "output:3.405323440765218e-13\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n",
      "tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1960e-13)\n",
      "output:1.138237589034738e-13\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n",
      "tensor([0.6488, 0.3512], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1955e-13)\n",
      "output:4.198740625473672e-14\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n",
      "tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.6415e-09)\n",
      "output:3.9309733246284395e-09\n",
      "Parameter containing:\n",
      "tensor([1.8333, 0.1667], requires_grad=True)\n",
      "tensor([0.4393, 0.5607], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5606775283813477\n",
      "Parameter containing:\n",
      "tensor([1.8382, 0.1618], requires_grad=True)\n",
      "tensor([0.3752, 0.6248], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6248224973678589\n",
      "Parameter containing:\n",
      "tensor([1.8429, 0.1571], requires_grad=True)\n",
      "tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8025e-14)\n",
      "output:6.160421497469586e-15\n",
      "Parameter containing:\n",
      "tensor([1.8429, 0.1571], requires_grad=True)\n",
      "tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0187e-18)\n",
      "output:2.983466244562252e-19\n",
      "Parameter containing:\n",
      "tensor([1.8429, 0.1571], requires_grad=True)\n",
      "tensor([0.5380, 0.4620], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0005)\n",
      "output:0.00022953245206736028\n",
      "Parameter containing:\n",
      "tensor([1.8429, 0.1571], requires_grad=True)\n",
      "tensor([0.4709, 0.5291], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9970)\n",
      "output:0.5275240540504456\n",
      "Parameter containing:\n",
      "tensor([1.8478, 0.1522], requires_grad=True)\n",
      "tensor([0.5016, 0.4984], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4217)\n",
      "output:0.21020309627056122\n",
      "Parameter containing:\n",
      "tensor([1.8500, 0.1500], requires_grad=True)\n",
      "tensor([0.5940, 0.4060], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.8824e-09)\n",
      "output:2.7944513369959623e-09\n",
      "Parameter containing:\n",
      "tensor([1.8500, 0.1500], requires_grad=True)\n",
      "tensor([0.5927, 0.4073], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8260e-09)\n",
      "output:3.594581965415955e-09\n",
      "Parameter containing:\n",
      "tensor([1.8500, 0.1500], requires_grad=True)\n",
      "tensor([0.4343, 0.5657], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5657075643539429\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.7335, 0.2665], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2320e-21)\n",
      "output:1.3943520649000346e-21\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6151, 0.3849], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0037e-10)\n",
      "output:3.863088668398795e-11\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6694, 0.3306], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9269e-15)\n",
      "output:6.370091162793468e-16\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6202, 0.3798], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.6246e-11)\n",
      "output:1.3766089830558048e-11\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6311, 0.3689], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.0726e-12)\n",
      "output:1.5022472198492065e-12\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.5657, 0.4343], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9484e-06)\n",
      "output:8.4612912587545e-07\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6331, 0.3669], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7571e-12)\n",
      "output:1.0116268716817145e-12\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6170, 0.3830], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.8251e-11)\n",
      "output:2.6137404740556036e-11\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9279e-14)\n",
      "output:1.3577036054397609e-14\n",
      "Parameter containing:\n",
      "tensor([1.8549, 0.1451], requires_grad=True)\n",
      "tensor([0.4727, 0.5273], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9957)\n",
      "output:0.5250096917152405\n",
      "Parameter containing:\n",
      "tensor([1.8598, 0.1402], requires_grad=True)\n",
      "tensor([0.4694, 0.5306], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9978)\n",
      "output:0.529491662979126\n",
      "Parameter containing:\n",
      "tensor([1.8648, 0.1352], requires_grad=True)\n",
      "tensor([0.6212, 0.3788], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.9514e-11)\n",
      "output:1.1178860788441103e-11\n",
      "Parameter containing:\n",
      "tensor([1.8648, 0.1352], requires_grad=True)\n",
      "tensor([0.5845, 0.4155], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.5491e-08)\n",
      "output:1.890018630490431e-08\n",
      "Parameter containing:\n",
      "tensor([1.8648, 0.1352], requires_grad=True)\n",
      "tensor([0.5525, 0.4475], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7424e-05)\n",
      "output:1.2271659215912223e-05\n",
      "Parameter containing:\n",
      "tensor([1.8648, 0.1352], requires_grad=True)\n",
      "tensor([0.5076, 0.4924], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1784)\n",
      "output:0.087825708091259\n",
      "Parameter containing:\n",
      "tensor([1.8657, 0.1343], requires_grad=True)\n",
      "tensor([0.4026, 0.5974], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5973718166351318\n",
      "Parameter containing:\n",
      "tensor([1.8705, 0.1295], requires_grad=True)\n",
      "tensor([0.5630, 0.4370], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3760e-06)\n",
      "output:1.4753500181541312e-06\n",
      "Parameter containing:\n",
      "tensor([1.8705, 0.1295], requires_grad=True)\n",
      "tensor([0.4134, 0.5866], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.586571216583252\n",
      "Parameter containing:\n",
      "tensor([1.8754, 0.1246], requires_grad=True)\n",
      "tensor([0.4720, 0.5280], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9963)\n",
      "output:0.5259944200515747\n",
      "Parameter containing:\n",
      "tensor([1.8803, 0.1197], requires_grad=True)\n",
      "tensor([0.5705, 0.4295], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.5725e-07)\n",
      "output:3.252622775562486e-07\n",
      "Parameter containing:\n",
      "tensor([1.8803, 0.1197], requires_grad=True)\n",
      "tensor([0.4647, 0.5353], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9991)\n",
      "output:0.5347982048988342\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.6757, 0.3243], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5068e-16)\n",
      "output:1.7859857775957393e-16\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.5948, 0.4052], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.8724e-09)\n",
      "output:2.379691776965842e-09\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.7360, 0.2640], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1417e-21)\n",
      "output:8.29269415255857e-22\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.5654, 0.4346], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0779e-06)\n",
      "output:9.030134151544189e-07\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.6503, 0.3497], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8373e-14)\n",
      "output:3.0905355721420544e-14\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3537e-13)\n",
      "output:1.1952048237836438e-13\n",
      "Parameter containing:\n",
      "tensor([1.8853, 0.1147], requires_grad=True)\n",
      "tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5955069065093994\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5536e-17)\n",
      "output:4.761424486603251e-18\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.7464, 0.2536], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9887e-22)\n",
      "output:1.0116732795054934e-22\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.6335, 0.3665], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5509e-12)\n",
      "output:9.349872221939282e-13\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.5818, 0.4182], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.8959e-08)\n",
      "output:3.3022800494109106e-08\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.7716, 0.2284], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5765e-24)\n",
      "output:5.885345101131803e-25\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.5243, 0.4757], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0077)\n",
      "output:0.0036782987881451845\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.6543, 0.3457], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9888e-14)\n",
      "output:1.379070519754019e-14\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.7475, 0.2525], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1855e-22)\n",
      "output:8.043653036699704e-23\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.6709, 0.3291], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4373e-15)\n",
      "output:4.730568896132124e-16\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.6522, 0.3478], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0159e-14)\n",
      "output:2.0922593017380468e-14\n",
      "Parameter containing:\n",
      "tensor([1.8901, 0.1099], requires_grad=True)\n",
      "tensor([0.5094, 0.4906], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1335)\n",
      "output:0.06550305336713791\n",
      "Parameter containing:\n",
      "tensor([1.8908, 0.1092], requires_grad=True)\n",
      "tensor([0.5984, 0.4016], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8292e-09)\n",
      "output:1.1361784846286582e-09\n",
      "Parameter containing:\n",
      "tensor([1.8908, 0.1092], requires_grad=True)\n",
      "tensor([0.7438, 0.2562], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7279e-22)\n",
      "output:1.7240016133834766e-22\n",
      "Parameter containing:\n",
      "tensor([1.8908, 0.1092], requires_grad=True)\n",
      "tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6623e-08)\n",
      "output:1.0989587018173097e-08\n",
      "Parameter containing:\n",
      "tensor([1.8908, 0.1092], requires_grad=True)\n",
      "tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0134)\n",
      "output:0.006389284040778875\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.5455, 0.4545], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:5.0683844165178016e-05\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.5534, 0.4466], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3124e-05)\n",
      "output:1.0327886229788419e-05\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.6360, 0.3640], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5531e-12)\n",
      "output:5.654181007945513e-13\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.7465, 0.2535], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8973e-22)\n",
      "output:9.880426039907997e-23\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.6353, 0.3647], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7653e-12)\n",
      "output:6.43777403348117e-13\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.5674, 0.4326], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3913e-06)\n",
      "output:6.018356657477852e-07\n",
      "Parameter containing:\n",
      "tensor([1.8909, 0.1091], requires_grad=True)\n",
      "tensor([0.4788, 0.5212], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9859)\n",
      "output:0.5138792395591736\n",
      "Parameter containing:\n",
      "tensor([1.8958, 0.1042], requires_grad=True)\n",
      "tensor([0.5870, 0.4130], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7627e-08)\n",
      "output:1.1409287736796614e-08\n",
      "Parameter containing:\n",
      "tensor([1.8958, 0.1042], requires_grad=True)\n",
      "tensor([0.6033, 0.3967], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0751e-09)\n",
      "output:4.2652234522044807e-10\n",
      "Parameter containing:\n",
      "tensor([1.8958, 0.1042], requires_grad=True)\n",
      "tensor([0.8065, 0.1935], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4006e-27)\n",
      "output:4.645872656596719e-28\n",
      "Parameter containing:\n",
      "tensor([1.8958, 0.1042], requires_grad=True)\n",
      "tensor([0.4243, 0.5757], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5757297277450562\n",
      "Parameter containing:\n",
      "tensor([1.9007, 0.0993], requires_grad=True)\n",
      "tensor([0.4246, 0.5754], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5753951072692871\n",
      "Parameter containing:\n",
      "tensor([1.9056, 0.0944], requires_grad=True)\n",
      "tensor([0.5198, 0.4802], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0185)\n",
      "output:0.008897948078811169\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.5625, 0.4375], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.7631e-06)\n",
      "output:1.6465437511214986e-06\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8865e-05)\n",
      "output:1.745900954119861e-05\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.7031, 0.2969], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2665e-18)\n",
      "output:6.728397220925373e-19\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.6567, 0.3433], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4729e-14)\n",
      "output:8.490576101081223e-15\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.6814, 0.3186], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7364e-16)\n",
      "output:5.5311946287420357e-17\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.5874, 0.4126], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5825e-08)\n",
      "output:1.065648991271928e-08\n",
      "Parameter containing:\n",
      "tensor([1.9057, 0.0943], requires_grad=True)\n",
      "tensor([0.4981, 0.5019], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5925)\n",
      "output:0.29735425114631653\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.7700, 0.2300], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5211e-24)\n",
      "output:8.098013658615233e-25\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.6127, 0.3873], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6111e-10)\n",
      "output:6.238954491921689e-11\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.5875, 0.4125], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5137e-08)\n",
      "output:1.0368996328224966e-08\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.5718, 0.4282], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.8085e-07)\n",
      "output:2.4872247195162345e-07\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3040e-13)\n",
      "output:4.5856652757794367e-14\n",
      "Parameter containing:\n",
      "tensor([1.9086, 0.0914], requires_grad=True)\n",
      "tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2015)\n",
      "output:0.09935297816991806\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.5704, 0.4296], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.6210e-07)\n",
      "output:3.2737247579461837e-07\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.5946, 0.4054], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0393e-09)\n",
      "output:2.448166558366438e-09\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.5966, 0.4034], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.0485e-09)\n",
      "output:1.6330665708608194e-09\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.5519, 0.4481], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0886e-05)\n",
      "output:1.3839337952958886e-05\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.5939, 0.4061], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.0087e-09)\n",
      "output:2.846369584474928e-09\n",
      "Parameter containing:\n",
      "tensor([1.9096, 0.0904], requires_grad=True)\n",
      "tensor([0.4577, 0.5423], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9998)\n",
      "output:0.5422069430351257\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4657e-09)\n",
      "output:1.803555416124425e-09\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.7533, 0.2467], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0035e-22)\n",
      "output:2.4760360618571835e-23\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.6651, 0.3349], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.5914e-15)\n",
      "output:1.5377843982128012e-15\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.6338, 0.3662], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3809e-12)\n",
      "output:8.718554849428128e-13\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.5669, 0.4331], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5391e-06)\n",
      "output:6.665500791314116e-07\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.6228, 0.3772], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1564e-11)\n",
      "output:8.13386337450428e-12\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.7114, 0.2886], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3223e-19)\n",
      "output:1.2472971153686435e-19\n",
      "Parameter containing:\n",
      "tensor([1.9146, 0.0854], requires_grad=True)\n",
      "tensor([0.4647, 0.5353], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9991)\n",
      "output:0.5348280072212219\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.5718, 0.4282], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7565e-07)\n",
      "output:2.464688293457584e-07\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.6156, 0.3844], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.0926e-11)\n",
      "output:3.49516353359558e-11\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.5432, 0.4568], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.127902401611209e-05\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.5465, 0.4535], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.1048e-05)\n",
      "output:4.128848740947433e-05\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.6055, 0.3945], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.8216e-10)\n",
      "output:2.6909252603957157e-10\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.7534, 0.2466], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.8026e-23)\n",
      "output:2.4174733948362912e-23\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.5871, 0.4129], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7365e-08)\n",
      "output:1.1299737145975541e-08\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.6185, 0.3815], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.1003e-11)\n",
      "output:1.9457975161674135e-11\n",
      "Parameter containing:\n",
      "tensor([1.9196, 0.0804], requires_grad=True)\n",
      "tensor([0.5161, 0.4839], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0387)\n",
      "output:0.018746420741081238\n",
      "Parameter containing:\n",
      "tensor([1.9198, 0.0802], requires_grad=True)\n",
      "tensor([0.6477, 0.3523], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4761e-13)\n",
      "output:5.2000399564664304e-14\n",
      "Parameter containing:\n",
      "tensor([1.9198, 0.0802], requires_grad=True)\n",
      "tensor([0.4994, 0.5006], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5299)\n",
      "output:0.26528850197792053\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5336, 0.4664], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0012)\n",
      "output:0.0005624316399917006\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5919, 0.4081], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0507e-08)\n",
      "output:4.2885197615305515e-09\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5691, 0.4309], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.8840e-07)\n",
      "output:4.2586583504089504e-07\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6249, 0.3751], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4183e-11)\n",
      "output:5.3199398011849475e-12\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6228, 0.3772], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1530e-11)\n",
      "output:8.12085901996662e-12\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5433, 0.4567], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:7.913153240224347e-05\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5803, 0.4197], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0625e-07)\n",
      "output:4.4595267922886705e-08\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6622, 0.3378], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.1285e-15)\n",
      "output:2.7456655570960503e-15\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5650, 0.4350], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2601e-06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:9.83155814537895e-07\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1817e-07)\n",
      "output:1.3528566000786668e-07\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6423, 0.3577], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3560e-13)\n",
      "output:1.5580973197846376e-13\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5309, 0.4691], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0020)\n",
      "output:0.0009607233805581927\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6206, 0.3794], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3460e-11)\n",
      "output:1.2694489556763777e-11\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6141, 0.3859], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2326e-10)\n",
      "output:4.7567796923608796e-11\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.7128, 0.2872], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2768e-19)\n",
      "output:9.410502310535921e-20\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.6555, 0.3445], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1336e-14)\n",
      "output:1.07961006806526e-14\n",
      "Parameter containing:\n",
      "tensor([1.9224, 0.0776], requires_grad=True)\n",
      "tensor([0.5263, 0.4737], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0052)\n",
      "output:0.002448957646265626\n",
      "Parameter containing:\n",
      "tensor([1.9225, 0.0775], requires_grad=True)\n",
      "tensor([0.6024, 0.3976], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2740e-09)\n",
      "output:5.065551311744798e-10\n",
      "Parameter containing:\n",
      "tensor([1.9225, 0.0775], requires_grad=True)\n",
      "tensor([0.4738, 0.5262], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9947)\n",
      "output:0.5234187841415405\n",
      "Parameter containing:\n",
      "tensor([1.9274, 0.0726], requires_grad=True)\n",
      "tensor([0.5041, 0.4959], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3045)\n",
      "output:0.15100935101509094\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.6287, 0.3713], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.6487e-12)\n",
      "output:2.4687680285490066e-12\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0255e-12)\n",
      "output:3.711875099822459e-13\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.7087, 0.2913], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.4654e-19)\n",
      "output:2.17470513479319e-19\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.5482, 0.4518], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.4606e-05)\n",
      "output:2.91865744657116e-05\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.5359, 0.4641], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0008)\n",
      "output:0.00035165014560334384\n",
      "Parameter containing:\n",
      "tensor([1.9289, 0.0711], requires_grad=True)\n",
      "tensor([0.4870, 0.5130], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9314)\n",
      "output:0.4778187870979309\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5710, 0.4290], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7997e-07)\n",
      "output:2.917009567227069e-07\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6114, 0.3886], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0903e-10)\n",
      "output:8.122087724604654e-11\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6343, 0.3657], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1441e-12)\n",
      "output:7.839915240441531e-13\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5923, 0.4077], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.6252e-09)\n",
      "output:3.924254698972618e-09\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.7412, 0.2588], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1296e-21)\n",
      "output:2.9237802903518583e-22\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6374, 0.3626], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1592e-12)\n",
      "output:4.2030983728180704e-13\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5598, 0.4402], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.4445e-06)\n",
      "output:2.837130978150526e-06\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5843, 0.4157], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7958e-08)\n",
      "output:1.993780429643266e-08\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9034e-08)\n",
      "output:1.6187730267347433e-08\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6576, 0.3424], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0382e-14)\n",
      "output:6.97830973507476e-15\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6321, 0.3679], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3662e-12)\n",
      "output:1.2384814311247605e-12\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5373, 0.4627], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0006)\n",
      "output:0.00026617530966177583\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.6177, 0.3823], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.9394e-11)\n",
      "output:2.2704314123211944e-11\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.5606, 0.4394], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.4070e-06)\n",
      "output:2.3756454083923018e-06\n",
      "Parameter containing:\n",
      "tensor([1.9336, 0.0664], requires_grad=True)\n",
      "tensor([0.4132, 0.5868], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5867999196052551\n",
      "Parameter containing:\n",
      "tensor([1.9385, 0.0615], requires_grad=True)\n",
      "tensor([0.6251, 0.3749], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3678e-11)\n",
      "output:5.128259362302545e-12\n",
      "Parameter containing:\n",
      "tensor([1.9385, 0.0615], requires_grad=True)\n",
      "tensor([0.6002, 0.3998], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9824e-09)\n",
      "output:7.925844980327668e-10\n",
      "Parameter containing:\n",
      "tensor([1.9385, 0.0615], requires_grad=True)\n",
      "tensor([0.6425, 0.3575], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1957e-13)\n",
      "output:1.499983947814143e-13\n",
      "Parameter containing:\n",
      "tensor([1.9385, 0.0615], requires_grad=True)\n",
      "tensor([0.4916, 0.5084], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.8416)\n",
      "output:0.4278402030467987\n",
      "Parameter containing:\n",
      "tensor([1.9427, 0.0573], requires_grad=True)\n",
      "tensor([0.4977, 0.5023], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.6129)\n",
      "output:0.30787569284439087\n",
      "Parameter containing:\n",
      "tensor([1.9457, 0.0543], requires_grad=True)\n",
      "tensor([0.6242, 0.3758], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6300e-11)\n",
      "output:6.1255570928120395e-12\n",
      "Parameter containing:\n",
      "tensor([1.9457, 0.0543], requires_grad=True)\n",
      "tensor([0.5106, 0.4894], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1081)\n",
      "output:0.052901741117239\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5425, 0.4575], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:9.223353845300153e-05\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.6526, 0.3474], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.6057e-14)\n",
      "output:1.9476328305657008e-14\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.6380, 0.3620], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0285e-12)\n",
      "output:3.723167336499439e-13\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5720, 0.4280], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5511e-07)\n",
      "output:2.3757536382618127e-07\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.6435, 0.3565], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4205e-13)\n",
      "output:1.2193597639844483e-13\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5692, 0.4308], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.7363e-07)\n",
      "output:4.1942723782995017e-07\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5289, 0.4711], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0031)\n",
      "output:0.0014612285885959864\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5913, 0.4087], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1695e-08)\n",
      "output:4.779569184876209e-09\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5559, 0.4441], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3933e-05)\n",
      "output:6.187453436723445e-06\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5723, 0.4277], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2653e-07)\n",
      "output:2.2520687537053163e-07\n",
      "Parameter containing:\n",
      "tensor([1.9463, 0.0537], requires_grad=True)\n",
      "tensor([0.5126, 0.4874], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0749)\n",
      "output:0.0364951528608799\n",
      "Parameter containing:\n",
      "tensor([1.9467, 0.0533], requires_grad=True)\n",
      "tensor([0.4492, 0.5508], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5508285164833069\n",
      "Parameter containing:\n",
      "tensor([1.9516, 0.0484], requires_grad=True)\n",
      "tensor([0.4438, 0.5562], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5562098026275635\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.6506, 0.3494], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.3251e-14)\n",
      "output:2.908911379459998e-14\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.5846, 0.4154], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4562e-08)\n",
      "output:1.850964004290745e-08\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.6099, 0.3901], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8697e-10)\n",
      "output:1.1195942090092004e-10\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.6629, 0.3371], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.0245e-15)\n",
      "output:2.3676248000993258e-15\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.6513, 0.3487], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.1522e-14)\n",
      "output:2.4936516135960936e-14\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7939e-08)\n",
      "output:2.414209276935253e-08\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.5777, 0.4223], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7835e-07)\n",
      "output:7.531715340292067e-08\n",
      "Parameter containing:\n",
      "tensor([1.9565, 0.0435], requires_grad=True)\n",
      "tensor([0.4445, 0.5555], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5554731488227844\n",
      "Parameter containing:\n",
      "tensor([1.9615, 0.0385], requires_grad=True)\n",
      "tensor([0.5875, 0.4125], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5299e-08)\n",
      "output:1.0436894015697362e-08\n",
      "Parameter containing:\n",
      "tensor([1.9615, 0.0385], requires_grad=True)\n",
      "tensor([0.4523, 0.5477], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5476898550987244\n",
      "Parameter containing:\n",
      "tensor([1.9664, 0.0336], requires_grad=True)\n",
      "tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4393)\n",
      "output:0.2191092073917389\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6769, 0.3231], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3099e-16)\n",
      "output:1.3925289150798682e-16\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.7996, 0.2004], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.4234e-27)\n",
      "output:1.8881310655197086e-27\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6685, 0.3315], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3117e-15)\n",
      "output:7.663334184518638e-16\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6379, 0.3621], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0472e-12)\n",
      "output:3.791674277071194e-13\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6188, 0.3812], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7558e-11)\n",
      "output:1.8127050208094353e-11\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.7593, 0.2407], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0234e-23)\n",
      "output:7.278299713137735e-24\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.7842, 0.2158], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0523e-25)\n",
      "output:4.4282879477904515e-26\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6076, 0.3924], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4689e-10)\n",
      "output:1.75339687213949e-10\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6289, 0.3711], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.3925e-12)\n",
      "output:2.3723779017659208e-12\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.5905, 0.4095], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3715e-08)\n",
      "output:5.615896192523451e-09\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6924, 0.3076], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9304e-17)\n",
      "output:5.937160397722342e-18\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6180, 0.3820], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.6138e-11)\n",
      "output:2.144376690105254e-11\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.5344, 0.4656], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0010)\n",
      "output:0.00048013715422712266\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6901, 0.3099], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0747e-17)\n",
      "output:9.528517641944328e-18\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.5499, 0.4501], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6765e-05)\n",
      "output:2.105101702909451e-05\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.5366, 0.4634], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0007)\n",
      "output:0.0003067356301471591\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6553, 0.3447], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2408e-14)\n",
      "output:1.1171125365082388e-14\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.6124, 0.3876], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7426e-10)\n",
      "output:6.755176973349819e-11\n",
      "Parameter containing:\n",
      "tensor([1.9686, 0.0314], requires_grad=True)\n",
      "tensor([0.5102, 0.4898], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1160)\n",
      "output:0.05683524161577225\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.6355, 0.3645], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7037e-12)\n",
      "output:6.210317633412177e-13\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.5925, 0.4075], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.2417e-09)\n",
      "output:3.766005729488597e-09\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.5665, 0.4335], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6708e-06)\n",
      "output:7.242637707349786e-07\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.6127, 0.3873], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6164e-10)\n",
      "output:6.259757295845603e-11\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.6084, 0.3916], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8296e-10)\n",
      "output:1.4995985009313983e-10\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.6619, 0.3381], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.7425e-15)\n",
      "output:2.9562438770141e-15\n",
      "Parameter containing:\n",
      "tensor([1.9692, 0.0308], requires_grad=True)\n",
      "tensor([0.4979, 0.5021], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.6020)\n",
      "output:0.3022378087043762\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5899, 0.4101], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5674e-08)\n",
      "output:6.428732657326464e-09\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.6020, 0.3980], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3720e-09)\n",
      "output:5.460125129808091e-10\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.7071, 0.2929], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0181e-18)\n",
      "output:2.9815218531348694e-19\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5609, 0.4391], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.1272e-06)\n",
      "output:2.2513236217491794e-06\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.6523, 0.3477], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.8554e-14)\n",
      "output:2.0356695387517554e-14\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5362, 0.4638], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0007)\n",
      "output:0.00032940521487034857\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.8152e-08)\n",
      "output:2.4231825435094834e-08\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5538, 0.4462], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1151e-05)\n",
      "output:9.437335393158719e-06\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.6433, 0.3567], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5557e-13)\n",
      "output:1.2682331584652068e-13\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.7467, 0.2533], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.7301e-22)\n",
      "output:9.448243859817234e-23\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.7005, 0.2995], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8225e-18)\n",
      "output:1.1447422807473417e-18\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5835, 0.4165], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5801e-08)\n",
      "output:2.3240675162128355e-08\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5580, 0.4420], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.1098e-06)\n",
      "output:4.026263468404068e-06\n",
      "Parameter containing:\n",
      "tensor([1.9722, 0.0278], requires_grad=True)\n",
      "tensor([0.5021, 0.4979], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3949)\n",
      "output:0.1966150403022766\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.6241, 0.3759], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6774e-11)\n",
      "output:6.306130530958631e-12\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2423e-19)\n",
      "output:6.396992866125743e-20\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.7175, 0.2825], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2726e-19)\n",
      "output:3.5946173956606044e-20\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.5998, 0.4002], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1240e-09)\n",
      "output:8.499039250153828e-10\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.6923, 0.3077], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9674e-17)\n",
      "output:6.052849464603702e-18\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.5670, 0.4330], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5136e-06)\n",
      "output:6.553861453539866e-07\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.6377, 0.3623], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1021e-12)\n",
      "output:3.9933879228577773e-13\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.5466, 0.4534], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8974e-05)\n",
      "output:4.033763980260119e-05\n",
      "Parameter containing:\n",
      "tensor([1.9742, 0.0258], requires_grad=True)\n",
      "tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.4401)\n",
      "output:0.2195427268743515\n",
      "Parameter containing:\n",
      "tensor([1.9764, 0.0236], requires_grad=True)\n",
      "tensor([0.4846, 0.5154], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9564)\n",
      "output:0.4929388463497162\n",
      "Parameter containing:\n",
      "tensor([1.9812, 0.0188], requires_grad=True)\n",
      "tensor([0.5820, 0.4180], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.5759e-08)\n",
      "output:3.166877959870362e-08\n",
      "Parameter containing:\n",
      "tensor([1.9812, 0.0188], requires_grad=True)\n",
      "tensor([0.6262, 0.3738], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0857e-11)\n",
      "output:4.05817870627323e-12\n",
      "Parameter containing:\n",
      "tensor([1.9812, 0.0188], requires_grad=True)\n",
      "tensor([0.5205, 0.4795], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0163)\n",
      "output:0.007831042632460594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1.9813, 0.0187], requires_grad=True)\n",
      "tensor([0.5355, 0.4645], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0008)\n",
      "output:0.0003844588645733893\n",
      "Parameter containing:\n",
      "tensor([1.9813, 0.0187], requires_grad=True)\n",
      "tensor([0.6782, 0.3218], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3077e-16)\n",
      "output:1.0643263458548353e-16\n",
      "Parameter containing:\n",
      "tensor([1.9813, 0.0187], requires_grad=True)\n",
      "tensor([0.4862, 0.5138], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9403)\n",
      "output:0.4831135869026184\n",
      "Parameter containing:\n",
      "tensor([1.9860, 0.0140], requires_grad=True)\n",
      "tensor([0.5253, 0.4747], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0062)\n",
      "output:0.0029665788169950247\n",
      "Parameter containing:\n",
      "tensor([1.9860, 0.0140], requires_grad=True)\n",
      "tensor([0.6876, 0.3124], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0525e-17)\n",
      "output:1.5782864167862885e-17\n",
      "Parameter containing:\n",
      "tensor([1.9860, 0.0140], requires_grad=True)\n",
      "tensor([0.4987, 0.5013], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5651)\n",
      "output:0.2832796573638916\n",
      "Parameter containing:\n",
      "tensor([1.9888, 0.0112], requires_grad=True)\n",
      "tensor([0.6232, 0.3768], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0071e-11)\n",
      "output:7.563542674116075e-12\n",
      "Parameter containing:\n",
      "tensor([1.9888, 0.0112], requires_grad=True)\n",
      "tensor([0.5050, 0.4950], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2674)\n",
      "output:0.13236647844314575\n",
      "Parameter containing:\n",
      "tensor([1.9902, 0.0098], requires_grad=True)\n",
      "tensor([0.5077, 0.4923], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1755)\n",
      "output:0.08638967573642731\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5777, 0.4223], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7957e-07)\n",
      "output:7.58390399369091e-08\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.6400, 0.3600], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.9462e-13)\n",
      "output:2.5007876628888037e-13\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5416, 0.4584], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:0.00011223822366446257\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5405, 0.4595], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00014052577898837626\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5656, 0.4344], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0034e-06)\n",
      "output:8.702485843059549e-07\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5770, 0.4230], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0458e-07)\n",
      "output:8.653431393668143e-08\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.6237, 0.3763], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8102e-11)\n",
      "output:6.812365775654694e-12\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.6378, 0.3622], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0817e-12)\n",
      "output:3.918342430034305e-13\n",
      "Parameter containing:\n",
      "tensor([1.9910, 0.0090], requires_grad=True)\n",
      "tensor([0.5213, 0.4787], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0139)\n",
      "output:0.0066471826285123825\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.5268, 0.4732], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0046)\n",
      "output:0.0021992202382534742\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.5719, 0.4281], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7321e-07)\n",
      "output:2.454122238759737e-07\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.6133, 0.3867], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4322e-10)\n",
      "output:5.537691832868674e-11\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8701e-10)\n",
      "output:7.256033274227747e-11\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.5851, 0.4149], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.0685e-08)\n",
      "output:1.6880797204521514e-08\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.6369, 0.3631], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2795e-12)\n",
      "output:4.645742883273296e-13\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.6657, 0.3343], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.0272e-15)\n",
      "output:1.3461921100492197e-15\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.5814, 0.4186], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.5716e-08)\n",
      "output:3.5883839899497616e-08\n",
      "Parameter containing:\n",
      "tensor([1.9911, 0.0089], requires_grad=True)\n",
      "tensor([0.5215, 0.4785], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0134)\n",
      "output:0.006399182602763176\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.6614, 0.3386], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.6280e-15)\n",
      "output:3.2603234111224736e-15\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.7577, 0.2423], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1459e-23)\n",
      "output:1.0046097874057083e-23\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.6794, 0.3206], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6109e-16)\n",
      "output:8.370249882846948e-17\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8385e-07)\n",
      "output:3.8032717952773964e-07\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.5472, 0.4528], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.8844e-05)\n",
      "output:3.5697277780855075e-05\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.7085, 0.2915], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.7857e-19)\n",
      "output:2.2696665030900434e-19\n",
      "Parameter containing:\n",
      "tensor([1.9912, 0.0088], requires_grad=True)\n",
      "tensor([0.4810, 0.5190], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9781)\n",
      "output:0.5076157450675964\n",
      "Parameter containing:\n",
      "tensor([1.9961, 0.0039], requires_grad=True)\n",
      "tensor([0.6932, 0.3068], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.6448e-17)\n",
      "output:5.0458625343484915e-18\n",
      "Parameter containing:\n",
      "tensor([1.9961, 0.0039], requires_grad=True)\n",
      "tensor([0.5556, 0.4444], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4867e-05)\n",
      "output:6.607176601391984e-06\n",
      "Parameter containing:\n",
      "tensor([1.9961, 0.0039], requires_grad=True)\n",
      "tensor([0.4520, 0.5480], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5479525327682495\n",
      "Parameter containing:\n",
      "tensor([ 2.0010e+00, -1.0367e-03], requires_grad=True)\n",
      "tensor([0.4980, 0.5020], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.5998)\n",
      "output:0.30111056566238403\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5734, 0.4266], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1943e-07)\n",
      "output:1.789177304090117e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6483, 0.3517], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3272e-13)\n",
      "output:4.6682967279158827e-14\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6282, 0.3718], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.3631e-12)\n",
      "output:2.7377947998952212e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6803, 0.3197], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1923e-16)\n",
      "output:7.009138743269722e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6582, 0.3418], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8020e-14)\n",
      "output:6.158407253121015e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5644, 0.4356], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5383e-06)\n",
      "output:1.1056210951210232e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2206e-29)\n",
      "output:5.538519744803244e-30\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5505, 0.4495], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1427e-05)\n",
      "output:1.862327553681098e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6630, 0.3370], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.0175e-15)\n",
      "output:2.36524273169341e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5298, 0.4702], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0026)\n",
      "output:0.001200770027935505\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8537e-10)\n",
      "output:7.191404416406755e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5542, 0.4458], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9622e-05)\n",
      "output:8.747576430323534e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6631, 0.3369], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.7723e-15)\n",
      "output:2.2813714350804204e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.7211, 0.2789], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.2424e-20)\n",
      "output:1.7410019319224494e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6291, 0.3709], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.0721e-12)\n",
      "output:2.251907644731932e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6855, 0.3145], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.7092e-17)\n",
      "output:2.4244754743796622e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6981, 0.3019], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.2125e-18)\n",
      "output:1.8755472529512036e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.6341, 0.3659], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2427e-12)\n",
      "output:8.205562965213353e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0040, -0.0040], requires_grad=True)\n",
      "tensor([0.5281, 0.4719], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0036)\n",
      "output:0.0017183320596814156\n",
      "Parameter containing:\n",
      "tensor([ 2.0041, -0.0041], requires_grad=True)\n",
      "tensor([0.5695, 0.4305], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.2729e-07)\n",
      "output:3.9923961026033794e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0041, -0.0041], requires_grad=True)\n",
      "tensor([0.4512, 0.5488], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9999)\n",
      "output:0.5487554669380188\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.6247, 0.3753], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4887e-11)\n",
      "output:5.5877871774079324e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.7386, 0.2614], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8966e-21)\n",
      "output:4.958271245143083e-22\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8966e-11)\n",
      "output:7.141936781557279e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.6386, 0.3614], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.1576e-13)\n",
      "output:3.309592996793981e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.6249, 0.3751], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4181e-11)\n",
      "output:5.319168282919007e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.6715, 0.3285], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2683e-15)\n",
      "output:4.166284281698578e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0090, -0.0090], requires_grad=True)\n",
      "tensor([0.4857, 0.5143], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9456)\n",
      "output:0.48632633686065674\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2794e-14)\n",
      "output:7.816774097034636e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.6146, 0.3854], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1081e-10)\n",
      "output:4.270553702334645e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.6609, 0.3391], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0663e-14)\n",
      "output:3.616192021933633e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.6283, 0.3717], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.1091e-12)\n",
      "output:2.6421252338759693e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.5854, 0.4146], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8036e-08)\n",
      "output:1.5768865324616854e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.5324, 0.4676], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0015)\n",
      "output:0.0007166268769651651\n",
      "Parameter containing:\n",
      "tensor([ 2.0138, -0.0138], requires_grad=True)\n",
      "tensor([0.5147, 0.4853], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0504)\n",
      "output:0.024440305307507515\n",
      "Parameter containing:\n",
      "tensor([ 2.0140, -0.0140], requires_grad=True)\n",
      "tensor([0.5862, 0.4138], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.2466e-08)\n",
      "output:1.3434060974759632e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0140, -0.0140], requires_grad=True)\n",
      "tensor([0.5257, 0.4743], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0058)\n",
      "output:0.0027364445850253105\n",
      "Parameter containing:\n",
      "tensor([ 2.0140, -0.0140], requires_grad=True)\n",
      "tensor([0.5147, 0.4853], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0502)\n",
      "output:0.024363990873098373\n",
      "Parameter containing:\n",
      "tensor([ 2.0143, -0.0143], requires_grad=True)\n",
      "tensor([0.5891, 0.4109], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8242e-08)\n",
      "output:7.49586170911698e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0143, -0.0143], requires_grad=True)\n",
      "tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.2478e-09)\n",
      "output:1.7144713426731073e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0143, -0.0143], requires_grad=True)\n",
      "tensor([0.5150, 0.4850], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0473)\n",
      "output:0.022960131987929344\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.5466, 0.4534], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.0168e-05)\n",
      "output:4.088480636710301e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.7580, 0.2420], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8825e-23)\n",
      "output:9.395035191760077e-24\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8014e-09)\n",
      "output:7.193307061115206e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.6329, 0.3671], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8736e-12)\n",
      "output:1.0549483378877178e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.5524, 0.4476], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8269e-05)\n",
      "output:1.2653906196646858e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.6033e-18)\n",
      "output:2.9201496011768038e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.7016, 0.2984], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.0664e-18)\n",
      "output:9.149325848235985e-19\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0766e-16)\n",
      "output:3.403652013414411e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0145, -0.0145], requires_grad=True)\n",
      "tensor([0.4682, 0.5318], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9983)\n",
      "output:0.5309268236160278\n",
      "Parameter containing:\n",
      "tensor([ 2.0195, -0.0195], requires_grad=True)\n",
      "tensor([0.6621, 0.3379], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.2469e-15)\n",
      "output:2.7862566464778972e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0195, -0.0195], requires_grad=True)\n",
      "tensor([0.7010, 0.2990], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4595e-18)\n",
      "output:1.0343023986356665e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0195, -0.0195], requires_grad=True)\n",
      "tensor([0.5207, 0.4793], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0155)\n",
      "output:0.007445344235748053\n",
      "Parameter containing:\n",
      "tensor([ 2.0196, -0.0196], requires_grad=True)\n",
      "tensor([0.6873, 0.3127], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.3433e-17)\n",
      "output:1.6706363345302812e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0196, -0.0196], requires_grad=True)\n",
      "tensor([0.4237, 0.5763], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5762591361999512\n",
      "Parameter containing:\n",
      "tensor([ 2.0245, -0.0245], requires_grad=True)\n",
      "tensor([0.5560, 0.4440], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3800e-05)\n",
      "output:6.1277023633010685e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0245, -0.0245], requires_grad=True)\n",
      "tensor([0.4368, 0.5632], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0000)\n",
      "output:0.5631851553916931\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5571, 0.4429], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0951e-05)\n",
      "output:4.850146979151759e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.6913, 0.3087], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.4089e-17)\n",
      "output:7.435714296238215e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5974, 0.4026], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4681e-09)\n",
      "output:1.3962667688716124e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5832, 0.4168], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.9660e-08)\n",
      "output:2.4867814474305305e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.6025, 0.3975], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2505e-09)\n",
      "output:4.970788225477918e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5922, 0.4078], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.8641e-09)\n",
      "output:4.022871813447182e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5753, 0.4247], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8999e-07)\n",
      "output:1.2316733943862346e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5846, 0.4154], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4524e-08)\n",
      "output:1.84936777003486e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5963, 0.4037], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.3001e-09)\n",
      "output:1.7358642301346094e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.6854, 0.3146], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.9506e-17)\n",
      "output:2.5016123826059472e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.7218, 0.2782], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.4680e-20)\n",
      "output:1.5213859639657607e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.6199, 0.3801], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8153e-11)\n",
      "output:1.4500195315292341e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5558, 0.4442], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4148e-05)\n",
      "output:6.284007668000413e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0294, -0.0294], requires_grad=True)\n",
      "tensor([0.5165, 0.4835], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0356)\n",
      "output:0.0171988345682621\n",
      "Parameter containing:\n",
      "tensor([ 2.0295, -0.0295], requires_grad=True)\n",
      "tensor([0.5748, 0.4252], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1542e-07)\n",
      "output:1.3409976418188307e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0295, -0.0295], requires_grad=True)\n",
      "tensor([0.6280, 0.3720], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.6627e-12)\n",
      "output:2.8507424285756366e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0295, -0.0295], requires_grad=True)\n",
      "tensor([0.6356, 0.3644], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6780e-12)\n",
      "output:6.115136608891847e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0295, -0.0295], requires_grad=True)\n",
      "tensor([0.5395, 0.4605], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0004)\n",
      "output:0.00016909358964767307\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.6363, 0.3637], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4375e-12)\n",
      "output:5.227753993586326e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.5726, 0.4274], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.9815e-07)\n",
      "output:2.1292787266702362e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.5389, 0.4611], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0004)\n",
      "output:0.00019098266784567386\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.5335, 0.4665], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0012)\n",
      "output:0.000574047677218914\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.5958, 0.4042], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7843e-09)\n",
      "output:1.9338666223944756e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.6600, 0.3400], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2752e-14)\n",
      "output:4.336005279191547e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.6234, 0.3766], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8962e-11)\n",
      "output:7.140445786729677e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0296, -0.0296], requires_grad=True)\n",
      "tensor([0.4753, 0.5247], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9929)\n",
      "output:0.52093106508255\n",
      "Parameter containing:\n",
      "tensor([ 2.0345, -0.0345], requires_grad=True)\n",
      "tensor([0.6439, 0.3561], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.1801e-13)\n",
      "output:1.1324907754194785e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0345, -0.0345], requires_grad=True)\n",
      "tensor([0.5271, 0.4729], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0044)\n",
      "output:0.0020775822922587395\n",
      "Parameter containing:\n",
      "tensor([ 2.0345, -0.0345], requires_grad=True)\n",
      "tensor([0.6467, 0.3533], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8094e-13)\n",
      "output:6.392458719479965e-14\n",
      "Parameter containing:\n",
      "tensor([ 2.0345, -0.0345], requires_grad=True)\n",
      "tensor([0.4607, 0.5393], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9996)\n",
      "output:0.5390592813491821\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6625, 0.3375], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.7331e-15)\n",
      "output:2.6101902604792502e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.5404, 0.4596], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00014153376105241477\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.5442, 0.4558], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:6.552852573804557e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6579, 0.3421], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9450e-14)\n",
      "output:6.654848181309077e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6228, 0.3772], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.1632e-11)\n",
      "output:8.159780143235373e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6006, 0.3994], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8286e-09)\n",
      "output:7.30337346155352e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.7255, 0.2745], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5662e-20)\n",
      "output:7.043109297145882e-21\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6333, 0.3667], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6625e-12)\n",
      "output:9.764497153549878e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.5422, 0.4578], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:9.828483598539606e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.6787, 0.3213], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.9901e-16)\n",
      "output:9.606313813118817e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0395, -0.0395], requires_grad=True)\n",
      "tensor([0.5030, 0.4970], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.3526)\n",
      "output:0.17522524297237396\n",
      "Parameter containing:\n",
      "tensor([ 2.0413, -0.0413], requires_grad=True)\n",
      "tensor([0.7304, 0.2696], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.7653e-21)\n",
      "output:2.6329591067121187e-21\n",
      "Parameter containing:\n",
      "tensor([ 2.0413, -0.0413], requires_grad=True)\n",
      "tensor([0.3571, 0.6429], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6428847312927246\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6743, 0.3257], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.1846e-16)\n",
      "output:2.3396918769603655e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6684, 0.3316], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3685e-15)\n",
      "output:7.854374524837965e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6764, 0.3236], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7491e-16)\n",
      "output:1.5367353479076268e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.7370, 0.2630], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5767e-21)\n",
      "output:6.775598259057827e-22\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.8872e-10)\n",
      "output:1.9197135547877053e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6976, 0.3024], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.8678e-18)\n",
      "output:2.0768340035953167e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.5970, 0.4030], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.7395e-09)\n",
      "output:1.5069578918058824e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6145, 0.3855], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1315e-10)\n",
      "output:4.3618237494102985e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6187, 0.3813], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.8487e-11)\n",
      "output:1.8485700817305606e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6857e-18)\n",
      "output:7.9955086723859e-19\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6756, 0.3244], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.5559e-16)\n",
      "output:1.8021498132073116e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6563, 0.3437], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.6618e-14)\n",
      "output:9.149067984606189e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6790, 0.3210], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.8104e-16)\n",
      "output:9.020235835045806e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.7398, 0.2602], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4887e-21)\n",
      "output:3.873795507307681e-22\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3589e-16)\n",
      "output:4.312045880252385e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.8208, 0.1792], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3555e-28)\n",
      "output:2.4284595345841054e-29\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.5597, 0.4403], grad_fn=<SoftmaxBackward>)\n",
      "tensor(6.5598e-06)\n",
      "output:2.8884373932669405e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6216, 0.3784], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7146e-11)\n",
      "output:1.027075213072548e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.6120, 0.3880], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8563e-10)\n",
      "output:7.201790552802123e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.5491, 0.4509], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.4701e-05)\n",
      "output:2.4666296667419374e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.5306, 0.4694], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0022)\n",
      "output:0.0010302740847691894\n",
      "Parameter containing:\n",
      "tensor([ 2.0459, -0.0459], requires_grad=True)\n",
      "tensor([0.4838, 0.5162], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9624)\n",
      "output:0.49680405855178833\n",
      "Parameter containing:\n",
      "tensor([ 2.0507, -0.0507], requires_grad=True)\n",
      "tensor([0.5508, 0.4492], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.8892e-05)\n",
      "output:1.7471287719672546e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0507, -0.0507], requires_grad=True)\n",
      "tensor([0.6307, 0.3693], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4654e-12)\n",
      "output:1.6491748288174901e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0507, -0.0507], requires_grad=True)\n",
      "tensor([0.3462, 0.6538], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6537829041481018\n",
      "Parameter containing:\n",
      "tensor([ 2.0552, -0.0552], requires_grad=True)\n",
      "tensor([0.7173, 0.2827], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3231e-19)\n",
      "output:3.739698089636443e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0552, -0.0552], requires_grad=True)\n",
      "tensor([0.4038, 0.5962], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5962218046188354\n",
      "Parameter containing:\n",
      "tensor([ 2.0600, -0.0600], requires_grad=True)\n",
      "tensor([0.5429, 0.4571], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0002)\n",
      "output:8.652410178910941e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0600, -0.0600], requires_grad=True)\n",
      "tensor([0.5442, 0.4558], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:6.66375199216418e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0600, -0.0600], requires_grad=True)\n",
      "tensor([0.5951, 0.4049], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.4827e-09)\n",
      "output:2.2198967108977286e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0600, -0.0600], requires_grad=True)\n",
      "tensor([0.5054, 0.4946], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.2549)\n",
      "output:0.12609587609767914\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.5796, 0.4204], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2073e-07)\n",
      "output:5.0748326430039015e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.6300, 0.3700], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.1483e-12)\n",
      "output:1.905062696136439e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.7222, 0.2778], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.0597e-20)\n",
      "output:1.4058188157518726e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.5853, 0.4147], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.9142e-08)\n",
      "output:1.62327911112925e-08\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.6049, 0.3951], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.6941e-10)\n",
      "output:3.0397481753929867e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.5243, 0.4757], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0077)\n",
      "output:0.0036427334416657686\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.6278, 0.3722], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.9405e-12)\n",
      "output:2.955495006715103e-12\n",
      "Parameter containing:\n",
      "tensor([ 2.0613, -0.0613], requires_grad=True)\n",
      "tensor([0.4008, 0.5992], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.5992186665534973\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.5408, 0.4592], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.0001315290865022689\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.6571, 0.3429], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.2599e-14)\n",
      "output:7.749135128064591e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.6042, 0.3958], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.9685e-10)\n",
      "output:3.5500791195630654e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.5381, 0.4619], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0005)\n",
      "output:0.00022590268054045737\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.7215, 0.2785], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7161e-20)\n",
      "output:1.5917006781180296e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.7067, 0.2933], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1210e-18)\n",
      "output:3.2883262442580844e-19\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0504e-13)\n",
      "output:3.682474721748534e-14\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.6184, 0.3816], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2296e-11)\n",
      "output:1.995758593109631e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.6334, 0.3666], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5639e-12)\n",
      "output:9.397881778339112e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0661, -0.0661], requires_grad=True)\n",
      "tensor([0.4940, 0.5060], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.7682)\n",
      "output:0.38869211077690125\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.6906, 0.3094], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7655e-17)\n",
      "output:8.555468691451249e-18\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.6866e-22)\n",
      "output:1.1924468143886404e-22\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.6666, 0.3334], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.3676e-15)\n",
      "output:1.1226792793892415e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.5529, 0.4471], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.5198e-05)\n",
      "output:1.1265061402809806e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.6760, 0.3240], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2104e-16)\n",
      "output:1.688425846219969e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.5319, 0.4681], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0017)\n",
      "output:0.0007993605686351657\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.6597, 0.3403], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.3433e-14)\n",
      "output:4.57117423611781e-15\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.5372, 0.4628], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0006)\n",
      "output:0.00026952751795761287\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.6183, 0.3817], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2762e-11)\n",
      "output:2.0137915640594528e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0700, -0.0700], requires_grad=True)\n",
      "tensor([0.4650, 0.5350], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9991)\n",
      "output:0.534480631351471\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.5697, 0.4303], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.8040e-07)\n",
      "output:3.78821340518698e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6727, 0.3273], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.8989e-16)\n",
      "output:3.2394772420762756e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.1878e-22)\n",
      "output:1.322609116185597e-22\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6000, 0.4000], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.0805e-09)\n",
      "output:8.322905697966121e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6373, 0.3627], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.1796e-12)\n",
      "output:4.278083963471513e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6015, 0.3985], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.5398e-09)\n",
      "output:6.136575136928002e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6108, 0.3892], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.3651e-10)\n",
      "output:9.204402517948296e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.6076, 0.3924], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.4977e-10)\n",
      "output:1.7648278671789086e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0750, -0.0750], requires_grad=True)\n",
      "tensor([0.3713, 0.6287], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.)\n",
      "output:0.6286752820014954\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.5893, 0.4107], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.7574e-08)\n",
      "output:7.217748176913119e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.6853, 0.3147], grad_fn=<SoftmaxBackward>)\n",
      "tensor(8.0592e-17)\n",
      "output:2.5363447039103137e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.7190, 0.2810], grad_fn=<SoftmaxBackward>)\n",
      "tensor(9.5790e-20)\n",
      "output:2.692062857845523e-20\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.6066, 0.3934], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.4555e-10)\n",
      "output:2.1459360677322792e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.6831, 0.3169], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.2602e-16)\n",
      "output:3.994100482971908e-17\n",
      "Parameter containing:\n",
      "tensor([ 2.0796, -0.0796], requires_grad=True)\n",
      "tensor([0.4813, 0.5187], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9770)\n",
      "output:0.5068037509918213\n",
      "Parameter containing:\n",
      "tensor([ 2.0845, -0.0845], requires_grad=True)\n",
      "tensor([0.5542, 0.4458], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.9721e-05)\n",
      "output:8.792213520791847e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0845, -0.0845], requires_grad=True)\n",
      "tensor([0.5556, 0.4444], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4689e-05)\n",
      "output:6.527338882733602e-06\n",
      "Parameter containing:\n",
      "tensor([ 2.0845, -0.0845], requires_grad=True)\n",
      "tensor([0.6534, 0.3466], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.7825e-14)\n",
      "output:1.657820168849463e-14\n",
      "Parameter containing:\n",
      "tensor([ 2.0845, -0.0845], requires_grad=True)\n",
      "tensor([0.5076, 0.4924], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.1784)\n",
      "output:0.08784965425729752\n",
      "Parameter containing:\n",
      "tensor([ 2.0854, -0.0854], requires_grad=True)\n",
      "tensor([0.6349, 0.3651], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.8995e-12)\n",
      "output:6.93399818899737e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0854, -0.0854], requires_grad=True)\n",
      "tensor([0.6494, 0.3506], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.0532e-13)\n",
      "output:3.692576436677489e-14\n",
      "Parameter containing:\n",
      "tensor([ 2.0854, -0.0854], requires_grad=True)\n",
      "tensor([0.4640, 0.5360], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9993)\n",
      "output:0.5356349945068359\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.6398, 0.3602], grad_fn=<SoftmaxBackward>)\n",
      "tensor(7.2545e-13)\n",
      "output:2.61335657975037e-13\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.5755, 0.4245], grad_fn=<SoftmaxBackward>)\n",
      "tensor(2.7805e-07)\n",
      "output:1.1803862776105234e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.6203, 0.3797], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.5724e-11)\n",
      "output:1.35654387029005e-11\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.5949, 0.4051], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.7134e-09)\n",
      "output:2.3144897109972362e-09\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.6780, 0.3220], grad_fn=<SoftmaxBackward>)\n",
      "tensor(3.4456e-16)\n",
      "output:1.109418409499714e-16\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.5405, 0.4595], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0003)\n",
      "output:0.00014080831897445023\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.5446, 0.4554], grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.0001)\n",
      "output:6.130734254838899e-05\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.6016, 0.3984], grad_fn=<SoftmaxBackward>)\n",
      "tensor(1.4994e-09)\n",
      "output:5.973742611686816e-10\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.5735, 0.4265], grad_fn=<SoftmaxBackward>)\n",
      "tensor(4.1598e-07)\n",
      "output:1.7742915758844902e-07\n",
      "Parameter containing:\n",
      "tensor([ 2.0904, -0.0904], requires_grad=True)\n",
      "tensor([0.6299, 0.3701], grad_fn=<SoftmaxBackward>)\n",
      "tensor(5.2225e-12)\n",
      "output:1.932898936393701e-12\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = regM()\n",
    "    output.backward()\n",
    "    print('output:{}'.format(output))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.load_state_dict(torch.load(\"checkpoints/Cityscapes/layerwise_policy_train_20600iter.model\")['state_dict'])\n",
    "# mtlmodel.load_state_dict(torch.load(\"checkpoints/Cityscapes/task_alter_train_5200iter.model\")['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_idx = 0\n",
    "for i, data in enumerate(valDataloaderDict[tasks[task_idx]]):\n",
    "    x = data['input']\n",
    "    y = data['label']\n",
    "    break\n",
    "    \n",
    "task = tasks[task_idx]\n",
    "tau = 2.0518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtlmodel.train()\n",
    "loss_list = []\n",
    "for i, data in enumerate(valDataloaderDict[task]):\n",
    "    x1 = data['input'].cuda()\n",
    "    y1 = data['label'].cuda()\n",
    "\n",
    "    output = mtlmodel(x1, 'mtl', task, tau=tau, hard=False)\n",
    "\n",
    "    if 'mask' in data:\n",
    "        loss = criterionDict[task](output, y1, data['mask'].cuda())\n",
    "        metricDict[task](output, y1, data['mask'].cuda())\n",
    "    else:\n",
    "        loss = criterionDict[task](output, y1)\n",
    "        metricDict[task](output, y1)\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "avg_loss = np.mean(loss_list)\n",
    "val_results = metricDict[task].val_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.595853839069605"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTLModel(\n",
       "  (headsDict): ModuleDict(\n",
       "    (segment_semantic): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (depth_zbuffer): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (net): ModuleList(\n",
       "    (0): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    )\n",
       "    (1): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (3): PoolNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): AbstractPool(\n",
       "        (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (7): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (10): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (11): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (14): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (17): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (18): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (21): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (24): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (25): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (26): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (27): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (28): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (29): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (30): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (31): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (32): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (33): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (34): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (35): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (36): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (37): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (38): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (39): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (40): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (41): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (42): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (43): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (44): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (45): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (46): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (47): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (48): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (49): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (50): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (51): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (52): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (53): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (54): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (55): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (56): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (57): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (58): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (59): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (60): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (61): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (62): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (63): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (64): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (65): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (66): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (67): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (68): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (69): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (70): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (71): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (72): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (73): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (74): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (75): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (76): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (77): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (78): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (79): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (80): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (81): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (82): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (83): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (84): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (85): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (86): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (87): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (88): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (89): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (90): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (91): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (92): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (93): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (94): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (95): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (96): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (97): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (98): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (99): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (100): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (101): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (102): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (103): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (104): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (105): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (106): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (107): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (108): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (109): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (110): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (111): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (112): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (113): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (114): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (115): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (116): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (117): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (118): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (119): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (120): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (121): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (inputNode): InputNode()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# output = mtlmodel(x.cuda(), 'pre_train', tasks[task_idx])\n",
    "output = mtlmodel(x.cuda(), 'pre_train_specific', tasks[task_idx])\n",
    "# output = mtlmodel(x.cuda(), 'mtl', task=task, tau=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29efe438>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.permute(0,2,3,1)[i].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29fdee10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.permute(0,2,3,1)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29f9f320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seg\n",
    "def resize_pred(pred, gt):\n",
    "    return F.interpolate(pred, size=gt.shape[-2:])\n",
    "pred = output\n",
    "gt = y.cuda()\n",
    "output = resize_pred(pred, gt)\n",
    "prediction = torch.argmax(output, dim=1)\n",
    "plt.imshow(prediction.cpu().detach().numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad3ffc1208>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX0klEQVR4nO2da2ykZ3XH/2cuvnt93Ys3uwnJKmlJuCStFRWRFqoIGvKhAVVCRBVKBWL5ABJIfChKK5GPUVVAqEVImyYiVFyERBGplFJCBI0oKoo35LLJAtnm0uz9Zq+vY3tmTj94QCbx8z/GY8+MeP4/ybI9Z573Pe/zvv95Z+Y85xxzdwghfv8ptNsBIURrkNiFyASJXYhMkNiFyASJXYhMKLVyZ12lPu8tD6WfYMY3UK2Ssfx1y0tNvq4V0r5ZrcmIRj0YX69xe4EcWzSn9Tq3R4dG5iXcf7TviCiSxOYlOq5icD1Fhx1tn/keHJeXi0lbpTKDldWFDb1rSuxmdgeALwEoAvgXd7+fPb+3PIR3HPpI0u7s5AAoXJxOG3u66dja+C5qj6j1pKeqNFNpatu2ssrtcwvU7gN9aWMwp1ZZpnbUuCC9p4uPL6fnzRaDeYteBNmLPwD09qRtgaDqu8icIr5WrcZfoK1K5jW4HlavGk7anpz6ctK25dudmRUBfBnA+wDcCOBuM7txq9sTQuwszby3vRXACXd/yd1XAHwLwF3b45YQYrtpRuxXAXht3f8nG4/9FmZ22MymzGxqpbbYxO6EEM2w49/Gu/sRd59098muIv8cJITYOZoR+ykAB9f9f6DxmBCiA2lG7E8CuN7MrjWzLgAfAvDI9rglhNhuthx6c/eqmX0SwH9iLfT2kLs/HwyCVVaS5vroAB8+kg6f2Rz/PqB4aY7aV64epfby+fn0vpeC8FUQpvFSOm4KAN7fy7c/m/YNQQjIh4OQ5MIsty+nzycAukagdt0bvuL5LQonTlK77eLXCwuv+Sy/HgpLQViwGJyzIHxG107sGeO7XiQhRxLRayrO7u6PAni0mW0IIVqDlssKkQkSuxCZILELkQkSuxCZILELkQkSuxCZ0NJ8dgBwkv9cvHCFj2XpmF1BqmWQ0lj+BV/8t3TLNUlbz3//go4t7BqkdlsK8rq7+bHVJ8bT+57m8WQsB/Hg/mCJc5SGSua98PJpPrarzDfNUnsB2Ez62G0wiNGvBumzER6c0xKR3mWugwKpEWCkRoDu7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCa0PPRmLFQTpUuODadtUaXSoEoqhnh4rPdlUtl2326+7fmgHBerggqEaaqFK6T6bFRKejWY82h8gJNQkLHw0yZYHeapv2VyTdTPX6RjC1FoLqhmbMG8+TxJmR4IUr2r5Hog8tKdXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMaG2c3b251EEWX4y6kQZx0foQT5csnk3H2X0liFUHaaK+wOPwFqXvsrLEQZlqmmqJuEurResXZkgp6uCcROWaw32za+Lag2kbAFwh5bmjbQPwIKXaBtPrOnxpiY9l55SlFNOtCiF+b5DYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITGhtnN0MKKd3SUtFA7A5krcdlFv2wF6Y5/nw3kdyzqM4e7NliYvBa3K0xoAR5F1b5HtQg8DYGoMgTz9cIxCVsSbn3IJ9rx7gbZPLZ0h9AwC4EpTwLpMy2UEb7RpZE+Ln0tdKU2I3s1cAzAGoAai6+2Qz2xNC7BzbcWf/c3fnZT+EEG1Hn9mFyIRmxe4AfmBmR83s8EZPMLPDZjZlZlMrtaAWmxBix2j2bfxt7n7KzPYAeMzMfuHuT6x/grsfAXAEAIZ69gXfqAghdoqm7uzufqrx+zyA7wK4dTucEkJsP1sWu5n1m9ngr/8G8F4Ax7bLMSHE9tLM2/i9AL7bqI9dAvANd/8+HVGr89xt0s4ZCPLGWa47AETtfYO687WxdP5xcYHnH3s3bz1swXFHsXAfScdlLWjJ7GztAoLcaSD2rZKe17BufHBOvcx98950vrwt8bUJrOY8gDjXfqCf2uk1Mc1bNhdJHwK2LmLLYnf3lwC8favjhRCtRaE3ITJBYhciEyR2ITJBYhciEyR2ITKh5S2bGWHJZFZ6OCorHLVNDsI8xYukJHKVp4HaPLd7ND5qH0x89yh0NjpEzXWSkgwAFqW4Vog98C0qY126HIQNSdjR+3m7Z5y9wLfdE7TZDlKq2bxEy0ydXetq2SyEkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMaG2cvV6HL6bTQeszPLWvwOLNQZzdgvbAHsSbaQpsL4+51k6fpfbixF5qxwpPUwUrcx2UgrZo/cEQj/HT8t4IYsIRs7wcs/UGsXJSLtqiOd2VTmkGgPp5XmPVg+0X94wnbVF6LC2hTdKldWcXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhNaG2cvFlAgMUSv8ng1i8Oz7QJx/rLNBvFi1ha5znPhLSg7HMVso7LF9BU7aE1cm57hu64HcfIgbxvz6XltKp4MwJd4CW9Wqtrn5/m+y0GL7/FRaq9fnqF2nyP77wpKj7NceuWzCyEkdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhNaG2d3wEmN8yjnvDCczjn3RZ6XHeZdBzFdWl/94mW+bdZqGvEaARtKt2QGgPpgenwhaD1cCPLN62FOebA2gsTZC0G757Ae/8gwH79Ejn33GN82q3cPxPUTonbUJJbuZM4AwNlxkXUV4Z3dzB4ys/NmdmzdY6Nm9piZvdj4PRJtRwjRXjbzNv6rAO543WOfBfC4u18P4PHG/0KIDiYUu7s/AeD171PvAvBw4++HAbx/e90SQmw3W/3MvtfdzzT+PgsgWUTNzA4DOAwAPYWgZ5kQYsdo+tt4d3eQ5ffufsTdJ919sqsQFAgUQuwYWxX7OTObAIDG7/Pb55IQYifYqtgfAXBP4+97AHxve9wRQuwU4Wd2M/smgHcDGDezkwA+B+B+AN82s48CeBXABze1NwOsmH598SukBzqAtU8MCVsQkwWpVw8Atp/Xbqd1xss8/7gwwiOTPsdj2V4JeoWznPLouKMe6dQKYJivAWBx/KjvvAc17aPe82xewjh6dD1FBDnpWE7XR4iuZWdjPT3fodjd/e6E6fZorBCic9ByWSEyQWIXIhMkdiEyQWIXIhMkdiEyofUpriR8FpZMJqmg1ddO8rEkPRYAqqM8zbR0maQdXpqmY6PjQoG/5hZIe18AtC0znW+g6VbXmOZttrF/T9p2aYbvOyj/7cG8VQ6l993zyzNJG4A4dBa1fA7srN10wYJ7MNGBzaSvNd3ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhciEFsfZnccfg/K7rFx0oa+Pjo1K+y5exUsiV96S3v6eR3hqrgUlk6NYtgdtkb2cPrZCEO/1Ci81TdsDA6iP8RRXkGO3vqByEVk/AADezc9peS6dxnrlHQfp2KGnzlE7EMTZgzi9s1bYe4Iy12xe5hRnFyJ7JHYhMkFiFyITJHYhMkFiFyITJHYhMkFiFyITWhtnLxiNKftAECsnbZejtsZRzLb3Ai8tXO0msfCgnHJUjpnGTTdhByuxTcoOAzyvGgBWSE44ANgKz4ev7E3P2+AzvFQ0yPoBAPCuwF5Mx/hXe/l9zknJcyAo3w3EcfZeUuZ6ga99oGtVSOtx3dmFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyITWxtmLRfgu0qa3VuPje9O51fW+IO+6j8c9F0k8GAAKxDUWMwUAW+SxbrDcZiCu7U7mzaOa9QHVXn6JLO/j2+8/lY4ZV67j9fDLV/i8eYnfq+rltG8W1dMP2kFH58T7ghoFLM8/itEzYyG93fDObmYPmdl5Mzu27rH7zOyUmT3d+Lkz2o4Qor1s5m38VwHcscHjX3T3mxs/j26vW0KI7SYUu7s/AeByC3wRQuwgzXxB90kze7bxNn8k9SQzO2xmU2Y2tVIN1kILIXaMrYr9KwAOAbgZwBkAn0890d2PuPuku092lXiiixBi59iS2N39nLvX3L0O4AEAt26vW0KI7WZLYjeziXX/fgDAsdRzhRCdQRhnN7NvAng3gHEzOwngcwDebWY3Yy3k9wqAj29mZ/VyEZWD6T7pXVd4TjmLR6+M8Dh7scJj+D2XgjrghFo/j7PXxnjOeHkmyF8OwvA0zj7Kc+0L80vUXprn81Ja4rn2hWra+dIcj6Mv7w7qGwTzwui5zK+HKFe+Osx9Y8cNAHWyRqDew/ddqKTj8CwPPxS7u9+9wcMPRuOEEJ2FlssKkQkSuxCZILELkQkSuxCZILELkQmtTXE1npa4uitIFa2RkslBuuPqILdP/wFPKxw4nQ6lWI1PY9ccD/PUevm+61083XJ1V9reHYQUV4OQpZeCdtNVnipamUif0+IyTwOtdfNzthKcU2NllYPq3MVlHlorkXbQALB4FQ+3Gtl/lH5bnifH3UyKqxDi9wOJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyISWx9nrJG7rxl97aqTNLtsuACwPcnvvBZ6SWCNLAHovBmPDeHEQb+4KYt1k95VDPI7edyFIUV3mx7Y8wi+hWjdpm9zH1w9U+/hxOzejZzodr17czfe9Mhi0ZHZuj3wvz6d965nhc86ul3pX+lrTnV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITGhpnL3aa7j0lvQu+08HbXQJq/3cPnctt4//nNvr5XTcdHF30NZ4hMdcS0v8uD14SV7tT2+/5zLf9tIY9332Ou57/6nAdzK8HqwfWCXdvQGgm8TRAcCL6e13zfGxfed5HYDpG3icvR4oq05KGKz08xNeGUsfFyutoDu7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJnQ2nx28JhxFJtcHt563LT/tSD52bYe41/ZtfXc5c1gvOw8tUdzuriX+17gXZWxOsDHLxwg9faDLtnlBb7tpfEgz5/My2pQ32D6zbyWf3memlHr4ed8ZSi9/+7pYNus/AErKc83C5jZQTP7kZm9YGbPm9mnGo+PmtljZvZi4/dItC0hRPvYzNv4KoDPuPuNAP4EwCfM7EYAnwXwuLtfD+Dxxv9CiA4lFLu7n3H3pxp/zwE4DuAqAHcBeLjxtIcBvH+HfBRCbAO/0xd0ZvYmALcA+BmAve5+pmE6C2BvYsxhM5sys6nq4kIzvgohmmDTYjezAQDfAfBpd59db3N3B7DhNxLufsTdJ919stQXZKsIIXaMTYndzMpYE/rX3f3fGg+fM7OJhn0CwPmdcVEIsR2EoTczMwAPAjju7l9YZ3oEwD0A7m/8/l60rXoJqIynQzGFlaDk8nA6nLE0uUTHlo/zFrz1Mt93lXTgXRnhpX8RRP26pvm+ozAP8215jI/1Ag8RVa+pUHu9GrRNJsfuS7ycc6EalHse5zHJ5bG0b97Fz1nXpahNdtBWeZafdBYSZemvAFDtJ63LyenYTJz9nQA+DOA5M3u68di9WBP5t83sowBeBfDBTWxLCNEmQrG7+0+Qvjfdvr3uCCF2Ci2XFSITJHYhMkFiFyITJHYhMkFiFyITWpviWnL42ErSvLyftw8e6EvnW87Nk2AzgNXBIJ4cLO4z4lphNSiJPM6Pazl4yS1WgjUAfeljq/GOzeg7G5S5XmhuXp1cYdXd6WsB4C26AaB3fJHaV5bTAWs7w9tkT77nBWqf+uGbqb2yh8fxC8vpea9M8PUD5WmyBoCcTt3ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhciElsbZu7tWccPBc0n7ibO76fjFSrpN7sTYFTr2DLUCVuRx0epqOrZ500G+9ddmhql9do7b99xxktoHy+n1BxXWwxfAlWUeiK/V+f3gXRMnqL1ASnTXWT9nAI+fvIHaI996u9Nx/IUyX/vw018dovb9t6avYwC4bugitS9W09fy0eO8v/jqvnQNbi+n51t3diEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEyoaVxdodhtZ6OVw/28xrllZV0fvKF2QE69q0HTlH7StDb+Or+dB/dZy7tp2O7g5judW/nvrF9A0CpkM5/HivzllvPXrmK2t82xH17Uw+PJ3eRQgA/uHQTH1vied1vHePrD94zcixpe3l5Dx370tI4tf/8wgFqr5LrHAAODaTnre+tPM//ldl0M4BL5FrTnV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITNhMf/aDAL4GYC8AB3DE3b9kZvcB+BiAC42n3uvuj7JtDZWW8N69x5P2E4s89vnC9N6k7VCQP3z09EFqPzDM8+HPLg1ued+9xXT+MRDH+OeqvMb57Eo6J/2PJ16lY6M4+b7SDLXP1Xld+X+/+PakbbCUzsMHgI9c+1Nqf3aen9OjC+m88L8ceoqOXayn880B4N4b/oPa//65u6j99MBQ0nZhjjcx2D88m7Sx+gGbWVRTBfAZd3/KzAYBHDWzxxq2L7r7P25iG0KINrOZ/uxn0Cj04u5zZnYcAF92JYToOH6nz+xm9iYAtwD4WeOhT5rZs2b2kJmNJMYcNrMpM5tamObLAIUQO8emxW5mAwC+A+DT7j4L4CsADgG4GWt3/s9vNM7dj7j7pLtP9o/wz0FCiJ1jU2I3szLWhP51d/83AHD3c+5ec/c6gAcA3LpzbgohmiUUu5kZgAcBHHf3L6x7fGLd0z4AIJ1iJIRoO5v5Nv6dAD4M4Dkze7rx2L0A7jazm7EWjnsFwMejDY0WF/HXQz9P2j+3cAcdf8tYOt3yl7M8bNffw78vOD27i9r3DM4nbVEK6lItnZoLAMcuTlD7m8fOUvtfTDyftD3w8m107F9dnT4fAHBmZZjaD3RdpvbRrnRb5Wt7LyRtAPCN1/ibxQ8f/B9qL5P02v+a5y2Xr+66RO2jxfT1AAATQ+nwGACcn0unZO8bmqNjl1bT1xMrz72Zb+N/go27PtOYuhCis9AKOiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhPMPZ0St93sv2nYP/atdyXt79v1DB3/z2dvT9r+sJ+30H21MkrtZ5bSKYcA0FVIx2xLBd7ueV8Pj7kOFHmq59v6/o/af3wlHTPe3z1Dx35gF4+z39TFU1j/afoaat9dSh/7t89N0rH7e/m8Hb3Iyznfc006Dv/yMm8P3lPgacm3D6bXNgDA96+8jdpv6kuvGXng1T+lY9+198Wk7cEP/Rinn5/ZMNiuO7sQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmdDSOLuZXQCwvrbxOABey7h9dKpvneoXIN+2ynb6do27b7iIoKVif8POzabcna+saBOd6lun+gXIt63SKt/0Nl6ITJDYhciEdov9SJv3z+hU3zrVL0C+bZWW+NbWz+xCiNbR7ju7EKJFSOxCZEJbxG5md5jZL83shJl9th0+pDCzV8zsOTN72sym2uzLQ2Z23syOrXts1MweM7MXG7837LHXJt/uM7NTjbl72szubJNvB83sR2b2gpk9b2afajze1rkjfrVk3lr+md3MigB+BeA9AE4CeBLA3e7+QksdSWBmrwCYdPe2L8Awsz8DMA/ga+7+lsZj/wDgsrvf33ihHHH3v+0Q3+4DMN/uNt6NbkUT69uMA3g/gL9BG+eO+PVBtGDe2nFnvxXACXd/yd1XAHwLAO9cnynu/gSA17dcuQvAw42/H8baxdJyEr51BO5+xt2favw9B+DXbcbbOnfEr5bQDrFfBeC1df+fRGf1e3cAPzCzo2Z2uN3ObMBedz/T+PssgL3tdGYDwjbereR1bcY7Zu620v68WfQF3Ru5zd3/CMD7AHyi8Xa1I/G1z2CdFDvdVBvvVrFBm/Hf0M6522r782Zph9hPATi47v8Djcc6Anc/1fh9HsB30XmtqM/9uoNu4/f5NvvzGzqpjfdGbcbRAXPXzvbn7RD7kwCuN7NrzawLwIcAPNIGP96AmfU3vjiBmfUDeC86rxX1IwDuafx9D4DvtdGX36JT2nin2oyjzXPX9vbn7t7yHwB3Yu0b+f8F8Hft8CHh13UAnmn8PN9u3wB8E2tv61ax9t3GRwGMAXgcwIsAfghgtIN8+1cAzwF4FmvCmmiTb7dh7S36swCebvzc2e65I361ZN60XFaITNAXdEJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkwv8DzPuleesiLDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# depth\n",
    "plt.imshow(output.cpu().detach().numpy()[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 1.9348e-01,  1.9046e-01,  1.7868e-01,  ...,  1.6289e-01,\n",
       "            1.3305e-01,  1.4691e-01],\n",
       "          [ 1.1127e-01,  1.8490e-02, -1.9056e-02,  ...,  1.0792e-01,\n",
       "            7.5129e-02,  2.6224e-02],\n",
       "          [ 5.9161e-02,  1.2628e-01,  4.1456e-02,  ...,  4.8540e-02,\n",
       "           -5.2689e-02, -2.5313e-02],\n",
       "          ...,\n",
       "          [-1.7076e-01, -1.6649e-01, -5.4048e-02,  ..., -4.0136e-02,\n",
       "           -1.8000e-01, -5.5735e-02],\n",
       "          [-9.9670e-02, -1.1982e-01, -4.6479e-02,  ..., -2.8480e-02,\n",
       "           -1.6647e-01, -4.2167e-02],\n",
       "          [-1.4900e-02, -1.7457e-01, -1.2356e-01,  ..., -1.2068e-01,\n",
       "           -1.8828e-01, -1.7409e-01]],\n",
       "\n",
       "         [[ 3.9546e-01,  2.6007e-01,  3.0369e-01,  ...,  3.1506e-01,\n",
       "            2.8149e-01,  3.6778e-01],\n",
       "          [ 2.1045e-01,  1.4817e-01,  1.9734e-01,  ...,  2.0418e-01,\n",
       "            2.5394e-01,  2.3090e-01],\n",
       "          [ 2.2047e-01,  7.8727e-02,  2.1716e-01,  ...,  2.0573e-01,\n",
       "            2.2162e-01,  1.1520e-01],\n",
       "          ...,\n",
       "          [ 7.8002e-03, -7.3256e-02, -3.7424e-02,  ...,  2.4563e-02,\n",
       "            1.7132e-02, -3.9162e-02],\n",
       "          [-8.2261e-02,  4.3826e-02,  1.0954e-02,  ...,  9.4626e-02,\n",
       "           -5.4367e-02,  8.6645e-02],\n",
       "          [-7.2165e-02, -6.1762e-02, -2.8604e-02,  ..., -9.3454e-02,\n",
       "            2.0433e-02, -3.5397e-02]],\n",
       "\n",
       "         [[ 3.0470e-01,  2.9425e-01,  1.6970e-01,  ...,  3.0008e-01,\n",
       "            4.0986e-01,  3.4495e-01],\n",
       "          [ 2.1641e-01,  2.3366e-01,  2.4421e-01,  ...,  3.0606e-01,\n",
       "            2.5837e-01,  3.7265e-01],\n",
       "          [ 2.6652e-01,  2.9613e-01,  1.8087e-01,  ...,  3.3646e-01,\n",
       "            2.9466e-01,  2.2690e-01],\n",
       "          ...,\n",
       "          [ 1.7562e-02,  1.2545e-01,  1.0439e-01,  ...,  8.7839e-02,\n",
       "            5.2315e-02,  6.9824e-02],\n",
       "          [-2.8949e-03,  3.3556e-02,  1.0388e-01,  ...,  6.7428e-02,\n",
       "            2.3506e-02,  5.6610e-02],\n",
       "          [ 1.2620e-02,  4.2862e-04, -2.9687e-02,  ...,  5.9172e-02,\n",
       "            3.1879e-03,  1.3941e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1861e-01, -6.9252e-02, -4.2111e-02,  ..., -4.9531e-02,\n",
       "           -5.0002e-02, -2.2789e-01],\n",
       "          [-1.2462e-01,  7.9621e-02,  3.1477e-01,  ...,  3.6418e-01,\n",
       "            1.0495e-01, -1.4629e-01],\n",
       "          [-2.5711e-01, -4.7194e-02,  2.3762e-01,  ...,  2.4443e-01,\n",
       "            1.1825e-01, -1.2448e-01],\n",
       "          ...,\n",
       "          [ 3.8341e-03,  1.2940e-02, -1.8498e-01,  ..., -2.3982e-01,\n",
       "           -1.2807e-01, -6.5849e-02],\n",
       "          [ 1.6280e-02, -2.2919e-01, -5.4524e-01,  ..., -5.5618e-01,\n",
       "           -2.8119e-01, -8.4630e-02],\n",
       "          [ 2.9217e-02, -1.4963e-01, -5.5530e-01,  ..., -5.1312e-01,\n",
       "           -3.5225e-01, -1.8325e-02]],\n",
       "\n",
       "         [[-1.3248e-01, -1.5879e-02, -7.3597e-02,  ...,  5.9925e-02,\n",
       "            2.0742e-02, -2.2118e-01],\n",
       "          [-9.0274e-02,  1.2198e-01,  2.4148e-01,  ...,  2.6748e-01,\n",
       "            1.1626e-01, -1.5355e-01],\n",
       "          [-2.5510e-01,  1.2519e-02,  2.6392e-01,  ...,  2.2350e-01,\n",
       "            7.7663e-02, -8.9623e-02],\n",
       "          ...,\n",
       "          [ 6.0900e-03, -3.6701e-02, -1.4688e-01,  ..., -1.5240e-01,\n",
       "            7.8715e-03,  2.9904e-02],\n",
       "          [ 1.1815e-01, -1.5965e-01, -5.5559e-01,  ..., -6.1041e-01,\n",
       "           -3.0734e-01,  4.5595e-02],\n",
       "          [ 9.5426e-02, -1.5706e-01, -4.7803e-01,  ..., -5.8104e-01,\n",
       "           -2.3293e-01,  1.2288e-01]],\n",
       "\n",
       "         [[-3.0093e-01, -9.1831e-02, -1.7149e-02,  ..., -1.7721e-02,\n",
       "           -1.9420e-02, -1.9703e-01],\n",
       "          [-1.4186e-01,  3.0824e-02,  1.3841e-01,  ...,  3.2936e-01,\n",
       "            9.5610e-02, -1.3391e-01],\n",
       "          [-1.9598e-01, -9.5541e-02,  1.7769e-01,  ...,  2.3178e-01,\n",
       "            6.7531e-02, -2.2220e-01],\n",
       "          ...,\n",
       "          [ 1.0961e-01,  9.5990e-02, -4.3585e-02,  ..., -7.1444e-02,\n",
       "           -1.6975e-03, -2.0844e-02],\n",
       "          [ 9.3435e-02, -1.3798e-01, -4.1175e-01,  ..., -4.7734e-01,\n",
       "           -1.4935e-01,  7.6791e-02],\n",
       "          [ 1.8279e-01, -1.7677e-01, -4.9691e-01,  ..., -4.8496e-01,\n",
       "           -1.1588e-01,  1.5386e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3422e-01,  5.6946e-02, -4.4012e-02,  ...,  7.5978e-02,\n",
       "            1.3772e-01,  1.4103e-01],\n",
       "          [ 9.2428e-02,  4.5984e-02, -7.3937e-02,  ...,  1.3230e-02,\n",
       "            1.8350e-01,  1.0859e-01],\n",
       "          [ 8.7874e-02,  3.8481e-02, -2.9248e-02,  ..., -6.9481e-02,\n",
       "            4.7970e-02,  6.6456e-02],\n",
       "          ...,\n",
       "          [ 3.3562e-01,  3.2084e-01,  3.8629e-01,  ...,  3.6651e-01,\n",
       "            3.8906e-01,  3.8730e-01],\n",
       "          [ 4.3496e-01,  3.4643e-01,  3.1617e-01,  ...,  3.5348e-01,\n",
       "            2.8155e-01,  3.0870e-01],\n",
       "          [ 3.4012e-01,  4.4205e-01,  4.0788e-01,  ...,  3.8313e-01,\n",
       "            2.8415e-01,  3.3847e-01]],\n",
       "\n",
       "         [[ 1.5787e-01,  1.2103e-02,  1.3330e-02,  ..., -3.5541e-02,\n",
       "            1.2316e-01,  1.5220e-01],\n",
       "          [ 1.6519e-01, -6.7258e-02, -5.6864e-02,  ...,  1.3928e-01,\n",
       "            8.3508e-02,  2.0923e-01],\n",
       "          [ 1.0559e-01, -5.6640e-02, -8.6579e-02,  ..., -1.9612e-02,\n",
       "            3.5222e-02,  5.6342e-02],\n",
       "          ...,\n",
       "          [ 3.2311e-01,  3.9540e-01,  3.4362e-01,  ...,  2.4250e-01,\n",
       "            4.4043e-01,  3.0391e-01],\n",
       "          [ 4.1096e-01,  4.0907e-01,  4.4725e-01,  ...,  4.2726e-01,\n",
       "            4.4643e-01,  3.1863e-01],\n",
       "          [ 2.7936e-01,  4.1867e-01,  2.8060e-01,  ...,  3.8285e-01,\n",
       "            3.7155e-01,  3.2962e-01]],\n",
       "\n",
       "         [[-4.2859e-02,  3.0449e-03,  1.1235e-02,  ...,  3.3652e-02,\n",
       "           -1.3945e-03,  6.2101e-02],\n",
       "          [-8.8811e-03, -1.5289e-01, -1.3418e-01,  ...,  1.3978e-02,\n",
       "           -5.1278e-02,  1.8524e-02],\n",
       "          [-1.2932e-01, -1.5300e-01, -8.2819e-02,  ..., -1.5588e-01,\n",
       "           -2.7543e-02,  8.3585e-03],\n",
       "          ...,\n",
       "          [ 2.9860e-01,  1.9212e-01,  3.2739e-01,  ...,  2.7992e-01,\n",
       "            3.6012e-01,  3.6647e-01],\n",
       "          [ 2.7816e-01,  3.3447e-01,  3.9162e-01,  ...,  2.5194e-01,\n",
       "            2.6685e-01,  2.1791e-01],\n",
       "          [ 1.7084e-01,  2.2893e-01,  1.7858e-01,  ...,  2.2817e-01,\n",
       "            2.7910e-01,  2.2406e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-6.5441e-03, -1.4997e-01, -2.2663e-01,  ..., -2.8896e-01,\n",
       "           -1.6126e-01, -6.5877e-02],\n",
       "          [ 2.1835e-02, -1.7180e-01, -2.9062e-01,  ..., -4.3270e-01,\n",
       "           -3.0434e-01, -8.7422e-02],\n",
       "          [-2.8007e-01, -2.7005e-01, -3.6075e-01,  ..., -4.0973e-01,\n",
       "           -4.3757e-01, -3.4216e-01],\n",
       "          ...,\n",
       "          [ 1.4845e-01,  1.5642e-01,  3.1548e-01,  ...,  2.8312e-01,\n",
       "            1.4152e-01,  5.3966e-02],\n",
       "          [ 6.4303e-01,  5.5613e-01,  6.7680e-01,  ...,  8.9608e-01,\n",
       "            9.0418e-01,  7.6326e-01],\n",
       "          [ 6.7288e-02,  3.1130e-01,  4.9437e-01,  ...,  3.8273e-01,\n",
       "            2.7193e-01, -7.8445e-02]],\n",
       "\n",
       "         [[-6.7413e-02, -3.3412e-01, -5.3041e-01,  ..., -4.3082e-01,\n",
       "           -1.8933e-01, -1.0943e-02],\n",
       "          [-1.7898e-01, -4.7312e-01, -6.7110e-01,  ..., -5.2439e-01,\n",
       "           -3.6046e-01, -1.3699e-01],\n",
       "          [-4.5686e-01, -5.1416e-01, -6.4736e-01,  ..., -6.6663e-01,\n",
       "           -4.7206e-01, -3.1133e-01],\n",
       "          ...,\n",
       "          [ 1.3257e-01,  1.7986e-01,  3.2450e-01,  ...,  3.1813e-01,\n",
       "            1.1754e-01, -5.1540e-03],\n",
       "          [ 3.9899e-01,  6.9933e-01,  9.9808e-01,  ...,  9.6575e-01,\n",
       "            6.0016e-01,  3.8259e-01],\n",
       "          [-6.2643e-02,  1.3653e-01,  2.7354e-01,  ...,  3.0888e-01,\n",
       "            1.9806e-01, -4.5998e-02]],\n",
       "\n",
       "         [[ 3.0253e-01, -9.1092e-05, -9.2978e-02,  ..., -3.2222e-01,\n",
       "           -8.7659e-02,  9.9027e-02],\n",
       "          [ 2.3355e-02, -3.0976e-01, -4.0508e-01,  ..., -4.0812e-01,\n",
       "           -4.1611e-01,  1.8582e-02],\n",
       "          [-2.9185e-01, -4.5287e-01, -3.2448e-01,  ..., -4.9735e-01,\n",
       "           -4.5263e-01, -5.0443e-01],\n",
       "          ...,\n",
       "          [ 2.5353e-01,  2.4393e-01,  3.8372e-01,  ...,  4.8763e-01,\n",
       "            4.2574e-01,  3.0660e-01],\n",
       "          [ 5.7360e-01,  6.8942e-01,  8.0363e-01,  ...,  9.0279e-01,\n",
       "            8.4379e-01,  6.9271e-01],\n",
       "          [ 4.3728e-02,  2.2124e-01,  4.7603e-01,  ...,  4.5979e-01,\n",
       "            1.8919e-01,  5.1313e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.6919e-01,  2.5433e-01,  2.9159e-03,  ..., -3.9586e-01,\n",
       "            8.3945e-02,  4.3993e-01],\n",
       "          [ 6.5795e-01,  3.8393e-01,  6.0518e-03,  ..., -1.8555e-01,\n",
       "            2.0616e-01,  4.9549e-01],\n",
       "          [ 7.3804e-01,  5.1392e-01,  1.7820e-01,  ..., -1.7999e-01,\n",
       "            3.3974e-01,  6.7964e-01],\n",
       "          ...,\n",
       "          [ 9.9047e-02,  1.3656e-02,  1.5119e-01,  ...,  2.1338e-01,\n",
       "            8.3008e-02, -4.1418e-02],\n",
       "          [-4.2290e-01, -1.5473e-01,  5.2264e-01,  ...,  1.0115e+00,\n",
       "            2.1076e-01, -5.3830e-01],\n",
       "          [-9.2606e-01, -5.5183e-01,  1.0243e-01,  ...,  5.1740e-01,\n",
       "           -1.0539e-01, -8.4427e-01]],\n",
       "\n",
       "         [[ 3.2742e-01,  1.4614e-01, -2.8483e-01,  ..., -5.5120e-01,\n",
       "           -1.0849e-01,  2.3948e-01],\n",
       "          [ 3.1597e-01, -5.9796e-02, -5.0310e-01,  ..., -8.5854e-01,\n",
       "           -4.0636e-01,  2.8207e-01],\n",
       "          [ 4.4305e-01,  1.9004e-01, -2.4569e-01,  ..., -5.5117e-01,\n",
       "           -4.9872e-02,  4.0563e-01],\n",
       "          ...,\n",
       "          [-6.9567e-02,  3.1811e-02,  1.1075e-01,  ...,  2.8371e-01,\n",
       "            2.5547e-01, -1.3306e-01],\n",
       "          [-4.0439e-01,  1.2942e-01,  8.2752e-01,  ...,  1.3252e+00,\n",
       "            5.8959e-01, -3.7102e-01],\n",
       "          [-7.4728e-01, -2.0629e-01,  3.8899e-01,  ...,  8.9909e-01,\n",
       "            1.5730e-01, -6.0746e-01]],\n",
       "\n",
       "         [[ 5.7015e-01,  2.9280e-01, -1.5205e-01,  ..., -3.7604e-01,\n",
       "           -3.5444e-02,  3.5109e-01],\n",
       "          [ 4.9243e-01,  3.1588e-01, -2.4055e-01,  ..., -4.4189e-01,\n",
       "           -8.0116e-02,  4.0551e-01],\n",
       "          [ 5.5391e-01,  2.3244e-01, -2.8367e-01,  ..., -6.7547e-01,\n",
       "           -1.0455e-01,  3.8945e-01],\n",
       "          ...,\n",
       "          [-1.6580e-02, -9.8518e-02,  8.5997e-02,  ...,  1.3854e-01,\n",
       "            1.7825e-01,  4.1639e-02],\n",
       "          [-6.1325e-01,  7.5046e-02,  1.0402e+00,  ...,  1.4916e+00,\n",
       "            6.1806e-01, -5.2196e-01],\n",
       "          [-1.1111e+00, -5.0135e-01,  3.6084e-01,  ...,  8.5078e-01,\n",
       "           -2.6013e-02, -9.8660e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0151e-01,  2.6595e-01,  1.6414e-01,  ...,  1.3755e-01,\n",
       "            1.0831e-01,  1.5255e-01],\n",
       "          [ 1.0509e-01,  1.3370e-01,  2.7623e-02,  ...,  1.0069e-01,\n",
       "            1.7135e-01,  1.4601e-01],\n",
       "          [ 1.6061e-01,  7.0673e-02,  1.1678e-01,  ...,  4.6247e-02,\n",
       "            1.3165e-01,  9.9891e-02],\n",
       "          ...,\n",
       "          [-1.5515e-01,  1.5890e-01, -8.8612e-02,  ..., -1.0895e-02,\n",
       "           -4.8173e-03, -1.5800e-02],\n",
       "          [-1.6857e-01,  8.4968e-02, -1.4325e-01,  ..., -8.5013e-02,\n",
       "           -8.1094e-02, -9.6158e-02],\n",
       "          [-2.6491e-01, -2.0877e-01, -2.1962e-01,  ..., -3.2122e-01,\n",
       "           -1.9045e-01, -3.0430e-01]],\n",
       "\n",
       "         [[ 3.5865e-01,  3.2134e-01,  2.2935e-01,  ...,  1.8148e-01,\n",
       "            1.8431e-01,  3.0497e-01],\n",
       "          [ 1.9506e-01,  2.6378e-01,  2.5425e-01,  ...,  6.8954e-02,\n",
       "            2.2453e-01,  2.9814e-01],\n",
       "          [ 2.6994e-01,  1.8870e-01,  1.9531e-01,  ...,  2.1734e-01,\n",
       "            1.4369e-01,  2.5881e-01],\n",
       "          ...,\n",
       "          [-4.0266e-02,  1.6479e-01, -4.9579e-02,  ...,  4.4656e-03,\n",
       "            1.3128e-01,  1.1565e-01],\n",
       "          [-9.3170e-02,  8.2513e-02, -9.2415e-02,  ..., -3.1801e-02,\n",
       "            1.3341e-01,  7.0919e-02],\n",
       "          [-1.8617e-01, -1.2449e-01, -2.6227e-01,  ..., -2.2110e-01,\n",
       "           -9.4408e-02, -1.5824e-01]],\n",
       "\n",
       "         [[ 2.8263e-01,  2.3268e-01,  3.3404e-01,  ...,  2.1798e-01,\n",
       "            2.5800e-01,  3.7063e-01],\n",
       "          [ 2.1164e-01,  2.1857e-01,  1.7825e-01,  ...,  1.8385e-01,\n",
       "            3.4764e-01,  3.6397e-01],\n",
       "          [ 3.3122e-01,  3.5719e-01,  2.4490e-01,  ...,  1.6883e-01,\n",
       "            3.2318e-01,  3.0268e-01],\n",
       "          ...,\n",
       "          [ 1.1991e-01,  1.1887e-01,  6.5936e-02,  ...,  1.0902e-01,\n",
       "            2.2308e-01,  2.0605e-01],\n",
       "          [ 7.4227e-02,  1.7524e-01,  1.1089e-01,  ..., -2.3913e-03,\n",
       "            6.3422e-02,  2.2222e-01],\n",
       "          [-5.4117e-02, -9.3127e-04, -1.3712e-01,  ..., -7.2513e-02,\n",
       "            7.5968e-02, -2.8270e-03]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.net[0].taskOp.segment_semantic.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-1.8881e-03,  1.8505e-02,  4.4373e-02,  ..., -1.2325e-02,\n",
       "           -4.9379e-02, -4.5097e-02],\n",
       "          [ 9.0981e-02,  4.1538e-02,  2.7948e-02,  ...,  1.1081e-01,\n",
       "            5.2511e-02, -2.9954e-02],\n",
       "          [ 8.2137e-02,  1.5644e-01,  7.6825e-02,  ...,  5.3679e-02,\n",
       "           -4.4415e-02, -1.1095e-02],\n",
       "          ...,\n",
       "          [ 7.3310e-03,  6.0403e-03,  1.1486e-01,  ...,  1.0638e-01,\n",
       "           -2.8108e-02,  1.0947e-01],\n",
       "          [ 4.7898e-02,  2.8627e-02,  1.0086e-01,  ...,  9.8602e-02,\n",
       "           -4.2270e-02,  8.3925e-02],\n",
       "          [ 1.5200e-01, -1.0719e-03,  4.9900e-02,  ...,  3.8274e-02,\n",
       "           -4.1196e-02, -3.8045e-02]],\n",
       "\n",
       "         [[ 1.4453e-01,  2.7311e-02,  1.0204e-01,  ...,  4.7457e-02,\n",
       "            3.2276e-03,  7.7583e-02],\n",
       "          [ 7.5282e-02,  4.6295e-02,  1.1917e-01,  ...,  7.4346e-02,\n",
       "            8.8846e-02,  3.4213e-02],\n",
       "          [ 1.2747e-01,  6.2407e-04,  1.4398e-01,  ...,  8.4125e-02,\n",
       "            9.4608e-02, -9.4846e-03],\n",
       "          ...,\n",
       "          [ 1.1121e-01,  2.1481e-02,  4.6624e-02,  ...,  8.4637e-02,\n",
       "            8.9381e-02,  4.6499e-02],\n",
       "          [-5.3406e-03,  1.1978e-01,  8.3513e-02,  ...,  1.4217e-01,\n",
       "           -7.0136e-03,  1.3663e-01],\n",
       "          [ 3.3121e-02,  4.8038e-02,  8.0051e-02,  ..., -2.9424e-03,\n",
       "            9.7495e-02,  3.0149e-02]],\n",
       "\n",
       "         [[ 1.0928e-01,  1.0661e-01, -5.2876e-03,  ...,  4.1116e-02,\n",
       "            1.3826e-01,  6.8635e-02],\n",
       "          [ 5.1532e-02,  8.8661e-02,  1.2679e-01,  ...,  1.1119e-01,\n",
       "            2.2422e-02,  1.1979e-01],\n",
       "          [ 9.1390e-02,  1.3639e-01,  2.7758e-02,  ...,  1.0734e-01,\n",
       "            4.9759e-02, -8.2104e-03],\n",
       "          ...,\n",
       "          [ 6.0015e-02,  1.5993e-01,  1.4492e-01,  ...,  8.7620e-02,\n",
       "            6.7153e-02,  9.6024e-02],\n",
       "          [ 6.8995e-03,  4.6961e-02,  1.1227e-01,  ...,  3.9240e-02,\n",
       "           -5.4205e-03,  2.8307e-02],\n",
       "          [ 4.5946e-02,  4.3813e-02,  1.0798e-02,  ...,  6.9518e-02,\n",
       "           -7.5302e-06,  1.2491e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6683e-02,  4.0883e-02,  1.8854e-03,  ..., -3.5610e-02,\n",
       "            2.0711e-02, -5.5826e-02],\n",
       "          [ 6.5390e-03,  1.4310e-02,  1.2567e-01,  ...,  1.2795e-01,\n",
       "            8.4157e-03, -3.3070e-02],\n",
       "          [-2.4160e-02, -9.2382e-03,  1.2563e-01,  ...,  8.8822e-02,\n",
       "            8.4750e-02,  6.4453e-02],\n",
       "          ...,\n",
       "          [-5.6057e-02, -2.7686e-02, -1.1744e-01,  ..., -1.3452e-01,\n",
       "           -1.1310e-01, -1.0587e-01],\n",
       "          [-9.0233e-02, -1.0198e-01, -1.7668e-01,  ..., -1.5836e-01,\n",
       "           -9.5884e-02, -1.4824e-01],\n",
       "          [-1.3170e-01, -4.3328e-02, -1.9971e-01,  ..., -1.2959e-01,\n",
       "           -1.8088e-01, -1.0824e-01]],\n",
       "\n",
       "         [[ 6.5237e-02,  8.2193e-02, -4.4000e-02,  ...,  5.9249e-02,\n",
       "            7.6291e-02, -5.5090e-02],\n",
       "          [ 5.8939e-02,  8.5619e-02,  9.2491e-02,  ...,  7.8200e-02,\n",
       "            5.2773e-02, -2.5329e-02],\n",
       "          [-2.3218e-02,  5.9611e-02,  1.8186e-01,  ...,  1.1307e-01,\n",
       "            7.1722e-02,  1.0947e-01],\n",
       "          ...,\n",
       "          [-5.9529e-02, -9.7144e-02, -9.9871e-02,  ..., -5.1507e-02,\n",
       "            1.8222e-02, -1.3077e-02],\n",
       "          [-5.7967e-03, -7.0799e-02, -2.1638e-01,  ..., -2.3015e-01,\n",
       "           -1.5042e-01, -4.3843e-02],\n",
       "          [-7.7959e-02, -8.3283e-02, -1.4523e-01,  ..., -2.1414e-01,\n",
       "           -9.7252e-02, -2.0398e-03]],\n",
       "\n",
       "         [[-7.0311e-02,  3.8725e-02,  4.2139e-02,  ..., -2.4517e-03,\n",
       "            5.6167e-02, -6.2173e-03],\n",
       "          [ 8.0540e-02,  7.2283e-02,  6.3451e-02,  ...,  2.0380e-01,\n",
       "            9.8312e-02,  6.0935e-02],\n",
       "          [ 1.1160e-01,  2.7187e-02,  1.6186e-01,  ...,  1.7844e-01,\n",
       "            1.2706e-01,  4.5506e-02],\n",
       "          ...,\n",
       "          [ 2.4663e-02,  2.0921e-02, -1.2830e-02,  ...,  1.0798e-02,\n",
       "           -9.6339e-03, -8.3221e-02],\n",
       "          [-6.9342e-02, -1.0163e-01, -1.4304e-01,  ..., -1.5820e-01,\n",
       "           -4.4681e-02, -4.7298e-02],\n",
       "          [-3.8436e-02, -1.6238e-01, -2.3991e-01,  ..., -1.8330e-01,\n",
       "           -3.4149e-02, -8.4074e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.9152e-02, -3.8948e-02, -1.2797e-01,  ..., -2.0761e-02,\n",
       "            7.0034e-03, -5.8029e-02],\n",
       "          [-1.2377e-01, -9.2795e-02, -1.8889e-01,  ..., -1.1239e-01,\n",
       "            2.8573e-03, -1.3575e-01],\n",
       "          [-7.1021e-02, -5.2340e-02, -1.1218e-01,  ..., -1.4661e-01,\n",
       "           -8.1519e-02, -1.4942e-01],\n",
       "          ...,\n",
       "          [-8.8186e-02, -1.1111e-01, -4.1545e-02,  ..., -5.9266e-02,\n",
       "           -4.8225e-02, -5.9224e-02],\n",
       "          [ 4.1756e-02, -5.5240e-02, -8.9392e-02,  ..., -4.5421e-02,\n",
       "           -1.1895e-01, -8.5804e-02],\n",
       "          [-1.6163e-02,  6.2620e-02,  1.9841e-02,  ...,  2.5227e-03,\n",
       "           -8.8995e-02, -1.2645e-02]],\n",
       "\n",
       "         [[-1.0932e-02, -9.2565e-02, -7.3016e-02,  ..., -1.4462e-01,\n",
       "           -3.5945e-02, -1.1159e-01],\n",
       "          [-3.9224e-02, -1.7961e-01, -1.6024e-01,  ..., -5.4298e-03,\n",
       "           -9.6810e-02, -1.5061e-02],\n",
       "          [-4.2473e-02, -1.1623e-01, -1.5375e-01,  ..., -1.1052e-01,\n",
       "           -9.9568e-02, -1.4858e-01],\n",
       "          ...,\n",
       "          [-2.2643e-02,  5.5030e-02,  7.4580e-03,  ..., -9.5128e-02,\n",
       "            6.2888e-02, -8.1478e-02],\n",
       "          [ 5.1431e-02,  3.8648e-02,  7.1968e-02,  ...,  5.8726e-02,\n",
       "            7.5018e-02, -4.5972e-02],\n",
       "          [-4.4147e-02,  6.7776e-02, -7.9680e-02,  ...,  3.2825e-02,\n",
       "            2.7359e-02,  1.1439e-02]],\n",
       "\n",
       "         [[-1.3977e-01, -4.0036e-02, -2.3115e-02,  ..., -9.3089e-03,\n",
       "           -6.6147e-02, -3.1765e-02],\n",
       "          [-8.6717e-02, -1.5617e-01, -1.3510e-01,  ..., -7.7681e-03,\n",
       "           -1.0239e-01, -8.3606e-02],\n",
       "          [-1.5576e-01, -1.2300e-01, -5.4681e-02,  ..., -1.3348e-01,\n",
       "           -3.8712e-02, -5.6399e-02],\n",
       "          ...,\n",
       "          [-1.4161e-02, -1.3291e-01,  6.6734e-03,  ..., -4.3878e-02,\n",
       "            1.6141e-02,  2.0091e-02],\n",
       "          [-5.9224e-02,  8.6859e-03,  5.9822e-02,  ..., -7.6480e-02,\n",
       "           -6.5007e-02, -1.2244e-01],\n",
       "          [-9.6133e-02, -4.1339e-02, -1.0000e-01,  ..., -4.3956e-02,\n",
       "            1.1956e-02, -1.0825e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.6009e-01, -1.9781e-01, -2.0495e-01,  ..., -2.4006e-01,\n",
       "           -2.0049e-01, -2.1981e-01],\n",
       "          [-1.1412e-01, -1.8976e-01, -2.3827e-01,  ..., -3.5196e-01,\n",
       "           -3.1394e-01, -2.2623e-01],\n",
       "          [-2.7263e-01, -2.0449e-01, -2.6106e-01,  ..., -2.6931e-01,\n",
       "           -3.4568e-01, -3.1177e-01],\n",
       "          ...,\n",
       "          [ 1.2993e-01,  6.8711e-02,  1.8003e-01,  ...,  1.4971e-01,\n",
       "            2.7778e-02,  5.9070e-03],\n",
       "          [ 6.1805e-01,  4.1368e-01,  4.4756e-01,  ...,  6.5496e-01,\n",
       "            7.3237e-01,  7.2099e-01],\n",
       "          [ 1.0684e-01,  2.4300e-01,  3.5639e-01,  ...,  2.4212e-01,\n",
       "            1.9912e-01, -3.7643e-02]],\n",
       "\n",
       "         [[-2.2964e-01, -3.9647e-01, -5.1924e-01,  ..., -3.9028e-01,\n",
       "           -2.3974e-01, -1.7248e-01],\n",
       "          [-3.2909e-01, -5.1372e-01, -6.3841e-01,  ..., -4.6136e-01,\n",
       "           -3.8922e-01, -2.9042e-01],\n",
       "          [-4.9083e-01, -4.9362e-01, -5.9250e-01,  ..., -5.7717e-01,\n",
       "           -4.4176e-01, -3.4792e-01],\n",
       "          ...,\n",
       "          [ 9.5847e-02,  6.3920e-02,  1.5848e-01,  ...,  1.5702e-01,\n",
       "           -2.2176e-02, -7.3767e-02],\n",
       "          [ 3.7119e-01,  5.3811e-01,  7.4545e-01,  ...,  7.0009e-01,\n",
       "            4.0607e-01,  3.2723e-01],\n",
       "          [-3.2275e-02,  3.7533e-02,  9.0675e-02,  ...,  1.2375e-01,\n",
       "            8.4111e-02, -3.0541e-02]],\n",
       "\n",
       "         [[ 9.1340e-02, -1.0028e-01, -1.2097e-01,  ..., -3.1570e-01,\n",
       "           -1.7155e-01, -9.5974e-02],\n",
       "          [-1.6211e-01, -3.7429e-01, -3.9909e-01,  ..., -3.6765e-01,\n",
       "           -4.6528e-01, -1.5412e-01],\n",
       "          [-3.2777e-01, -4.3549e-01, -2.7377e-01,  ..., -3.9685e-01,\n",
       "           -4.0161e-01, -5.1445e-01],\n",
       "          ...,\n",
       "          [ 2.2381e-01,  1.4478e-01,  2.2986e-01,  ...,  3.3815e-01,\n",
       "            3.0017e-01,  2.5566e-01],\n",
       "          [ 6.0110e-01,  5.9775e-01,  6.2023e-01,  ...,  7.1481e-01,\n",
       "            7.2459e-01,  7.1145e-01],\n",
       "          [ 1.3323e-01,  2.0006e-01,  3.8098e-01,  ...,  3.7882e-01,\n",
       "            1.7407e-01,  1.6331e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0958e-01,  8.5405e-02,  1.6207e-01,  ...,  1.3733e-02,\n",
       "            1.7304e-01,  2.0652e-01],\n",
       "          [ 2.5334e-01,  1.3793e-01,  1.3710e-01,  ...,  2.0194e-01,\n",
       "            2.1380e-01,  1.6340e-01],\n",
       "          [ 3.0407e-01,  2.1367e-01,  2.4087e-01,  ...,  1.5908e-01,\n",
       "            2.6772e-01,  2.8596e-01],\n",
       "          ...,\n",
       "          [ 2.6788e-01,  2.0282e-01,  2.8065e-01,  ...,  3.2407e-01,\n",
       "            2.5097e-01,  2.4438e-01],\n",
       "          [ 7.9057e-02,  1.8837e-01,  3.3231e-01,  ...,  4.8041e-01,\n",
       "            2.7250e-01,  1.4326e-01],\n",
       "          [ 8.6786e-02,  1.9163e-01,  3.5202e-01,  ...,  4.3784e-01,\n",
       "            3.4447e-01,  2.1363e-01]],\n",
       "\n",
       "         [[-8.5786e-02, -2.5866e-02, -5.2851e-02,  ..., -4.2326e-02,\n",
       "            1.3406e-02, -2.6057e-03],\n",
       "          [-9.9259e-02, -2.6698e-01, -2.6504e-01,  ..., -3.3792e-01,\n",
       "           -3.3015e-01, -2.6936e-02],\n",
       "          [ 3.5468e-02, -3.1086e-02, -4.4233e-02,  ..., -6.5587e-02,\n",
       "           -3.5204e-02,  5.8893e-02],\n",
       "          ...,\n",
       "          [ 1.1945e-01,  1.8033e-01,  1.6820e-01,  ...,  2.5330e-01,\n",
       "            2.5018e-01,  7.5003e-02],\n",
       "          [ 7.6678e-02,  3.3485e-01,  4.1735e-01,  ...,  5.0506e-01,\n",
       "            4.0683e-01,  1.8820e-01],\n",
       "          [ 1.5558e-01,  3.1569e-01,  3.3694e-01,  ...,  4.7152e-01,\n",
       "            3.0406e-01,  2.5056e-01]],\n",
       "\n",
       "         [[ 7.6451e-02,  3.1400e-02, -3.8363e-02,  ...,  2.1706e-02,\n",
       "           -1.6686e-03,  5.8998e-02],\n",
       "          [ 3.5040e-02,  6.3375e-02, -6.7294e-02,  ...,  2.4780e-02,\n",
       "           -3.7639e-02,  9.8991e-02],\n",
       "          [ 1.3202e-01,  2.9531e-04, -1.1175e-01,  ..., -2.0559e-01,\n",
       "           -8.5566e-02,  7.5696e-02],\n",
       "          ...,\n",
       "          [ 1.8560e-01,  1.9509e-01,  3.5868e-01,  ...,  3.2477e-01,\n",
       "            3.2440e-01,  2.8330e-01],\n",
       "          [ 2.1788e-01,  4.3615e-01,  6.4752e-01,  ...,  6.9252e-01,\n",
       "            5.9177e-01,  3.2042e-01],\n",
       "          [ 2.2971e-01,  3.1784e-01,  4.6639e-01,  ...,  5.8299e-01,\n",
       "            4.1029e-01,  3.1998e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.2384e-02,  1.0712e-01,  4.5798e-02,  ...,  2.1719e-02,\n",
       "           -6.6324e-02, -5.1191e-02],\n",
       "          [-7.2668e-02, -5.8957e-02, -7.4742e-02,  ...,  6.9956e-03,\n",
       "           -3.6493e-02, -1.3680e-01],\n",
       "          [ 3.1078e-02, -1.2669e-02,  8.3280e-02,  ..., -4.6805e-02,\n",
       "           -1.3146e-02, -1.0897e-01],\n",
       "          ...,\n",
       "          [-2.6120e-02,  1.1696e-01,  4.9857e-03,  ...,  1.1745e-01,\n",
       "            3.5596e-02,  9.8396e-03],\n",
       "          [ 2.3642e-02,  1.0695e-01, -4.1315e-03,  ...,  5.7631e-02,\n",
       "           -1.3937e-02,  5.2891e-03],\n",
       "          [ 9.5991e-02,  8.1035e-02,  1.1794e-01,  ...,  1.6321e-02,\n",
       "            6.3304e-02, -5.7973e-02]],\n",
       "\n",
       "         [[ 1.9198e-01,  1.3765e-01,  8.3738e-02,  ...,  3.2911e-02,\n",
       "           -2.4238e-02,  7.1116e-02],\n",
       "          [-4.2372e-03,  5.9821e-02,  1.2987e-01,  ..., -5.0988e-02,\n",
       "            4.6882e-03,  2.2649e-02],\n",
       "          [ 7.9848e-02,  2.5288e-02,  8.8045e-02,  ...,  7.6979e-02,\n",
       "           -5.4888e-02,  1.1912e-02],\n",
       "          ...,\n",
       "          [ 1.6449e-02,  1.3121e-01,  6.6725e-02,  ...,  1.0976e-01,\n",
       "            1.4587e-01,  8.3812e-02],\n",
       "          [ 3.0585e-02,  6.3675e-02,  1.1716e-03,  ...,  7.4248e-02,\n",
       "            1.4842e-01,  9.9108e-02],\n",
       "          [ 9.0442e-02,  9.9373e-02,  2.2783e-02,  ...,  6.4793e-02,\n",
       "            8.6218e-02, -3.9031e-03]],\n",
       "\n",
       "         [[ 8.9923e-02,  2.9298e-02,  1.6825e-01,  ...,  3.4455e-02,\n",
       "            2.4535e-02,  1.1417e-01],\n",
       "          [ 2.3448e-03,  1.5306e-02,  4.9995e-02,  ...,  4.0442e-02,\n",
       "            1.2179e-01,  8.7534e-02],\n",
       "          [ 9.7047e-02,  1.5361e-01,  9.7889e-02,  ..., -1.1014e-02,\n",
       "            9.3893e-02,  3.3833e-02],\n",
       "          ...,\n",
       "          [ 4.0533e-02,  2.7074e-03,  7.9974e-02,  ...,  8.5046e-02,\n",
       "            1.3238e-01,  8.2900e-02],\n",
       "          [ 6.6170e-02,  1.0521e-01,  1.3531e-01,  ...,  4.2043e-03,\n",
       "           -1.2089e-02,  1.3392e-01],\n",
       "          [ 1.2661e-02,  7.5848e-02,  1.1228e-02,  ...,  7.0121e-02,\n",
       "            1.2090e-01, -9.2491e-03]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.net[0].taskOp.depth_zbuffer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTLModel(\n",
      "  (headsDict): ModuleDict(\n",
      "    (segment_semantic): ASPPHeadNode(\n",
      "      (fc1): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc2): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc3): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc4): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (depth_zbuffer): ASPPHeadNode(\n",
      "      (fc1): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc2): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc3): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc4): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (net): ModuleList(\n",
      "    (0): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (1): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (3): PoolNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): AbstractPool(\n",
      "        (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (7): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (10): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (11): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (14): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (17): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (18): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (21): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (24): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (25): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (26): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (27): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (28): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (29): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (30): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (31): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (32): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (33): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (34): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (35): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (36): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (37): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (38): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (39): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (40): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (41): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (42): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (43): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (44): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (45): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (46): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (47): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (48): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (49): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (50): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (51): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (52): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (53): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (54): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (55): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (56): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (57): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (58): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (59): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (60): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "    )\n",
      "    (61): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (62): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (63): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (64): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (65): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (66): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (67): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (68): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (69): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (70): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (71): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (72): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (73): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (74): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (75): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (76): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (77): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (78): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (79): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (80): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (81): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (82): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (83): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (84): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (85): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (86): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (87): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (88): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (89): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (90): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (91): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (92): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (93): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (94): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (95): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (96): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (97): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (98): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (99): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (100): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (101): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (102): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (103): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (104): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "    )\n",
      "    (105): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (106): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (107): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (108): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (109): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (110): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (111): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (112): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (113): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (114): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (115): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (116): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (117): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (118): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (119): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (120): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (121): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (inputNode): InputNode()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mtlmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
