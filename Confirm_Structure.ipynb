{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import pytorch_to_caffe, deeplab_resnet, pytorch_model_visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplab Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = deeplab_resnet.resnet34()\n",
    "# model = models.mobilenet_v2()\n",
    "model = models.mnasnet1_0()\n",
    "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNASNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (8): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand((1,3,224,224))\n",
    "output = newmodel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "MaxPool2DWithIndicesBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = pytorch_model_visual.make_dot(output)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Transform, This will take a while\n",
      "46921146733408:blob1 was added to blobs\n",
      "torch ops name: {Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (8): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "  )\n",
      "): '', Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (8): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (9): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (10): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (11): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (12): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (13): Sequential(\n",
      "    (0): _InvertedResidual(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (14): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace=True)\n",
      "): '0', Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): '0.0', BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.1', ReLU(inplace=True): '0.2', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False): '0.3', BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.4', ReLU(inplace=True): '0.5', Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.6', BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "      (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "      (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "      (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.8', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.8.0', Sequential(\n",
      "  (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.8.0.layers', Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.0.layers.0', BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.0.layers.1', ReLU(inplace=True): '0.8.0.layers.2', Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False): '0.8.0.layers.3', BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.0.layers.4', ReLU(inplace=True): '0.8.0.layers.5', Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.0.layers.6', BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.0.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "    (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.8.1', Sequential(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.8.1.layers', Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.1.layers.0', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.1.layers.1', ReLU(inplace=True): '0.8.1.layers.2', Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False): '0.8.1.layers.3', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.1.layers.4', ReLU(inplace=True): '0.8.1.layers.5', Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.1.layers.6', BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.1.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "    (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.8.2', Sequential(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.8.2.layers', Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.2.layers.0', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.2.layers.1', ReLU(inplace=True): '0.8.2.layers.2', Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False): '0.8.2.layers.3', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.2.layers.4', ReLU(inplace=True): '0.8.2.layers.5', Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.8.2.layers.6', BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.8.2.layers.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "      (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "      (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "      (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.9', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "    (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.9.0', Sequential(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.9.0.layers', Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.0.layers.0', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.0.layers.1', ReLU(inplace=True): '0.9.0.layers.2', Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False): '0.9.0.layers.3', BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.0.layers.4', ReLU(inplace=True): '0.9.0.layers.5', Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.0.layers.6', BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.0.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "    (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.9.1', Sequential(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.9.1.layers', Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.1.layers.0', BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.1.layers.1', ReLU(inplace=True): '0.9.1.layers.2', Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False): '0.9.1.layers.3', BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.1.layers.4', ReLU(inplace=True): '0.9.1.layers.5', Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.1.layers.6', BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.1.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "    (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.9.2', Sequential(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.9.2.layers', Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.2.layers.0', BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.2.layers.1', ReLU(inplace=True): '0.9.2.layers.2', Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False): '0.9.2.layers.3', BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.2.layers.4', ReLU(inplace=True): '0.9.2.layers.5', Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.9.2.layers.6', BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.9.2.layers.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "      (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "      (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "      (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.10', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "    (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.10.0', Sequential(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "  (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.10.0.layers', Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.0.layers.0', BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.0.layers.1', ReLU(inplace=True): '0.10.0.layers.2', Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False): '0.10.0.layers.3', BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.0.layers.4', ReLU(inplace=True): '0.10.0.layers.5', Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.0.layers.6', BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.0.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "    (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.10.1', Sequential(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.10.1.layers', Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.1.layers.0', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.1.layers.1', ReLU(inplace=True): '0.10.1.layers.2', Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False): '0.10.1.layers.3', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.1.layers.4', ReLU(inplace=True): '0.10.1.layers.5', Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.1.layers.6', BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.1.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "    (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.10.2', Sequential(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.10.2.layers', Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.2.layers.0', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.2.layers.1', ReLU(inplace=True): '0.10.2.layers.2', Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False): '0.10.2.layers.3', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.2.layers.4', ReLU(inplace=True): '0.10.2.layers.5', Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.10.2.layers.6', BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.10.2.layers.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "      (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.11', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "    (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.11.0', Sequential(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.11.0.layers', Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.11.0.layers.0', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.0.layers.1', ReLU(inplace=True): '0.11.0.layers.2', Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False): '0.11.0.layers.3', BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.0.layers.4', ReLU(inplace=True): '0.11.0.layers.5', Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.11.0.layers.6', BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.0.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "    (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.11.1', Sequential(\n",
      "  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "  (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.11.1.layers', Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.11.1.layers.0', BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.1.layers.1', ReLU(inplace=True): '0.11.1.layers.2', Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False): '0.11.1.layers.3', BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.1.layers.4', ReLU(inplace=True): '0.11.1.layers.5', Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.11.1.layers.6', BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.11.1.layers.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "      (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.12', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "    (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.12.0', Sequential(\n",
      "  (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "  (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.12.0.layers', Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.0.layers.0', BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.0.layers.1', ReLU(inplace=True): '0.12.0.layers.2', Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False): '0.12.0.layers.3', BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.0.layers.4', ReLU(inplace=True): '0.12.0.layers.5', Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.0.layers.6', BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.0.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "    (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.12.1', Sequential(\n",
      "  (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "  (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.12.1.layers', Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.1.layers.0', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.1.layers.1', ReLU(inplace=True): '0.12.1.layers.2', Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False): '0.12.1.layers.3', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.1.layers.4', ReLU(inplace=True): '0.12.1.layers.5', Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.1.layers.6', BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.1.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "    (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.12.2', Sequential(\n",
      "  (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "  (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.12.2.layers', Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.2.layers.0', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.2.layers.1', ReLU(inplace=True): '0.12.2.layers.2', Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False): '0.12.2.layers.3', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.2.layers.4', ReLU(inplace=True): '0.12.2.layers.5', Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.2.layers.6', BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.2.layers.7', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "    (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.12.3', Sequential(\n",
      "  (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "  (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.12.3.layers', Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.3.layers.0', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.3.layers.1', ReLU(inplace=True): '0.12.3.layers.2', Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False): '0.12.3.layers.3', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.3.layers.4', ReLU(inplace=True): '0.12.3.layers.5', Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.12.3.layers.6', BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.12.3.layers.7', Sequential(\n",
      "  (0): _InvertedResidual(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "      (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "): '0.13', _InvertedResidual(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "    (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  )\n",
      "): '0.13.0', Sequential(\n",
      "  (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "  (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "): '0.13.0.layers', Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.13.0.layers.0', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.13.0.layers.1', ReLU(inplace=True): '0.13.0.layers.2', Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False): '0.13.0.layers.3', BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.13.0.layers.4', ReLU(inplace=True): '0.13.0.layers.5', Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.13.0.layers.6', BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.13.0.layers.7', Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False): '0.14', BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True): '0.15', ReLU(inplace=True): '0.16'}\n",
      "0.0\n",
      "conv:  blob1\n",
      "conv1 was added to layers\n",
      "46921143276816:conv_blob1 was added to blobs\n",
      "0.1\n",
      "batch_norm1 was added to layers\n",
      "46921146733840:batch_norm_blob1 was added to blobs\n",
      "0.2\n",
      "relu1 was added to layers\n",
      "46921146733768:relu_blob1 was added to blobs\n",
      "0.3\n",
      "conv:  relu_blob1\n",
      "conv2 was added to layers\n",
      "46921146734056:conv_blob2 was added to blobs\n",
      "0.4\n",
      "batch_norm2 was added to layers\n",
      "46921146734128:batch_norm_blob2 was added to blobs\n",
      "0.5\n",
      "relu2 was added to layers\n",
      "46921146733984:relu_blob2 was added to blobs\n",
      "0.6\n",
      "conv:  relu_blob2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3 was added to layers\n",
      "46921146735352:conv_blob3 was added to blobs\n",
      "0.7\n",
      "batch_norm3 was added to layers\n",
      "46921155105992:batch_norm_blob3 was added to blobs\n",
      "0.8.0.layers.0\n",
      "conv:  batch_norm_blob3\n",
      "conv4 was added to layers\n",
      "46912673218064:conv_blob4 was added to blobs\n",
      "0.8.0.layers.1\n",
      "batch_norm4 was added to layers\n",
      "46921155106136:batch_norm_blob4 was added to blobs\n",
      "0.8.0.layers.2\n",
      "relu3 was added to layers\n",
      "46921155106208:relu_blob3 was added to blobs\n",
      "0.8.0.layers.3\n",
      "conv:  relu_blob3\n",
      "conv5 was added to layers\n",
      "46921155106424:conv_blob5 was added to blobs\n",
      "0.8.0.layers.4\n",
      "batch_norm5 was added to layers\n",
      "46921155106496:batch_norm_blob5 was added to blobs\n",
      "0.8.0.layers.5\n",
      "relu4 was added to layers\n",
      "46921155106352:relu_blob4 was added to blobs\n",
      "0.8.0.layers.6\n",
      "conv:  relu_blob4\n",
      "conv6 was added to layers\n",
      "46921155106712:conv_blob6 was added to blobs\n",
      "0.8.0.layers.7\n",
      "batch_norm6 was added to layers\n",
      "46921155106784:batch_norm_blob6 was added to blobs\n",
      "0.8.1.layers.0\n",
      "conv:  batch_norm_blob6\n",
      "conv7 was added to layers\n",
      "46921143276960:conv_blob7 was added to blobs\n",
      "0.8.1.layers.1\n",
      "batch_norm7 was added to layers\n",
      "46921155107000:batch_norm_blob7 was added to blobs\n",
      "0.8.1.layers.2\n",
      "relu5 was added to layers\n",
      "46921155106640:relu_blob5 was added to blobs\n",
      "0.8.1.layers.3\n",
      "conv:  relu_blob5\n",
      "conv8 was added to layers\n",
      "46921155107144:conv_blob8 was added to blobs\n",
      "0.8.1.layers.4\n",
      "batch_norm8 was added to layers\n",
      "46921155107216:batch_norm_blob8 was added to blobs\n",
      "0.8.1.layers.5\n",
      "relu6 was added to layers\n",
      "46921155107072:relu_blob6 was added to blobs\n",
      "0.8.1.layers.6\n",
      "conv:  relu_blob6\n",
      "conv9 was added to layers\n",
      "46921155107432:conv_blob9 was added to blobs\n",
      "0.8.1.layers.7\n",
      "batch_norm9 was added to layers\n",
      "46921155107504:batch_norm_blob9 was added to blobs\n",
      "add1 was added to layers\n",
      "46921155107360:add_blob1 was added to blobs\n",
      "0.8.2.layers.0\n",
      "conv:  add_blob1\n",
      "conv10 was added to layers\n",
      "46921155107720:conv_blob10 was added to blobs\n",
      "0.8.2.layers.1\n",
      "batch_norm10 was added to layers\n",
      "46921155107792:batch_norm_blob10 was added to blobs\n",
      "0.8.2.layers.2\n",
      "relu7 was added to layers\n",
      "46921155107648:relu_blob7 was added to blobs\n",
      "0.8.2.layers.3\n",
      "conv:  relu_blob7\n",
      "conv11 was added to layers\n",
      "46921155108008:conv_blob11 was added to blobs\n",
      "0.8.2.layers.4\n",
      "batch_norm11 was added to layers\n",
      "46921155108080:batch_norm_blob11 was added to blobs\n",
      "0.8.2.layers.5\n",
      "relu8 was added to layers\n",
      "46921155107936:relu_blob8 was added to blobs\n",
      "0.8.2.layers.6\n",
      "conv:  relu_blob8\n",
      "conv12 was added to layers\n",
      "46921155108296:conv_blob12 was added to blobs\n",
      "0.8.2.layers.7\n",
      "batch_norm12 was added to layers\n",
      "46921155108368:batch_norm_blob12 was added to blobs\n",
      "add2 was added to layers\n",
      "46921155108224:add_blob2 was added to blobs\n",
      "0.9.0.layers.0\n",
      "conv:  add_blob2\n",
      "conv13 was added to layers\n",
      "46921155108584:conv_blob13 was added to blobs\n",
      "0.9.0.layers.1\n",
      "batch_norm13 was added to layers\n",
      "46921155108656:batch_norm_blob13 was added to blobs\n",
      "0.9.0.layers.2\n",
      "relu9 was added to layers\n",
      "46921155108512:relu_blob9 was added to blobs\n",
      "0.9.0.layers.3\n",
      "conv:  relu_blob9\n",
      "conv14 was added to layers\n",
      "46921155108800:conv_blob14 was added to blobs\n",
      "0.9.0.layers.4\n",
      "batch_norm14 was added to layers\n",
      "46921155022992:batch_norm_blob14 was added to blobs\n",
      "0.9.0.layers.5\n",
      "relu10 was added to layers\n",
      "46921155022920:relu_blob10 was added to blobs\n",
      "0.9.0.layers.6\n",
      "conv:  relu_blob10\n",
      "conv15 was added to layers\n",
      "46921155023208:conv_blob15 was added to blobs\n",
      "0.9.0.layers.7\n",
      "batch_norm15 was added to layers\n",
      "46921155023280:batch_norm_blob15 was added to blobs\n",
      "0.9.1.layers.0\n",
      "conv:  batch_norm_blob15\n",
      "conv16 was added to layers\n",
      "46921155023136:conv_blob16 was added to blobs\n",
      "0.9.1.layers.1\n",
      "batch_norm16 was added to layers\n",
      "46921155023424:batch_norm_blob16 was added to blobs\n",
      "0.9.1.layers.2\n",
      "relu11 was added to layers\n",
      "46921155023496:relu_blob11 was added to blobs\n",
      "0.9.1.layers.3\n",
      "conv:  relu_blob11\n",
      "conv17 was added to layers\n",
      "46921155023712:conv_blob17 was added to blobs\n",
      "0.9.1.layers.4\n",
      "batch_norm17 was added to layers\n",
      "46921155023784:batch_norm_blob17 was added to blobs\n",
      "0.9.1.layers.5\n",
      "relu12 was added to layers\n",
      "46921155023640:relu_blob12 was added to blobs\n",
      "0.9.1.layers.6\n",
      "conv:  relu_blob12\n",
      "conv18 was added to layers\n",
      "46921155024000:conv_blob18 was added to blobs\n",
      "0.9.1.layers.7\n",
      "batch_norm18 was added to layers\n",
      "46921155024072:batch_norm_blob18 was added to blobs\n",
      "add3 was added to layers\n",
      "46921155023928:add_blob3 was added to blobs\n",
      "0.9.2.layers.0\n",
      "conv:  add_blob3\n",
      "conv19 was added to layers\n",
      "46921155024288:conv_blob19 was added to blobs\n",
      "0.9.2.layers.1\n",
      "batch_norm19 was added to layers\n",
      "46921155024360:batch_norm_blob19 was added to blobs\n",
      "0.9.2.layers.2\n",
      "relu13 was added to layers\n",
      "46921155024216:relu_blob13 was added to blobs\n",
      "0.9.2.layers.3\n",
      "conv:  relu_blob13\n",
      "conv20 was added to layers\n",
      "46921155024576:conv_blob20 was added to blobs\n",
      "0.9.2.layers.4\n",
      "batch_norm20 was added to layers\n",
      "46921155024648:batch_norm_blob20 was added to blobs\n",
      "0.9.2.layers.5\n",
      "relu14 was added to layers\n",
      "46921155024504:relu_blob14 was added to blobs\n",
      "0.9.2.layers.6\n",
      "conv:  relu_blob14\n",
      "conv21 was added to layers\n",
      "46921155024864:conv_blob21 was added to blobs\n",
      "0.9.2.layers.7\n",
      "batch_norm21 was added to layers\n",
      "46921155024936:batch_norm_blob21 was added to blobs\n",
      "add4 was added to layers\n",
      "46921155024792:add_blob4 was added to blobs\n",
      "0.10.0.layers.0\n",
      "conv:  add_blob4\n",
      "conv22 was added to layers\n",
      "46921155025152:conv_blob22 was added to blobs\n",
      "0.10.0.layers.1\n",
      "batch_norm22 was added to layers\n",
      "46921155025224:batch_norm_blob22 was added to blobs\n",
      "0.10.0.layers.2\n",
      "relu15 was added to layers\n",
      "46921155025080:relu_blob15 was added to blobs\n",
      "0.10.0.layers.3\n",
      "conv:  relu_blob15\n",
      "conv23 was added to layers\n",
      "46921155025440:conv_blob23 was added to blobs\n",
      "0.10.0.layers.4\n",
      "batch_norm23 was added to layers\n",
      "46921155025512:batch_norm_blob23 was added to blobs\n",
      "0.10.0.layers.5\n",
      "relu16 was added to layers\n",
      "46921155025368:relu_blob16 was added to blobs\n",
      "0.10.0.layers.6\n",
      "conv:  relu_blob16\n",
      "conv24 was added to layers\n",
      "46921155025728:conv_blob24 was added to blobs\n",
      "0.10.0.layers.7\n",
      "batch_norm24 was added to layers\n",
      "46921155025800:batch_norm_blob24 was added to blobs\n",
      "0.10.1.layers.0\n",
      "conv:  batch_norm_blob24\n",
      "conv25 was added to layers\n",
      "46921155025656:conv_blob25 was added to blobs\n",
      "0.10.1.layers.1\n",
      "batch_norm25 was added to layers\n",
      "46921155025944:batch_norm_blob25 was added to blobs\n",
      "0.10.1.layers.2\n",
      "relu17 was added to layers\n",
      "46921155026016:relu_blob17 was added to blobs\n",
      "0.10.1.layers.3\n",
      "conv:  relu_blob17\n",
      "conv26 was added to layers\n",
      "46921155026232:conv_blob26 was added to blobs\n",
      "0.10.1.layers.4\n",
      "batch_norm26 was added to layers\n",
      "46921155026304:batch_norm_blob26 was added to blobs\n",
      "0.10.1.layers.5\n",
      "relu18 was added to layers\n",
      "46921155026160:relu_blob18 was added to blobs\n",
      "0.10.1.layers.6\n",
      "conv:  relu_blob18\n",
      "conv27 was added to layers\n",
      "46921155026520:conv_blob27 was added to blobs\n",
      "0.10.1.layers.7\n",
      "batch_norm27 was added to layers\n",
      "46921155026592:batch_norm_blob27 was added to blobs\n",
      "add5 was added to layers\n",
      "46921155026448:add_blob5 was added to blobs\n",
      "0.10.2.layers.0\n",
      "conv:  add_blob5\n",
      "conv28 was added to layers\n",
      "46921155026808:conv_blob28 was added to blobs\n",
      "0.10.2.layers.1\n",
      "batch_norm28 was added to layers\n",
      "46921155026880:batch_norm_blob28 was added to blobs\n",
      "0.10.2.layers.2\n",
      "relu19 was added to layers\n",
      "46921155026736:relu_blob19 was added to blobs\n",
      "0.10.2.layers.3\n",
      "conv:  relu_blob19\n",
      "conv29 was added to layers\n",
      "46921155072216:conv_blob29 was added to blobs\n",
      "0.10.2.layers.4\n",
      "batch_norm29 was added to layers\n",
      "46921155072288:batch_norm_blob29 was added to blobs\n",
      "0.10.2.layers.5\n",
      "relu20 was added to layers\n",
      "46921155072144:relu_blob20 was added to blobs\n",
      "0.10.2.layers.6\n",
      "conv:  relu_blob20\n",
      "conv30 was added to layers\n",
      "46921155072504:conv_blob30 was added to blobs\n",
      "0.10.2.layers.7\n",
      "batch_norm30 was added to layers\n",
      "46921155072576:batch_norm_blob30 was added to blobs\n",
      "add6 was added to layers\n",
      "46921155072432:add_blob6 was added to blobs\n",
      "0.11.0.layers.0\n",
      "conv:  add_blob6\n",
      "conv31 was added to layers\n",
      "46921155072792:conv_blob31 was added to blobs\n",
      "0.11.0.layers.1\n",
      "batch_norm31 was added to layers\n",
      "46921155072864:batch_norm_blob31 was added to blobs\n",
      "0.11.0.layers.2\n",
      "relu21 was added to layers\n",
      "46921155072720:relu_blob21 was added to blobs\n",
      "0.11.0.layers.3\n",
      "conv:  relu_blob21\n",
      "conv32 was added to layers\n",
      "46921155073080:conv_blob32 was added to blobs\n",
      "0.11.0.layers.4\n",
      "batch_norm32 was added to layers\n",
      "46921155073152:batch_norm_blob32 was added to blobs\n",
      "0.11.0.layers.5\n",
      "relu22 was added to layers\n",
      "46921155073008:relu_blob22 was added to blobs\n",
      "0.11.0.layers.6\n",
      "conv:  relu_blob22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv33 was added to layers\n",
      "46921155073368:conv_blob33 was added to blobs\n",
      "0.11.0.layers.7\n",
      "batch_norm33 was added to layers\n",
      "46921155073440:batch_norm_blob33 was added to blobs\n",
      "0.11.1.layers.0\n",
      "conv:  batch_norm_blob33\n",
      "conv34 was added to layers\n",
      "46921155073296:conv_blob34 was added to blobs\n",
      "0.11.1.layers.1\n",
      "batch_norm34 was added to layers\n",
      "46921155073584:batch_norm_blob34 was added to blobs\n",
      "0.11.1.layers.2\n",
      "relu23 was added to layers\n",
      "46921155073656:relu_blob23 was added to blobs\n",
      "0.11.1.layers.3\n",
      "conv:  relu_blob23\n",
      "conv35 was added to layers\n",
      "46921155073872:conv_blob35 was added to blobs\n",
      "0.11.1.layers.4\n",
      "batch_norm35 was added to layers\n",
      "46921155073944:batch_norm_blob35 was added to blobs\n",
      "0.11.1.layers.5\n",
      "relu24 was added to layers\n",
      "46921155073800:relu_blob24 was added to blobs\n",
      "0.11.1.layers.6\n",
      "conv:  relu_blob24\n",
      "conv36 was added to layers\n",
      "46921155074160:conv_blob36 was added to blobs\n",
      "0.11.1.layers.7\n",
      "batch_norm36 was added to layers\n",
      "46921155074232:batch_norm_blob36 was added to blobs\n",
      "add7 was added to layers\n",
      "46921155074088:add_blob7 was added to blobs\n",
      "0.12.0.layers.0\n",
      "conv:  add_blob7\n",
      "conv37 was added to layers\n",
      "46921155074448:conv_blob37 was added to blobs\n",
      "0.12.0.layers.1\n",
      "batch_norm37 was added to layers\n",
      "46921155074520:batch_norm_blob37 was added to blobs\n",
      "0.12.0.layers.2\n",
      "relu25 was added to layers\n",
      "46921155074376:relu_blob25 was added to blobs\n",
      "0.12.0.layers.3\n",
      "conv:  relu_blob25\n",
      "conv38 was added to layers\n",
      "46921155074736:conv_blob38 was added to blobs\n",
      "0.12.0.layers.4\n",
      "batch_norm38 was added to layers\n",
      "46921155074808:batch_norm_blob38 was added to blobs\n",
      "0.12.0.layers.5\n",
      "relu26 was added to layers\n",
      "46921155074664:relu_blob26 was added to blobs\n",
      "0.12.0.layers.6\n",
      "conv:  relu_blob26\n",
      "conv39 was added to layers\n",
      "46921155075024:conv_blob39 was added to blobs\n",
      "0.12.0.layers.7\n",
      "batch_norm39 was added to layers\n",
      "46921155075096:batch_norm_blob39 was added to blobs\n",
      "0.12.1.layers.0\n",
      "conv:  batch_norm_blob39\n",
      "conv40 was added to layers\n",
      "46921155074952:conv_blob40 was added to blobs\n",
      "0.12.1.layers.1\n",
      "batch_norm40 was added to layers\n",
      "46921155075240:batch_norm_blob40 was added to blobs\n",
      "0.12.1.layers.2\n",
      "relu27 was added to layers\n",
      "46921155075312:relu_blob27 was added to blobs\n",
      "0.12.1.layers.3\n",
      "conv:  relu_blob27\n",
      "conv41 was added to layers\n",
      "46921155075528:conv_blob41 was added to blobs\n",
      "0.12.1.layers.4\n",
      "batch_norm41 was added to layers\n",
      "46921155075600:batch_norm_blob41 was added to blobs\n",
      "0.12.1.layers.5\n",
      "relu28 was added to layers\n",
      "46921155075456:relu_blob28 was added to blobs\n",
      "0.12.1.layers.6\n",
      "conv:  relu_blob28\n",
      "conv42 was added to layers\n",
      "46921155075816:conv_blob42 was added to blobs\n",
      "0.12.1.layers.7\n",
      "batch_norm42 was added to layers\n",
      "46921155075888:batch_norm_blob42 was added to blobs\n",
      "add8 was added to layers\n",
      "46921155075744:add_blob8 was added to blobs\n",
      "0.12.2.layers.0\n",
      "conv:  add_blob8\n",
      "conv43 was added to layers\n",
      "46921155076032:conv_blob43 was added to blobs\n",
      "0.12.2.layers.1\n",
      "batch_norm43 was added to layers\n",
      "46921155084432:batch_norm_blob43 was added to blobs\n",
      "0.12.2.layers.2\n",
      "relu29 was added to layers\n",
      "46921155084360:relu_blob29 was added to blobs\n",
      "0.12.2.layers.3\n",
      "conv:  relu_blob29\n",
      "conv44 was added to layers\n",
      "46921155084648:conv_blob44 was added to blobs\n",
      "0.12.2.layers.4\n",
      "batch_norm44 was added to layers\n",
      "46921155084720:batch_norm_blob44 was added to blobs\n",
      "0.12.2.layers.5\n",
      "relu30 was added to layers\n",
      "46921155084576:relu_blob30 was added to blobs\n",
      "0.12.2.layers.6\n",
      "conv:  relu_blob30\n",
      "conv45 was added to layers\n",
      "46921155084936:conv_blob45 was added to blobs\n",
      "0.12.2.layers.7\n",
      "batch_norm45 was added to layers\n",
      "46921155085008:batch_norm_blob45 was added to blobs\n",
      "add9 was added to layers\n",
      "46921155084864:add_blob9 was added to blobs\n",
      "0.12.3.layers.0\n",
      "conv:  add_blob9\n",
      "conv46 was added to layers\n",
      "46921155085224:conv_blob46 was added to blobs\n",
      "0.12.3.layers.1\n",
      "batch_norm46 was added to layers\n",
      "46921155085296:batch_norm_blob46 was added to blobs\n",
      "0.12.3.layers.2\n",
      "relu31 was added to layers\n",
      "46921155085152:relu_blob31 was added to blobs\n",
      "0.12.3.layers.3\n",
      "conv:  relu_blob31\n",
      "conv47 was added to layers\n",
      "46921155085512:conv_blob47 was added to blobs\n",
      "0.12.3.layers.4\n",
      "batch_norm47 was added to layers\n",
      "46921155085584:batch_norm_blob47 was added to blobs\n",
      "0.12.3.layers.5\n",
      "relu32 was added to layers\n",
      "46921155085440:relu_blob32 was added to blobs\n",
      "0.12.3.layers.6\n",
      "conv:  relu_blob32\n",
      "conv48 was added to layers\n",
      "46921155085800:conv_blob48 was added to blobs\n",
      "0.12.3.layers.7\n",
      "batch_norm48 was added to layers\n",
      "46921155085872:batch_norm_blob48 was added to blobs\n",
      "add10 was added to layers\n",
      "46921155085728:add_blob10 was added to blobs\n",
      "0.13.0.layers.0\n",
      "conv:  add_blob10\n",
      "conv49 was added to layers\n",
      "46921155086088:conv_blob49 was added to blobs\n",
      "0.13.0.layers.1\n",
      "batch_norm49 was added to layers\n",
      "46921155086160:batch_norm_blob49 was added to blobs\n",
      "0.13.0.layers.2\n",
      "relu33 was added to layers\n",
      "46921155086016:relu_blob33 was added to blobs\n",
      "0.13.0.layers.3\n",
      "conv:  relu_blob33\n",
      "conv50 was added to layers\n",
      "46921155086376:conv_blob50 was added to blobs\n",
      "0.13.0.layers.4\n",
      "batch_norm50 was added to layers\n",
      "46921155086448:batch_norm_blob50 was added to blobs\n",
      "0.13.0.layers.5\n",
      "relu34 was added to layers\n",
      "46921155086304:relu_blob34 was added to blobs\n",
      "0.13.0.layers.6\n",
      "conv:  relu_blob34\n",
      "conv51 was added to layers\n",
      "46921155086664:conv_blob51 was added to blobs\n",
      "0.13.0.layers.7\n",
      "batch_norm51 was added to layers\n",
      "46921155086736:batch_norm_blob51 was added to blobs\n",
      "0.14\n",
      "conv:  batch_norm_blob51\n",
      "conv52 was added to layers\n",
      "46921155086592:conv_blob52 was added to blobs\n",
      "0.15\n",
      "batch_norm52 was added to layers\n",
      "46921155086880:batch_norm_blob52 was added to blobs\n",
      "0.16\n",
      "relu35 was added to layers\n",
      "46921155086952:relu_blob35 was added to blobs\n",
      "Transform Completed\n"
     ]
    }
   ],
   "source": [
    "name = 'mnasnet2'\n",
    "newmodel.eval()\n",
    "input = torch.autograd.Variable(torch.ones([10,3,224,224]))\n",
    "pytorch_to_caffe.trans_net(newmodel,input,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_to_caffe.save_prototxt('{}.prototxt'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot(var, params=None):\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style=\"filled\", shape=\"box\", align=\"left\", fontsize=\"12\", ranksep=\"0.1\", height=\"0.2\")\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return \"(\" + (\", \").join([\"%d\" % v for v in size]) + \")\"\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor=\"orange\")\n",
    "                dot.edge(str(id(var.grad_fn)), str(id(var)))\n",
    "                var = var.grad_fn\n",
    "            if hasattr(var, \"variable\"):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else \"\"\n",
    "                node_name = \"%s\\n %s\" % (name, size_to_str(u.size()))\n",
    "#                 print(node_name)\n",
    "                \n",
    "                dot.node(str(id(var)), node_name, fillcolor=\"lightblue\")\n",
    "            else:\n",
    "                print(type(var).__name__)\n",
    "                \n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, \"next_functions\"):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, \"saved_tensors\"):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "\n",
    "    add_nodes(var)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddmmBackward\n",
      "MulBackward0\n",
      "ViewBackward\n",
      "ViewBackward\n",
      "MeanBackward1\n",
      "ViewBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "HardtanhBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "TBackward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 3, 224, 224)\n",
    "mobilenet = models.mobilenet_v2()\n",
    "y = mobilenet(inputs)\n",
    "\n",
    "g = make_dot(y)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from framework.mtl_model import MTLModel\n",
    "prototxt = 'models/mobilenetv2.prototxt'\n",
    "mtlmodel = MTLModel(prototxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijunzhang/policymtl2/framework/mtl_model.py:103: UserWarning: No task specified. Return feature.\n",
      "  warnings.warn('No task specified. Return feature.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mtlmodel(inputs, 'common')\n",
    "g = make_dot(y)\n",
    "g.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
