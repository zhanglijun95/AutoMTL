{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from framework.mtl_model import MTLModel\n",
    "from framework.trainer import Trainer\n",
    "from data.dataloader.cityscapes_dataloader import CityScapes\n",
    "from data.heads.pixel2pixel import ASPPHeadNode\n",
    "from data.metrics.pixel2pixel_loss import CityScapesCriterions\n",
    "from data.metrics.pixel2pixel_metrics import CityScapesMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/data/Cityscapes/'\n",
    "\n",
    "headsDict = nn.ModuleDict()\n",
    "trainDataloaderDict = {}\n",
    "valDataloaderDict = {}\n",
    "criterionDict = {}\n",
    "metricDict = {}\n",
    "\n",
    "tasks = ['segment_semantic', 'depth_zbuffer']\n",
    "task_cls_num = {'segment_semantic': 19, 'depth_zbuffer': 1}\n",
    "for task in tasks:\n",
    "    headsDict[task] = ASPPHeadNode(512, task_cls_num[task])\n",
    "\n",
    "    # For model trainer\n",
    "    dataset = CityScapes(dataroot, 'train', task, crop_h=224, crop_w=224)\n",
    "    trainDataloaderDict[task] = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "    dataset = CityScapes(dataroot, 'test', task)\n",
    "    valDataloaderDict[task] = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "    criterionDict[task] = CityScapesCriterions(task)\n",
    "    metricDict[task] = CityScapesMetrics(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prototxt = 'models/deeplab_resnet34_adashare.prototxt'\n",
    "# prototxt = 'models/mobilenetv2.prototxt'\n",
    "# prototxt = 'models/mnasnet.prototxt'\n",
    "mtlmodel = MTLModel(prototxt, headsDict, BNsp=True)\n",
    "mtlmodel = mtlmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(mtlmodel, trainDataloaderDict, valDataloaderDict, criterionDict, metricDict, \n",
    "                  print_iters=100, val_iters=200, policy_update_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2050 Task segm] Train Loss: 0.5143\n",
      "[Iter 2050 Task dept] Train Loss: 0.0217\n",
      "[Iter 2050 Total] Train Loss: 0.2680\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Train Loss: 0.4637\n",
      "[Iter 2100 Task dept] Train Loss: 0.0213\n",
      "[Iter 2100 Total] Train Loss: 0.2425\n",
      "======================================================================\n",
      "[Iter 2150 Task segm] Train Loss: 0.4574\n",
      "[Iter 2150 Task dept] Train Loss: 0.0205\n",
      "[Iter 2150 Total] Train Loss: 0.2389\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Train Loss: 0.4476\n",
      "[Iter 2200 Task dept] Train Loss: 0.0203\n",
      "[Iter 2200 Total] Train Loss: 0.2339\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 0.9370\n",
      "{'mIoU': 0.2595, 'Pixel Acc': 0.6065, 'cmp': -0.2713}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0956\n",
      "{'abs_err': 0.0935, 'rel_err': 2.467, 'sigma_1.25': 26.6127, 'sigma_1.25^2': 42.6742, 'sigma_1.25^3': 51.8795, 'cmp': -2.5088}\n",
      "======================================================================\n",
      "[Iter 2250 Task segm] Train Loss: 0.4394\n",
      "[Iter 2250 Task dept] Train Loss: 0.0201\n",
      "[Iter 2250 Total] Train Loss: 0.2298\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Train Loss: 0.4446\n",
      "[Iter 2300 Task dept] Train Loss: 0.0189\n",
      "[Iter 2300 Total] Train Loss: 0.2317\n",
      "======================================================================\n",
      "[Iter 2350 Task segm] Train Loss: 0.4506\n",
      "[Iter 2350 Task dept] Train Loss: 0.0194\n",
      "[Iter 2350 Total] Train Loss: 0.2350\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Train Loss: 0.4373\n",
      "[Iter 2400 Task dept] Train Loss: 0.0199\n",
      "[Iter 2400 Total] Train Loss: 0.2286\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 1.6052\n",
      "{'mIoU': 0.1696, 'Pixel Acc': 0.5136, 'cmp': -0.4453}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0915\n",
      "{'abs_err': 0.0895, 'rel_err': 2.347, 'sigma_1.25': 26.3131, 'sigma_1.25^2': 43.6865, 'sigma_1.25^3': 53.1667, 'cmp': -2.3847}\n",
      "======================================================================\n",
      "[Iter 2450 Task segm] Train Loss: 0.4226\n",
      "[Iter 2450 Task dept] Train Loss: 0.0187\n",
      "[Iter 2450 Total] Train Loss: 0.2206\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Train Loss: 0.4389\n",
      "[Iter 2500 Task dept] Train Loss: 0.0192\n",
      "[Iter 2500 Total] Train Loss: 0.2291\n",
      "======================================================================\n",
      "[Iter 2550 Task segm] Train Loss: 0.4426\n",
      "[Iter 2550 Task dept] Train Loss: 0.0194\n",
      "[Iter 2550 Total] Train Loss: 0.2310\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Train Loss: 0.4308\n",
      "[Iter 2600 Task dept] Train Loss: 0.0193\n",
      "[Iter 2600 Total] Train Loss: 0.2251\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 1.4627\n",
      "{'mIoU': 0.206, 'Pixel Acc': 0.5554, 'cmp': -0.372}\n",
      "[Iter 2600 Task dept] Val Loss: 0.1030\n",
      "{'abs_err': 0.1016, 'rel_err': 2.6878, 'sigma_1.25': 24.7714, 'sigma_1.25^2': 41.4197, 'sigma_1.25^3': 50.1271, 'cmp': -2.7498}\n",
      "======================================================================\n",
      "[Iter 2650 Task segm] Train Loss: 0.4262\n",
      "[Iter 2650 Task dept] Train Loss: 0.0187\n",
      "[Iter 2650 Total] Train Loss: 0.2224\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Train Loss: 0.4304\n",
      "[Iter 2700 Task dept] Train Loss: 0.0191\n",
      "[Iter 2700 Total] Train Loss: 0.2248\n",
      "======================================================================\n",
      "[Iter 2750 Task segm] Train Loss: 0.4223\n",
      "[Iter 2750 Task dept] Train Loss: 0.0189\n",
      "[Iter 2750 Total] Train Loss: 0.2206\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Train Loss: 0.4216\n",
      "[Iter 2800 Task dept] Train Loss: 0.0186\n",
      "[Iter 2800 Total] Train Loss: 0.2201\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 1.1661\n",
      "{'mIoU': 0.1921, 'Pixel Acc': 0.5684, 'cmp': -0.3806}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0932\n",
      "{'abs_err': 0.0919, 'rel_err': 2.3997, 'sigma_1.25': 24.3676, 'sigma_1.25^2': 44.0692, 'sigma_1.25^3': 53.397, 'cmp': -2.4493}\n",
      "======================================================================\n",
      "[Iter 2850 Task segm] Train Loss: 0.4071\n",
      "[Iter 2850 Task dept] Train Loss: 0.0189\n",
      "[Iter 2850 Total] Train Loss: 0.2130\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Train Loss: 0.4139\n",
      "[Iter 2900 Task dept] Train Loss: 0.0190\n",
      "[Iter 2900 Total] Train Loss: 0.2165\n",
      "======================================================================\n",
      "[Iter 2950 Task segm] Train Loss: 0.4207\n",
      "[Iter 2950 Task dept] Train Loss: 0.0185\n",
      "[Iter 2950 Total] Train Loss: 0.2196\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Train Loss: 0.4068\n",
      "[Iter 3000 Task dept] Train Loss: 0.0184\n",
      "[Iter 3000 Total] Train Loss: 0.2126\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 1.7996\n",
      "{'mIoU': 0.1631, 'Pixel Acc': 0.5134, 'cmp': -0.4535}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0870\n",
      "{'abs_err': 0.0862, 'rel_err': 2.1954, 'sigma_1.25': 23.4835, 'sigma_1.25^2': 45.3944, 'sigma_1.25^3': 55.9754, 'cmp': -2.2522}\n",
      "======================================================================\n",
      "[Iter 3050 Task segm] Train Loss: 0.4077\n",
      "[Iter 3050 Task dept] Train Loss: 0.0190\n",
      "[Iter 3050 Total] Train Loss: 0.2134\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Train Loss: 0.4058\n",
      "[Iter 3100 Task dept] Train Loss: 0.0186\n",
      "[Iter 3100 Total] Train Loss: 0.2122\n",
      "======================================================================\n",
      "[Iter 3150 Task segm] Train Loss: 0.4106\n",
      "[Iter 3150 Task dept] Train Loss: 0.0183\n",
      "[Iter 3150 Total] Train Loss: 0.2144\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Train Loss: 0.4002\n",
      "[Iter 3200 Task dept] Train Loss: 0.0181\n",
      "[Iter 3200 Total] Train Loss: 0.2092\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 1.5426\n",
      "{'mIoU': 0.1639, 'Pixel Acc': 0.5346, 'cmp': -0.4383}\n",
      "[Iter 3200 Task dept] Val Loss: 0.1044\n",
      "{'abs_err': 0.1021, 'rel_err': 2.6546, 'sigma_1.25': 24.3518, 'sigma_1.25^2': 40.7884, 'sigma_1.25^3': 49.9315, 'cmp': -2.7397}\n",
      "======================================================================\n",
      "[Iter 3250 Task segm] Train Loss: 0.4122\n",
      "[Iter 3250 Task dept] Train Loss: 0.0177\n",
      "[Iter 3250 Total] Train Loss: 0.2149\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Train Loss: 0.3964\n",
      "[Iter 3300 Task dept] Train Loss: 0.0183\n",
      "[Iter 3300 Total] Train Loss: 0.2074\n",
      "======================================================================\n",
      "[Iter 3350 Task segm] Train Loss: 0.4159\n",
      "[Iter 3350 Task dept] Train Loss: 0.0181\n",
      "[Iter 3350 Total] Train Loss: 0.2170\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Train Loss: 0.3751\n",
      "[Iter 3400 Task dept] Train Loss: 0.0178\n",
      "[Iter 3400 Total] Train Loss: 0.1964\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.3266\n",
      "{'mIoU': 0.1955, 'Pixel Acc': 0.5611, 'cmp': -0.3813}\n",
      "[Iter 3400 Task dept] Val Loss: 0.1168\n",
      "{'abs_err': 0.1152, 'rel_err': 3.0537, 'sigma_1.25': 23.5151, 'sigma_1.25^2': 38.8866, 'sigma_1.25^3': 47.3895, 'cmp': -3.1476}\n",
      "======================================================================\n",
      "[Iter 3450 Task segm] Train Loss: 0.4098\n",
      "[Iter 3450 Task dept] Train Loss: 0.0178\n",
      "[Iter 3450 Total] Train Loss: 0.2138\n",
      "======================================================================\n",
      "[Iter 3500 Task segm] Train Loss: 0.4013\n",
      "[Iter 3500 Task dept] Train Loss: 0.0174\n",
      "[Iter 3500 Total] Train Loss: 0.2093\n",
      "======================================================================\n",
      "[Iter 3550 Task segm] Train Loss: 0.4062\n",
      "[Iter 3550 Task dept] Train Loss: 0.0177\n",
      "[Iter 3550 Total] Train Loss: 0.2119\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3600 Task segm] Train Loss: 0.3689\n",
      "[Iter 3600 Task dept] Train Loss: 0.0177\n",
      "[Iter 3600 Total] Train Loss: 0.1933\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.4957\n",
      "{'mIoU': 0.1748, 'Pixel Acc': 0.5406, 'cmp': -0.4207}\n",
      "[Iter 3600 Task dept] Val Loss: 0.1065\n",
      "{'abs_err': 0.1044, 'rel_err': 2.7337, 'sigma_1.25': 23.15, 'sigma_1.25^2': 40.9303, 'sigma_1.25^3': 50.0324, 'cmp': -2.8173}\n",
      "======================================================================\n",
      "[Iter 3650 Task segm] Train Loss: 0.4020\n",
      "[Iter 3650 Task dept] Train Loss: 0.0181\n",
      "[Iter 3650 Total] Train Loss: 0.2100\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Train Loss: 0.3951\n",
      "[Iter 3700 Task dept] Train Loss: 0.0176\n",
      "[Iter 3700 Total] Train Loss: 0.2064\n",
      "======================================================================\n",
      "[Iter 3750 Task segm] Train Loss: 0.4014\n",
      "[Iter 3750 Task dept] Train Loss: 0.0171\n",
      "[Iter 3750 Total] Train Loss: 0.2093\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Train Loss: 0.3749\n",
      "[Iter 3800 Task dept] Train Loss: 0.0179\n",
      "[Iter 3800 Total] Train Loss: 0.1964\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.6010\n",
      "{'mIoU': 0.1758, 'Pixel Acc': 0.5505, 'cmp': -0.4129}\n",
      "[Iter 3800 Task dept] Val Loss: 0.1092\n",
      "{'abs_err': 0.1075, 'rel_err': 2.8253, 'sigma_1.25': 22.9117, 'sigma_1.25^2': 40.686, 'sigma_1.25^3': 49.4555, 'cmp': -2.912}\n",
      "======================================================================\n",
      "[Iter 3850 Task segm] Train Loss: 0.3928\n",
      "[Iter 3850 Task dept] Train Loss: 0.0174\n",
      "[Iter 3850 Total] Train Loss: 0.2051\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Train Loss: 0.3753\n",
      "[Iter 3900 Task dept] Train Loss: 0.0169\n",
      "[Iter 3900 Total] Train Loss: 0.1961\n",
      "======================================================================\n",
      "[Iter 3950 Task segm] Train Loss: 0.3833\n",
      "[Iter 3950 Task dept] Train Loss: 0.0175\n",
      "[Iter 3950 Total] Train Loss: 0.2004\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Train Loss: 0.3899\n",
      "[Iter 4000 Task dept] Train Loss: 0.0178\n",
      "[Iter 4000 Total] Train Loss: 0.2039\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.5790\n",
      "{'mIoU': 0.2001, 'Pixel Acc': 0.5446, 'cmp': -0.3866}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0980\n",
      "{'abs_err': 0.0962, 'rel_err': 2.4959, 'sigma_1.25': 23.5905, 'sigma_1.25^2': 42.9878, 'sigma_1.25^3': 52.4618, 'cmp': -2.5654}\n",
      "======================================================================\n",
      "[Iter 4050 Task segm] Train Loss: 0.3799\n",
      "[Iter 4050 Task dept] Train Loss: 0.0178\n",
      "[Iter 4050 Total] Train Loss: 0.1988\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Train Loss: 0.3725\n",
      "[Iter 4100 Task dept] Train Loss: 0.0169\n",
      "[Iter 4100 Total] Train Loss: 0.1947\n",
      "======================================================================\n",
      "[Iter 4150 Task segm] Train Loss: 0.3693\n",
      "[Iter 4150 Task dept] Train Loss: 0.0173\n",
      "[Iter 4150 Total] Train Loss: 0.1933\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Train Loss: 0.3879\n",
      "[Iter 4200 Task dept] Train Loss: 0.0175\n",
      "[Iter 4200 Total] Train Loss: 0.2027\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.7209\n",
      "{'mIoU': 0.1843, 'Pixel Acc': 0.508, 'cmp': -0.4307}\n",
      "[Iter 4200 Task dept] Val Loss: 0.1093\n",
      "{'abs_err': 0.1073, 'rel_err': 2.8056, 'sigma_1.25': 23.1175, 'sigma_1.25^2': 40.455, 'sigma_1.25^3': 49.2892, 'cmp': -2.8978}\n",
      "======================================================================\n",
      "[Iter 4250 Task segm] Train Loss: 0.3819\n",
      "[Iter 4250 Task dept] Train Loss: 0.0179\n",
      "[Iter 4250 Total] Train Loss: 0.1999\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Train Loss: 0.3820\n",
      "[Iter 4300 Task dept] Train Loss: 0.0177\n",
      "[Iter 4300 Total] Train Loss: 0.1998\n",
      "======================================================================\n",
      "[Iter 4350 Task segm] Train Loss: 0.3731\n",
      "[Iter 4350 Task dept] Train Loss: 0.0169\n",
      "[Iter 4350 Total] Train Loss: 0.1950\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Train Loss: 0.3712\n",
      "[Iter 4400 Task dept] Train Loss: 0.0169\n",
      "[Iter 4400 Total] Train Loss: 0.1940\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.7049\n",
      "{'mIoU': 0.1839, 'Pixel Acc': 0.5148, 'cmp': -0.4268}\n",
      "[Iter 4400 Task dept] Val Loss: 0.1019\n",
      "{'abs_err': 0.1, 'rel_err': 2.5899, 'sigma_1.25': 22.3116, 'sigma_1.25^2': 42.2162, 'sigma_1.25^3': 51.6136, 'cmp': -2.6745}\n",
      "======================================================================\n",
      "[Iter 4450 Task segm] Train Loss: 0.3580\n",
      "[Iter 4450 Task dept] Train Loss: 0.0173\n",
      "[Iter 4450 Total] Train Loss: 0.1877\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Train Loss: 0.3718\n",
      "[Iter 4500 Task dept] Train Loss: 0.0177\n",
      "[Iter 4500 Total] Train Loss: 0.1947\n",
      "======================================================================\n",
      "[Iter 4550 Task segm] Train Loss: 0.3698\n",
      "[Iter 4550 Task dept] Train Loss: 0.0170\n",
      "[Iter 4550 Total] Train Loss: 0.1934\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Train Loss: 0.3801\n",
      "[Iter 4600 Task dept] Train Loss: 0.0163\n",
      "[Iter 4600 Total] Train Loss: 0.1982\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.4870\n",
      "{'mIoU': 0.1377, 'Pixel Acc': 0.5097, 'cmp': -0.4875}\n",
      "[Iter 4600 Task dept] Val Loss: 0.1018\n",
      "{'abs_err': 0.0995, 'rel_err': 2.5693, 'sigma_1.25': 23.1304, 'sigma_1.25^2': 41.9427, 'sigma_1.25^3': 51.3815, 'cmp': -2.6548}\n",
      "======================================================================\n",
      "[Iter 4650 Task segm] Train Loss: 0.3640\n",
      "[Iter 4650 Task dept] Train Loss: 0.0168\n",
      "[Iter 4650 Total] Train Loss: 0.1904\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Train Loss: 0.3543\n",
      "[Iter 4700 Task dept] Train Loss: 0.0169\n",
      "[Iter 4700 Total] Train Loss: 0.1856\n",
      "======================================================================\n",
      "[Iter 4750 Task segm] Train Loss: 0.3610\n",
      "[Iter 4750 Task dept] Train Loss: 0.0166\n",
      "[Iter 4750 Total] Train Loss: 0.1888\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Train Loss: 0.3478\n",
      "[Iter 4800 Task dept] Train Loss: 0.0173\n",
      "[Iter 4800 Total] Train Loss: 0.1826\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.5884\n",
      "{'mIoU': 0.1708, 'Pixel Acc': 0.5341, 'cmp': -0.4301}\n",
      "[Iter 4800 Task dept] Val Loss: 0.1332\n",
      "{'abs_err': 0.131, 'rel_err': 3.4052, 'sigma_1.25': 22.5862, 'sigma_1.25^2': 35.1043, 'sigma_1.25^3': 43.9235, 'cmp': -3.565}\n",
      "======================================================================\n",
      "[Iter 4850 Task segm] Train Loss: 0.3623\n",
      "[Iter 4850 Task dept] Train Loss: 0.0171\n",
      "[Iter 4850 Total] Train Loss: 0.1897\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Train Loss: 0.3636\n",
      "[Iter 4900 Task dept] Train Loss: 0.0165\n",
      "[Iter 4900 Total] Train Loss: 0.1901\n",
      "======================================================================\n",
      "[Iter 4950 Task segm] Train Loss: 0.3571\n",
      "[Iter 4950 Task dept] Train Loss: 0.0174\n",
      "[Iter 4950 Total] Train Loss: 0.1873\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Train Loss: 0.3523\n",
      "[Iter 5000 Task dept] Train Loss: 0.0170\n",
      "[Iter 5000 Total] Train Loss: 0.1847\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.2556\n",
      "{'mIoU': 0.1696, 'Pixel Acc': 0.587, 'cmp': -0.3962}\n",
      "[Iter 5000 Task dept] Val Loss: 0.1069\n",
      "{'abs_err': 0.1054, 'rel_err': 2.7392, 'sigma_1.25': 21.7582, 'sigma_1.25^2': 40.9451, 'sigma_1.25^3': 50.5153, 'cmp': -2.8352}\n",
      "======================================================================\n",
      "[Iter 5050 Task segm] Train Loss: 0.3549\n",
      "[Iter 5050 Task dept] Train Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5050 Total] Train Loss: 0.1860\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Train Loss: 0.3613\n",
      "[Iter 5100 Task dept] Train Loss: 0.0170\n",
      "[Iter 5100 Total] Train Loss: 0.1892\n",
      "======================================================================\n",
      "[Iter 5150 Task segm] Train Loss: 0.3385\n",
      "[Iter 5150 Task dept] Train Loss: 0.0164\n",
      "[Iter 5150 Total] Train Loss: 0.1775\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Train Loss: 0.3531\n",
      "[Iter 5200 Task dept] Train Loss: 0.0167\n",
      "[Iter 5200 Total] Train Loss: 0.1849\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 2.5822\n",
      "{'mIoU': 0.1622, 'Pixel Acc': 0.42, 'cmp': -0.5171}\n",
      "[Iter 5200 Task dept] Val Loss: 0.1146\n",
      "{'abs_err': 0.1128, 'rel_err': 2.9495, 'sigma_1.25': 22.2777, 'sigma_1.25^2': 39.269, 'sigma_1.25^3': 48.0924, 'cmp': -3.0574}\n",
      "======================================================================\n",
      "[Iter 5250 Task segm] Train Loss: 0.3570\n",
      "[Iter 5250 Task dept] Train Loss: 0.0162\n",
      "[Iter 5250 Total] Train Loss: 0.1866\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Train Loss: 0.3463\n",
      "[Iter 5300 Task dept] Train Loss: 0.0167\n",
      "[Iter 5300 Total] Train Loss: 0.1815\n",
      "======================================================================\n",
      "[Iter 5350 Task segm] Train Loss: 0.3359\n",
      "[Iter 5350 Task dept] Train Loss: 0.0169\n",
      "[Iter 5350 Total] Train Loss: 0.1764\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Train Loss: 0.3472\n",
      "[Iter 5400 Task dept] Train Loss: 0.0164\n",
      "[Iter 5400 Total] Train Loss: 0.1818\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 2.2982\n",
      "{'mIoU': 0.1742, 'Pixel Acc': 0.5249, 'cmp': -0.4319}\n",
      "[Iter 5400 Task dept] Val Loss: 0.1070\n",
      "{'abs_err': 0.1052, 'rel_err': 2.7384, 'sigma_1.25': 22.1472, 'sigma_1.25^2': 41.0512, 'sigma_1.25^3': 50.3471, 'cmp': -2.8311}\n",
      "======================================================================\n",
      "[Iter 5450 Task segm] Train Loss: 0.3522\n",
      "[Iter 5450 Task dept] Train Loss: 0.0167\n",
      "[Iter 5450 Total] Train Loss: 0.1845\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Train Loss: 0.3465\n",
      "[Iter 5500 Task dept] Train Loss: 0.0166\n",
      "[Iter 5500 Total] Train Loss: 0.1816\n",
      "======================================================================\n",
      "[Iter 5550 Task segm] Train Loss: 0.3459\n",
      "[Iter 5550 Task dept] Train Loss: 0.0166\n",
      "[Iter 5550 Total] Train Loss: 0.1813\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Train Loss: 0.3457\n",
      "[Iter 5600 Task dept] Train Loss: 0.0162\n",
      "[Iter 5600 Total] Train Loss: 0.1809\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.3661\n",
      "{'mIoU': 0.1698, 'Pixel Acc': 0.5739, 'cmp': -0.4047}\n",
      "[Iter 5600 Task dept] Val Loss: 0.1102\n",
      "{'abs_err': 0.1077, 'rel_err': 2.8077, 'sigma_1.25': 23.1905, 'sigma_1.25^2': 40.0115, 'sigma_1.25^3': 49.1428, 'cmp': -2.9043}\n",
      "======================================================================\n",
      "[Iter 5650 Task segm] Train Loss: 0.3549\n",
      "[Iter 5650 Task dept] Train Loss: 0.0164\n",
      "[Iter 5650 Total] Train Loss: 0.1856\n",
      "======================================================================\n",
      "[Iter 5700 Task segm] Train Loss: 0.3521\n",
      "[Iter 5700 Task dept] Train Loss: 0.0170\n",
      "[Iter 5700 Total] Train Loss: 0.1845\n",
      "======================================================================\n",
      "[Iter 5750 Task segm] Train Loss: 0.3392\n",
      "[Iter 5750 Task dept] Train Loss: 0.0162\n",
      "[Iter 5750 Total] Train Loss: 0.1777\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Train Loss: 0.3265\n",
      "[Iter 5800 Task dept] Train Loss: 0.0165\n",
      "[Iter 5800 Total] Train Loss: 0.1715\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.1617\n",
      "{'mIoU': 0.1979, 'Pixel Acc': 0.6056, 'cmp': -0.3485}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0993\n",
      "{'abs_err': 0.0979, 'rel_err': 2.474, 'sigma_1.25': 19.9878, 'sigma_1.25^2': 41.0056, 'sigma_1.25^3': 53.3449, 'cmp': -2.5851}\n",
      "======================================================================\n",
      "[Iter 5850 Task segm] Train Loss: 0.3476\n",
      "[Iter 5850 Task dept] Train Loss: 0.0164\n",
      "[Iter 5850 Total] Train Loss: 0.1820\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Train Loss: 0.3374\n",
      "[Iter 5900 Task dept] Train Loss: 0.0165\n",
      "[Iter 5900 Total] Train Loss: 0.1770\n",
      "======================================================================\n",
      "[Iter 5950 Task segm] Train Loss: 0.3478\n",
      "[Iter 5950 Task dept] Train Loss: 0.0164\n",
      "[Iter 5950 Total] Train Loss: 0.1821\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Train Loss: 0.3401\n",
      "[Iter 6000 Task dept] Train Loss: 0.0167\n",
      "[Iter 6000 Total] Train Loss: 0.1784\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.7790\n",
      "{'mIoU': 0.1641, 'Pixel Acc': 0.5313, 'cmp': -0.4403}\n",
      "[Iter 6000 Task dept] Val Loss: 0.1024\n",
      "{'abs_err': 0.1005, 'rel_err': 2.5782, 'sigma_1.25': 21.1839, 'sigma_1.25^2': 41.7631, 'sigma_1.25^3': 52.0935, 'cmp': -2.6767}\n",
      "======================================================================\n",
      "[Iter 6050 Task segm] Train Loss: 0.3435\n",
      "[Iter 6050 Task dept] Train Loss: 0.0162\n",
      "[Iter 6050 Total] Train Loss: 0.1799\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Train Loss: 0.3269\n",
      "[Iter 6100 Task dept] Train Loss: 0.0165\n",
      "[Iter 6100 Total] Train Loss: 0.1717\n",
      "======================================================================\n",
      "[Iter 6150 Task segm] Train Loss: 0.3426\n",
      "[Iter 6150 Task dept] Train Loss: 0.0162\n",
      "[Iter 6150 Total] Train Loss: 0.1794\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Train Loss: 0.3359\n",
      "[Iter 6200 Task dept] Train Loss: 0.0167\n",
      "[Iter 6200 Total] Train Loss: 0.1763\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 0.9747\n",
      "{'mIoU': 0.2158, 'Pixel Acc': 0.6357, 'cmp': -0.3061}\n",
      "[Iter 6200 Task dept] Val Loss: 0.1047\n",
      "{'abs_err': 0.1028, 'rel_err': 2.6571, 'sigma_1.25': 21.5821, 'sigma_1.25^2': 41.1022, 'sigma_1.25^3': 51.4226, 'cmp': -2.7533}\n",
      "======================================================================\n",
      "[Iter 6250 Task segm] Train Loss: 0.3364\n",
      "[Iter 6250 Task dept] Train Loss: 0.0161\n",
      "[Iter 6250 Total] Train Loss: 0.1763\n",
      "======================================================================\n",
      "[Iter 6300 Task segm] Train Loss: 0.3204\n",
      "[Iter 6300 Task dept] Train Loss: 0.0163\n",
      "[Iter 6300 Total] Train Loss: 0.1684\n",
      "======================================================================\n",
      "[Iter 6350 Task segm] Train Loss: 0.3270\n",
      "[Iter 6350 Task dept] Train Loss: 0.0163\n",
      "[Iter 6350 Total] Train Loss: 0.1717\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Train Loss: 0.3445\n",
      "[Iter 6400 Task dept] Train Loss: 0.0163\n",
      "[Iter 6400 Total] Train Loss: 0.1804\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.6024\n",
      "{'mIoU': 0.1699, 'Pixel Acc': 0.5366, 'cmp': -0.4295}\n",
      "[Iter 6400 Task dept] Val Loss: 0.1019\n",
      "{'abs_err': 0.1, 'rel_err': 2.5857, 'sigma_1.25': 22.6008, 'sigma_1.25^2': 41.9145, 'sigma_1.25^3': 51.7038, 'cmp': -2.671}\n",
      "======================================================================\n",
      "[Iter 6450 Task segm] Train Loss: 0.3472\n",
      "[Iter 6450 Task dept] Train Loss: 0.0160\n",
      "[Iter 6450 Total] Train Loss: 0.1816\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Train Loss: 0.3392\n",
      "[Iter 6500 Task dept] Train Loss: 0.0167\n",
      "[Iter 6500 Total] Train Loss: 0.1780\n",
      "======================================================================\n",
      "[Iter 6550 Task segm] Train Loss: 0.3264\n",
      "[Iter 6550 Task dept] Train Loss: 0.0163\n",
      "[Iter 6550 Total] Train Loss: 0.1713\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Train Loss: 0.3416\n",
      "[Iter 6600 Task dept] Train Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6600 Total] Train Loss: 0.1786\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.7116\n",
      "{'mIoU': 0.1817, 'Pixel Acc': 0.5553, 'cmp': -0.4023}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0850\n",
      "{'abs_err': 0.0833, 'rel_err': 1.9788, 'sigma_1.25': 20.714, 'sigma_1.25^2': 42.4984, 'sigma_1.25^3': 58.2807, 'cmp': -2.0965}\n",
      "======================================================================\n",
      "[Iter 6650 Task segm] Train Loss: 0.3350\n",
      "[Iter 6650 Task dept] Train Loss: 0.0162\n",
      "[Iter 6650 Total] Train Loss: 0.1756\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Train Loss: 0.3217\n",
      "[Iter 6700 Task dept] Train Loss: 0.0161\n",
      "[Iter 6700 Total] Train Loss: 0.1689\n",
      "======================================================================\n",
      "[Iter 6750 Task segm] Train Loss: 0.3357\n",
      "[Iter 6750 Task dept] Train Loss: 0.0163\n",
      "[Iter 6750 Total] Train Loss: 0.1760\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Train Loss: 0.3280\n",
      "[Iter 6800 Task dept] Train Loss: 0.0162\n",
      "[Iter 6800 Total] Train Loss: 0.1721\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.1479\n",
      "{'mIoU': 0.2075, 'Pixel Acc': 0.6085, 'cmp': -0.3346}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0758\n",
      "{'abs_err': 0.0745, 'rel_err': 1.6921, 'sigma_1.25': 21.7334, 'sigma_1.25^2': 44.4366, 'sigma_1.25^3': 62.075, 'cmp': -1.8038}\n",
      "======================================================================\n",
      "[Iter 6850 Task segm] Train Loss: 0.3269\n",
      "[Iter 6850 Task dept] Train Loss: 0.0164\n",
      "[Iter 6850 Total] Train Loss: 0.1716\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Train Loss: 0.3340\n",
      "[Iter 6900 Task dept] Train Loss: 0.0156\n",
      "[Iter 6900 Total] Train Loss: 0.1748\n",
      "======================================================================\n",
      "[Iter 6950 Task segm] Train Loss: 0.3364\n",
      "[Iter 6950 Task dept] Train Loss: 0.0159\n",
      "[Iter 6950 Total] Train Loss: 0.1762\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Train Loss: 0.3415\n",
      "[Iter 7000 Task dept] Train Loss: 0.0161\n",
      "[Iter 7000 Total] Train Loss: 0.1788\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 2.3331\n",
      "{'mIoU': 0.151, 'Pixel Acc': 0.509, 'cmp': -0.4715}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0981\n",
      "{'abs_err': 0.096, 'rel_err': 2.4583, 'sigma_1.25': 23.1868, 'sigma_1.25^2': 42.2766, 'sigma_1.25^3': 52.1969, 'cmp': -2.5436}\n",
      "======================================================================\n",
      "[Iter 7050 Task segm] Train Loss: 0.3314\n",
      "[Iter 7050 Task dept] Train Loss: 0.0166\n",
      "[Iter 7050 Total] Train Loss: 0.1740\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Train Loss: 0.3119\n",
      "[Iter 7100 Task dept] Train Loss: 0.0156\n",
      "[Iter 7100 Total] Train Loss: 0.1637\n",
      "======================================================================\n",
      "[Iter 7150 Task segm] Train Loss: 0.3317\n",
      "[Iter 7150 Task dept] Train Loss: 0.0161\n",
      "[Iter 7150 Total] Train Loss: 0.1739\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Train Loss: 0.3375\n",
      "[Iter 7200 Task dept] Train Loss: 0.0156\n",
      "[Iter 7200 Total] Train Loss: 0.1766\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.8431\n",
      "{'mIoU': 0.1587, 'Pixel Acc': 0.5115, 'cmp': -0.4602}\n",
      "[Iter 7200 Task dept] Val Loss: 0.1139\n",
      "{'abs_err': 0.1113, 'rel_err': 2.8461, 'sigma_1.25': 22.8986, 'sigma_1.25^2': 38.0878, 'sigma_1.25^3': 47.569, 'cmp': -2.9788}\n",
      "======================================================================\n",
      "[Iter 7250 Task segm] Train Loss: 0.3302\n",
      "[Iter 7250 Task dept] Train Loss: 0.0164\n",
      "[Iter 7250 Total] Train Loss: 0.1733\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Train Loss: 0.3359\n",
      "[Iter 7300 Task dept] Train Loss: 0.0154\n",
      "[Iter 7300 Total] Train Loss: 0.1757\n",
      "======================================================================\n",
      "[Iter 7350 Task segm] Train Loss: 0.3194\n",
      "[Iter 7350 Task dept] Train Loss: 0.0161\n",
      "[Iter 7350 Total] Train Loss: 0.1677\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Train Loss: 0.3270\n",
      "[Iter 7400 Task dept] Train Loss: 0.0158\n",
      "[Iter 7400 Total] Train Loss: 0.1714\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 2.3700\n",
      "{'mIoU': 0.139, 'Pixel Acc': 0.4525, 'cmp': -0.5242}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0843\n",
      "{'abs_err': 0.0828, 'rel_err': 1.9683, 'sigma_1.25': 20.9844, 'sigma_1.25^2': 42.3429, 'sigma_1.25^3': 58.2388, 'cmp': -2.084}\n",
      "======================================================================\n",
      "[Iter 7450 Task segm] Train Loss: 0.3167\n",
      "[Iter 7450 Task dept] Train Loss: 0.0161\n",
      "[Iter 7450 Total] Train Loss: 0.1664\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Train Loss: 0.3250\n",
      "[Iter 7500 Task dept] Train Loss: 0.0161\n",
      "[Iter 7500 Total] Train Loss: 0.1706\n",
      "======================================================================\n",
      "[Iter 7550 Task segm] Train Loss: 0.3176\n",
      "[Iter 7550 Task dept] Train Loss: 0.0157\n",
      "[Iter 7550 Total] Train Loss: 0.1667\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Train Loss: 0.3280\n",
      "[Iter 7600 Task dept] Train Loss: 0.0161\n",
      "[Iter 7600 Total] Train Loss: 0.1721\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.4451\n",
      "{'mIoU': 0.1816, 'Pixel Acc': 0.5568, 'cmp': -0.4015}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0945\n",
      "{'abs_err': 0.093, 'rel_err': 2.3227, 'sigma_1.25': 21.1652, 'sigma_1.25^2': 41.1186, 'sigma_1.25^3': 54.517, 'cmp': -2.4294}\n",
      "======================================================================\n",
      "[Iter 7650 Task segm] Train Loss: 0.3251\n",
      "[Iter 7650 Task dept] Train Loss: 0.0161\n",
      "[Iter 7650 Total] Train Loss: 0.1706\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Train Loss: 0.3273\n",
      "[Iter 7700 Task dept] Train Loss: 0.0155\n",
      "[Iter 7700 Total] Train Loss: 0.1714\n",
      "======================================================================\n",
      "[Iter 7750 Task segm] Train Loss: 0.3368\n",
      "[Iter 7750 Task dept] Train Loss: 0.0165\n",
      "[Iter 7750 Total] Train Loss: 0.1767\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Train Loss: 0.3292\n",
      "[Iter 7800 Task dept] Train Loss: 0.0164\n",
      "[Iter 7800 Total] Train Loss: 0.1728\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 0.9708\n",
      "{'mIoU': 0.2192, 'Pixel Acc': 0.6221, 'cmp': -0.311}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0846\n",
      "{'abs_err': 0.083, 'rel_err': 1.9745, 'sigma_1.25': 20.7147, 'sigma_1.25^2': 42.5438, 'sigma_1.25^3': 58.2208, 'cmp': -2.0906}\n",
      "======================================================================\n",
      "[Iter 7850 Task segm] Train Loss: 0.3121\n",
      "[Iter 7850 Task dept] Train Loss: 0.0158\n",
      "[Iter 7850 Total] Train Loss: 0.1640\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Train Loss: 0.3158\n",
      "[Iter 7900 Task dept] Train Loss: 0.0159\n",
      "[Iter 7900 Total] Train Loss: 0.1658\n",
      "======================================================================\n",
      "[Iter 7950 Task segm] Train Loss: 0.3324\n",
      "[Iter 7950 Task dept] Train Loss: 0.0157\n",
      "[Iter 7950 Total] Train Loss: 0.1740\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Train Loss: 0.3125\n",
      "[Iter 8000 Task dept] Train Loss: 0.0158\n",
      "[Iter 8000 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 3.1718\n",
      "{'mIoU': 0.152, 'Pixel Acc': 0.4751, 'cmp': -0.493}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0885\n",
      "{'abs_err': 0.0867, 'rel_err': 2.1076, 'sigma_1.25': 21.3724, 'sigma_1.25^2': 42.2772, 'sigma_1.25^3': 56.3626, 'cmp': -2.2176}\n",
      "======================================================================\n",
      "[Iter 8050 Task segm] Train Loss: 0.3188\n",
      "[Iter 8050 Task dept] Train Loss: 0.0159\n",
      "[Iter 8050 Total] Train Loss: 0.1673\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8100 Task segm] Train Loss: 0.3271\n",
      "[Iter 8100 Task dept] Train Loss: 0.0152\n",
      "[Iter 8100 Total] Train Loss: 0.1712\n",
      "======================================================================\n",
      "[Iter 8150 Task segm] Train Loss: 0.3063\n",
      "[Iter 8150 Task dept] Train Loss: 0.0156\n",
      "[Iter 8150 Total] Train Loss: 0.1609\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 0.3051\n",
      "[Iter 8200 Task dept] Train Loss: 0.0154\n",
      "[Iter 8200 Total] Train Loss: 0.1603\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.2307\n",
      "{'mIoU': 0.2002, 'Pixel Acc': 0.5812, 'cmp': -0.362}\n",
      "[Iter 8200 Task dept] Val Loss: 0.0941\n",
      "{'abs_err': 0.0921, 'rel_err': 2.2972, 'sigma_1.25': 22.0893, 'sigma_1.25^2': 42.3863, 'sigma_1.25^3': 53.9933, 'cmp': -2.3984}\n",
      "======================================================================\n",
      "[Iter 8250 Task segm] Train Loss: 0.3006\n",
      "[Iter 8250 Task dept] Train Loss: 0.0161\n",
      "[Iter 8250 Total] Train Loss: 0.1584\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Train Loss: 0.3336\n",
      "[Iter 8300 Task dept] Train Loss: 0.0159\n",
      "[Iter 8300 Total] Train Loss: 0.1747\n",
      "======================================================================\n",
      "[Iter 8350 Task segm] Train Loss: 0.3160\n",
      "[Iter 8350 Task dept] Train Loss: 0.0160\n",
      "[Iter 8350 Total] Train Loss: 0.1660\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 0.3126\n",
      "[Iter 8400 Task dept] Train Loss: 0.0158\n",
      "[Iter 8400 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 1.1843\n",
      "{'mIoU': 0.1963, 'Pixel Acc': 0.6085, 'cmp': -0.3485}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0980\n",
      "{'abs_err': 0.0955, 'rel_err': 2.4151, 'sigma_1.25': 22.6665, 'sigma_1.25^2': 41.6501, 'sigma_1.25^3': 52.6416, 'cmp': -2.5139}\n",
      "======================================================================\n",
      "[Iter 8450 Task segm] Train Loss: 0.3185\n",
      "[Iter 8450 Task dept] Train Loss: 0.0152\n",
      "[Iter 8450 Total] Train Loss: 0.1668\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Train Loss: 0.3084\n",
      "[Iter 8500 Task dept] Train Loss: 0.0154\n",
      "[Iter 8500 Total] Train Loss: 0.1619\n",
      "======================================================================\n",
      "[Iter 8550 Task segm] Train Loss: 0.3213\n",
      "[Iter 8550 Task dept] Train Loss: 0.0162\n",
      "[Iter 8550 Total] Train Loss: 0.1688\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Train Loss: 0.3042\n",
      "[Iter 8600 Task dept] Train Loss: 0.0159\n",
      "[Iter 8600 Total] Train Loss: 0.1601\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 1.4170\n",
      "{'mIoU': 0.172, 'Pixel Acc': 0.5819, 'cmp': -0.3966}\n",
      "[Iter 8600 Task dept] Val Loss: 0.1155\n",
      "{'abs_err': 0.113, 'rel_err': 2.8964, 'sigma_1.25': 21.4123, 'sigma_1.25^2': 38.1598, 'sigma_1.25^3': 48.1969, 'cmp': -3.0325}\n",
      "======================================================================\n",
      "[Iter 8650 Task segm] Train Loss: 0.3111\n",
      "[Iter 8650 Task dept] Train Loss: 0.0153\n",
      "[Iter 8650 Total] Train Loss: 0.1632\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Train Loss: 0.3104\n",
      "[Iter 8700 Task dept] Train Loss: 0.0155\n",
      "[Iter 8700 Total] Train Loss: 0.1629\n",
      "======================================================================\n",
      "[Iter 8750 Task segm] Train Loss: 0.3037\n",
      "[Iter 8750 Task dept] Train Loss: 0.0147\n",
      "[Iter 8750 Total] Train Loss: 0.1592\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.3080\n",
      "[Iter 8800 Task dept] Train Loss: 0.0155\n",
      "[Iter 8800 Total] Train Loss: 0.1618\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.3760\n",
      "{'mIoU': 0.1904, 'Pixel Acc': 0.5828, 'cmp': -0.3731}\n",
      "[Iter 8800 Task dept] Val Loss: 0.1033\n",
      "{'abs_err': 0.1011, 'rel_err': 2.5607, 'sigma_1.25': 21.1996, 'sigma_1.25^2': 39.6832, 'sigma_1.25^3': 51.7942, 'cmp': -2.6783}\n",
      "======================================================================\n",
      "[Iter 8850 Task segm] Train Loss: 0.3205\n",
      "[Iter 8850 Task dept] Train Loss: 0.0164\n",
      "[Iter 8850 Total] Train Loss: 0.1684\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Train Loss: 0.3161\n",
      "[Iter 8900 Task dept] Train Loss: 0.0157\n",
      "[Iter 8900 Total] Train Loss: 0.1659\n",
      "======================================================================\n",
      "[Iter 8950 Task segm] Train Loss: 0.3119\n",
      "[Iter 8950 Task dept] Train Loss: 0.0158\n",
      "[Iter 8950 Total] Train Loss: 0.1639\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.3170\n",
      "[Iter 9000 Task dept] Train Loss: 0.0161\n",
      "[Iter 9000 Total] Train Loss: 0.1665\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 1.0887\n",
      "{'mIoU': 0.217, 'Pixel Acc': 0.618, 'cmp': -0.3164}\n",
      "[Iter 9000 Task dept] Val Loss: 0.1115\n",
      "{'abs_err': 0.1094, 'rel_err': 2.8214, 'sigma_1.25': 21.8089, 'sigma_1.25^2': 39.278, 'sigma_1.25^3': 49.11, 'cmp': -2.9387}\n",
      "======================================================================\n",
      "[Iter 9050 Task segm] Train Loss: 0.3172\n",
      "[Iter 9050 Task dept] Train Loss: 0.0151\n",
      "[Iter 9050 Total] Train Loss: 0.1661\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Train Loss: 0.3164\n",
      "[Iter 9100 Task dept] Train Loss: 0.0157\n",
      "[Iter 9100 Total] Train Loss: 0.1661\n",
      "======================================================================\n",
      "[Iter 9150 Task segm] Train Loss: 0.3134\n",
      "[Iter 9150 Task dept] Train Loss: 0.0162\n",
      "[Iter 9150 Total] Train Loss: 0.1648\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.3028\n",
      "[Iter 9200 Task dept] Train Loss: 0.0158\n",
      "[Iter 9200 Total] Train Loss: 0.1593\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 1.5985\n",
      "{'mIoU': 0.1718, 'Pixel Acc': 0.5596, 'cmp': -0.4118}\n",
      "[Iter 9200 Task dept] Val Loss: 0.0927\n",
      "{'abs_err': 0.0916, 'rel_err': 2.1091, 'sigma_1.25': 17.833, 'sigma_1.25^2': 36.5068, 'sigma_1.25^3': 53.724, 'cmp': -2.3059}\n",
      "======================================================================\n",
      "[Iter 9250 Task segm] Train Loss: 0.3126\n",
      "[Iter 9250 Task dept] Train Loss: 0.0154\n",
      "[Iter 9250 Total] Train Loss: 0.1640\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Train Loss: 0.3175\n",
      "[Iter 9300 Task dept] Train Loss: 0.0152\n",
      "[Iter 9300 Total] Train Loss: 0.1664\n",
      "======================================================================\n",
      "[Iter 9350 Task segm] Train Loss: 0.3119\n",
      "[Iter 9350 Task dept] Train Loss: 0.0159\n",
      "[Iter 9350 Total] Train Loss: 0.1639\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.3065\n",
      "[Iter 9400 Task dept] Train Loss: 0.0159\n",
      "[Iter 9400 Total] Train Loss: 0.1612\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.5920\n",
      "{'mIoU': 0.1855, 'Pixel Acc': 0.5527, 'cmp': -0.3993}\n",
      "[Iter 9400 Task dept] Val Loss: 0.1065\n",
      "{'abs_err': 0.1044, 'rel_err': 2.6555, 'sigma_1.25': 21.3719, 'sigma_1.25^2': 38.8284, 'sigma_1.25^3': 50.6621, 'cmp': -2.7782}\n",
      "======================================================================\n",
      "[Iter 9450 Task segm] Train Loss: 0.3108\n",
      "[Iter 9450 Task dept] Train Loss: 0.0158\n",
      "[Iter 9450 Total] Train Loss: 0.1633\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Train Loss: 0.2962\n",
      "[Iter 9500 Task dept] Train Loss: 0.0151\n",
      "[Iter 9500 Total] Train Loss: 0.1557\n",
      "======================================================================\n",
      "[Iter 9550 Task segm] Train Loss: 0.3125\n",
      "[Iter 9550 Task dept] Train Loss: 0.0159\n",
      "[Iter 9550 Total] Train Loss: 0.1642\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Train Loss: 0.2988\n",
      "[Iter 9600 Task dept] Train Loss: 0.0147\n",
      "[Iter 9600 Total] Train Loss: 0.1567\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9600 Task segm] Val Loss: 1.3054\n",
      "{'mIoU': 0.1964, 'Pixel Acc': 0.5882, 'cmp': -0.362}\n",
      "[Iter 9600 Task dept] Val Loss: 0.1058\n",
      "{'abs_err': 0.1044, 'rel_err': 2.6382, 'sigma_1.25': 19.6295, 'sigma_1.25^2': 38.3761, 'sigma_1.25^3': 51.6513, 'cmp': -2.7714}\n",
      "======================================================================\n",
      "[Iter 9650 Task segm] Train Loss: 0.3068\n",
      "[Iter 9650 Task dept] Train Loss: 0.0154\n",
      "[Iter 9650 Total] Train Loss: 0.1611\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Train Loss: 0.3020\n",
      "[Iter 9700 Task dept] Train Loss: 0.0155\n",
      "[Iter 9700 Total] Train Loss: 0.1588\n",
      "======================================================================\n",
      "[Iter 9750 Task segm] Train Loss: 0.2949\n",
      "[Iter 9750 Task dept] Train Loss: 0.0161\n",
      "[Iter 9750 Total] Train Loss: 0.1555\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.3090\n",
      "[Iter 9800 Task dept] Train Loss: 0.0156\n",
      "[Iter 9800 Total] Train Loss: 0.1623\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 1.2233\n",
      "{'mIoU': 0.1882, 'Pixel Acc': 0.5828, 'cmp': -0.3758}\n",
      "[Iter 9800 Task dept] Val Loss: 0.0981\n",
      "{'abs_err': 0.0964, 'rel_err': 2.4097, 'sigma_1.25': 20.8561, 'sigma_1.25^2': 40.3609, 'sigma_1.25^3': 53.4102, 'cmp': -2.5273}\n",
      "======================================================================\n",
      "[Iter 9850 Task segm] Train Loss: 0.3018\n",
      "[Iter 9850 Task dept] Train Loss: 0.0158\n",
      "[Iter 9850 Total] Train Loss: 0.1588\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Train Loss: 0.2865\n",
      "[Iter 9900 Task dept] Train Loss: 0.0159\n",
      "[Iter 9900 Total] Train Loss: 0.1512\n",
      "======================================================================\n",
      "[Iter 9950 Task segm] Train Loss: 0.3061\n",
      "[Iter 9950 Task dept] Train Loss: 0.0155\n",
      "[Iter 9950 Total] Train Loss: 0.1608\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.3141\n",
      "[Iter 10000 Task dept] Train Loss: 0.0154\n",
      "[Iter 10000 Total] Train Loss: 0.1648\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 2.0799\n",
      "{'mIoU': 0.1601, 'Pixel Acc': 0.4947, 'cmp': -0.4697}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0966\n",
      "{'abs_err': 0.0953, 'rel_err': 2.1922, 'sigma_1.25': 16.9319, 'sigma_1.25^2': 34.9723, 'sigma_1.25^3': 52.4714, 'cmp': -2.4081}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train(iters=10000, lr=0.0001, savePath='checkpoints/Cityscapes/', reload='pre_train_all_2000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau: 4.825\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0059,  0.0065, -0.0124], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012,  0.0011, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0022,  0.0023, -0.0045], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([-2.9610e-05, -3.1099e-04,  3.4060e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0015,  0.0013, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 6.3688e-05, -1.1672e-04,  5.3036e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 7.1520e-05,  2.4590e-04, -3.1742e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 3.3834e-04,  4.3117e-05, -3.8146e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "tau: 4.656125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0075, -0.0140], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0004, -0.0002], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0014,  0.0014, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.0143e-05,  6.3563e-05, -1.5371e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0023,  0.0025, -0.0047], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.4311e-05,  4.1435e-05, -1.1575e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([-9.2524e-05, -3.4504e-04,  4.3756e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2650e-06,  1.9726e-05, -1.8461e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0015,  0.0013, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.3922e-05,  6.7734e-06, -9.0695e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 7.3616e-05, -1.5413e-04,  8.0515e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.0989e-06,  3.4763e-05, -3.8862e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 6.4632e-05,  2.7527e-04, -3.3990e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-6.0916e-05,  9.8104e-07,  5.9935e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 3.2064e-04,  8.2377e-05, -4.0302e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002,  0.0001,  0.0001], device='cuda:0', requires_grad=True)\n",
      "[Iter 200 Task segm] Train Loss: 0.3082\n",
      "[Iter 200 Task dept] Train Loss: 0.0419\n",
      "[Iter 200 Total] Train Loss: 0.1750\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 0.5675\n",
      "{'mIoU': 0.2986, 'Pixel Acc': 0.6831, 'cmp': -0.1714}\n",
      "[Iter 200 Task dept] Val Loss: 0.0393\n",
      "{'abs_err': 0.0411, 'rel_err': 0.5628, 'sigma_1.25': 40.4623, 'sigma_1.25^2': 61.7244, 'sigma_1.25^3': 74.4217, 'cmp': -0.6067}\n",
      "======================================================================\n",
      "tau: 4.493160625\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0091,  0.0114, -0.0205], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0005, -0.0002], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0046,  0.0047, -0.0093], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.9762e-04,  9.1800e-05, -2.8942e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0038,  0.0040, -0.0078], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.3569e-05,  5.4471e-05, -1.1804e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0008,  0.0007, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-5.1972e-06,  2.0891e-05, -1.5694e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0023,  0.0018, -0.0041], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.1269e-05,  9.3976e-06, -1.0067e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 4.0615e-04, -3.1434e-04, -9.1819e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.6180e-06,  3.6701e-05, -3.2083e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0004,  0.0007, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-6.2817e-05,  9.4824e-07,  6.1868e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0004,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002,  0.0001,  0.0001], device='cuda:0', requires_grad=True)\n",
      "tau: 4.3359000031249995\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0094,  0.0122, -0.0216], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0012, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0058,  0.0055, -0.0114], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0002, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0038,  0.0040, -0.0078], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.2785e-05,  1.7437e-04, -2.3715e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012,  0.0010, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.0055e-05,  3.2630e-05, -5.2685e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0023,  0.0019, -0.0042], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2584e-04,  2.6819e-05, -1.5266e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0006, -0.0003, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.5659e-06,  6.0965e-05, -6.5531e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0005,  0.0009, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-6.1197e-05,  6.7737e-06,  5.4424e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0004,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0001,  0.0001], device='cuda:0', requires_grad=True)\n",
      "[Iter 400 Task segm] Train Loss: 0.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 400 Task dept] Train Loss: 0.0313\n",
      "[Iter 400 Total] Train Loss: 0.1672\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 0.5316\n",
      "{'mIoU': 0.3108, 'Pixel Acc': 0.7043, 'cmp': -0.1421}\n",
      "[Iter 400 Task dept] Val Loss: 0.0406\n",
      "{'abs_err': 0.0426, 'rel_err': 0.548, 'sigma_1.25': 37.7907, 'sigma_1.25^2': 59.2871, 'sigma_1.25^3': 72.476, 'cmp': -0.633}\n",
      "======================================================================\n",
      "tau: 4.184143503015624\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0208,  0.0238, -0.0446], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0013, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0070,  0.0077, -0.0147], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005,  0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0055,  0.0059, -0.0114], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.6062e-05,  1.8686e-04, -2.5292e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0024,  0.0022, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.3005e-05,  3.4697e-05, -5.7702e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0036,  0.0030, -0.0066], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.3204e-04,  2.7961e-05, -1.6000e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0014,  0.0006, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.9350e-06,  6.1483e-05, -6.6418e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012,  0.0014, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-6.0656e-05,  7.8599e-06,  5.2796e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0008,  0.0002, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0001,  0.0001], device='cuda:0', requires_grad=True)\n",
      "tau: 4.037698480410078\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0210,  0.0239, -0.0449], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0013, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0073,  0.0079, -0.0152], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0003, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0061,  0.0064, -0.0125], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.3907e-05,  2.6749e-04, -3.6140e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0027,  0.0024, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.8760e-05,  4.2745e-05, -8.1504e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0036,  0.0031, -0.0067], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.3527e-04,  3.6916e-05, -1.7219e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0015,  0.0009, -0.0024], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-8.4267e-06,  6.9906e-05, -6.1479e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012,  0.0014, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.2730e-05,  7.1364e-06,  3.5594e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0009,  0.0003, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0002,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 600 Task segm] Train Loss: 0.3047\n",
      "[Iter 600 Task dept] Train Loss: 0.0308\n",
      "[Iter 600 Total] Train Loss: 0.1677\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 0.8466\n",
      "{'mIoU': 0.26, 'Pixel Acc': 0.6461, 'cmp': -0.2441}\n",
      "[Iter 600 Task dept] Val Loss: 0.0391\n",
      "{'abs_err': 0.0388, 'rel_err': 0.6859, 'sigma_1.25': 43.9816, 'sigma_1.25^2': 65.2523, 'sigma_1.25^3': 78.1689, 'cmp': -0.6281}\n",
      "======================================================================\n",
      "tau: 3.896379033595725\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0246,  0.0264, -0.0510], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0013, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0110,  0.0107, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002,  0.0003, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0064,  0.0069, -0.0133], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.7867e-05,  2.7818e-04, -3.6605e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0033,  0.0029, -0.0062], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.4667e-05,  4.3163e-05, -8.7831e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0039,  0.0032, -0.0071], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.3063e-04,  3.6119e-05, -1.6675e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0021,  0.0016, -0.0037], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2140e-05,  6.9554e-05, -5.7414e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0020,  0.0023, -0.0043], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.1269e-05,  5.6420e-06,  3.5627e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 6.6023e-04,  4.3156e-05, -7.0338e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0003,  0.0002,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 3.7600057674198744\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0265,  0.0277, -0.0542], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0014, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0109,  0.0106, -0.0215], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0003, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0070, -0.0135], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0003, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0032,  0.0028, -0.0061], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.4604e-05,  5.4265e-05, -9.8869e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0039,  0.0031, -0.0070], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.2271e-04,  3.1925e-05, -2.5464e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0022,  0.0017, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-3.4308e-05,  8.6174e-05, -5.1866e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0020,  0.0023, -0.0043], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.6853e-05,  4.7295e-06,  2.2123e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 6.5125e-04,  7.1834e-06, -6.5843e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0002,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 800 Task segm] Train Loss: 0.3017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 800 Task dept] Train Loss: 0.0286\n",
      "[Iter 800 Total] Train Loss: 0.1652\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 0.5052\n",
      "{'mIoU': 0.3079, 'Pixel Acc': 0.7056, 'cmp': -0.1447}\n",
      "[Iter 800 Task dept] Val Loss: 0.0385\n",
      "{'abs_err': 0.039, 'rel_err': 0.6425, 'sigma_1.25': 43.6823, 'sigma_1.25^2': 64.0495, 'sigma_1.25^3': 76.112, 'cmp': -0.6126}\n",
      "======================================================================\n",
      "tau: 3.6284055655601786\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0337,  0.0377, -0.0714], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0014, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0144,  0.0137, -0.0281], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0003, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0097,  0.0098, -0.0195], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0004, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0033,  0.0025, -0.0058], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.0939e-05,  5.5491e-05, -1.0643e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0047,  0.0039, -0.0086], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.3075e-04,  3.0574e-05, -2.6132e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0028,  0.0024, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.2911e-05,  8.4595e-05, -4.1684e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0023,  0.0026, -0.0049], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.8775e-05,  6.5131e-06,  2.2262e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0002,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 3.501411370765572\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0342,  0.0384, -0.0726], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002,  0.0012, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0150,  0.0142, -0.0292], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0100,  0.0101, -0.0201], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0004, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0033,  0.0026, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.5241e-05,  7.6437e-05, -1.7168e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0049,  0.0041, -0.0090], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.3960e-04,  3.3493e-05, -2.7309e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0029,  0.0026, -0.0055], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.4206e-05,  6.9472e-05, -2.5265e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0025,  0.0027, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.0841e-07,  5.7226e-06, -6.6311e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 1000 Task segm] Train Loss: 0.3040\n",
      "[Iter 1000 Task dept] Train Loss: 0.0285\n",
      "[Iter 1000 Total] Train Loss: 0.1663\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 0.5048\n",
      "{'mIoU': 0.3113, 'Pixel Acc': 0.7029, 'cmp': -0.1423}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0389\n",
      "{'abs_err': 0.0401, 'rel_err': 0.5808, 'sigma_1.25': 41.2788, 'sigma_1.25^2': 63.1232, 'sigma_1.25^3': 75.5248, 'cmp': -0.5979}\n",
      "======================================================================\n",
      "tau: 3.3788619727887768\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0432,  0.0430, -0.0861], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002,  0.0012, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0203,  0.0196, -0.0400], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0107,  0.0112, -0.0218], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0004, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0050,  0.0046, -0.0096], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0369e-04,  7.8806e-05, -1.8250e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0058,  0.0049, -0.0107], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.3812e-04,  3.6388e-05, -2.7451e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0044,  0.0038, -0.0082], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-3.8765e-05,  6.8123e-05, -2.9358e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0034,  0.0036, -0.0069], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.8318e-06,  4.5250e-06, -1.0357e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0881e-03, -5.5448e-05, -1.0327e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 3.2606018037411695\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0502,  0.0461, -0.0963], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0010, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0205,  0.0196, -0.0401], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013,  0.0004, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0102,  0.0109, -0.0211], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0005, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0049,  0.0042, -0.0091], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2375e-04,  8.7601e-05, -2.1135e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0057,  0.0049, -0.0105], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.3573e-04,  3.4988e-05, -3.7072e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0038,  0.0035, -0.0072], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.0538e-05,  7.7526e-05, -6.9883e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0033,  0.0036, -0.0069], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.7487e-05, -5.4159e-06, -3.2071e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0009, -0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 1200 Task segm] Train Loss: 0.3052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1200 Task dept] Train Loss: 0.0282\n",
      "[Iter 1200 Total] Train Loss: 0.1667\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 0.4953\n",
      "{'mIoU': 0.3135, 'Pixel Acc': 0.7075, 'cmp': -0.1365}\n",
      "[Iter 1200 Task dept] Val Loss: 0.0447\n",
      "{'abs_err': 0.0466, 'rel_err': 0.6862, 'sigma_1.25': 37.647, 'sigma_1.25^2': 60.0622, 'sigma_1.25^3': 73.6694, 'cmp': -0.7603}\n",
      "======================================================================\n",
      "tau: 3.1464807406102286\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0551,  0.0540, -0.1091], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0010, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0269,  0.0261, -0.0530], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013,  0.0004, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0126,  0.0131, -0.0257], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0005, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0064,  0.0060, -0.0123], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.3383e-04,  8.9598e-05, -2.2343e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0067,  0.0059, -0.0126], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.2579e-04,  3.7102e-05, -3.6289e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0045,  0.0043, -0.0088], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.6565e-05,  7.4698e-05,  1.8677e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0039,  0.0041, -0.0080], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.0500e-05, -7.2331e-06, -3.3267e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0008, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "tau: 3.0363539146888705\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0557,  0.0549, -0.1106], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0008, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0273,  0.0268, -0.0541], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016,  0.0005, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0130,  0.0134, -0.0264], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0005, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0071,  0.0066, -0.0137], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002,  0.0001, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0071,  0.0063, -0.0134], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.1530e-04,  2.4770e-05, -4.4007e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0049,  0.0047, -0.0096], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.8327e-05,  6.2784e-05,  1.5544e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0042,  0.0043, -0.0086], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.1133e-05, -2.7877e-05, -4.3256e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0009, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "[Iter 1400 Task segm] Train Loss: 0.3084\n",
      "[Iter 1400 Task dept] Train Loss: 0.0267\n",
      "[Iter 1400 Total] Train Loss: 0.1675\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 0.5982\n",
      "{'mIoU': 0.2923, 'Pixel Acc': 0.6904, 'cmp': -0.1743}\n",
      "[Iter 1400 Task dept] Val Loss: 0.0432\n",
      "{'abs_err': 0.0449, 'rel_err': 0.6437, 'sigma_1.25': 37.4599, 'sigma_1.25^2': 59.1547, 'sigma_1.25^3': 72.4284, 'cmp': -0.7189}\n",
      "======================================================================\n",
      "tau: 2.93008152767476\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0693,  0.0693, -0.1385], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0008, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0316,  0.0324, -0.0640], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017,  0.0005, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0156,  0.0169, -0.0325], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0005, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0091,  0.0087, -0.0178], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002,  0.0001, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0084,  0.0071, -0.0155], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.0489e-04,  2.6708e-05, -4.3159e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0054,  0.0050, -0.0104], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.3705e-05,  6.3132e-05,  1.0573e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0044,  0.0048, -0.0092], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.5367e-05, -3.0194e-05, -4.5173e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "tau: 2.827528674206143\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0706,  0.0715, -0.1421], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010,  0.0010, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0319,  0.0329, -0.0647], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024,  0.0006, -0.0030], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0156,  0.0170, -0.0326], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012,  0.0006, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0092,  0.0088, -0.0180], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.6883e-04,  9.5794e-05, -2.6462e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0090,  0.0078, -0.0168], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.6359e-04,  1.7704e-05, -4.8129e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0055,  0.0051, -0.0106], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.3290e-04,  5.6168e-05,  7.6734e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0045,  0.0047, -0.0092], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.2826e-05, -2.6768e-05, -6.6058e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "[Iter 1600 Task segm] Train Loss: 0.3037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1600 Task dept] Train Loss: 0.0269\n",
      "[Iter 1600 Total] Train Loss: 0.1653\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 0.6820\n",
      "{'mIoU': 0.2704, 'Pixel Acc': 0.6705, 'cmp': -0.2148}\n",
      "[Iter 1600 Task dept] Val Loss: 0.0480\n",
      "{'abs_err': 0.0489, 'rel_err': 0.698, 'sigma_1.25': 35.0609, 'sigma_1.25^2': 56.4971, 'sigma_1.25^3': 70.8227, 'cmp': -0.8156}\n",
      "======================================================================\n",
      "tau: 2.728565170608928\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0870,  0.0831, -0.1701], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012,  0.0009, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0424,  0.0454, -0.0878], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025,  0.0006, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0176,  0.0196, -0.0372], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013,  0.0006, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0114,  0.0118, -0.0232], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.8000e-04,  9.6348e-05, -2.7635e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0118,  0.0096, -0.0213], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.5518e-04,  2.0581e-05, -4.7577e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0074,  0.0069, -0.0142], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.3188e-04,  6.0452e-05,  7.1425e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0064, -0.0129], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0058e-04, -2.7942e-05, -7.2642e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0008, -0.0005, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "tau: 2.6330653896376153\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0883,  0.0854, -0.1737], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020,  0.0007, -0.0027], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0440,  0.0473, -0.0913], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027,  0.0007, -0.0034], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0174,  0.0197, -0.0370], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013,  0.0008, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0113,  0.0120, -0.0233], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002,  0.0001, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0115,  0.0094, -0.0209], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.5849e-04,  1.8521e-05, -5.7702e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0074,  0.0068, -0.0142], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4768e-04,  3.2162e-05,  1.1551e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0064, -0.0129], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1143e-04, -1.8517e-05, -9.2909e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 6.5573e-04, -6.0047e-04, -5.5259e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "[Iter 1800 Task segm] Train Loss: 0.3047\n",
      "[Iter 1800 Task dept] Train Loss: 0.0262\n",
      "[Iter 1800 Total] Train Loss: 0.1655\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 0.8274\n",
      "{'mIoU': 0.2429, 'Pixel Acc': 0.6474, 'cmp': -0.2646}\n",
      "[Iter 1800 Task dept] Val Loss: 0.0424\n",
      "{'abs_err': 0.0422, 'rel_err': 0.771, 'sigma_1.25': 41.8344, 'sigma_1.25^2': 64.1082, 'sigma_1.25^3': 76.9007, 'cmp': -0.7309}\n",
      "======================================================================\n",
      "tau: 2.5409081010002987\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0920,  0.0976, -0.1896], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021,  0.0007, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0512,  0.0558, -0.1069], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027,  0.0007, -0.0034], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0227,  0.0242, -0.0468], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014,  0.0008, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0157,  0.0150, -0.0307], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002,  0.0001, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0132,  0.0112, -0.0244], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.6980e-04,  1.5896e-05, -5.8569e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0097,  0.0088, -0.0185], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4323e-04,  2.6850e-05,  1.1638e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0072,  0.0071, -0.0143], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1340e-04, -1.7501e-05, -9.5898e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0007, -0.0005, -0.0002], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0003,  0.0003], device='cuda:0', requires_grad=True)\n",
      "tau: 2.451976317465288\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0930,  0.0987, -0.1917], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0030,  0.0008, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0518,  0.0564, -0.1083], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032,  0.0007, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0229,  0.0242, -0.0471], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017,  0.0009, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0160,  0.0150, -0.0310], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0001, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0136,  0.0118, -0.0253], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.1815e-04, -1.4562e-05, -7.0359e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0100,  0.0091, -0.0191], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.7355e-04,  4.2452e-05,  1.3110e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0074,  0.0072, -0.0146], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.3430e-04, -7.7632e-06, -1.2654e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0007, -0.0004, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0004,  0.0004], device='cuda:0', requires_grad=True)\n",
      "[Iter 2000 Task segm] Train Loss: 0.3096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2000 Task dept] Train Loss: 0.0268\n",
      "[Iter 2000 Total] Train Loss: 0.1682\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 0.8051\n",
      "{'mIoU': 0.259, 'Pixel Acc': 0.6512, 'cmp': -0.242}\n",
      "[Iter 2000 Task dept] Val Loss: 0.0465\n",
      "{'abs_err': 0.047, 'rel_err': 0.8047, 'sigma_1.25': 38.3669, 'sigma_1.25^2': 59.9507, 'sigma_1.25^3': 73.405, 'cmp': -0.8351}\n",
      "======================================================================\n",
      "tau: 2.366157146354003\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1347,  0.1552, -0.2899], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029,  0.0009, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0658,  0.0726, -0.1383], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033,  0.0007, -0.0040], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0261,  0.0248, -0.0509], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018,  0.0009, -0.0027], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0151,  0.0144, -0.0295], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0001, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0157,  0.0152, -0.0309], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.1563e-04, -1.1771e-05, -7.0386e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0091,  0.0094, -0.0185], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.7803e-04,  4.6999e-05,  1.3103e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0075,  0.0078, -0.0153], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.4079e-04, -3.0976e-06, -1.3769e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012, -0.0006, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0004,  0.0004], device='cuda:0', requires_grad=True)\n",
      "tau: 2.2833416462316127\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1344,  0.1544, -0.2888], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041,  0.0005, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0678,  0.0736, -0.1414], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0035,  0.0007, -0.0042], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0263,  0.0248, -0.0511], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020,  0.0009, -0.0029], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0152,  0.0147, -0.0298], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0157,  0.0150, -0.0307], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.3111e-04, -1.1710e-05, -7.1940e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0092,  0.0095, -0.0188], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2276e-04,  4.7052e-05,  7.5703e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0074,  0.0078, -0.0152], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.2610e-04, -3.5143e-05, -1.9095e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0012, -0.0006, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0005,  0.0004], device='cuda:0', requires_grad=True)\n",
      "[Iter 2200 Task segm] Train Loss: 0.3201\n",
      "[Iter 2200 Task dept] Train Loss: 0.0266\n",
      "[Iter 2200 Total] Train Loss: 0.1734\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 1.0573\n",
      "{'mIoU': 0.2272, 'Pixel Acc': 0.6134, 'cmp': -0.3068}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0483\n",
      "{'abs_err': 0.0486, 'rel_err': 0.7908, 'sigma_1.25': 36.9809, 'sigma_1.25^2': 58.7684, 'sigma_1.25^3': 72.0748, 'cmp': -0.8554}\n",
      "======================================================================\n",
      "tau: 2.2034246886135063\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1663,  0.1743, -0.3405], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0042,  0.0004, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0737,  0.0794, -0.1531], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0034,  0.0007, -0.0042], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0296,  0.0261, -0.0558], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021,  0.0008, -0.0030], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0172,  0.0164, -0.0335], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0185,  0.0176, -0.0361], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.3447e-04, -8.6855e-06, -7.2578e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0078,  0.0094, -0.0172], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2174e-04,  4.9135e-05,  7.2602e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0089,  0.0076, -0.0165], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.2980e-04, -3.6177e-05, -1.9362e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0005, -0.0009,  0.0004], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0005,  0.0004], device='cuda:0', requires_grad=True)\n",
      "tau: 2.1263048245120335\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1691,  0.1759, -0.3450], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0055, -0.0006, -0.0049], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0740,  0.0796, -0.1536], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040,  0.0007, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0296,  0.0264, -0.0560], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024,  0.0008, -0.0032], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0171,  0.0159, -0.0330], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0187,  0.0179, -0.0366], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.5383e-04, -6.4267e-05, -7.8957e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0080,  0.0097, -0.0177], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2908e-04,  7.7309e-05,  5.1766e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0090,  0.0077, -0.0166], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.6706e-04, -1.0764e-05, -2.5629e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0004, -0.0009,  0.0005], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0005,  0.0005], device='cuda:0', requires_grad=True)\n",
      "[Iter 2400 Task segm] Train Loss: 0.3102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2400 Task dept] Train Loss: 0.0261\n",
      "[Iter 2400 Total] Train Loss: 0.1681\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 0.8938\n",
      "{'mIoU': 0.2362, 'Pixel Acc': 0.6377, 'cmp': -0.2794}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0470\n",
      "{'abs_err': 0.0465, 'rel_err': 0.8013, 'sigma_1.25': 37.9803, 'sigma_1.25^2': 58.7095, 'sigma_1.25^3': 72.5435, 'cmp': -0.8335}\n",
      "======================================================================\n",
      "tau: 2.051884155654112\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1801,  0.1875, -0.3676], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0056, -0.0006, -0.0049], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0813,  0.0848, -0.1661], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041,  0.0007, -0.0049], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0367,  0.0323, -0.0690], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024,  0.0008, -0.0032], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0201,  0.0203, -0.0404], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.1206e-04,  9.9553e-05, -5.1161e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0205,  0.0198, -0.0403], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.7104e-04, -7.2981e-05, -7.9806e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0110,  0.0111, -0.0221], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.2448e-04,  7.7013e-05,  4.7470e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0098,  0.0087, -0.0184], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.6676e-04, -5.7657e-06, -2.6100e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0014, -0.0004, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0005,  0.0005], device='cuda:0', requires_grad=True)\n",
      "tau: 1.9800682102062181\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1811,  0.1884, -0.3695], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0058, -0.0005, -0.0053], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0812,  0.0847, -0.1659], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0044,  0.0009, -0.0053], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0373,  0.0336, -0.0708], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029,  0.0007, -0.0036], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0200,  0.0202, -0.0403], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005,  0.0001, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0208,  0.0200, -0.0409], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0049e-03, -9.7472e-05, -9.0748e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0114,  0.0115, -0.0229], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.5685e-04,  6.0149e-05,  9.6705e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0099,  0.0088, -0.0187], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.0664e-04,  8.1865e-07, -3.0746e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0013, -0.0004, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0005,  0.0005], device='cuda:0', requires_grad=True)\n",
      "[Iter 2600 Task segm] Train Loss: 0.3069\n",
      "[Iter 2600 Task dept] Train Loss: 0.0255\n",
      "[Iter 2600 Total] Train Loss: 0.1662\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 0.9723\n",
      "{'mIoU': 0.2332, 'Pixel Acc': 0.6305, 'cmp': -0.2879}\n",
      "[Iter 2600 Task dept] Val Loss: 0.0525\n",
      "{'abs_err': 0.0524, 'rel_err': 0.8952, 'sigma_1.25': 36.4135, 'sigma_1.25^2': 57.4593, 'sigma_1.25^3': 70.5035, 'cmp': -0.9708}\n",
      "======================================================================\n",
      "tau: 1.9107658228490005\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2051,  0.2157, -0.4208], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0058, -0.0004, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0954,  0.1023, -0.1976], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045,  0.0009, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0391,  0.0396, -0.0787], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0030,  0.0007, -0.0036], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0217,  0.0220, -0.0436], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005,  0.0001, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0231,  0.0219, -0.0450], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0001, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0137,  0.0122, -0.0258], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.6106e-04,  5.9678e-05,  1.0138e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0110,  0.0105, -0.0215], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.0875e-04, -1.4509e-06, -3.0730e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0018,  0.0002, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0005,  0.0004], device='cuda:0', requires_grad=True)\n",
      "tau: 1.8438890190492854\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2071,  0.2177, -0.4248], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0006, -0.0062], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0968,  0.1044, -0.2012], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050,  0.0009, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0392,  0.0398, -0.0790], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0030,  0.0007, -0.0037], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0222,  0.0239, -0.0462], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005,  0.0001, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0233,  0.0221, -0.0454], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0001, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0139,  0.0125, -0.0264], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4394e-04,  7.3989e-05,  6.9947e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0112,  0.0106, -0.0218], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.2703e-04, -2.5112e-05, -4.0192e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0017,  0.0002, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0005,  0.0005], device='cuda:0', requires_grad=True)\n",
      "[Iter 2800 Task segm] Train Loss: 0.3185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 2800 Task dept] Train Loss: 0.0254\n",
      "[Iter 2800 Total] Train Loss: 0.1720\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 0.9358\n",
      "{'mIoU': 0.2237, 'Pixel Acc': 0.6221, 'cmp': -0.3054}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0577\n",
      "{'abs_err': 0.0568, 'rel_err': 1.0219, 'sigma_1.25': 36.3312, 'sigma_1.25^2': 56.1162, 'sigma_1.25^3': 68.6226, 'cmp': -1.1074}\n",
      "======================================================================\n",
      "tau: 1.7793529033825604\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2542,  0.2660, -0.5202], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0006, -0.0062], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1229,  0.1254, -0.2483], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050,  0.0009, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0446,  0.0433, -0.0879], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0030,  0.0007, -0.0037], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0261,  0.0276, -0.0537], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005,  0.0001, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0257,  0.0262, -0.0519], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0155,  0.0151, -0.0306], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4105e-04,  6.7644e-05,  7.3403e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0124,  0.0116, -0.0240], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.3512e-04, -2.7395e-05, -4.0773e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0028,  0.0007, -0.0035], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0010,  0.0006,  0.0005], device='cuda:0', requires_grad=True)\n",
      "tau: 1.7170755517641707\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2626,  0.2717, -0.5343], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0077, -0.0005, -0.0072], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1237,  0.1258, -0.2495], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0056,  0.0009, -0.0065], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0455,  0.0445, -0.0900], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0036,  0.0005, -0.0041], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0265,  0.0276, -0.0541], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0255,  0.0266, -0.0521], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0002, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0163,  0.0157, -0.0320], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.5397e-04,  7.6009e-05,  1.7796e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0124,  0.0116, -0.0240], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.1575e-04, -1.7094e-05, -3.9866e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0027,  0.0009, -0.0036], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0011,  0.0006,  0.0005], device='cuda:0', requires_grad=True)\n",
      "[Iter 3000 Task segm] Train Loss: 0.3362\n",
      "[Iter 3000 Task dept] Train Loss: 0.0252\n",
      "[Iter 3000 Total] Train Loss: 0.1807\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 0.9288\n",
      "{'mIoU': 0.228, 'Pixel Acc': 0.6284, 'cmp': -0.2959}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0633\n",
      "{'abs_err': 0.0621, 'rel_err': 1.1756, 'sigma_1.25': 32.1431, 'sigma_1.25^2': 52.4395, 'sigma_1.25^3': 65.9499, 'cmp': -1.2883}\n",
      "======================================================================\n",
      "tau: 1.6569779074524247\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2809,  0.2877, -0.5686], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0076, -0.0004, -0.0072], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1413,  0.1482, -0.2895], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0057,  0.0009, -0.0066], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0556,  0.0502, -0.1058], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0037,  0.0004, -0.0041], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0299,  0.0300, -0.0599], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0318,  0.0320, -0.0638], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0002, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0208,  0.0205, -0.0413], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.7421e-04,  6.7487e-05,  2.0672e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0146,  0.0126, -0.0272], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.0299e-04, -1.0577e-05, -3.9242e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0028,  0.0011, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0011,  0.0006,  0.0005], device='cuda:0', requires_grad=True)\n",
      "tau: 1.5989836806915898\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2818,  0.2876, -0.5693], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0087, -0.0004, -0.0083], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1457,  0.1516, -0.2973], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0063,  0.0011, -0.0074], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0574,  0.0525, -0.1099], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041,  0.0004, -0.0044], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0310,  0.0305, -0.0614], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0323,  0.0324, -0.0647], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0002, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0216,  0.0218, -0.0434], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4970e-04,  2.8386e-05,  1.2131e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0148,  0.0127, -0.0275], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.9755e-04, -3.3753e-05, -4.6380e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0028,  0.0012, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0004,  0.0004], device='cuda:0', requires_grad=True)\n",
      "[Iter 3200 Task segm] Train Loss: 0.3277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3200 Task dept] Train Loss: 0.0251\n",
      "[Iter 3200 Total] Train Loss: 0.1764\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 1.0481\n",
      "{'mIoU': 0.2115, 'Pixel Acc': 0.6075, 'cmp': -0.3303}\n",
      "[Iter 3200 Task dept] Val Loss: 0.0597\n",
      "{'abs_err': 0.0588, 'rel_err': 1.0762, 'sigma_1.25': 32.4579, 'sigma_1.25^2': 52.3654, 'sigma_1.25^3': 66.0205, 'cmp': -1.1883}\n",
      "======================================================================\n",
      "tau: 1.5430192518673842\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3302,  0.3231, -0.6533], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0089, -0.0005, -0.0084], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1595,  0.1626, -0.3221], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0064,  0.0010, -0.0074], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0641,  0.0571, -0.1211], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041,  0.0003, -0.0045], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0348,  0.0354, -0.0701], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0337,  0.0322, -0.0660], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0237,  0.0219, -0.0456], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.3282e-04,  2.8393e-05,  1.0442e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0165,  0.0132, -0.0297], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.0394e-04, -3.5674e-05, -4.6826e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0038,  0.0020, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0004,  0.0004], device='cuda:0', requires_grad=True)\n",
      "tau: 1.4890135780520257\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3341,  0.3274, -0.6615], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0139, -0.0016, -0.0124], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1615,  0.1643, -0.3258], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0070,  0.0010, -0.0080], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0645,  0.0577, -0.1222], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0046,  0.0002, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0347,  0.0361, -0.0708], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0332,  0.0319, -0.0650], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0003, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0236,  0.0212, -0.0448], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.8962e-04, -2.1940e-05,  2.1156e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0162,  0.0129, -0.0291], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.1311e-04, -5.1518e-05, -5.6160e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0038,  0.0021, -0.0060], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0005,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 3400 Task segm] Train Loss: 0.3432\n",
      "[Iter 3400 Task dept] Train Loss: 0.0275\n",
      "[Iter 3400 Total] Train Loss: 0.1854\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.0562\n",
      "{'mIoU': 0.2114, 'Pixel Acc': 0.6027, 'cmp': -0.3337}\n",
      "[Iter 3400 Task dept] Val Loss: 0.0573\n",
      "{'abs_err': 0.0569, 'rel_err': 1.0336, 'sigma_1.25': 31.0367, 'sigma_1.25^2': 54.0041, 'sigma_1.25^3': 69.2407, 'cmp': -1.1337}\n",
      "======================================================================\n",
      "tau: 1.4368981028202048\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3625,  0.3536, -0.7161], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0142, -0.0015, -0.0127], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1710,  0.1760, -0.3470], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0070,  0.0011, -0.0081], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0779,  0.0699, -0.1479], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0046,  0.0002, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0374,  0.0404, -0.0778], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0370,  0.0357, -0.0727], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0003, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0254,  0.0243, -0.0496], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.9760e-04, -2.3234e-05,  2.2083e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0192,  0.0158, -0.0350], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.1503e-04, -5.7088e-05, -5.5794e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0056,  0.0038, -0.0094], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0005,  0.0001], device='cuda:0', requires_grad=True)\n",
      "tau: 1.3866066692214976\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3688,  0.3679, -0.7367], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0157, -0.0017, -0.0140], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1725,  0.1808, -0.3533], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0077,  0.0011, -0.0088], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0779,  0.0710, -0.1489], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0048,  0.0002, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0375,  0.0403, -0.0778], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006,  0.0002, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0383,  0.0363, -0.0746], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0003, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0252,  0.0244, -0.0496], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.0260e-04, -5.9474e-05,  2.6208e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0193,  0.0159, -0.0352], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.1041e-04, -7.6865e-05, -6.3355e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0056,  0.0038, -0.0094], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0005,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 3600 Task segm] Train Loss: 0.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3600 Task dept] Train Loss: 0.0250\n",
      "[Iter 3600 Total] Train Loss: 0.1755\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.2141\n",
      "{'mIoU': 0.1992, 'Pixel Acc': 0.5886, 'cmp': -0.3582}\n",
      "[Iter 3600 Task dept] Val Loss: 0.0645\n",
      "{'abs_err': 0.0645, 'rel_err': 1.0293, 'sigma_1.25': 32.0812, 'sigma_1.25^2': 51.9854, 'sigma_1.25^3': 65.3698, 'cmp': -1.2307}\n",
      "======================================================================\n",
      "tau: 1.338075435798745\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3945,  0.3917, -0.7862], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0158, -0.0016, -0.0141], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1943,  0.2011, -0.3953], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0078,  0.0010, -0.0089], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0845,  0.0766, -0.1611], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0048,  0.0002, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0420,  0.0460, -0.0880], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006,  0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0381,  0.0358, -0.0739], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0003, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0299,  0.0311, -0.0610], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.7051e-04, -5.1901e-05,  2.2241e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0238,  0.0193, -0.0430], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.4004e-04, -8.7645e-05, -6.5240e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0051, -0.0116], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0007,  0.0005,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 1.2912427955457888\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3955,  0.3918, -0.7873], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0182, -0.0025, -0.0157], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1998,  0.2085, -0.4083], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0083,  0.0009, -0.0092], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0854,  0.0788, -0.1641], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.1379e-03,  8.3907e-05, -5.2218e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0438,  0.0469, -0.0907], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0380,  0.0361, -0.0741], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0003, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0315,  0.0319, -0.0634], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0001, -0.0001,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0242,  0.0200, -0.0442], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0001, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0051, -0.0117], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0005,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 3800 Task segm] Train Loss: 0.3341\n",
      "[Iter 3800 Task dept] Train Loss: 0.0253\n",
      "[Iter 3800 Total] Train Loss: 0.1797\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.0143\n",
      "{'mIoU': 0.2177, 'Pixel Acc': 0.6068, 'cmp': -0.3231}\n",
      "[Iter 3800 Task dept] Val Loss: 0.0619\n",
      "{'abs_err': 0.0606, 'rel_err': 1.1479, 'sigma_1.25': 31.4126, 'sigma_1.25^2': 53.025, 'sigma_1.25^3': 66.9082, 'cmp': -1.2531}\n",
      "======================================================================\n",
      "tau: 1.2460492977016862\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4348,  0.4369, -0.8717], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0186, -0.0023, -0.0163], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2182,  0.2378, -0.4561], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0084,  0.0009, -0.0093], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0933,  0.0907, -0.1840], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.1820e-03,  9.7981e-05, -5.2800e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0479,  0.0545, -0.1024], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007,  0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0410,  0.0394, -0.0804], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0003, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0342,  0.0342, -0.0684], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002, -0.0001,  0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0261,  0.0226, -0.0487], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0001, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0065, -0.0130], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0007,  0.0005,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 1.202437572282127\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4366,  0.4379, -0.8745], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0213, -0.0022, -0.0191], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2205,  0.2383, -0.4588], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0090,  0.0007, -0.0097], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0927,  0.0909, -0.1836], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0056,  0.0003, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0484,  0.0551, -0.1034], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0406,  0.0395, -0.0801], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0004, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0343,  0.0343, -0.0687], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-9.4486e-05, -1.7869e-04,  2.7317e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0263,  0.0228, -0.0491], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0065,  0.0065, -0.0131], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0004,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 4000 Task segm] Train Loss: 0.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4000 Task dept] Train Loss: 0.0257\n",
      "[Iter 4000 Total] Train Loss: 0.1788\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.5018\n",
      "{'mIoU': 0.1699, 'Pixel Acc': 0.5487, 'cmp': -0.4214}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0672\n",
      "{'abs_err': 0.0664, 'rel_err': 1.3612, 'sigma_1.25': 30.2685, 'sigma_1.25^2': 51.5563, 'sigma_1.25^3': 64.5878, 'cmp': -1.4615}\n",
      "======================================================================\n",
      "tau: 1.1603522572522524\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4559,  0.4491, -0.9050], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0214, -0.0023, -0.0192], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2292,  0.2536, -0.4828], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0091,  0.0007, -0.0098], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1130,  0.1067, -0.2197], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0056,  0.0004, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0495,  0.0601, -0.1096], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008,  0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0484,  0.0435, -0.0919], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0004, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0383,  0.0392, -0.0775], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-8.6654e-05, -1.9177e-04,  2.7843e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0289,  0.0250, -0.0539], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0088,  0.0082, -0.0169], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0004,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 1.1197399282484235\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4559,  0.4495, -0.9053], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0252, -0.0031, -0.0221], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2302,  0.2543, -0.4845], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0097,  0.0011, -0.0107], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1137,  0.1073, -0.2210], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0060,  0.0003, -0.0063], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0497,  0.0598, -0.1095], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0490,  0.0435, -0.0925], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0005, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0385,  0.0393, -0.0778], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-5.2919e-05, -2.2784e-04,  2.8076e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0291,  0.0250, -0.0541], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0090,  0.0083, -0.0173], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0001], device='cuda:0', requires_grad=True)\n",
      "[Iter 4200 Task segm] Train Loss: 0.3329\n",
      "[Iter 4200 Task dept] Train Loss: 0.0263\n",
      "[Iter 4200 Total] Train Loss: 0.1796\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.4002\n",
      "{'mIoU': 0.1756, 'Pixel Acc': 0.5487, 'cmp': -0.4144}\n",
      "[Iter 4200 Task dept] Val Loss: 0.0638\n",
      "{'abs_err': 0.0642, 'rel_err': 1.0693, 'sigma_1.25': 27.9704, 'sigma_1.25^2': 48.905, 'sigma_1.25^3': 64.4074, 'cmp': -1.2724}\n",
      "======================================================================\n",
      "tau: 1.0805490307597287\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5207,  0.4919, -1.0126], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0255, -0.0031, -0.0223], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2555,  0.2716, -0.5271], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0097,  0.0011, -0.0108], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1334,  0.1299, -0.2633], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0061,  0.0003, -0.0064], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0590,  0.0623, -0.1213], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0545,  0.0502, -0.1047], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0006, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0446,  0.0441, -0.0887], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-9.0669e-05, -2.2763e-04,  3.1830e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0344,  0.0293, -0.0638], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0002, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0097,  0.0089, -0.0186], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0003,  0.0001], device='cuda:0', requires_grad=True)\n",
      "tau: 1.0427298146831383\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5242,  0.4925, -1.0167], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0286, -0.0036, -0.0250], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2580,  0.2730, -0.5311], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0099,  0.0010, -0.0109], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1349,  0.1308, -0.2657], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0066,  0.0002, -0.0068], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0616,  0.0651, -0.1267], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0551,  0.0506, -0.1057], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0006, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0450,  0.0447, -0.0897], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0001, -0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0343,  0.0288, -0.0631], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0003, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0096,  0.0089, -0.0185], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0004,  0.0002], device='cuda:0', requires_grad=True)\n",
      "[Iter 4400 Task segm] Train Loss: 0.3493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4400 Task dept] Train Loss: 0.0255\n",
      "[Iter 4400 Total] Train Loss: 0.1874\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.0350\n",
      "{'mIoU': 0.2132, 'Pixel Acc': 0.6206, 'cmp': -0.3195}\n",
      "[Iter 4400 Task dept] Val Loss: 0.0643\n",
      "{'abs_err': 0.0658, 'rel_err': 0.7447, 'sigma_1.25': 22.9258, 'sigma_1.25^2': 42.3828, 'sigma_1.25^3': 58.0313, 'cmp': -1.1379}\n",
      "======================================================================\n",
      "tau: 1.0062342711692285\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5841,  0.5587, -1.1429], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0287, -0.0035, -0.0251], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2782,  0.2987, -0.5769], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0100,  0.0010, -0.0110], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1508,  0.1437, -0.2944], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0066,  0.0003, -0.0068], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0650,  0.0706, -0.1356], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0580,  0.0569, -0.1149], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0006, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0487,  0.0481, -0.0968], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0002, -0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0340,  0.0283, -0.0623], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0003, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0113,  0.0099, -0.0211], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0006,  0.0004,  0.0002], device='cuda:0', requires_grad=True)\n",
      "tau: 0.9710160716783055\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5878,  0.5617, -1.1495], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0322, -0.0039, -0.0283], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2787,  0.2995, -0.5782], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0105,  0.0012, -0.0117], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1523,  0.1466, -0.2989], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0004, -0.0069], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0653,  0.0718, -0.1371], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011,  0.0001, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0579,  0.0568, -0.1147], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0007, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0485,  0.0482, -0.0966], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0001, -0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0343,  0.0287, -0.0630], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0003, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0111,  0.0097, -0.0208], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "[Iter 4600 Task segm] Train Loss: 0.3564\n",
      "[Iter 4600 Task dept] Train Loss: 0.0274\n",
      "[Iter 4600 Total] Train Loss: 0.1919\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.4393\n",
      "{'mIoU': 0.176, 'Pixel Acc': 0.5358, 'cmp': -0.4224}\n",
      "[Iter 4600 Task dept] Val Loss: 0.0774\n",
      "{'abs_err': 0.0762, 'rel_err': 1.3503, 'sigma_1.25': 25.9379, 'sigma_1.25^2': 44.0637, 'sigma_1.25^3': 58.177, 'cmp': -1.6138}\n",
      "======================================================================\n",
      "tau: 0.9370305091695648\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6476,  0.6277, -1.2753], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0328, -0.0040, -0.0288], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3010,  0.3173, -0.6183], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0105,  0.0012, -0.0118], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1670,  0.1563, -0.3232], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0005, -0.0069], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0781,  0.0792, -0.1573], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011,  0.0001, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0610,  0.0607, -0.1216], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0007, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0555,  0.0500, -0.1055], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0001, -0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0407,  0.0337, -0.0744], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0003, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0114,  0.0110, -0.0224], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0005,  0.0002,  0.0003], device='cuda:0', requires_grad=True)\n",
      "tau: 0.90423444134863\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6521,  0.6289, -1.2809], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0363, -0.0044, -0.0318], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3023,  0.3186, -0.6209], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0118,  0.0007, -0.0124], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1681,  0.1565, -0.3245], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0077, -0.0006, -0.0071], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0790,  0.0803, -0.1593], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011,  0.0001, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0609,  0.0613, -0.1222], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0028, -0.0007, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0557,  0.0502, -0.1059], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.0048e-05, -2.4602e-04,  1.7598e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0412,  0.0336, -0.0748], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0003, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0114,  0.0110, -0.0224], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0004,  0.0003,  0.0001], device='cuda:0', requires_grad=True)\n",
      "[Iter 4800 Task segm] Train Loss: 0.3493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4800 Task dept] Train Loss: 0.0260\n",
      "[Iter 4800 Total] Train Loss: 0.1877\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.4059\n",
      "{'mIoU': 0.1782, 'Pixel Acc': 0.5405, 'cmp': -0.4165}\n",
      "[Iter 4800 Task dept] Val Loss: 0.0823\n",
      "{'abs_err': 0.0832, 'rel_err': 1.5146, 'sigma_1.25': 29.9676, 'sigma_1.25^2': 50.1429, 'sigma_1.25^3': 65.0727, 'cmp': -1.7554}\n",
      "======================================================================\n",
      "tau: 0.8725862359014279\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6731,  0.6492, -1.3223], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0364, -0.0044, -0.0320], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3462,  0.3552, -0.7014], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0118,  0.0006, -0.0124], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1774,  0.1745, -0.3519], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0077, -0.0006, -0.0071], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0868,  0.0967, -0.1835], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011,  0.0001, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0667,  0.0654, -0.1321], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027, -0.0007, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0624,  0.0580, -0.1204], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.4715e-05, -2.8695e-04,  1.9223e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0425,  0.0338, -0.0763], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0003, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0123,  0.0122, -0.0245], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.8194e-04,  2.0805e-04,  7.3890e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.8420457176448779\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6747,  0.6526, -1.3273], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0388, -0.0045, -0.0343], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3497,  0.3586, -0.7084], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0122,  0.0003, -0.0125], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1787,  0.1753, -0.3540], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0085, -0.0008, -0.0077], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0863,  0.0973, -0.1836], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2310e-03, -2.5063e-05, -1.2059e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0665,  0.0651, -0.1317], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0008, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0625,  0.0585, -0.1210], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0001, -0.0003,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0428,  0.0338, -0.0766], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0003, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0123,  0.0120, -0.0242], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.5239e-04,  7.5154e-05,  7.7239e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 5000 Task segm] Train Loss: 0.3402\n",
      "[Iter 5000 Task dept] Train Loss: 0.0259\n",
      "[Iter 5000 Total] Train Loss: 0.1831\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.5740\n",
      "{'mIoU': 0.1694, 'Pixel Acc': 0.5496, 'cmp': -0.4215}\n",
      "[Iter 5000 Task dept] Val Loss: 0.0740\n",
      "{'abs_err': 0.0743, 'rel_err': 1.1827, 'sigma_1.25': 24.5523, 'sigma_1.25^2': 43.2658, 'sigma_1.25^3': 57.6668, 'cmp': -1.4975}\n",
      "======================================================================\n",
      "tau: 0.8125741175273071\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7596,  0.6973, -1.4568], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0390, -0.0047, -0.0343], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3683,  0.3796, -0.7479], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0122,  0.0004, -0.0126], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1889,  0.1821, -0.3710], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0086, -0.0009, -0.0077], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0893,  0.0995, -0.1888], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2449e-03, -2.5271e-05, -1.2196e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0758,  0.0733, -0.1491], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0008, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0624,  0.0617, -0.1241], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002, -0.0003,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0477,  0.0386, -0.0863], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0003, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0122,  0.0126, -0.0248], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.2331e-04,  8.3362e-05,  1.3995e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.7841340234138513\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7606,  0.6990, -1.4596], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0448, -0.0058, -0.0391], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3693,  0.3829, -0.7522], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0118,  0.0008, -0.0126], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1893,  0.1826, -0.3719], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0093, -0.0012, -0.0081], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0890,  0.0999, -0.1890], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2364e-03, -8.4139e-05, -1.1522e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0758,  0.0735, -0.1494], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033, -0.0010, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0626,  0.0615, -0.1241], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.9798e-04, -4.5164e-04,  5.3669e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0474,  0.0389, -0.0863], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0121,  0.0126, -0.0247], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.6152e-05, -4.2813e-05, -4.3340e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 5200 Task segm] Train Loss: 0.3643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5200 Task dept] Train Loss: 0.0266\n",
      "[Iter 5200 Total] Train Loss: 0.1954\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 1.6511\n",
      "{'mIoU': 0.1526, 'Pixel Acc': 0.5029, 'cmp': -0.4736}\n",
      "[Iter 5200 Task dept] Val Loss: 0.0670\n",
      "{'abs_err': 0.0663, 'rel_err': 1.2706, 'sigma_1.25': 29.5567, 'sigma_1.25^2': 48.9331, 'sigma_1.25^3': 62.0455, 'cmp': -1.4202}\n",
      "======================================================================\n",
      "tau: 0.7566893325943664\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8091,  0.7494, -1.5586], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0451, -0.0056, -0.0395], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4214,  0.4140, -0.8353], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0117,  0.0008, -0.0125], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1994,  0.1933, -0.3927], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0096, -0.0014, -0.0082], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1008,  0.1101, -0.2108], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1838e-03, -9.0664e-05, -1.0931e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0814,  0.0846, -0.1660], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033, -0.0011, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0674,  0.0656, -0.1330], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004, -0.0005,  0.0001], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0504,  0.0438, -0.0942], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0131,  0.0144, -0.0275], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.6080e-05, -3.8788e-05,  2.7060e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.7302052059535636\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8107,  0.7500, -1.5607], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0504, -0.0051, -0.0453], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4294,  0.4189, -0.8483], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0131,  0.0004, -0.0136], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2005,  0.1967, -0.3972], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0105, -0.0015, -0.0090], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1011,  0.1111, -0.2122], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0817,  0.0847, -0.1664], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0034, -0.0011, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0670,  0.0654, -0.1324], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.4939e-04, -5.8045e-04,  3.1062e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0504,  0.0439, -0.0943], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0004, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0130,  0.0147, -0.0277], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.4095e-04, -3.4703e-05, -1.0625e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 5400 Task segm] Train Loss: 0.3512\n",
      "[Iter 5400 Task dept] Train Loss: 0.0270\n",
      "[Iter 5400 Total] Train Loss: 0.1891\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 1.4983\n",
      "{'mIoU': 0.1554, 'Pixel Acc': 0.5212, 'cmp': -0.4578}\n",
      "[Iter 5400 Task dept] Val Loss: 0.0842\n",
      "{'abs_err': 0.0827, 'rel_err': 1.2919, 'sigma_1.25': 26.9214, 'sigma_1.25^2': 45.0166, 'sigma_1.25^3': 58.4238, 'cmp': -1.6493}\n",
      "======================================================================\n",
      "tau: 0.7046480237451889\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8275,  0.7904, -1.6179], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0507, -0.0051, -0.0456], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4884,  0.4440, -0.9324], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0131,  0.0004, -0.0135], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2107,  0.2077, -0.4184], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0105, -0.0015, -0.0090], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1069,  0.1227, -0.2296], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0001, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0882,  0.0908, -0.1790], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033, -0.0011, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0744,  0.0670, -0.1414], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.6638e-04, -6.0901e-04,  4.2626e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0505,  0.0479, -0.0984], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0004, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0154,  0.0175, -0.0329], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.6223e-05,  2.2452e-06, -9.8470e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.6799853429141073\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8275,  0.7922, -1.6197], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0533, -0.0052, -0.0481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4938,  0.4452, -0.9390], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0140,  0.0003, -0.0144], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2102,  0.2075, -0.4177], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0113, -0.0018, -0.0095], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1086,  0.1242, -0.2328], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1501e-03, -3.5551e-05, -1.1146e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0897,  0.0917, -0.1814], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0036, -0.0012, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0733,  0.0667, -0.1400], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.2361e-04, -7.1918e-04,  9.5569e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0510,  0.0481, -0.0991], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0154,  0.0179, -0.0333], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.8186e-04, -1.9662e-06, -1.7990e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 5600 Task segm] Train Loss: 0.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 5600 Task dept] Train Loss: 0.0273\n",
      "[Iter 5600 Total] Train Loss: 0.1884\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.7395\n",
      "{'mIoU': 0.1443, 'Pixel Acc': 0.5097, 'cmp': -0.4794}\n",
      "[Iter 5600 Task dept] Val Loss: 0.0788\n",
      "{'abs_err': 0.0785, 'rel_err': 1.5891, 'sigma_1.25': 29.2722, 'sigma_1.25^2': 48.8289, 'sigma_1.25^3': 62.3185, 'cmp': -1.7569}\n",
      "======================================================================\n",
      "tau: 0.6561858559121135\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8642,  0.8159, -1.6801], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0538, -0.0052, -0.0486], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5148,  0.4697, -0.9845], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0143,  0.0002, -0.0145], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2209,  0.2293, -0.4501], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0113, -0.0018, -0.0095], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1199,  0.1321, -0.2520], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1200e-03, -2.6905e-05, -1.0931e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0795,  0.0923, -0.1718], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0036, -0.0012, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0798,  0.0718, -0.1516], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006, -0.0008,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0502,  0.0526, -0.1028], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0145,  0.0205, -0.0350], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.5307e-04,  1.9344e-05, -1.7242e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.6332193509551896\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8684,  0.8186, -1.6870], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0579, -0.0055, -0.0524], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5162,  0.4705, -0.9867], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0146, -0.0005, -0.0141], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2202,  0.2290, -0.4492], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0122, -0.0018, -0.0104], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1205,  0.1331, -0.2536], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0837e-03,  9.1853e-05, -1.1756e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0791,  0.0924, -0.1715], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0014, -0.0025], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0816,  0.0726, -0.1542], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006, -0.0008,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0504,  0.0532, -0.1036], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014, -0.0003, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0145,  0.0205, -0.0349], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.2036e-04,  2.1876e-05, -1.4223e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 5800 Task segm] Train Loss: 0.3737\n",
      "[Iter 5800 Task dept] Train Loss: 0.0275\n",
      "[Iter 5800 Total] Train Loss: 0.2006\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.5271\n",
      "{'mIoU': 0.1448, 'Pixel Acc': 0.5004, 'cmp': -0.485}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0837\n",
      "{'abs_err': 0.0832, 'rel_err': 1.5298, 'sigma_1.25': 28.276, 'sigma_1.25^2': 45.5224, 'sigma_1.25^3': 57.7763, 'cmp': -1.7961}\n",
      "======================================================================\n",
      "tau: 0.6110566736717579\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8779,  0.8357, -1.7136], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0587, -0.0056, -0.0532], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5606,  0.5121, -1.0727], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0146, -0.0005, -0.0141], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2423,  0.2427, -0.4850], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0122, -0.0017, -0.0105], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1264,  0.1495, -0.2759], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011,  0.0001, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0921,  0.1021, -0.1942], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0013, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0884,  0.0790, -0.1674], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0006, -0.0008,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0516,  0.0535, -0.1051], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0148,  0.0210, -0.0358], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.0870e-04, -2.1061e-05, -1.8764e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.5896696900932463\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8847,  0.8505, -1.7352], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0627, -0.0062, -0.0566], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5628,  0.5121, -1.0750], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0153, -0.0008, -0.0145], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2448,  0.2444, -0.4892], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0132, -0.0020, -0.0112], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1259,  0.1502, -0.2761], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.1313e-03, -1.5874e-05, -1.1154e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0921,  0.1021, -0.1942], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0014, -0.0024], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0887,  0.0798, -0.1685], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.3799e-04, -6.6318e-04, -7.4805e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0511,  0.0542, -0.1053], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0147,  0.0216, -0.0363], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.5198e-05,  2.1233e-04, -2.5753e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 6000 Task segm] Train Loss: 0.3690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6000 Task dept] Train Loss: 0.0265\n",
      "[Iter 6000 Total] Train Loss: 0.1978\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.1213\n",
      "{'mIoU': 0.2013, 'Pixel Acc': 0.5978, 'cmp': -0.3495}\n",
      "[Iter 6000 Task dept] Val Loss: 0.0770\n",
      "{'abs_err': 0.0767, 'rel_err': 1.3962, 'sigma_1.25': 24.5851, 'sigma_1.25^2': 44.1239, 'sigma_1.25^3': 59.9736, 'cmp': -1.6479}\n",
      "======================================================================\n",
      "tau: 0.5690312509399826\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9075,  0.8598, -1.7673], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0630, -0.0061, -0.0569], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5808,  0.5169, -1.0977], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0154, -0.0009, -0.0145], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2583,  0.2495, -0.5078], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0133, -0.0021, -0.0112], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1321,  0.1563, -0.2884], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0468e-03, -3.5858e-05, -1.0109e-03], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0920,  0.1055, -0.1975], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0014, -0.0024], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1012,  0.0820, -0.1832], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.1481e-04, -6.5791e-04, -5.6898e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0565,  0.0558, -0.1123], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0003, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0170,  0.0265, -0.0436], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-4.8798e-05,  2.7087e-04, -2.2208e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.5491151571570833\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9065,  0.8592, -1.7657], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0677, -0.0057, -0.0620], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5857,  0.5198, -1.1055], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0164, -0.0014, -0.0150], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2611,  0.2515, -0.5127], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0143, -0.0018, -0.0124], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1368,  0.1567, -0.2935], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0935,  0.1066, -0.2001], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0015, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1026,  0.0827, -0.1853], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.7443e-04, -6.8158e-04,  7.1436e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0568,  0.0561, -0.1129], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0004, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0175,  0.0271, -0.0446], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 4.0691e-05,  2.2299e-04, -2.6369e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 6200 Task segm] Train Loss: 0.3817\n",
      "[Iter 6200 Task dept] Train Loss: 0.0272\n",
      "[Iter 6200 Total] Train Loss: 0.2045\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 1.5930\n",
      "{'mIoU': 0.1672, 'Pixel Acc': 0.5229, 'cmp': -0.4421}\n",
      "[Iter 6200 Task dept] Val Loss: 0.0769\n",
      "{'abs_err': 0.0762, 'rel_err': 1.1879, 'sigma_1.25': 26.4161, 'sigma_1.25^2': 44.9386, 'sigma_1.25^3': 58.1789, 'cmp': -1.5123}\n",
      "======================================================================\n",
      "tau: 0.5298961266565854\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9704,  0.8704, -1.8408], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0683, -0.0057, -0.0626], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6023,  0.5635, -1.1658], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0165, -0.0014, -0.0151], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2915,  0.2639, -0.5554], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0143, -0.0018, -0.0125], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1386,  0.1710, -0.3096], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0968,  0.1316, -0.2284], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0015, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1038,  0.0882, -0.1920], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.7684e-04, -6.7040e-04, -6.4409e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0597,  0.0605, -0.1203], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0004, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0201,  0.0290, -0.0491], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 7.8244e-05,  1.8461e-04, -2.6285e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.5113497622236048\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9701,  0.8696, -1.8397], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0735, -0.0062, -0.0674], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6057,  0.5636, -1.1693], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0175, -0.0015, -0.0160], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2964,  0.2661, -0.5625], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0145, -0.0018, -0.0127], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1384,  0.1716, -0.3100], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0002, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0969,  0.1320, -0.2289], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0014, -0.0027], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1039,  0.0892, -0.1931], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0590,  0.0604, -0.1194], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0004, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0204,  0.0292, -0.0496], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.0278e-04,  9.4998e-05,  7.7808e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 6400 Task segm] Train Loss: 0.3677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6400 Task dept] Train Loss: 0.0266\n",
      "[Iter 6400 Total] Train Loss: 0.1972\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.5260\n",
      "{'mIoU': 0.1473, 'Pixel Acc': 0.5133, 'cmp': -0.4733}\n",
      "[Iter 6400 Task dept] Val Loss: 0.0801\n",
      "{'abs_err': 0.0804, 'rel_err': 1.498, 'sigma_1.25': 25.3048, 'sigma_1.25^2': 43.8087, 'sigma_1.25^3': 58.1373, 'cmp': -1.7558}\n",
      "======================================================================\n",
      "tau: 0.49345252054577865\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9815,  0.9476, -1.9290], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0739, -0.0062, -0.0677], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6070,  0.5817, -1.1887], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0176, -0.0014, -0.0161], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3132,  0.2877, -0.6008], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0145, -0.0019, -0.0126], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1493,  0.1760, -0.3253], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0002, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1011,  0.1530, -0.2542], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0013, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1119,  0.0969, -0.2088], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0638,  0.0635, -0.1273], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0004, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0240,  0.0329, -0.0569], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.4586e-05,  7.3184e-05,  1.4007e-06], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.4761816823266764\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9811,  0.9487, -1.9298], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0804, -0.0061, -0.0743], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6066,  0.5822, -1.1888], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0178, -0.0016, -0.0163], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3138,  0.2892, -0.6030], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0156, -0.0021, -0.0135], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1499,  0.1784, -0.3283], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1013,  0.1545, -0.2558], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0043, -0.0015, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1127,  0.0979, -0.2106], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.3918e-04, -6.8318e-04,  4.3994e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0642,  0.0633, -0.1274], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0019, -0.0004, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0241,  0.0332, -0.0573], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.0988e-04,  1.8650e-05,  9.1225e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 6600 Task segm] Train Loss: 0.3663\n",
      "[Iter 6600 Task dept] Train Loss: 0.0274\n",
      "[Iter 6600 Total] Train Loss: 0.1969\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.4733\n",
      "{'mIoU': 0.1497, 'Pixel Acc': 0.5436, 'cmp': -0.4499}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0803\n",
      "{'abs_err': 0.0807, 'rel_err': 1.383, 'sigma_1.25': 33.9874, 'sigma_1.25^2': 50.445, 'sigma_1.25^3': 62.5367, 'cmp': -1.6394}\n",
      "======================================================================\n",
      "tau: 0.4595153234452427\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0017,  0.9508, -1.9525], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0808, -0.0060, -0.0748], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6181,  0.6059, -1.2239], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0179, -0.0016, -0.0164], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3387,  0.3008, -0.6395], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0156, -0.0022, -0.0135], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1576,  0.1915, -0.3491], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1063,  0.1643, -0.2707], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0043, -0.0014, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1170,  0.1015, -0.2185], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.1812e-04, -6.6789e-04,  4.9775e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0714,  0.0709, -0.1423], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0019, -0.0004, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0244,  0.0354, -0.0599], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-8.0577e-05, -8.4059e-06,  8.8982e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.4434322871246592\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0077,  0.9521, -1.9599], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0861, -0.0047, -0.0814], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6200,  0.6054, -1.2255], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0182, -0.0016, -0.0166], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3415,  0.3015, -0.6430], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0162, -0.0021, -0.0140], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1582,  0.1929, -0.3511], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0004, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1049,  0.1655, -0.2704], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0047, -0.0015, -0.0032], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1159,  0.1015, -0.2174], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0727,  0.0708, -0.1435], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0244,  0.0355, -0.0599], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-1.4505e-04, -8.5183e-06,  1.5356e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 6800 Task segm] Train Loss: 0.3545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 6800 Task dept] Train Loss: 0.0268\n",
      "[Iter 6800 Total] Train Loss: 0.1906\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.6520\n",
      "{'mIoU': 0.1468, 'Pixel Acc': 0.4855, 'cmp': -0.4925}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0823\n",
      "{'abs_err': 0.0821, 'rel_err': 1.2621, 'sigma_1.25': 22.3377, 'sigma_1.25^2': 38.8333, 'sigma_1.25^3': 52.165, 'cmp': -1.6652}\n",
      "======================================================================\n",
      "tau: 0.4279121570752961\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0336,  0.9619, -1.9955], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0867, -0.0045, -0.0822], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6333,  0.6275, -1.2608], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0179, -0.0018, -0.0161], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3543,  0.3211, -0.6755], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0163, -0.0020, -0.0142], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1659,  0.1961, -0.3620], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0004, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1154,  0.1822, -0.2976], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0048, -0.0015, -0.0033], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1293,  0.1113, -0.2406], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0846,  0.0761, -0.1607], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0006, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0283,  0.0403, -0.0685], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-2.9542e-04,  3.1738e-05,  2.6368e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.41293523157766077\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0337,  0.9606, -1.9943], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0931, -0.0033, -0.0898], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6412,  0.6403, -1.2816], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192, -0.0028, -0.0164], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3542,  0.3229, -0.6771], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0169, -0.0022, -0.0147], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1672,  0.1972, -0.3644], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0004, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1163,  0.1837, -0.3000], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0048, -0.0015, -0.0033], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1295,  0.1113, -0.2409], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0860,  0.0769, -0.1629], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0290,  0.0406, -0.0696], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0003,  0.0005], device='cuda:0', requires_grad=True)\n",
      "[Iter 7000 Task segm] Train Loss: 0.3659\n",
      "[Iter 7000 Task dept] Train Loss: 0.0281\n",
      "[Iter 7000 Total] Train Loss: 0.1970\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 1.3517\n",
      "{'mIoU': 0.1654, 'Pixel Acc': 0.5663, 'cmp': -0.4152}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0774\n",
      "{'abs_err': 0.0772, 'rel_err': 1.3009, 'sigma_1.25': 26.9584, 'sigma_1.25^2': 47.1204, 'sigma_1.25^3': 62.0423, 'cmp': -1.5776}\n",
      "======================================================================\n",
      "tau: 0.3984824984724426\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0813,  1.0869, -2.1682], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0935, -0.0034, -0.0901], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6626,  0.6583, -1.3209], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193, -0.0029, -0.0163], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3770,  0.3405, -0.7175], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0169, -0.0022, -0.0147], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1734,  0.2022, -0.3756], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0003, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1209,  0.1875, -0.3084], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0049, -0.0015, -0.0034], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1308,  0.1220, -0.2529], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0005, -0.0007,  0.0002], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0913,  0.0778, -0.1691], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0289,  0.0442, -0.0732], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0003,  0.0006], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3845356110259071\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0809,  1.0858, -2.1667], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1000, -0.0013, -0.0986], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6642,  0.6583, -1.3226], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0189, -0.0024, -0.0165], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3804,  0.3436, -0.7241], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0174, -0.0024, -0.0150], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1778,  0.2033, -0.3811], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0004, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1251,  0.1895, -0.3146], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0049, -0.0014, -0.0035], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1308,  0.1239, -0.2547], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.0325e-04, -5.6934e-04, -3.3908e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0915,  0.0787, -0.1703], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0290,  0.0447, -0.0738], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0003,  0.0007], device='cuda:0', requires_grad=True)\n",
      "[Iter 7200 Task segm] Train Loss: 0.3461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7200 Task dept] Train Loss: 0.0283\n",
      "[Iter 7200 Total] Train Loss: 0.1872\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 3.0015\n",
      "{'mIoU': 0.1448, 'Pixel Acc': 0.4662, 'cmp': -0.5079}\n",
      "[Iter 7200 Task dept] Val Loss: 0.0742\n",
      "{'abs_err': 0.0747, 'rel_err': 1.2236, 'sigma_1.25': 26.881, 'sigma_1.25^2': 45.3134, 'sigma_1.25^3': 60.0229, 'cmp': -1.5101}\n",
      "======================================================================\n",
      "tau: 0.37107686464000034\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1133,  1.1084, -2.2217], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1005, -0.0012, -0.0994], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6771,  0.6936, -1.3707], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0190, -0.0025, -0.0165], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3957,  0.3628, -0.7585], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0175, -0.0025, -0.0150], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1871,  0.2236, -0.4107], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0004, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1337,  0.1916, -0.3253], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0049, -0.0014, -0.0035], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1329,  0.1256, -0.2585], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.7313e-04, -5.7616e-04, -9.6968e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0974,  0.0831, -0.1805], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0289,  0.0486, -0.0775], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0002,  0.0006], device='cuda:0', requires_grad=True)\n",
      "tau: 0.3580891743776003\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1125,  1.1075, -2.2199], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0320e-01,  1.2315e-05, -1.0322e-01], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6768,  0.6933, -1.3702], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192, -0.0016, -0.0176], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3984,  0.3631, -0.7615], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0179, -0.0027, -0.0151], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1880,  0.2257, -0.4137], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0006, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1336,  0.1915, -0.3252], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0051, -0.0014, -0.0037], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1341,  0.1262, -0.2602], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0007, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0978,  0.0837, -0.1815], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0019, -0.0005, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0284,  0.0487, -0.0772], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-8.2970e-04,  5.6800e-05,  7.7290e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 7400 Task segm] Train Loss: 0.3612\n",
      "[Iter 7400 Task dept] Train Loss: 0.0292\n",
      "[Iter 7400 Total] Train Loss: 0.1952\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 1.4505\n",
      "{'mIoU': 0.1714, 'Pixel Acc': 0.5358, 'cmp': -0.4281}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0833\n",
      "{'abs_err': 0.0825, 'rel_err': 1.4234, 'sigma_1.25': 28.1411, 'sigma_1.25^2': 47.1651, 'sigma_1.25^3': 60.3436, 'cmp': -1.7148}\n",
      "======================================================================\n",
      "tau: 0.34555605327438427\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1528,  1.1279, -2.2806], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.0351e-01,  1.3546e-06, -1.0351e-01], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7021,  0.6989, -1.4010], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192, -0.0017, -0.0176], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4018,  0.3821, -0.7840], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0178, -0.0027, -0.0151], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2004,  0.2336, -0.4340], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0006, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1368,  0.1937, -0.3305], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0051, -0.0014, -0.0037], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1268,  0.1296, -0.2564], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0007, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1022,  0.0884, -0.1907], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0019, -0.0005, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0323,  0.0543, -0.0866], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-8.2987e-04,  6.5893e-05,  7.6397e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.3334615914097808\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1557,  1.1284, -2.2841], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1075,  0.0023, -0.1099], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7077,  0.6990, -1.4067], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205, -0.0019, -0.0186], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4033,  0.3914, -0.7947], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0182, -0.0022, -0.0161], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2072,  0.2351, -0.4423], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0007, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1383,  0.1940, -0.3324], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0052, -0.0015, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1260,  0.1298, -0.2558], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0006, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1029,  0.0897, -0.1926], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0323,  0.0543, -0.0866], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-6.9876e-04, -2.3302e-06,  7.0109e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Iter 7600 Task segm] Train Loss: 0.3692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7600 Task dept] Train Loss: 0.0283\n",
      "[Iter 7600 Total] Train Loss: 0.1988\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.3410\n",
      "{'mIoU': 0.1641, 'Pixel Acc': 0.5362, 'cmp': -0.437}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0927\n",
      "{'abs_err': 0.0939, 'rel_err': 1.6673, 'sigma_1.25': 25.2512, 'sigma_1.25^2': 44.0878, 'sigma_1.25^3': 58.23, 'cmp': -2.0165}\n",
      "======================================================================\n",
      "tau: 0.32179043571043847\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3062,  1.1337, -2.4400], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1085,  0.0022, -0.1106], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7060,  0.7120, -1.4181], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0207, -0.0022, -0.0185], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4285,  0.4056, -0.8342], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0182, -0.0021, -0.0161], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2214,  0.2426, -0.4641], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0007, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1400,  0.2147, -0.3547], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0052, -0.0014, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1401,  0.1408, -0.2809], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0006, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1077,  0.0932, -0.2009], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0005, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0353,  0.0561, -0.0914], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-7.2786e-04,  2.8918e-05,  6.9894e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tau: 0.3105277704605731\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3050,  1.1325, -2.4375], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1132,  0.0054, -0.1186], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7052,  0.7115, -1.4167], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0202, -0.0018, -0.0184], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4290,  0.4052, -0.8342], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0186, -0.0018, -0.0168], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2209,  0.2433, -0.4642], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0008, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1386,  0.2148, -0.3534], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050, -0.0012, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1438,  0.1420, -0.2858], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0004, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1068,  0.0930, -0.1999], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0004, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0355,  0.0558, -0.0913], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0008,  0.0001,  0.0007], device='cuda:0', requires_grad=True)\n",
      "[Iter 7800 Task segm] Train Loss: 0.3545\n",
      "[Iter 7800 Task dept] Train Loss: 0.0280\n",
      "[Iter 7800 Total] Train Loss: 0.1913\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 1.4925\n",
      "{'mIoU': 0.1517, 'Pixel Acc': 0.5251, 'cmp': -0.4599}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0766\n",
      "{'abs_err': 0.0759, 'rel_err': 1.4687, 'sigma_1.25': 27.188, 'sigma_1.25^2': 46.3269, 'sigma_1.25^3': 59.9307, 'cmp': -1.6696}\n",
      "======================================================================\n",
      "tau: 0.29965929849445305\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3271,  1.1642, -2.4914], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1134,  0.0053, -0.1187], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7731,  0.7375, -1.5105], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0201, -0.0018, -0.0183], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4398,  0.4280, -0.8678], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0187, -0.0017, -0.0169], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2243,  0.2449, -0.4693], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0008, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1589,  0.2258, -0.3847], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050, -0.0012, -0.0038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1481,  0.1512, -0.2993], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0004, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1158,  0.1019, -0.2177], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0004, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0372,  0.0577, -0.0949], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0009,  0.0002,  0.0007], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2891712230471472\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3262,  1.1628, -2.4890], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1170,  0.0055, -0.1224], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7749,  0.7372, -1.5121], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0203, -0.0013, -0.0191], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4412,  0.4327, -0.8739], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0189, -0.0014, -0.0175], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2236,  0.2470, -0.4706], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0007, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1595,  0.2262, -0.3856], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050, -0.0011, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1488,  0.1515, -0.3003], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0004, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1159,  0.1022, -0.2181], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0004, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0377,  0.0578, -0.0954], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0011,  0.0003,  0.0008], device='cuda:0', requires_grad=True)\n",
      "[Iter 8000 Task segm] Train Loss: 0.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8000 Task dept] Train Loss: 0.0291\n",
      "[Iter 8000 Total] Train Loss: 0.1959\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 1.0927\n",
      "{'mIoU': 0.1906, 'Pixel Acc': 0.5985, 'cmp': -0.3623}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0718\n",
      "{'abs_err': 0.072, 'rel_err': 1.3522, 'sigma_1.25': 25.1176, 'sigma_1.25^2': 47.8126, 'sigma_1.25^3': 63.0922, 'cmp': -1.549}\n",
      "======================================================================\n",
      "tau: 0.279050230240497\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3412,  1.1770, -2.5182], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1170,  0.0054, -0.1224], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8035,  0.7428, -1.5463], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0202, -0.0010, -0.0192], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4460,  0.4544, -0.9004], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0190, -0.0014, -0.0176], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2355,  0.2509, -0.4865], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016, -0.0008, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1665,  0.2412, -0.4077], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0049, -0.0011, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1487,  0.1596, -0.3082], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0003, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1213,  0.1084, -0.2296], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0004, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0391,  0.0599, -0.0990], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0011,  0.0004,  0.0008], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2692834721820796\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.3394,  1.1763, -2.5157], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1235,  0.0053, -0.1287], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8033,  0.7421, -1.5453], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206, -0.0011, -0.0195], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4475,  0.4576, -0.9050], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.8629e-02, -8.6527e-06, -1.8621e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2361,  0.2513, -0.4874], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0005, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1662,  0.2429, -0.4091], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050, -0.0011, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1481,  0.1593, -0.3075], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014, -0.0008, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1235,  0.1087, -0.2323], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0002, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0377,  0.0599, -0.0976], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0012,  0.0004,  0.0008], device='cuda:0', requires_grad=True)\n",
      "[Iter 8200 Task segm] Train Loss: 0.3527\n",
      "[Iter 8200 Task dept] Train Loss: 0.0294\n",
      "[Iter 8200 Total] Train Loss: 0.1911\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.6478\n",
      "{'mIoU': 0.1666, 'Pixel Acc': 0.5512, 'cmp': -0.4238}\n",
      "[Iter 8200 Task dept] Val Loss: 0.1062\n",
      "{'abs_err': 0.1073, 'rel_err': 1.7855, 'sigma_1.25': 25.431, 'sigma_1.25^2': 42.7518, 'sigma_1.25^3': 56.8885, 'cmp': -2.2507}\n",
      "======================================================================\n",
      "tau: 0.2598585506557068\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.4215,  1.1813, -2.6028], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1238,  0.0059, -0.1297], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8397,  0.7752, -1.6149], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206, -0.0012, -0.0194], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4647,  0.4925, -0.9572], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0187,  0.0001, -0.0189], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2479,  0.2634, -0.5113], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0010, -0.0005, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1700,  0.2628, -0.4328], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0050, -0.0011, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1470,  0.1596, -0.3066], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015, -0.0008, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1212,  0.1060, -0.2272], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0002, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0399,  0.0641, -0.1041], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0012,  0.0004,  0.0008], device='cuda:0', requires_grad=True)\n",
      "tau: 0.25076350138275705\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.4199,  1.1804, -2.6003], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1302,  0.0066, -0.1368], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8397,  0.7760, -1.6158], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205, -0.0010, -0.0195], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4666,  0.4924, -0.9590], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192,  0.0002, -0.0195], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2460,  0.2637, -0.5098], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0003, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1697,  0.2670, -0.4367], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0053, -0.0012, -0.0041], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1464,  0.1597, -0.3061], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0013, -0.0008, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1206,  0.1058, -0.2264], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0002, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0408,  0.0650, -0.1057], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0018,  0.0006,  0.0012], device='cuda:0', requires_grad=True)\n",
      "[Iter 8400 Task segm] Train Loss: 0.3531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8400 Task dept] Train Loss: 0.0285\n",
      "[Iter 8400 Total] Train Loss: 0.1908\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 1.3990\n",
      "{'mIoU': 0.1676, 'Pixel Acc': 0.5505, 'cmp': -0.4231}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0776\n",
      "{'abs_err': 0.0767, 'rel_err': 1.3753, 'sigma_1.25': 26.5731, 'sigma_1.25^2': 45.0254, 'sigma_1.25^3': 57.4603, 'cmp': -1.6324}\n",
      "======================================================================\n",
      "tau: 0.24198677883436054\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5010,  1.2926, -2.7936], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1309,  0.0069, -0.1378], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8379,  0.7776, -1.6155], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0204, -0.0010, -0.0194], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4814,  0.5232, -1.0046], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0191,  0.0002, -0.0193], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2474,  0.2666, -0.5140], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1870,  0.2760, -0.4630], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0053, -0.0012, -0.0041], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1558,  0.1653, -0.3211], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014, -0.0008, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1210,  0.1102, -0.2312], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0003, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0423,  0.0681, -0.1104], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0020,  0.0006,  0.0015], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2335172415751579\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5047,  1.2981, -2.8029], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1393,  0.0066, -0.1459], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8370,  0.7769, -1.6139], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0212, -0.0015, -0.0197], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4841,  0.5237, -1.0078], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192,  0.0006, -0.0198], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2472,  0.2671, -0.5143], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.8550e-04, -6.8811e-05, -8.1669e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1878,  0.2764, -0.4642], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0059, -0.0012, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1564,  0.1655, -0.3219], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0010, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1209,  0.1102, -0.2311], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0002, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0431,  0.0688, -0.1119], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0024,  0.0007,  0.0017], device='cuda:0', requires_grad=True)\n",
      "[Iter 8600 Task segm] Train Loss: 0.3525\n",
      "[Iter 8600 Task dept] Train Loss: 0.0293\n",
      "[Iter 8600 Total] Train Loss: 0.1909\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 2.2806\n",
      "{'mIoU': 0.1353, 'Pixel Acc': 0.4483, 'cmp': -0.5317}\n",
      "[Iter 8600 Task dept] Val Loss: 0.0721\n",
      "{'abs_err': 0.0726, 'rel_err': 1.0709, 'sigma_1.25': 26.042, 'sigma_1.25^2': 44.8194, 'sigma_1.25^3': 60.3008, 'cmp': -1.3959}\n",
      "======================================================================\n",
      "tau: 0.22534413812002738\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5200,  1.3613, -2.8813], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1397,  0.0063, -0.1460], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8364,  0.7839, -1.6203], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0209, -0.0014, -0.0195], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4828,  0.5347, -1.0174], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192,  0.0006, -0.0198], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2584,  0.2750, -0.5335], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009, -0.0001, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1993,  0.2990, -0.4983], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0059, -0.0012, -0.0047], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1636,  0.1742, -0.3378], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0010, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1235,  0.1081, -0.2316], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0002, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0484,  0.0717, -0.1201], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0024,  0.0008,  0.0016], device='cuda:0', requires_grad=True)\n",
      "tau: 0.2174570932858264\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5196,  1.3592, -2.8788], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1433,  0.0103, -0.1536], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8366,  0.7833, -1.6198], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0204, -0.0013, -0.0191], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4823,  0.5382, -1.0205], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0200,  0.0008, -0.0208], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2595,  0.2755, -0.5350], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.3080e-04, -9.4903e-05, -8.3589e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1987,  0.2986, -0.4973], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0058, -0.0012, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1639,  0.1739, -0.3378], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0008, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1249,  0.1079, -0.2328], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0001, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0484,  0.0718, -0.1202], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0020,  0.0003,  0.0017], device='cuda:0', requires_grad=True)\n",
      "[Iter 8800 Task segm] Train Loss: 0.3506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8800 Task dept] Train Loss: 0.0276\n",
      "[Iter 8800 Total] Train Loss: 0.1891\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.3895\n",
      "{'mIoU': 0.1698, 'Pixel Acc': 0.545, 'cmp': -0.424}\n",
      "[Iter 8800 Task dept] Val Loss: 0.0903\n",
      "{'abs_err': 0.0799, 'rel_err': 1.2083, 'sigma_1.25': 31.6282, 'sigma_1.25^2': 49.0159, 'sigma_1.25^3': 63.0609, 'cmp': -1.5338}\n",
      "======================================================================\n",
      "tau: 0.20984609502082247\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5224,  1.3541, -2.8765], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1433,  0.0105, -0.1538], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8554,  0.7930, -1.6484], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0203, -0.0013, -0.0191], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5020,  0.5444, -1.0464], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0200,  0.0007, -0.0207], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2654,  0.2842, -0.5496], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.2101e-04, -5.0550e-05, -8.7046e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2057,  0.3034, -0.5091], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0058, -0.0012, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1655,  0.1787, -0.3442], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0009, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1336,  0.1103, -0.2439], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0001, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0502,  0.0721, -0.1223], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0020,  0.0003,  0.0017], device='cuda:0', requires_grad=True)\n",
      "tau: 0.20250148169509366\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5210,  1.3527, -2.8738], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1478,  0.0140, -0.1618], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8543,  0.7924, -1.6467], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0201, -0.0013, -0.0188], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5025,  0.5450, -1.0475], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0197,  0.0014, -0.0210], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2647,  0.2854, -0.5501], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 8.6446e-04, -2.3139e-05, -8.4132e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2061,  0.3027, -0.5089], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0060, -0.0012, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1652,  0.1787, -0.3438], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0007, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1354,  0.1102, -0.2456], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0001, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0507,  0.0724, -0.1231], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0020,  0.0008,  0.0013], device='cuda:0', requires_grad=True)\n",
      "[Iter 9000 Task segm] Train Loss: 0.3423\n",
      "[Iter 9000 Task dept] Train Loss: 0.0284\n",
      "[Iter 9000 Total] Train Loss: 0.1853\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 1.5246\n",
      "{'mIoU': 0.1601, 'Pixel Acc': 0.559, 'cmp': -0.4268}\n",
      "[Iter 9000 Task dept] Val Loss: 0.0682\n",
      "{'abs_err': 0.0676, 'rel_err': 1.0153, 'sigma_1.25': 28.5113, 'sigma_1.25^2': 48.3606, 'sigma_1.25^3': 62.4394, 'cmp': -1.2834}\n",
      "======================================================================\n",
      "tau: 0.1954139298357654\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5218,  1.3491, -2.8709], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1482,  0.0140, -0.1622], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8516,  0.7957, -1.6472], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0200, -0.0014, -0.0187], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5013,  0.5567, -1.0580], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0196,  0.0014, -0.0210], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2728,  0.3041, -0.5769], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 9.1235e-04, -8.2447e-05, -8.2990e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2205,  0.3049, -0.5254], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0059, -0.0011, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1814,  0.2018, -0.3832], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0007, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1479,  0.1256, -0.2735], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0002, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0521,  0.0720, -0.1242], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0020,  0.0007,  0.0012], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1885744422915136\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5202,  1.3478, -2.8680], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1556,  0.0142, -0.1698], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8514,  0.8052, -1.6567], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193, -0.0019, -0.0174], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5007,  0.5567, -1.0574], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0194,  0.0015, -0.0209], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2767,  0.3064, -0.5831], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.0220e-04, -3.7851e-04,  7.6307e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2218,  0.3053, -0.5271], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0062, -0.0011, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1814,  0.2022, -0.3836], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0008, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1487,  0.1254, -0.2742], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0005, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0535,  0.0722, -0.1257], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0016,  0.0006,  0.0010], device='cuda:0', requires_grad=True)\n",
      "[Iter 9200 Task segm] Train Loss: 0.3459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9200 Task dept] Train Loss: 0.0283\n",
      "[Iter 9200 Total] Train Loss: 0.1871\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 2.2292\n",
      "{'mIoU': 0.1253, 'Pixel Acc': 0.4747, 'cmp': -0.5264}\n",
      "[Iter 9200 Task dept] Val Loss: 0.0825\n",
      "{'abs_err': 0.082, 'rel_err': 1.3403, 'sigma_1.25': 27.2416, 'sigma_1.25^2': 45.2604, 'sigma_1.25^3': 58.1318, 'cmp': -1.6703}\n",
      "======================================================================\n",
      "tau: 0.18197433681131062\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5114,  1.3533, -2.8647], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1559,  0.0141, -0.1699], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8507,  0.8047, -1.6554], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193, -0.0023, -0.0170], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5256,  0.5731, -1.0987], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0194,  0.0015, -0.0209], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2850,  0.3204, -0.6054], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.9986e-04, -3.7075e-04,  7.0893e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2343,  0.3136, -0.5479], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0062, -0.0011, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1819,  0.2025, -0.3843], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0008, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1510,  0.1336, -0.2846], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0005, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0537,  0.0886, -0.1423], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0016,  0.0006,  0.0010], device='cuda:0', requires_grad=True)\n",
      "tau: 0.17560523502291475\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5096,  1.3523, -2.8620], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1604,  0.0155, -0.1759], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8496,  0.8041, -1.6538], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205, -0.0023, -0.0183], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5290,  0.5751, -1.1041], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193,  0.0020, -0.0213], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2847,  0.3211, -0.6058], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 2.8182e-04, -3.6516e-04,  8.3344e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2352,  0.3157, -0.5509], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0062, -0.0010, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1822,  0.2024, -0.3846], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0008, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1513,  0.1339, -0.2853], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0005, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0537,  0.0887, -0.1424], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0024,  0.0012,  0.0013], device='cuda:0', requires_grad=True)\n",
      "[Iter 9400 Task segm] Train Loss: 0.3542\n",
      "[Iter 9400 Task dept] Train Loss: 0.0285\n",
      "[Iter 9400 Total] Train Loss: 0.1914\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.5521\n",
      "{'mIoU': 0.1489, 'Pixel Acc': 0.507, 'cmp': -0.4754}\n",
      "[Iter 9400 Task dept] Val Loss: 0.0799\n",
      "{'abs_err': 0.0799, 'rel_err': 1.1471, 'sigma_1.25': 26.7462, 'sigma_1.25^2': 44.1188, 'sigma_1.25^3': 56.9477, 'cmp': -1.535}\n",
      "======================================================================\n",
      "tau: 0.16945905179711274\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6351,  1.3571, -2.9921], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1600,  0.0160, -0.1760], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8710,  0.8190, -1.6900], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206, -0.0023, -0.0184], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5308,  0.5735, -1.1044], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0194,  0.0020, -0.0214], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3050,  0.3361, -0.6411], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0002, -0.0003,  0.0001], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2453,  0.3170, -0.5622], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0062, -0.0010, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1865,  0.2155, -0.4020], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0008, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1553,  0.1314, -0.2867], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0006, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0565,  0.0893, -0.1459], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0025,  0.0012,  0.0013], device='cuda:0', requires_grad=True)\n",
      "tau: 0.16352798498421378\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6326,  1.3571, -2.9897], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1652,  0.0195, -0.1847], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8708,  0.8183, -1.6891], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0207, -0.0025, -0.0182], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5304,  0.5763, -1.1066], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0198,  0.0019, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3049,  0.3353, -0.6402], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 1.8411e-04, -1.5140e-04, -3.2711e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2454,  0.3168, -0.5622], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0060, -0.0010, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1859,  0.2149, -0.4008], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0011, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1555,  0.1318, -0.2874], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0006, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0565,  0.0901, -0.1466], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0026,  0.0014,  0.0013], device='cuda:0', requires_grad=True)\n",
      "[Iter 9600 Task segm] Train Loss: 0.3465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9600 Task dept] Train Loss: 0.0285\n",
      "[Iter 9600 Total] Train Loss: 0.1875\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 1.5388\n",
      "{'mIoU': 0.1623, 'Pixel Acc': 0.5248, 'cmp': -0.4468}\n",
      "[Iter 9600 Task dept] Val Loss: 0.0855\n",
      "{'abs_err': 0.0832, 'rel_err': 1.4266, 'sigma_1.25': 27.9265, 'sigma_1.25^2': 45.9734, 'sigma_1.25^3': 57.5525, 'cmp': -1.7345}\n",
      "======================================================================\n",
      "tau: 0.1578045055097663\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6268,  1.3599, -2.9867], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1654,  0.0198, -0.1852], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8775,  0.8265, -1.7040], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0209, -0.0026, -0.0182], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5455,  0.5904, -1.1360], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0197,  0.0020, -0.0216], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3067,  0.3464, -0.6531], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 6.3706e-05,  1.1849e-04, -1.8219e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2581,  0.3361, -0.5942], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0059, -0.0009, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1910,  0.2241, -0.4151], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0011, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1596,  0.1396, -0.2992], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0006, -0.0018], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0577,  0.0920, -0.1496], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0027,  0.0014,  0.0013], device='cuda:0', requires_grad=True)\n",
      "tau: 0.15228134781692448\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6230,  1.3607, -2.9838], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1693,  0.0260, -0.1954], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8768,  0.8259, -1.7027], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0209, -0.0025, -0.0184], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5509,  0.5910, -1.1419], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193,  0.0024, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3070,  0.3462, -0.6532], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0002, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2583,  0.3361, -0.5944], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0061, -0.0010, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1924,  0.2237, -0.4161], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0011, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1622,  0.1398, -0.3019], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0006, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0581,  0.0921, -0.1502], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0028,  0.0017,  0.0012], device='cuda:0', requires_grad=True)\n",
      "[Iter 9800 Task segm] Train Loss: 0.3496\n",
      "[Iter 9800 Task dept] Train Loss: 0.0281\n",
      "[Iter 9800 Total] Train Loss: 0.1888\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 1.6151\n",
      "{'mIoU': 0.1395, 'Pixel Acc': 0.4964, 'cmp': -0.4943}\n",
      "[Iter 9800 Task dept] Val Loss: 0.0808\n",
      "{'abs_err': 0.0791, 'rel_err': 1.2887, 'sigma_1.25': 27.3728, 'sigma_1.25^2': 45.8697, 'sigma_1.25^3': 58.5659, 'cmp': -1.6021}\n",
      "======================================================================\n",
      "tau: 0.14695150064333212\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6191,  1.3617, -2.9808], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1692,  0.0272, -0.1964], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8818,  0.8342, -1.7160], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0210, -0.0025, -0.0185], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5655,  0.6013, -1.1669], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0191,  0.0026, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3119,  0.3468, -0.6588], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0002, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2606,  0.3381, -0.5988], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0061, -0.0010, -0.0051], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2023,  0.2255, -0.4277], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0023, -0.0011, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1588,  0.1441, -0.3028], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0025, -0.0006, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0592,  0.0925, -0.1517], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0028,  0.0017,  0.0012], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1418081981208155\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6175,  1.3603, -2.9778], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1797,  0.0273, -0.2070], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.8810,  0.8334, -1.7143], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0215, -0.0025, -0.0190], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5668,  0.6023, -1.1691], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0209,  0.0029, -0.0238], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3155,  0.3466, -0.6620], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 5.8910e-04,  8.3113e-05, -6.7221e-04], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2618,  0.3384, -0.6002], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0069, -0.0015, -0.0053], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2026,  0.2254, -0.4280], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0012, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1579,  0.1439, -0.3018], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0031, -0.0011, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0597,  0.0925, -0.1522], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0028,  0.0015,  0.0013], device='cuda:0', requires_grad=True)\n",
      "[Iter 10000 Task segm] Train Loss: 0.3366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10000 Task dept] Train Loss: 0.0296\n",
      "[Iter 10000 Total] Train Loss: 0.1831\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 1.1483\n",
      "{'mIoU': 0.1938, 'Pixel Acc': 0.5932, 'cmp': -0.3619}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0736\n",
      "{'abs_err': 0.0737, 'rel_err': 1.2692, 'sigma_1.25': 26.381, 'sigma_1.25^2': 45.7045, 'sigma_1.25^3': 58.695, 'cmp': -1.5291}\n",
      "======================================================================\n",
      "tau: 0.13684491118658695\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6136,  1.3615, -2.9752], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1804,  0.0288, -0.2092], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9074,  0.8338, -1.7412], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0216, -0.0024, -0.0192], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5851,  0.6128, -1.1979], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0211,  0.0029, -0.0240], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3405,  0.3491, -0.6896], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2774,  0.3414, -0.6188], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0070, -0.0016, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2024,  0.2278, -0.4302], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0024, -0.0015, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1567,  0.1470, -0.3038], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0012, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0603,  0.0920, -0.1523], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0030,  0.0015,  0.0016], device='cuda:0', requires_grad=True)\n",
      "tau: 0.13205533929505642\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6101,  1.3621, -2.9723], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1855,  0.0334, -0.2190], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9079,  0.8333, -1.7412], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0211, -0.0010, -0.0201], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5892,  0.6128, -1.2020], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206,  0.0037, -0.0243], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3434,  0.3515, -0.6950], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.2687e-04, -3.0290e-04, -2.3975e-05], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2775,  0.3414, -0.6189], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0016, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2017,  0.2283, -0.4300], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0014, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1564,  0.1471, -0.3035], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0012, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0607,  0.0919, -0.1526], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0032,  0.0020,  0.0012], device='cuda:0', requires_grad=True)\n",
      "[Iter 10200 Task segm] Train Loss: 0.3549\n",
      "[Iter 10200 Task dept] Train Loss: 0.0281\n",
      "[Iter 10200 Total] Train Loss: 0.1915\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Val Loss: 1.1817\n",
      "{'mIoU': 0.1957, 'Pixel Acc': 0.6017, 'cmp': -0.3538}\n",
      "[Iter 10200 Task dept] Val Loss: 0.0791\n",
      "{'abs_err': 0.0796, 'rel_err': 1.1764, 'sigma_1.25': 29.6901, 'sigma_1.25^2': 48.5248, 'sigma_1.25^3': 61.7547, 'cmp': -1.5205}\n",
      "======================================================================\n",
      "tau: 0.12743340241972945\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6087,  1.3606, -2.9693], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1858,  0.0336, -0.2195], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9177,  0.8350, -1.7526], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0212, -0.0010, -0.0202], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5876,  0.6345, -1.2221], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206,  0.0037, -0.0243], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3515,  0.3682, -0.7197], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 3.1282e-04, -3.1215e-04, -6.6780e-07], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2953,  0.3595, -0.6548], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0072, -0.0016, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2013,  0.2368, -0.4381], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020, -0.0014, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1637,  0.1495, -0.3132], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0012, -0.0020], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0594,  0.0956, -0.1550], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0032,  0.0020,  0.0012], device='cuda:0', requires_grad=True)\n",
      "tau: 0.12297323333503891\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6086,  1.3577, -2.9663], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1927,  0.0384, -0.2311], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.9162,  0.8347, -1.7509], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0227, -0.0002, -0.0225], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5867,  0.6346, -1.2213], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206,  0.0042, -0.0248], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3513,  0.3683, -0.7196], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0003,  0.0001, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2958,  0.3597, -0.6554], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0069, -0.0015, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2042,  0.2388, -0.4430], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0015, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1640,  0.1499, -0.3139], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0037, -0.0013, -0.0024], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0594,  0.0956, -0.1550], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0031,  0.0013,  0.0017], device='cuda:0', requires_grad=True)\n",
      "[Iter 10400 Task segm] Train Loss: 0.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10400 Task dept] Train Loss: 0.0282\n",
      "[Iter 10400 Total] Train Loss: 0.1889\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Val Loss: 1.3687\n",
      "{'mIoU': 0.1715, 'Pixel Acc': 0.5524, 'cmp': -0.4169}\n",
      "[Iter 10400 Task dept] Val Loss: 0.0719\n",
      "{'abs_err': 0.0705, 'rel_err': 1.3085, 'sigma_1.25': 30.0472, 'sigma_1.25^2': 49.6316, 'sigma_1.25^3': 62.5062, 'cmp': -1.4878}\n",
      "======================================================================\n",
      "tau: 0.11866917016831255\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6106,  1.3530, -2.9636], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1922,  0.0385, -0.2307], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0214,  0.8448, -1.8662], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0222,  0.0003, -0.0225], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5906,  0.6443, -1.2349], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205,  0.0040, -0.0246], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3722,  0.3955, -0.7677], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0002, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2962,  0.3693, -0.6655], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0070, -0.0016, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2174,  0.2425, -0.4600], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0016, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1593,  0.1486, -0.3080], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0014, -0.0025], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0608,  0.0981, -0.1589], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0035,  0.0014,  0.0022], device='cuda:0', requires_grad=True)\n",
      "tau: 0.11451574921242161\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6098,  1.3509, -2.9607], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1976,  0.0401, -0.2377], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0257,  0.8440, -1.8697], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0003, -0.0198], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.5907,  0.6437, -1.2343], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0212,  0.0048, -0.0260], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3726,  0.3957, -0.7683], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0003, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2944,  0.3706, -0.6650], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0071, -0.0017, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2174,  0.2439, -0.4613], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0026, -0.0014, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1590,  0.1484, -0.3074], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0042, -0.0013, -0.0029], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0608,  0.0976, -0.1584], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0046,  0.0023,  0.0024], device='cuda:0', requires_grad=True)\n",
      "[Iter 10600 Task segm] Train Loss: 0.3303\n",
      "[Iter 10600 Task dept] Train Loss: 0.0280\n",
      "[Iter 10600 Total] Train Loss: 0.1791\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Val Loss: 1.1489\n",
      "{'mIoU': 0.1966, 'Pixel Acc': 0.5873, 'cmp': -0.3624}\n",
      "[Iter 10600 Task dept] Val Loss: 0.0697\n",
      "{'abs_err': 0.07, 'rel_err': 1.251, 'sigma_1.25': 32.0542, 'sigma_1.25^2': 52.7137, 'sigma_1.25^3': 66.0403, 'cmp': -1.4268}\n",
      "======================================================================\n",
      "tau: 0.11050769798998684\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6030,  1.3553, -2.9583], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1976,  0.0411, -0.2387], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0259,  0.8438, -1.8697], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0002, -0.0197], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6246,  0.6431, -1.2677], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0212,  0.0048, -0.0260], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3943,  0.3791, -0.7734], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0004,  0.0003, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2952,  0.3861, -0.6813], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0071, -0.0017, -0.0053], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2196,  0.2475, -0.4671], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0026, -0.0015, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1612,  0.1571, -0.3183], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0042, -0.0013, -0.0029], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0689,  0.1010, -0.1699], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0046,  0.0023,  0.0023], device='cuda:0', requires_grad=True)\n",
      "tau: 0.1066399285603373\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6032,  1.3522, -2.9554], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1992,  0.0490, -0.2483], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0253,  0.8426, -1.8678], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192,  0.0005, -0.0197], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6281,  0.6424, -1.2705], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0211,  0.0045, -0.0256], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3960,  0.3785, -0.7745], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007, -0.0004, -0.0003], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2950,  0.3861, -0.6811], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0019, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2194,  0.2475, -0.4669], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0014, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1609,  0.1570, -0.3179], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0042, -0.0012, -0.0030], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0696,  0.1011, -0.1707], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0043,  0.0020,  0.0023], device='cuda:0', requires_grad=True)\n",
      "[Iter 10800 Task segm] Train Loss: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10800 Task dept] Train Loss: 0.0279\n",
      "[Iter 10800 Total] Train Loss: 0.1939\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Val Loss: 1.5353\n",
      "{'mIoU': 0.177, 'Pixel Acc': 0.551, 'cmp': -0.4111}\n",
      "[Iter 10800 Task dept] Val Loss: 0.0845\n",
      "{'abs_err': 0.0846, 'rel_err': 1.6402, 'sigma_1.25': 22.9762, 'sigma_1.25^2': 41.3374, 'sigma_1.25^3': 55.6711, 'cmp': -1.9087}\n",
      "======================================================================\n",
      "tau: 0.10290753106072549\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6025,  1.3500, -2.9525], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.1990,  0.0490, -0.2481], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0296,  0.8753, -1.9049], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0192,  0.0005, -0.0197], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6435,  0.6418, -1.2853], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0211,  0.0044, -0.0255], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3816,  0.4180, -0.7996], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0004, -0.0004], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3100,  0.3968, -0.7068], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0072, -0.0018, -0.0054], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2276,  0.2462, -0.4737], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0014, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1643,  0.1637, -0.3280], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0012, -0.0030], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0700,  0.1042, -0.1742], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0044,  0.0021,  0.0023], device='cuda:0', requires_grad=True)\n",
      "tau: 0.09930576747360009\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6010,  1.3486, -2.9496], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2074,  0.0501, -0.2574], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0298,  0.8742, -1.9040], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0191,  0.0020, -0.0211], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6446,  0.6410, -1.2856], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0212,  0.0049, -0.0262], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3816,  0.4218, -0.8034], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0008, -0.0002, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3098,  0.3969, -0.7067], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0016, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2273,  0.2464, -0.4737], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0026, -0.0013, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1643,  0.1635, -0.3278], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0038, -0.0012, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0698,  0.1047, -0.1745], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0041,  0.0019,  0.0022], device='cuda:0', requires_grad=True)\n",
      "[Iter 11000 Task segm] Train Loss: 0.3450\n",
      "[Iter 11000 Task dept] Train Loss: 0.0281\n",
      "[Iter 11000 Total] Train Loss: 0.1866\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 1.2998\n",
      "{'mIoU': 0.189, 'Pixel Acc': 0.5822, 'cmp': -0.3753}\n",
      "[Iter 11000 Task dept] Val Loss: 0.0845\n",
      "{'abs_err': 0.084, 'rel_err': 1.3846, 'sigma_1.25': 23.3208, 'sigma_1.25^2': 40.0243, 'sigma_1.25^3': 53.3653, 'cmp': -1.7538}\n",
      "======================================================================\n",
      "tau: 0.09583006561202409\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6057,  1.3410, -2.9466], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2073,  0.0502, -0.2575], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0249,  0.8746, -1.8995], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0191,  0.0020, -0.0211], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6573,  0.6571, -1.3144], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0213,  0.0049, -0.0262], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3797,  0.4365, -0.8162], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0007, -0.0002, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3272,  0.4122, -0.7393], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0017, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2289,  0.2559, -0.4848], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0026, -0.0013, -0.0013], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1724,  0.1685, -0.3408], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0038, -0.0012, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0697,  0.1060, -0.1757], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0043,  0.0019,  0.0023], device='cuda:0', requires_grad=True)\n",
      "tau: 0.09247601331560325\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6051,  1.3386, -2.9437], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2091,  0.0550, -0.2642], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0236,  0.8740, -1.8976], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193,  0.0024, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6567,  0.6566, -1.3133], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0204,  0.0048, -0.0252], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3868,  0.4367, -0.8235], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0002, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3307,  0.4125, -0.7432], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0017, -0.0056], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2286,  0.2561, -0.4847], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027, -0.0015, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1730,  0.1691, -0.3420], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0014, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0696,  0.1058, -0.1754], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0036,  0.0014,  0.0022], device='cuda:0', requires_grad=True)\n",
      "[Iter 11200 Task segm] Train Loss: 0.3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 11200 Task dept] Train Loss: 0.0279\n",
      "[Iter 11200 Total] Train Loss: 0.1824\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Val Loss: 1.1134\n",
      "{'mIoU': 0.2116, 'Pixel Acc': 0.6081, 'cmp': -0.3298}\n",
      "[Iter 11200 Task dept] Val Loss: 0.0947\n",
      "{'abs_err': 0.0788, 'rel_err': 1.1722, 'sigma_1.25': 25.9569, 'sigma_1.25^2': 45.798, 'sigma_1.25^3': 60.7063, 'cmp': -1.5274}\n",
      "======================================================================\n",
      "tau: 0.08923935284955713\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6067,  1.3341, -2.9408], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2092,  0.0551, -0.2642], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0990,  0.9358, -2.0348], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0193,  0.0024, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6572,  0.6390, -1.2962], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0200,  0.0048, -0.0248], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3969,  0.4662, -0.8630], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0002, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3305,  0.4322, -0.7627], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0017, -0.0056], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2355,  0.2530, -0.4885], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0028, -0.0014, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1744,  0.1683, -0.3427], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0015, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0744,  0.1084, -0.1828], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0035,  0.0013,  0.0022], device='cuda:0', requires_grad=True)\n",
      "tau: 0.08611597549982263\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6055,  1.3323, -2.9379], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2145,  0.0579, -0.2723], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.0993,  0.9351, -2.0344], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0184,  0.0020, -0.0204], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6571,  0.6381, -1.2952], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0202,  0.0052, -0.0254], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3998,  0.4662, -0.8660], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0005, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3301,  0.4320, -0.7622], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0070, -0.0014, -0.0056], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2372,  0.2526, -0.4898], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0013, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1743,  0.1670, -0.3413], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0014, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0747,  0.1087, -0.1834], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0043,  0.0019,  0.0024], device='cuda:0', requires_grad=True)\n",
      "[Iter 11400 Task segm] Train Loss: 0.3500\n",
      "[Iter 11400 Task dept] Train Loss: 0.0278\n",
      "[Iter 11400 Total] Train Loss: 0.1889\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Val Loss: 1.3253\n",
      "{'mIoU': 0.1804, 'Pixel Acc': 0.5419, 'cmp': -0.4129}\n",
      "[Iter 11400 Task dept] Val Loss: 0.0695\n",
      "{'abs_err': 0.0697, 'rel_err': 1.3294, 'sigma_1.25': 27.7312, 'sigma_1.25^2': 48.7575, 'sigma_1.25^3': 62.8783, 'cmp': -1.4991}\n",
      "======================================================================\n",
      "tau: 0.08310191635732883\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5941,  1.3408, -2.9349], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2144,  0.0579, -0.2723], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1393,  0.9310, -2.0704], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0184,  0.0020, -0.0205], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6694,  0.6501, -1.3195], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0199,  0.0052, -0.0251], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4125,  0.4853, -0.8978], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0011, -0.0006, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3401,  0.4402, -0.7803], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0071, -0.0014, -0.0057], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2389,  0.2602, -0.4991], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022, -0.0012, -0.0010], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1717,  0.1631, -0.3348], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0014, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0773,  0.1072, -0.1845], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0044,  0.0019,  0.0024], device='cuda:0', requires_grad=True)\n",
      "tau: 0.08019334928482232\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5926,  1.3394, -2.9320], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2189,  0.0642, -0.2831], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1461,  0.9299, -2.0761], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0189,  0.0021, -0.0210], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6687,  0.6585, -1.3272], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205,  0.0052, -0.0257], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4125,  0.4850, -0.8975], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0003, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3393,  0.4406, -0.7799], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0016, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2375,  0.2603, -0.4978], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0013, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1712,  0.1624, -0.3336], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0015, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0772,  0.1071, -0.1843], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0048,  0.0017,  0.0031], device='cuda:0', requires_grad=True)\n",
      "[Iter 11600 Task segm] Train Loss: 0.3561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 11600 Task dept] Train Loss: 0.0286\n",
      "[Iter 11600 Total] Train Loss: 0.1923\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Val Loss: 1.1255\n",
      "{'mIoU': 0.1802, 'Pixel Acc': 0.5787, 'cmp': -0.3885}\n",
      "[Iter 11600 Task dept] Val Loss: 0.0848\n",
      "{'abs_err': 0.0842, 'rel_err': 1.4184, 'sigma_1.25': 28.4313, 'sigma_1.25^2': 45.9673, 'sigma_1.25^3': 58.2526, 'cmp': -1.7385}\n",
      "======================================================================\n",
      "tau: 0.07738658205985353\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6049,  1.3242, -2.9291], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2188,  0.0648, -0.2836], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1887,  0.9329, -2.1216], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0188,  0.0022, -0.0210], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6678,  0.7340, -1.4018], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0206,  0.0053, -0.0258], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4093,  0.4988, -0.9081], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0012, -0.0003, -0.0009], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3414,  0.4457, -0.7871], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0016, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2374,  0.2665, -0.5038], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021, -0.0013, -0.0008], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1685,  0.1666, -0.3351], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0015, -0.0026], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0707,  0.1078, -0.1786], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0049,  0.0016,  0.0033], device='cuda:0', requires_grad=True)\n",
      "tau: 0.07467805168775866\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6053,  1.3208, -2.9261], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2231,  0.0662, -0.2893], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1886,  0.9317, -2.1202], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0187,  0.0028, -0.0215], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6671,  0.7346, -1.4016], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0204,  0.0057, -0.0261], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4099,  0.4985, -0.9084], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017, -0.0002, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3407,  0.4458, -0.7865], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0061, -0.0015, -0.0046], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2371,  0.2661, -0.5032], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027, -0.0015, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1682,  0.1662, -0.3345], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0017, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0708,  0.1075, -0.1783], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0071,  0.0023,  0.0048], device='cuda:0', requires_grad=True)\n",
      "[Iter 11800 Task segm] Train Loss: 0.3394\n",
      "[Iter 11800 Task dept] Train Loss: 0.0279\n",
      "[Iter 11800 Total] Train Loss: 0.1837\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Val Loss: 1.3936\n",
      "{'mIoU': 0.1959, 'Pixel Acc': 0.5766, 'cmp': -0.3704}\n",
      "[Iter 11800 Task dept] Val Loss: 0.0870\n",
      "{'abs_err': 0.0848, 'rel_err': 1.5925, 'sigma_1.25': 26.8588, 'sigma_1.25^2': 46.8589, 'sigma_1.25^3': 60.6795, 'cmp': -1.8477}\n",
      "======================================================================\n",
      "tau: 0.07206431987868711\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5982,  1.3250, -2.9232], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2238,  0.0662, -0.2900], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1979,  0.9294, -2.1273], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0187,  0.0028, -0.0215], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6973,  0.7425, -1.4398], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0204,  0.0058, -0.0262], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4179,  0.4990, -0.9169], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018, -0.0002, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3399,  0.4466, -0.7865], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0060, -0.0015, -0.0045], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2382,  0.2757, -0.5138], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0027, -0.0015, -0.0012], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1678,  0.1694, -0.3372], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0017, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0708,  0.1069, -0.1777], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0072,  0.0023,  0.0049], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06954206868293306\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.5965,  1.3238, -2.9203], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2346,  0.0700, -0.3047], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1967,  0.9285, -2.1252], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0188,  0.0029, -0.0218], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.6963,  0.7416, -1.4380], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0213,  0.0059, -0.0272], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4205,  0.4980, -0.9185], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0022,  0.0009, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3399,  0.4462, -0.7861], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0023, -0.0045], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2380,  0.2764, -0.5143], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0028, -0.0013, -0.0015], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1676,  0.1690, -0.3366], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0018, -0.0022], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0712,  0.1077, -0.1789], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0072,  0.0022,  0.0051], device='cuda:0', requires_grad=True)\n",
      "[Iter 12000 Task segm] Train Loss: 0.3316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12000 Task dept] Train Loss: 0.0278\n",
      "[Iter 12000 Total] Train Loss: 0.1797\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 1.0734\n",
      "{'mIoU': 0.1988, 'Pixel Acc': 0.6054, 'cmp': -0.3476}\n",
      "[Iter 12000 Task dept] Val Loss: 0.0845\n",
      "{'abs_err': 0.0846, 'rel_err': 1.2158, 'sigma_1.25': 24.2298, 'sigma_1.25^2': 40.1151, 'sigma_1.25^3': 51.4729, 'cmp': -1.6596}\n",
      "======================================================================\n",
      "tau: 0.0671080962790304\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6026,  1.3146, -2.9173], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2347,  0.0707, -0.3054], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1959,  0.9270, -2.1229], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0189,  0.0029, -0.0217], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7095,  0.7470, -1.4565], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0220,  0.0059, -0.0279], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4292,  0.5097, -0.9389], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0021,  0.0009, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3384,  0.4573, -0.7957], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0068, -0.0023, -0.0045], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2384,  0.2772, -0.5156], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0028, -0.0012, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1730,  0.1702, -0.3432], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0018, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0735,  0.1117, -0.1851], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0074,  0.0023,  0.0051], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06475931290926433\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6010,  1.3134, -2.9143], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2462,  0.0697, -0.3159], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1946,  0.9261, -2.1207], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0025, -0.0220], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7088,  0.7463, -1.4550], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0225,  0.0061, -0.0286], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4309,  0.5092, -0.9401], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020,  0.0008, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3380,  0.4569, -0.7949], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0067, -0.0023, -0.0044], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2380,  0.2770, -0.5150], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0012, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1747,  0.1699, -0.3445], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0019, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0738,  0.1110, -0.1848], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0090,  0.0027,  0.0064], device='cuda:0', requires_grad=True)\n",
      "[Iter 12200 Task segm] Train Loss: 0.3266\n",
      "[Iter 12200 Task dept] Train Loss: 0.0276\n",
      "[Iter 12200 Total] Train Loss: 0.1771\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Val Loss: 1.5158\n",
      "{'mIoU': 0.1757, 'Pixel Acc': 0.5234, 'cmp': -0.4312}\n",
      "[Iter 12200 Task dept] Val Loss: 0.0724\n",
      "{'abs_err': 0.071, 'rel_err': 1.328, 'sigma_1.25': 27.2478, 'sigma_1.25^2': 47.5297, 'sigma_1.25^3': 61.6734, 'cmp': -1.5197}\n",
      "======================================================================\n",
      "tau: 0.06249273695744008\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6030,  1.3085, -2.9115], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2471,  0.0696, -0.3168], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1985,  0.9202, -2.1187], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0025, -0.0219], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7323,  0.7595, -1.4917], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0226,  0.0061, -0.0286], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4326,  0.5111, -0.9437], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0020,  0.0008, -0.0028], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3367,  0.4762, -0.8129], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0067, -0.0023, -0.0044], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2377,  0.2711, -0.5088], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0029, -0.0012, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1842,  0.1719, -0.3561], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0020, -0.0021], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0743,  0.1122, -0.1865], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0091,  0.0027,  0.0064], device='cuda:0', requires_grad=True)\n",
      "tau: 0.06030549116392967\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6019,  1.3067, -2.9086], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2513,  0.0761, -0.3274], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1972,  0.9195, -2.1167], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0026, -0.0222], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7315,  0.7592, -1.4907], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0225,  0.0073, -0.0298], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4322,  0.5152, -0.9474], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0016,  0.0016, -0.0032], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3334,  0.4757, -0.8091], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0025, -0.0048], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2380,  0.2709, -0.5088], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0031, -0.0020, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1840,  0.1718, -0.3557], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045, -0.0020, -0.0025], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0742,  0.1128, -0.1869], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0088,  0.0026,  0.0061], device='cuda:0', requires_grad=True)\n",
      "[Iter 12400 Task segm] Train Loss: 0.3304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12400 Task dept] Train Loss: 0.0279\n",
      "[Iter 12400 Total] Train Loss: 0.1792\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Val Loss: 1.4668\n",
      "{'mIoU': 0.1851, 'Pixel Acc': 0.5406, 'cmp': -0.4079}\n",
      "[Iter 12400 Task dept] Val Loss: 0.0873\n",
      "{'abs_err': 0.0877, 'rel_err': 1.7371, 'sigma_1.25': 26.11, 'sigma_1.25^2': 44.2653, 'sigma_1.25^3': 56.7295, 'cmp': -1.9858}\n",
      "======================================================================\n",
      "tau: 0.05819479897319213\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6702,  1.3059, -2.9762], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2518,  0.0764, -0.3282], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1984,  0.9216, -2.1199], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0195,  0.0026, -0.0221], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7642,  0.7610, -1.5252], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0226,  0.0074, -0.0300], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4419,  0.5348, -0.9767], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018,  0.0016, -0.0034], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3386,  0.4855, -0.8242], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0072, -0.0025, -0.0047], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2518,  0.2842, -0.5359], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0020, -0.0011], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1799,  0.1824, -0.3624], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0046, -0.0021, -0.0025], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0804,  0.1159, -0.1963], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0091,  0.0029,  0.0061], device='cuda:0', requires_grad=True)\n",
      "tau: 0.0561579810091304\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6679,  1.3071, -2.9750], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2509,  0.0748, -0.3257], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1977,  0.9201, -2.1178], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205,  0.0034, -0.0239], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7597,  0.7640, -1.5237], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0226,  0.0090, -0.0316], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4415,  0.5345, -0.9760], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0018,  0.0013, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3383,  0.4851, -0.8233], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0023, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2522,  0.2899, -0.5421], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0022, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1803,  0.1824, -0.3627], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045, -0.0019, -0.0027], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0805,  0.1159, -0.1964], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0080,  0.0029,  0.0052], device='cuda:0', requires_grad=True)\n",
      "[Iter 12600 Task segm] Train Loss: 0.3292\n",
      "[Iter 12600 Task dept] Train Loss: 0.0282\n",
      "[Iter 12600 Total] Train Loss: 0.1787\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Val Loss: 1.6788\n",
      "{'mIoU': 0.1607, 'Pixel Acc': 0.5285, 'cmp': -0.4464}\n",
      "[Iter 12600 Task dept] Val Loss: 0.0797\n",
      "{'abs_err': 0.0795, 'rel_err': 1.4034, 'sigma_1.25': 35.1796, 'sigma_1.25^2': 51.624, 'sigma_1.25^3': 62.9951, 'cmp': -1.6313}\n",
      "======================================================================\n",
      "tau: 0.054192451673810836\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6584,  1.3092, -2.9676], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2505,  0.0740, -0.3246], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1952,  0.9561, -2.1512], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0205,  0.0034, -0.0239], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7557,  0.7902, -1.5459], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0226,  0.0090, -0.0316], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4526,  0.5338, -0.9864], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0019,  0.0016, -0.0035], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3442,  0.4816, -0.8258], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0023, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2644,  0.2924, -0.5568], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0023, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1914,  0.1946, -0.3860], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045, -0.0019, -0.0027], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0839,  0.1213, -0.2052], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0083,  0.0030,  0.0053], device='cuda:0', requires_grad=True)\n",
      "tau: 0.05229571586522745\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6562,  1.3084, -2.9646], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2556,  0.0759, -0.3315], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1939,  0.9554, -2.1493], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0217,  0.0030, -0.0247], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7548,  0.7918, -1.5466], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0084, -0.0315], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4526,  0.5331, -0.9857], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017,  0.0023, -0.0039], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3440,  0.4805, -0.8245], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0024, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2642,  0.2926, -0.5569], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0035, -0.0021, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1912,  0.1945, -0.3857], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0043, -0.0024, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0838,  0.1220, -0.2058], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0077,  0.0023,  0.0053], device='cuda:0', requires_grad=True)\n",
      "[Iter 12800 Task segm] Train Loss: 0.3344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12800 Task dept] Train Loss: 0.0281\n",
      "[Iter 12800 Total] Train Loss: 0.1813\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Val Loss: 1.2842\n",
      "{'mIoU': 0.2002, 'Pixel Acc': 0.5768, 'cmp': -0.3649}\n",
      "[Iter 12800 Task dept] Val Loss: 0.0933\n",
      "{'abs_err': 0.0913, 'rel_err': 1.5457, 'sigma_1.25': 25.5192, 'sigma_1.25^2': 42.9193, 'sigma_1.25^3': 55.9808, 'cmp': -1.919}\n",
      "======================================================================\n",
      "tau: 0.05046536580994449\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6516,  1.3006, -2.9522], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2554,  0.0756, -0.3310], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1928,  0.9522, -2.1450], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0217,  0.0030, -0.0247], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7509,  0.7943, -1.5452], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0083, -0.0315], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4495,  0.5336, -0.9830], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0017,  0.0023, -0.0040], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3479,  0.4864, -0.8343], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0024, -0.0050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2661,  0.2943, -0.5604], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0035, -0.0021, -0.0014], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1884,  0.2164, -0.4048], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0039, -0.0023, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0912,  0.1218, -0.2129], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0076,  0.0023,  0.0053], device='cuda:0', requires_grad=True)\n",
      "tau: 0.04869907800659643\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6494,  1.2998, -2.9493], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2569,  0.0779, -0.3348], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1915,  0.9514, -2.1429], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0229,  0.0031, -0.0259], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7502,  0.7936, -1.5438], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0256,  0.0076, -0.0331], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4486,  0.5555, -1.0041], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014,  0.0020, -0.0033], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3475,  0.4864, -0.8339], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0076, -0.0024, -0.0052], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2658,  0.2940, -0.5599], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0025, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1881,  0.2163, -0.4043], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0040, -0.0025, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.0913,  0.1222, -0.2136], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0079,  0.0019,  0.0060], device='cuda:0', requires_grad=True)\n",
      "[Iter 13000 Task segm] Train Loss: 0.3409\n",
      "[Iter 13000 Task dept] Train Loss: 0.0271\n",
      "[Iter 13000 Total] Train Loss: 0.1840\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Val Loss: 1.9716\n",
      "{'mIoU': 0.2047, 'Pixel Acc': 0.5987, 'cmp': -0.3447}\n",
      "[Iter 13000 Task dept] Val Loss: 0.0886\n",
      "{'abs_err': 0.0886, 'rel_err': 1.5479, 'sigma_1.25': 33.0449, 'sigma_1.25^2': 51.0614, 'sigma_1.25^3': 62.7407, 'cmp': -1.8331}\n",
      "======================================================================\n",
      "tau: 0.046994610276365555\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6447,  1.3017, -2.9463], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2569,  0.0766, -0.3335], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1913,  0.9509, -2.1422], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0230,  0.0029, -0.0259], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7513,  0.8408, -1.5922], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0257,  0.0075, -0.0332], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4456,  0.5519, -0.9974], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014,  0.0020, -0.0034], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3556,  0.5225, -0.8780], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0077, -0.0024, -0.0053], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2998,  0.3052, -0.6050], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0025, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1959,  0.2191, -0.4149], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0025, -0.0016], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1119,  0.1171, -0.2290], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0079,  0.0019,  0.0060], device='cuda:0', requires_grad=True)\n",
      "tau: 0.04534979891669276\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6420,  1.3015, -2.9434], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2676,  0.0821, -0.3497], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1917,  0.9497, -2.1414], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0230,  0.0028, -0.0259], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7507,  0.8410, -1.5917], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0263,  0.0074, -0.0336], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4450,  0.5513, -0.9964], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014,  0.0018, -0.0033], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3555,  0.5218, -0.8773], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0085, -0.0019, -0.0066], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2998,  0.3050, -0.6048], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0027, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1960,  0.2197, -0.4156], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0025, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1119,  0.1168, -0.2287], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0089,  0.0026,  0.0063], device='cuda:0', requires_grad=True)\n",
      "[Iter 13200 Task segm] Train Loss: 0.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 13200 Task dept] Train Loss: 0.0276\n",
      "[Iter 13200 Total] Train Loss: 0.1768\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Val Loss: 1.6718\n",
      "{'mIoU': 0.1691, 'Pixel Acc': 0.5348, 'cmp': -0.4317}\n",
      "[Iter 13200 Task dept] Val Loss: 0.0734\n",
      "{'abs_err': 0.0727, 'rel_err': 1.3549, 'sigma_1.25': 32.4834, 'sigma_1.25^2': 50.8555, 'sigma_1.25^3': 63.3211, 'cmp': -1.5304}\n",
      "======================================================================\n",
      "tau: 0.04376255595460851\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6478,  1.2927, -2.9405], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2677,  0.0866, -0.3543], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1921,  0.9475, -2.1396], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0230,  0.0032, -0.0261], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7759,  0.8472, -1.6231], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0262,  0.0074, -0.0337], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4434,  0.5551, -0.9986], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0014,  0.0019, -0.0033], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3560,  0.5229, -0.8789], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0084, -0.0018, -0.0066], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2991,  0.3046, -0.6037], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0032, -0.0027, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1956,  0.2211, -0.4167], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0024, -0.0017], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1156,  0.1205, -0.2361], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0088,  0.0026,  0.0062], device='cuda:0', requires_grad=True)\n",
      "tau: 0.042230866496197214\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6461,  1.2915, -2.9375], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2735,  0.0909, -0.3644], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1906,  0.9469, -2.1374], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0079, -0.0311], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7756,  0.8477, -1.6233], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0260,  0.0080, -0.0339], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4430,  0.5545, -0.9975], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015,  0.0021, -0.0036], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3554,  0.5224, -0.8777], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0074, -0.0015, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.2986,  0.3055, -0.6042], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0031, -0.0026, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1954,  0.2212, -0.4167], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0023, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1149,  0.1206, -0.2355], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0088,  0.0026,  0.0062], device='cuda:0', requires_grad=True)\n",
      "[Iter 13400 Task segm] Train Loss: 0.3197\n",
      "[Iter 13400 Task dept] Train Loss: 0.0271\n",
      "[Iter 13400 Total] Train Loss: 0.1734\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Val Loss: 0.9881\n",
      "{'mIoU': 0.2286, 'Pixel Acc': 0.6199, 'cmp': -0.3007}\n",
      "[Iter 13400 Task dept] Val Loss: 0.1099\n",
      "{'abs_err': 0.1105, 'rel_err': 1.741, 'sigma_1.25': 31.9678, 'sigma_1.25^2': 46.2592, 'sigma_1.25^3': 58.5548, 'cmp': -2.2311}\n",
      "======================================================================\n",
      "tau: 0.04075278616883031\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6297,  1.3049, -2.9346], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2732,  0.0909, -0.3641], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1895,  0.9319, -2.1214], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0078, -0.0309], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7752,  0.8605, -1.6356], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0260,  0.0082, -0.0341], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4587,  0.5491, -1.0078], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0015,  0.0021, -0.0036], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3536,  0.5217, -0.8752], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0073, -0.0015, -0.0059], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3122,  0.3036, -0.6158], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0031, -0.0026, -0.0005], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1662,  0.2218, -0.3880], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0041, -0.0023, -0.0019], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1172,  0.1223, -0.2395], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0088,  0.0025,  0.0064], device='cuda:0', requires_grad=True)\n",
      "tau: 0.03932643865292125\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6282,  1.3036, -2.9317], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2768,  0.0980, -0.3748], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1884,  0.9306, -2.1190], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0073, -0.0305], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7745,  0.8595, -1.6340], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0264,  0.0080, -0.0343], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4588,  0.5483, -1.0071], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0022, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3531,  0.5213, -0.8745], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0067, -0.0011, -0.0056], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3165,  0.3046, -0.6211], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033, -0.0027, -0.0006], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1660,  0.2216, -0.3876], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045, -0.0022, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1171,  0.1222, -0.2393], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0085,  0.0025,  0.0059], device='cuda:0', requires_grad=True)\n",
      "[Iter 13600 Task segm] Train Loss: 0.3361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 13600 Task dept] Train Loss: 0.0263\n",
      "[Iter 13600 Total] Train Loss: 0.1812\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Val Loss: 1.1593\n",
      "{'mIoU': 0.1832, 'Pixel Acc': 0.5742, 'cmp': -0.3877}\n",
      "[Iter 13600 Task dept] Val Loss: 0.0756\n",
      "{'abs_err': 0.0748, 'rel_err': 1.2159, 'sigma_1.25': 23.7585, 'sigma_1.25^2': 42.6949, 'sigma_1.25^3': 58.1044, 'cmp': -1.5263}\n",
      "======================================================================\n",
      "tau: 0.037950013300069\n",
      "net.0.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.6150,  1.3138, -2.9288], device='cuda:0', requires_grad=True)\n",
      "net.0.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.2768,  0.1000, -0.3768], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.segment_semantic Parameter containing:\n",
      "tensor([ 1.1887,  0.9368, -2.1255], device='cuda:0', requires_grad=True)\n",
      "net.4.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0232,  0.0074, -0.0306], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.7779,  0.8566, -1.6345], device='cuda:0', requires_grad=True)\n",
      "net.7.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0263,  0.0076, -0.0339], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.4595,  0.5479, -1.0074], device='cuda:0', requires_grad=True)\n",
      "net.11.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0009,  0.0022, -0.0031], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3557,  0.5256, -0.8813], device='cuda:0', requires_grad=True)\n",
      "net.14.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0066, -0.0010, -0.0056], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.3211,  0.3160, -0.6372], device='cuda:0', requires_grad=True)\n",
      "net.18.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0033, -0.0026, -0.0007], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1706,  0.2216, -0.3922], device='cuda:0', requires_grad=True)\n",
      "net.21.policy.depth_zbuffer Parameter containing:\n",
      "tensor([ 0.0045, -0.0022, -0.0023], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.segment_semantic Parameter containing:\n",
      "tensor([ 0.1175,  0.1214, -0.2389], device='cuda:0', requires_grad=True)\n",
      "net.25.policy.depth_zbuffer Parameter containing:\n",
      "tensor([-0.0083,  0.0025,  0.0058], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-86614717fef9>\", line 3, in <module>\n",
      "    savePath='checkpoints/Cityscapes/', reload='pre_train_all_10000iter.model')\n",
      "  File \"/home/lijunzhang/policymtl2/framework/trainer.py\", line 176, in task_alter_train\n",
      "    self.train_step_task('mtl', self.tasks[task_idx], optimizer,tau=tau)\n",
      "  File \"/home/lijunzhang/policymtl2/framework/trainer.py\", line 373, in train_step_task\n",
      "    loss.backward()\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "trainer.task_alter_train(iters=20000, task_iters=(100,100), policy_lr=0.01, network_lr=0.001, \n",
    "                         tau=5, \n",
    "                         savePath='checkpoints/Cityscapes/', reload='pre_train_all_10000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 8100 Task segm] Train Loss: 0.2829\n",
      "[Iter 8100 Task dept] Train Loss: 0.0179\n",
      "[Iter 8100 Total] Train Loss: 0.1504\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 0.2758\n",
      "[Iter 8200 Task dept] Train Loss: 0.0175\n",
      "[Iter 8200 Total] Train Loss: 0.1466\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Train Loss: 0.2824\n",
      "[Iter 8300 Task dept] Train Loss: 0.0180\n",
      "[Iter 8300 Total] Train Loss: 0.1502\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 0.2759\n",
      "[Iter 8400 Task dept] Train Loss: 0.0176\n",
      "[Iter 8400 Total] Train Loss: 0.1468\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Train Loss: 0.2755\n",
      "[Iter 8500 Task dept] Train Loss: 0.0177\n",
      "[Iter 8500 Total] Train Loss: 0.1466\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Val Loss: 0.4597\n",
      "{'mIoU': 0.32, 'Pixel Acc': 0.7126, 'cmp': -0.125}\n",
      "[Iter 8500 Task dept] Val Loss: 0.0302\n",
      "{'abs_err': 0.0308, 'rel_err': 0.6219, 'sigma_1.25': 54.3325, 'sigma_1.25^2': 72.943, 'sigma_1.25^3': 83.1928, 'cmp': -0.4368}\n",
      "======================================================================\n",
      "tau: 3.0363539146888705\n",
      "[Iter 8600 Task segm] Train Loss: 0.2827\n",
      "[Iter 8600 Task dept] Train Loss: 0.0180\n",
      "[Iter 8600 Total] Train Loss: 0.1504\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Train Loss: 0.2831\n",
      "[Iter 8700 Task dept] Train Loss: 0.0181\n",
      "[Iter 8700 Total] Train Loss: 0.1506\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.2805\n",
      "[Iter 8800 Task dept] Train Loss: 0.0178\n",
      "[Iter 8800 Total] Train Loss: 0.1492\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Train Loss: 0.2839\n",
      "[Iter 8900 Task dept] Train Loss: 0.0178\n",
      "[Iter 8900 Total] Train Loss: 0.1508\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.2908\n",
      "[Iter 9000 Task dept] Train Loss: 0.0176\n",
      "[Iter 9000 Total] Train Loss: 0.1542\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 0.6759\n",
      "{'mIoU': 0.2882, 'Pixel Acc': 0.6696, 'cmp': -0.1934}\n",
      "[Iter 9000 Task dept] Val Loss: 0.0321\n",
      "{'abs_err': 0.0333, 'rel_err': 0.6277, 'sigma_1.25': 51.4771, 'sigma_1.25^2': 70.4511, 'sigma_1.25^3': 81.391, 'cmp': -0.4885}\n",
      "======================================================================\n",
      "tau: 2.93008152767476\n",
      "[Iter 9100 Task segm] Train Loss: 0.2838\n",
      "[Iter 9100 Task dept] Train Loss: 0.0179\n",
      "[Iter 9100 Total] Train Loss: 0.1509\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.2896\n",
      "[Iter 9200 Task dept] Train Loss: 0.0179\n",
      "[Iter 9200 Total] Train Loss: 0.1537\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Train Loss: 0.2881\n",
      "[Iter 9300 Task dept] Train Loss: 0.0182\n",
      "[Iter 9300 Total] Train Loss: 0.1532\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.2845\n",
      "[Iter 9400 Task dept] Train Loss: 0.0181\n",
      "[Iter 9400 Total] Train Loss: 0.1513\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Train Loss: 0.2837\n",
      "[Iter 9500 Task dept] Train Loss: 0.0179\n",
      "[Iter 9500 Total] Train Loss: 0.1508\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Val Loss: 0.6304\n",
      "{'mIoU': 0.3084, 'Pixel Acc': 0.6936, 'cmp': -0.1521}\n",
      "[Iter 9500 Task dept] Val Loss: 0.0412\n",
      "{'abs_err': 0.041, 'rel_err': 0.8882, 'sigma_1.25': 47.2964, 'sigma_1.25^2': 65.504, 'sigma_1.25^3': 76.193, 'cmp': -0.7715}\n",
      "======================================================================\n",
      "tau: 2.827528674206143\n",
      "[Iter 9600 Task segm] Train Loss: 0.2826\n",
      "[Iter 9600 Task dept] Train Loss: 0.0182\n",
      "[Iter 9600 Total] Train Loss: 0.1504\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Train Loss: 0.2834\n",
      "[Iter 9700 Task dept] Train Loss: 0.0180\n",
      "[Iter 9700 Total] Train Loss: 0.1507\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.2817\n",
      "[Iter 9800 Task dept] Train Loss: 0.0182\n",
      "[Iter 9800 Total] Train Loss: 0.1499\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Train Loss: 0.2783\n",
      "[Iter 9900 Task dept] Train Loss: 0.0177\n",
      "[Iter 9900 Total] Train Loss: 0.1480\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.2829\n",
      "[Iter 10000 Task dept] Train Loss: 0.0179\n",
      "[Iter 10000 Total] Train Loss: 0.1504\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 0.5964\n",
      "{'mIoU': 0.2924, 'Pixel Acc': 0.687, 'cmp': -0.1764}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0388\n",
      "{'abs_err': 0.0377, 'rel_err': 0.7992, 'sigma_1.25': 48.7131, 'sigma_1.25^2': 67.22, 'sigma_1.25^3': 78.0535, 'cmp': -0.6666}\n",
      "======================================================================\n",
      "tau: 2.728565170608928\n",
      "[Iter 10100 Task segm] Train Loss: 0.2916\n",
      "[Iter 10100 Task dept] Train Loss: 0.0182\n",
      "[Iter 10100 Total] Train Loss: 0.1549\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Train Loss: 0.2835\n",
      "[Iter 10200 Task dept] Train Loss: 0.0183\n",
      "[Iter 10200 Total] Train Loss: 0.1509\n",
      "======================================================================\n",
      "[Iter 10300 Task segm] Train Loss: 0.2819\n",
      "[Iter 10300 Task dept] Train Loss: 0.0178\n",
      "[Iter 10300 Total] Train Loss: 0.1498\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Train Loss: 0.2856\n",
      "[Iter 10400 Task dept] Train Loss: 0.0178\n",
      "[Iter 10400 Total] Train Loss: 0.1517\n",
      "======================================================================\n",
      "[Iter 10500 Task segm] Train Loss: 0.2778\n",
      "[Iter 10500 Task dept] Train Loss: 0.0181\n",
      "[Iter 10500 Total] Train Loss: 0.1480\n",
      "======================================================================\n",
      "[Iter 10500 Task segm] Val Loss: 0.6068\n",
      "{'mIoU': 0.2926, 'Pixel Acc': 0.6883, 'cmp': -0.1754}\n",
      "[Iter 10500 Task dept] Val Loss: 0.0425\n",
      "{'abs_err': 0.0429, 'rel_err': 0.9107, 'sigma_1.25': 47.4868, 'sigma_1.25^2': 66.4025, 'sigma_1.25^3': 77.174, 'cmp': -0.8022}\n",
      "======================================================================\n",
      "tau: 2.6330653896376153\n",
      "[Iter 10600 Task segm] Train Loss: 0.2829\n",
      "[Iter 10600 Task dept] Train Loss: 0.0180\n",
      "[Iter 10600 Total] Train Loss: 0.1505\n",
      "======================================================================\n",
      "[Iter 10700 Task segm] Train Loss: 0.2856\n",
      "[Iter 10700 Task dept] Train Loss: 0.0181\n",
      "[Iter 10700 Total] Train Loss: 0.1519\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Train Loss: 0.2829\n",
      "[Iter 10800 Task dept] Train Loss: 0.0182\n",
      "[Iter 10800 Total] Train Loss: 0.1506\n",
      "======================================================================\n",
      "[Iter 10900 Task segm] Train Loss: 0.2801\n",
      "[Iter 10900 Task dept] Train Loss: 0.0184\n",
      "[Iter 10900 Total] Train Loss: 0.1492\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Train Loss: 0.2894\n",
      "[Iter 11000 Task dept] Train Loss: 0.0179\n",
      "[Iter 11000 Total] Train Loss: 0.1536\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 0.5330\n",
      "{'mIoU': 0.3121, 'Pixel Acc': 0.6989, 'cmp': -0.144}\n",
      "[Iter 11000 Task dept] Val Loss: 0.0440\n",
      "{'abs_err': 0.0441, 'rel_err': 0.9623, 'sigma_1.25': 48.9627, 'sigma_1.25^2': 66.5021, 'sigma_1.25^3': 76.9631, 'cmp': -0.8442}\n",
      "======================================================================\n",
      "tau: 2.5409081010002987\n",
      "[Iter 11100 Task segm] Train Loss: 0.2879\n",
      "[Iter 11100 Task dept] Train Loss: 0.0182\n",
      "[Iter 11100 Total] Train Loss: 0.1531\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Train Loss: 0.2791\n",
      "[Iter 11200 Task dept] Train Loss: 0.0186\n",
      "[Iter 11200 Total] Train Loss: 0.1488\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 11300 Task segm] Train Loss: 0.2853\n",
      "[Iter 11300 Task dept] Train Loss: 0.0179\n",
      "[Iter 11300 Total] Train Loss: 0.1516\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Train Loss: 0.2860\n",
      "[Iter 11400 Task dept] Train Loss: 0.0187\n",
      "[Iter 11400 Total] Train Loss: 0.1524\n",
      "======================================================================\n",
      "[Iter 11500 Task segm] Train Loss: 0.2821\n",
      "[Iter 11500 Task dept] Train Loss: 0.0183\n",
      "[Iter 11500 Total] Train Loss: 0.1502\n",
      "======================================================================\n",
      "[Iter 11500 Task segm] Val Loss: 0.6436\n",
      "{'mIoU': 0.2781, 'Pixel Acc': 0.6827, 'cmp': -0.1972}\n",
      "[Iter 11500 Task dept] Val Loss: 0.0381\n",
      "{'abs_err': 0.0385, 'rel_err': 0.7072, 'sigma_1.25': 47.6531, 'sigma_1.25^2': 67.4792, 'sigma_1.25^3': 78.7822, 'cmp': -0.6212}\n",
      "======================================================================\n",
      "tau: 2.451976317465288\n",
      "[Iter 11600 Task segm] Train Loss: 0.2918\n",
      "[Iter 11600 Task dept] Train Loss: 0.0186\n",
      "[Iter 11600 Total] Train Loss: 0.1552\n",
      "======================================================================\n",
      "[Iter 11700 Task segm] Train Loss: 0.2793\n",
      "[Iter 11700 Task dept] Train Loss: 0.0183\n",
      "[Iter 11700 Total] Train Loss: 0.1488\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Train Loss: 0.2860\n",
      "[Iter 11800 Task dept] Train Loss: 0.0179\n",
      "[Iter 11800 Total] Train Loss: 0.1519\n",
      "======================================================================\n",
      "[Iter 11900 Task segm] Train Loss: 0.2920\n",
      "[Iter 11900 Task dept] Train Loss: 0.0182\n",
      "[Iter 11900 Total] Train Loss: 0.1551\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Train Loss: 0.2821\n",
      "[Iter 12000 Task dept] Train Loss: 0.0183\n",
      "[Iter 12000 Total] Train Loss: 0.1502\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 0.6814\n",
      "{'mIoU': 0.2667, 'Pixel Acc': 0.6683, 'cmp': -0.221}\n",
      "[Iter 12000 Task dept] Val Loss: 0.0392\n",
      "{'abs_err': 0.0396, 'rel_err': 0.793, 'sigma_1.25': 47.1865, 'sigma_1.25^2': 66.7874, 'sigma_1.25^3': 77.5475, 'cmp': -0.6912}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# alter_train w/o reg\n",
    "trainer.alter_train(iters=20000, policy_network_iters=(100,100), policy_lr=0.01, network_lr=0.001, \n",
    "                    tau=5, \n",
    "                    savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-training/', reload='pre_train_all_10000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Policy:\n",
      "OrderedDict([('net.0.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.4.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.7.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.11.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.14.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.18.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.21.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.25.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.27.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.30.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.34.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.37.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.41.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.44.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.48.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.51.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.55.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.57.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.60.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.64.policy.segment_semantic', tensor([1., 0., 0.], device='cuda:0')), ('net.67.policy.segment_semantic', tensor([0.8118, 0.2909, 0.4706], device='cuda:0')), ('net.71.policy.segment_semantic', tensor([0.6482, 0.3304, 0.9998], device='cuda:0')), ('net.74.policy.segment_semantic', tensor([0.2239, 0.9056, 0.2352], device='cuda:0')), ('net.78.policy.segment_semantic', tensor([0.2784, 0.8313, 0.1379], device='cuda:0')), ('net.81.policy.segment_semantic', tensor([0.7892, 0.5138, 0.4531], device='cuda:0')), ('net.85.policy.segment_semantic', tensor([0.3002, 0.8806, 0.3544], device='cuda:0')), ('net.88.policy.segment_semantic', tensor([0.1253, 0.5761, 0.8799], device='cuda:0')), ('net.92.policy.segment_semantic', tensor([0.9539, 0.8182, 0.3096], device='cuda:0')), ('net.95.policy.segment_semantic', tensor([0.2749, 0.5826, 0.6949], device='cuda:0')), ('net.99.policy.segment_semantic', tensor([0.4336, 0.4498, 0.0478], device='cuda:0')), ('net.101.policy.segment_semantic', tensor([0.5056, 0.9907, 0.1023], device='cuda:0')), ('net.104.policy.segment_semantic', tensor([0.2388, 0.1741, 0.3392], device='cuda:0')), ('net.108.policy.segment_semantic', tensor([0.2974, 0.3249, 0.7407], device='cuda:0')), ('net.111.policy.segment_semantic', tensor([0.5212, 0.0879, 0.5218], device='cuda:0')), ('net.115.policy.segment_semantic', tensor([0.0391, 0.3500, 0.8904], device='cuda:0')), ('net.118.policy.segment_semantic', tensor([0.5467, 0.2671, 0.5539], device='cuda:0')), ('net.0.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.4.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.7.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.11.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.14.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.18.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.21.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.25.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.27.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.30.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.34.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.37.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.41.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.44.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.48.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.51.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.55.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.57.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.60.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.64.policy.depth_zbuffer', tensor([1., 0., 0.], device='cuda:0')), ('net.67.policy.depth_zbuffer', tensor([0.1500, 0.0989, 0.3724], device='cuda:0')), ('net.71.policy.depth_zbuffer', tensor([0.1443, 0.7750, 0.4351], device='cuda:0')), ('net.74.policy.depth_zbuffer', tensor([0.3630, 0.2122, 0.6828], device='cuda:0')), ('net.78.policy.depth_zbuffer', tensor([0.3082, 0.6281, 0.1586], device='cuda:0')), ('net.81.policy.depth_zbuffer', tensor([0.2058, 0.5761, 0.0399], device='cuda:0')), ('net.85.policy.depth_zbuffer', tensor([0.3461, 0.9014, 0.7874], device='cuda:0')), ('net.88.policy.depth_zbuffer', tensor([0.3849, 0.2291, 0.9488], device='cuda:0')), ('net.92.policy.depth_zbuffer', tensor([0.7399, 0.6669, 0.1767], device='cuda:0')), ('net.95.policy.depth_zbuffer', tensor([0.2840, 0.2215, 0.3333], device='cuda:0')), ('net.99.policy.depth_zbuffer', tensor([0.4553, 0.7902, 0.3832], device='cuda:0')), ('net.101.policy.depth_zbuffer', tensor([0.5621, 0.7572, 0.3890], device='cuda:0')), ('net.104.policy.depth_zbuffer', tensor([0.0312, 0.1866, 0.7103], device='cuda:0')), ('net.108.policy.depth_zbuffer', tensor([0.1517, 0.2663, 0.2264], device='cuda:0')), ('net.111.policy.depth_zbuffer', tensor([0.5724, 0.7758, 0.1546], device='cuda:0')), ('net.115.policy.depth_zbuffer', tensor([0.9961, 0.2391, 0.5708], device='cuda:0')), ('net.118.policy.depth_zbuffer', tensor([0.6231, 0.7077, 0.9900], device='cuda:0'))])\n",
      "[Iter 200 Task segm] Train Loss: 1.4128\n",
      "[Iter 200 Task dept] Train Loss: 0.4117\n",
      "[Iter 200 Total] Train Loss: 0.9122\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 1.5955\n",
      "{'mIoU': 0.2738, 'Pixel Acc': 0.4528, 'cmp': -0.3564}\n",
      "[Iter 200 Task dept] Val Loss: 0.0537\n",
      "{'abs_err': 0.0571, 'rel_err': 0.548, 'sigma_1.25': 14.6823, 'sigma_1.25^2': 43.7154, 'sigma_1.25^3': 58.3736, 'cmp': -0.9355}\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Train Loss: 0.9595\n",
      "[Iter 400 Task dept] Train Loss: 0.0471\n",
      "[Iter 400 Total] Train Loss: 0.5033\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 1.1529\n",
      "{'mIoU': 0.342, 'Pixel Acc': 0.5928, 'cmp': -0.1778}\n",
      "[Iter 400 Task dept] Val Loss: 0.0283\n",
      "{'abs_err': 0.0297, 'rel_err': 0.4976, 'sigma_1.25': 54.3309, 'sigma_1.25^2': 74.5226, 'sigma_1.25^3': 85.3231, 'cmp': -0.3404}\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Train Loss: 0.8009\n",
      "[Iter 600 Task dept] Train Loss: 0.0611\n",
      "[Iter 600 Total] Train Loss: 0.4310\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 1.7928\n",
      "{'mIoU': 0.2092, 'Pixel Acc': 0.4155, 'cmp': -0.4616}\n",
      "[Iter 600 Task dept] Val Loss: 0.0308\n",
      "{'abs_err': 0.0347, 'rel_err': 0.4218, 'sigma_1.25': 45.3249, 'sigma_1.25^2': 69.8725, 'sigma_1.25^3': 81.639, 'cmp': -0.3985}\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Train Loss: 0.7591\n",
      "[Iter 800 Task dept] Train Loss: 0.0317\n",
      "[Iter 800 Total] Train Loss: 0.3954\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 0.8460\n",
      "{'mIoU': 0.3483, 'Pixel Acc': 0.6535, 'cmp': -0.1294}\n",
      "[Iter 800 Task dept] Val Loss: 0.0424\n",
      "{'abs_err': 0.0466, 'rel_err': 0.4816, 'sigma_1.25': 24.4502, 'sigma_1.25^2': 64.2465, 'sigma_1.25^3': 78.4667, 'cmp': -0.654}\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Train Loss: 0.7021\n",
      "[Iter 1000 Task dept] Train Loss: 0.0314\n",
      "[Iter 1000 Total] Train Loss: 0.3668\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 0.8186\n",
      "{'mIoU': 0.3793, 'Pixel Acc': 0.6575, 'cmp': -0.0881}\n",
      "[Iter 1000 Task dept] Val Loss: 0.0339\n",
      "{'abs_err': 0.0385, 'rel_err': 0.4617, 'sigma_1.25': 39.5648, 'sigma_1.25^2': 67.7956, 'sigma_1.25^3': 79.4988, 'cmp': -0.4928}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 1200 Task segm] Train Loss: 0.6974\n",
      "[Iter 1200 Task dept] Train Loss: 0.0295\n",
      "[Iter 1200 Total] Train Loss: 0.3635\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 1.0201\n",
      "{'mIoU': 0.4027, 'Pixel Acc': 0.5416, 'cmp': -0.1366}\n",
      "[Iter 1200 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0271, 'rel_err': 0.399, 'sigma_1.25': 57.7441, 'sigma_1.25^2': 77.573, 'sigma_1.25^3': 87.7783, 'cmp': -0.2281}\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Train Loss: 0.6416\n",
      "[Iter 1400 Task dept] Train Loss: 0.0275\n",
      "[Iter 1400 Total] Train Loss: 0.3345\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 1.1275\n",
      "{'mIoU': 0.3126, 'Pixel Acc': 0.558, 'cmp': -0.2377}\n",
      "[Iter 1400 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0295, 'rel_err': 0.4566, 'sigma_1.25': 54.4899, 'sigma_1.25^2': 77.4812, 'sigma_1.25^3': 87.6785, 'cmp': -0.3011}\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Train Loss: 0.6091\n",
      "[Iter 1600 Task dept] Train Loss: 0.0289\n",
      "[Iter 1600 Total] Train Loss: 0.3190\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 0.8322\n",
      "{'mIoU': 0.3487, 'Pixel Acc': 0.6261, 'cmp': -0.1472}\n",
      "[Iter 1600 Task dept] Val Loss: 0.0394\n",
      "{'abs_err': 0.0438, 'rel_err': 0.4482, 'sigma_1.25': 23.5705, 'sigma_1.25^2': 61.5556, 'sigma_1.25^3': 76.6825, 'cmp': -0.6126}\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Train Loss: 0.6114\n",
      "[Iter 1800 Task dept] Train Loss: 0.0266\n",
      "[Iter 1800 Total] Train Loss: 0.3190\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 1.0359\n",
      "{'mIoU': 0.2841, 'Pixel Acc': 0.5783, 'cmp': -0.2596}\n",
      "[Iter 1800 Task dept] Val Loss: 0.0286\n",
      "{'abs_err': 0.0326, 'rel_err': 0.3789, 'sigma_1.25': 47.5638, 'sigma_1.25^2': 74.026, 'sigma_1.25^3': 86.532, 'cmp': -0.3203}\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Train Loss: 0.5834\n",
      "[Iter 2000 Task dept] Train Loss: 0.0261\n",
      "[Iter 2000 Total] Train Loss: 0.3047\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 0.7927\n",
      "{'mIoU': 0.287, 'Pixel Acc': 0.6352, 'cmp': -0.2178}\n",
      "[Iter 2000 Task dept] Val Loss: 0.0351\n",
      "{'abs_err': 0.0405, 'rel_err': 0.491, 'sigma_1.25': 34.4458, 'sigma_1.25^2': 59.1117, 'sigma_1.25^3': 73.4871, 'cmp': -0.5813}\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Train Loss: 0.5769\n",
      "[Iter 2200 Task dept] Train Loss: 0.0257\n",
      "[Iter 2200 Total] Train Loss: 0.3013\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 0.7472\n",
      "{'mIoU': 0.3246, 'Pixel Acc': 0.6533, 'cmp': -0.159}\n",
      "[Iter 2200 Task dept] Val Loss: 0.0232\n",
      "{'abs_err': 0.0255, 'rel_err': 0.3696, 'sigma_1.25': 55.2152, 'sigma_1.25^2': 77.4097, 'sigma_1.25^3': 88.6489, 'cmp': -0.1981}\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Train Loss: 0.5912\n",
      "[Iter 2400 Task dept] Train Loss: 0.0245\n",
      "[Iter 2400 Total] Train Loss: 0.3079\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 0.6718\n",
      "{'mIoU': 0.3484, 'Pixel Acc': 0.6808, 'cmp': -0.111}\n",
      "[Iter 2400 Task dept] Val Loss: 0.0319\n",
      "{'abs_err': 0.0362, 'rel_err': 0.4024, 'sigma_1.25': 39.0594, 'sigma_1.25^2': 72.1607, 'sigma_1.25^3': 84.98, 'cmp': -0.4091}\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Train Loss: 0.5625\n",
      "[Iter 2600 Task dept] Train Loss: 0.0249\n",
      "[Iter 2600 Total] Train Loss: 0.2937\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 0.7563\n",
      "{'mIoU': 0.2902, 'Pixel Acc': 0.6497, 'cmp': -0.2042}\n",
      "[Iter 2600 Task dept] Val Loss: 0.0319\n",
      "{'abs_err': 0.0371, 'rel_err': 0.4414, 'sigma_1.25': 36.8932, 'sigma_1.25^2': 62.046, 'sigma_1.25^3': 77.3652, 'cmp': -0.4894}\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Train Loss: 0.5543\n",
      "[Iter 2800 Task dept] Train Loss: 0.0247\n",
      "[Iter 2800 Total] Train Loss: 0.2895\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 0.6751\n",
      "{'mIoU': 0.3171, 'Pixel Acc': 0.6719, 'cmp': -0.1558}\n",
      "[Iter 2800 Task dept] Val Loss: 0.0240\n",
      "{'abs_err': 0.0261, 'rel_err': 0.483, 'sigma_1.25': 58.8738, 'sigma_1.25^2': 78.3832, 'sigma_1.25^3': 87.8573, 'cmp': -0.2628}\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Train Loss: 0.5331\n",
      "[Iter 3000 Task dept] Train Loss: 0.0241\n",
      "[Iter 3000 Total] Train Loss: 0.2786\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 0.6042\n",
      "{'mIoU': 0.2842, 'Pixel Acc': 0.6909, 'cmp': -0.1841}\n",
      "[Iter 3000 Task dept] Val Loss: 0.0232\n",
      "{'abs_err': 0.0273, 'rel_err': 0.3857, 'sigma_1.25': 54.1929, 'sigma_1.25^2': 77.9216, 'sigma_1.25^3': 88.5649, 'cmp': -0.2305}\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Train Loss: 0.5383\n",
      "[Iter 3200 Task dept] Train Loss: 0.0230\n",
      "[Iter 3200 Total] Train Loss: 0.2807\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 0.6975\n",
      "{'mIoU': 0.3445, 'Pixel Acc': 0.6749, 'cmp': -0.1198}\n",
      "[Iter 3200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0291, 'rel_err': 0.4466, 'sigma_1.25': 54.3923, 'sigma_1.25^2': 78.9368, 'sigma_1.25^3': 88.8185, 'cmp': -0.2854}\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Train Loss: 0.5081\n",
      "[Iter 3400 Task dept] Train Loss: 0.0250\n",
      "[Iter 3400 Total] Train Loss: 0.2665\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.4936\n",
      "{'mIoU': 0.1798, 'Pixel Acc': 0.4545, 'cmp': -0.4722}\n",
      "[Iter 3400 Task dept] Val Loss: 0.0365\n",
      "{'abs_err': 0.041, 'rel_err': 0.4568, 'sigma_1.25': 32.3642, 'sigma_1.25^2': 70.1199, 'sigma_1.25^3': 85.0155, 'cmp': -0.5224}\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Train Loss: 0.5434\n",
      "[Iter 3600 Task dept] Train Loss: 0.0235\n",
      "[Iter 3600 Total] Train Loss: 0.2835\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 0.6312\n",
      "{'mIoU': 0.3306, 'Pixel Acc': 0.6856, 'cmp': -0.1299}\n",
      "[Iter 3600 Task dept] Val Loss: 0.0224\n",
      "{'abs_err': 0.0249, 'rel_err': 0.4219, 'sigma_1.25': 58.5466, 'sigma_1.25^2': 80.18, 'sigma_1.25^3': 89.6362, 'cmp': -0.2036}\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Train Loss: 0.5092\n",
      "[Iter 3800 Task dept] Train Loss: 0.0239\n",
      "[Iter 3800 Total] Train Loss: 0.2665\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 0.6402\n",
      "{'mIoU': 0.3029, 'Pixel Acc': 0.6776, 'cmp': -0.1698}\n",
      "[Iter 3800 Task dept] Val Loss: 0.0237\n",
      "{'abs_err': 0.0239, 'rel_err': 0.5066, 'sigma_1.25': 60.2082, 'sigma_1.25^2': 77.6882, 'sigma_1.25^3': 87.2843, 'cmp': -0.2498}\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Train Loss: 0.5011\n",
      "[Iter 4000 Task dept] Train Loss: 0.0228\n",
      "[Iter 4000 Total] Train Loss: 0.2619\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 0.6101\n",
      "{'mIoU': 0.294, 'Pixel Acc': 0.6823, 'cmp': -0.1777}\n",
      "[Iter 4000 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0301, 'rel_err': 0.3928, 'sigma_1.25': 48.9858, 'sigma_1.25^2': 76.2711, 'sigma_1.25^3': 88.3426, 'cmp': -0.2862}\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Train Loss: 0.4644\n",
      "[Iter 4200 Task dept] Train Loss: 0.0207\n",
      "[Iter 4200 Total] Train Loss: 0.2425\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 0.5618\n",
      "{'mIoU': 0.2901, 'Pixel Acc': 0.6911, 'cmp': -0.1766}\n",
      "[Iter 4200 Task dept] Val Loss: 0.0202\n",
      "{'abs_err': 0.021, 'rel_err': 0.3962, 'sigma_1.25': 65.6714, 'sigma_1.25^2': 83.1695, 'sigma_1.25^3': 91.1576, 'cmp': -0.112}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 4400 Task segm] Train Loss: 0.4463\n",
      "[Iter 4400 Task dept] Train Loss: 0.0206\n",
      "[Iter 4400 Total] Train Loss: 0.2334\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 0.6075\n",
      "{'mIoU': 0.2991, 'Pixel Acc': 0.6846, 'cmp': -0.1697}\n",
      "[Iter 4400 Task dept] Val Loss: 0.0201\n",
      "{'abs_err': 0.0233, 'rel_err': 0.3937, 'sigma_1.25': 61.1884, 'sigma_1.25^2': 81.7955, 'sigma_1.25^3': 90.5506, 'cmp': -0.1551}\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Train Loss: 0.4387\n",
      "[Iter 4600 Task dept] Train Loss: 0.0200\n",
      "[Iter 4600 Total] Train Loss: 0.2293\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 0.4394\n",
      "{'mIoU': 0.3286, 'Pixel Acc': 0.7217, 'cmp': -0.1082}\n",
      "[Iter 4600 Task dept] Val Loss: 0.0274\n",
      "{'abs_err': 0.0326, 'rel_err': 0.4017, 'sigma_1.25': 41.3958, 'sigma_1.25^2': 66.2324, 'sigma_1.25^3': 80.4143, 'cmp': -0.3839}\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Train Loss: 0.4295\n",
      "[Iter 4800 Task dept] Train Loss: 0.0197\n",
      "[Iter 4800 Total] Train Loss: 0.2246\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 0.6665\n",
      "{'mIoU': 0.2766, 'Pixel Acc': 0.6699, 'cmp': -0.2076}\n",
      "[Iter 4800 Task dept] Val Loss: 0.0215\n",
      "{'abs_err': 0.0263, 'rel_err': 0.3616, 'sigma_1.25': 55.4085, 'sigma_1.25^2': 80.2283, 'sigma_1.25^3': 90.5201, 'cmp': -0.1911}\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Train Loss: 0.4393\n",
      "[Iter 5000 Task dept] Train Loss: 0.0203\n",
      "[Iter 5000 Total] Train Loss: 0.2298\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 0.5528\n",
      "{'mIoU': 0.2989, 'Pixel Acc': 0.6906, 'cmp': -0.1661}\n",
      "[Iter 5000 Task dept] Val Loss: 0.0215\n",
      "{'abs_err': 0.0254, 'rel_err': 0.3702, 'sigma_1.25': 57.2785, 'sigma_1.25^2': 81.7905, 'sigma_1.25^3': 91.1448, 'cmp': -0.1747}\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Train Loss: 0.4403\n",
      "[Iter 5200 Task dept] Train Loss: 0.0204\n",
      "[Iter 5200 Total] Train Loss: 0.2304\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 0.6916\n",
      "{'mIoU': 0.2462, 'Pixel Acc': 0.6708, 'cmp': -0.2449}\n",
      "[Iter 5200 Task dept] Val Loss: 0.0190\n",
      "{'abs_err': 0.0229, 'rel_err': 0.3777, 'sigma_1.25': 63.2775, 'sigma_1.25^2': 83.3936, 'sigma_1.25^3': 91.8217, 'cmp': -0.1287}\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Train Loss: 0.4356\n",
      "[Iter 5400 Task dept] Train Loss: 0.0204\n",
      "[Iter 5400 Total] Train Loss: 0.2280\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 0.5517\n",
      "{'mIoU': 0.3028, 'Pixel Acc': 0.6983, 'cmp': -0.156}\n",
      "[Iter 5400 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0298, 'rel_err': 0.3843, 'sigma_1.25': 53.0329, 'sigma_1.25^2': 79.6331, 'sigma_1.25^3': 90.3772, 'cmp': -0.2545}\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Train Loss: 0.4370\n",
      "[Iter 5600 Task dept] Train Loss: 0.0197\n",
      "[Iter 5600 Total] Train Loss: 0.2283\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 0.4563\n",
      "{'mIoU': 0.2972, 'Pixel Acc': 0.7134, 'cmp': -0.1529}\n",
      "[Iter 5600 Task dept] Val Loss: 0.0193\n",
      "{'abs_err': 0.0224, 'rel_err': 0.4114, 'sigma_1.25': 63.2819, 'sigma_1.25^2': 82.6847, 'sigma_1.25^3': 90.836, 'cmp': -0.1461}\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Train Loss: 0.4250\n",
      "[Iter 5800 Task dept] Train Loss: 0.0195\n",
      "[Iter 5800 Total] Train Loss: 0.2223\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 0.6889\n",
      "{'mIoU': 0.272, 'Pixel Acc': 0.6669, 'cmp': -0.2152}\n",
      "[Iter 5800 Task dept] Val Loss: 0.0274\n",
      "{'abs_err': 0.0328, 'rel_err': 0.3918, 'sigma_1.25': 43.0415, 'sigma_1.25^2': 71.2486, 'sigma_1.25^3': 85.022, 'cmp': -0.3539}\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Train Loss: 0.4143\n",
      "[Iter 6000 Task dept] Train Loss: 0.0193\n",
      "[Iter 6000 Total] Train Loss: 0.2168\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 0.4689\n",
      "{'mIoU': 0.276, 'Pixel Acc': 0.7176, 'cmp': -0.1764}\n",
      "[Iter 6000 Task dept] Val Loss: 0.0228\n",
      "{'abs_err': 0.0275, 'rel_err': 0.3716, 'sigma_1.25': 57.3639, 'sigma_1.25^2': 83.0335, 'sigma_1.25^3': 92.0167, 'cmp': -0.1954}\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Train Loss: 0.4315\n",
      "[Iter 6200 Task dept] Train Loss: 0.0192\n",
      "[Iter 6200 Total] Train Loss: 0.2254\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 0.4658\n",
      "{'mIoU': 0.3091, 'Pixel Acc': 0.7149, 'cmp': -0.1371}\n",
      "[Iter 6200 Task dept] Val Loss: 0.0210\n",
      "{'abs_err': 0.0249, 'rel_err': 0.3672, 'sigma_1.25': 55.9661, 'sigma_1.25^2': 79.24, 'sigma_1.25^3': 89.8114, 'cmp': -0.18}\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Train Loss: 0.4193\n",
      "[Iter 6400 Task dept] Train Loss: 0.0200\n",
      "[Iter 6400 Total] Train Loss: 0.2196\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 0.6287\n",
      "{'mIoU': 0.2417, 'Pixel Acc': 0.6752, 'cmp': -0.2475}\n",
      "[Iter 6400 Task dept] Val Loss: 0.0207\n",
      "{'abs_err': 0.025, 'rel_err': 0.3544, 'sigma_1.25': 55.2158, 'sigma_1.25^2': 77.1734, 'sigma_1.25^3': 88.2705, 'cmp': -0.1842}\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Train Loss: 0.4190\n",
      "[Iter 6600 Task dept] Train Loss: 0.0197\n",
      "[Iter 6600 Total] Train Loss: 0.2194\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 0.4585\n",
      "{'mIoU': 0.3052, 'Pixel Acc': 0.7161, 'cmp': -0.141}\n",
      "[Iter 6600 Task dept] Val Loss: 0.0202\n",
      "{'abs_err': 0.0218, 'rel_err': 0.4047, 'sigma_1.25': 63.2386, 'sigma_1.25^2': 82.0722, 'sigma_1.25^3': 90.6353, 'cmp': -0.1369}\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Train Loss: 0.4088\n",
      "[Iter 6800 Task dept] Train Loss: 0.0189\n",
      "[Iter 6800 Total] Train Loss: 0.2138\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 0.4673\n",
      "{'mIoU': 0.2887, 'Pixel Acc': 0.7102, 'cmp': -0.1655}\n",
      "[Iter 6800 Task dept] Val Loss: 0.0275\n",
      "{'abs_err': 0.0325, 'rel_err': 0.3836, 'sigma_1.25': 45.4952, 'sigma_1.25^2': 74.4959, 'sigma_1.25^3': 87.1151, 'cmp': -0.3264}\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Train Loss: 0.4124\n",
      "[Iter 7000 Task dept] Train Loss: 0.0195\n",
      "[Iter 7000 Total] Train Loss: 0.2159\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 0.4626\n",
      "{'mIoU': 0.3218, 'Pixel Acc': 0.7171, 'cmp': -0.1197}\n",
      "[Iter 7000 Task dept] Val Loss: 0.0227\n",
      "{'abs_err': 0.0279, 'rel_err': 0.3678, 'sigma_1.25': 52.7818, 'sigma_1.25^2': 76.1561, 'sigma_1.25^3': 87.2194, 'cmp': -0.2374}\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Train Loss: 0.4037\n",
      "[Iter 7200 Task dept] Train Loss: 0.0191\n",
      "[Iter 7200 Total] Train Loss: 0.2114\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.0247\n",
      "{'mIoU': 0.267, 'Pixel Acc': 0.6177, 'cmp': -0.2545}\n",
      "[Iter 7200 Task dept] Val Loss: 0.0212\n",
      "{'abs_err': 0.0257, 'rel_err': 0.3871, 'sigma_1.25': 57.1298, 'sigma_1.25^2': 81.0134, 'sigma_1.25^3': 90.6937, 'cmp': -0.1918}\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Train Loss: 0.4121\n",
      "[Iter 7400 Task dept] Train Loss: 0.0193\n",
      "[Iter 7400 Total] Train Loss: 0.2157\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 0.6178\n",
      "{'mIoU': 0.3014, 'Pixel Acc': 0.6804, 'cmp': -0.1697}\n",
      "[Iter 7400 Task dept] Val Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs_err': 0.0235, 'rel_err': 0.4094, 'sigma_1.25': 61.8712, 'sigma_1.25^2': 82.3104, 'sigma_1.25^3': 91.0669, 'cmp': -0.1631}\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Train Loss: 0.4088\n",
      "[Iter 7600 Task dept] Train Loss: 0.0194\n",
      "[Iter 7600 Total] Train Loss: 0.2141\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 0.4416\n",
      "{'mIoU': 0.3105, 'Pixel Acc': 0.7186, 'cmp': -0.1329}\n",
      "[Iter 7600 Task dept] Val Loss: 0.0187\n",
      "{'abs_err': 0.0214, 'rel_err': 0.404, 'sigma_1.25': 65.4661, 'sigma_1.25^2': 83.3904, 'sigma_1.25^3': 91.2162, 'cmp': -0.1213}\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Train Loss: 0.3951\n",
      "[Iter 7800 Task dept] Train Loss: 0.0192\n",
      "[Iter 7800 Total] Train Loss: 0.2072\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 0.5351\n",
      "{'mIoU': 0.2934, 'Pixel Acc': 0.6914, 'cmp': -0.1723}\n",
      "[Iter 7800 Task dept] Val Loss: 0.0193\n",
      "{'abs_err': 0.0232, 'rel_err': 0.3451, 'sigma_1.25': 62.4231, 'sigma_1.25^2': 83.9182, 'sigma_1.25^3': 92.2879, 'cmp': -0.1118}\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Train Loss: 0.4115\n",
      "[Iter 8000 Task dept] Train Loss: 0.0192\n",
      "[Iter 8000 Total] Train Loss: 0.2153\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 0.8852\n",
      "{'mIoU': 0.2488, 'Pixel Acc': 0.626, 'cmp': -0.2715}\n",
      "[Iter 8000 Task dept] Val Loss: 0.0182\n",
      "{'abs_err': 0.0195, 'rel_err': 0.3504, 'sigma_1.25': 66.0676, 'sigma_1.25^2': 84.0884, 'sigma_1.25^3': 92.2896, 'cmp': -0.0614}\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 0.3918\n",
      "[Iter 8200 Task dept] Train Loss: 0.0177\n",
      "[Iter 8200 Total] Train Loss: 0.2048\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 0.4000\n",
      "{'mIoU': 0.3111, 'Pixel Acc': 0.7315, 'cmp': -0.1235}\n",
      "[Iter 8200 Task dept] Val Loss: 0.0176\n",
      "{'abs_err': 0.0211, 'rel_err': 0.3724, 'sigma_1.25': 67.3508, 'sigma_1.25^2': 85.0205, 'sigma_1.25^3': 92.3772, 'cmp': -0.0877}\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 0.3740\n",
      "[Iter 8400 Task dept] Train Loss: 0.0173\n",
      "[Iter 8400 Total] Train Loss: 0.1956\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 0.4059\n",
      "{'mIoU': 0.3219, 'Pixel Acc': 0.7251, 'cmp': -0.1143}\n",
      "[Iter 8400 Task dept] Val Loss: 0.0196\n",
      "{'abs_err': 0.0201, 'rel_err': 0.4411, 'sigma_1.25': 65.0244, 'sigma_1.25^2': 81.8452, 'sigma_1.25^3': 90.1513, 'cmp': -0.136}\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Train Loss: 0.3628\n",
      "[Iter 8600 Task dept] Train Loss: 0.0179\n",
      "[Iter 8600 Total] Train Loss: 0.1904\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 0.4346\n",
      "{'mIoU': 0.3095, 'Pixel Acc': 0.7165, 'cmp': -0.1355}\n",
      "[Iter 8600 Task dept] Val Loss: 0.0179\n",
      "{'abs_err': 0.0218, 'rel_err': 0.3666, 'sigma_1.25': 64.5285, 'sigma_1.25^2': 84.6755, 'sigma_1.25^3': 92.4613, 'cmp': -0.1007}\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.3507\n",
      "[Iter 8800 Task dept] Train Loss: 0.0174\n",
      "[Iter 8800 Total] Train Loss: 0.1840\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 0.4006\n",
      "{'mIoU': 0.3248, 'Pixel Acc': 0.7271, 'cmp': -0.1093}\n",
      "[Iter 8800 Task dept] Val Loss: 0.0187\n",
      "{'abs_err': 0.023, 'rel_err': 0.3503, 'sigma_1.25': 62.0695, 'sigma_1.25^2': 82.3089, 'sigma_1.25^3': 91.2499, 'cmp': -0.1205}\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.3705\n",
      "[Iter 9000 Task dept] Train Loss: 0.0180\n",
      "[Iter 9000 Total] Train Loss: 0.1943\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 0.3685\n",
      "{'mIoU': 0.3335, 'Pixel Acc': 0.7364, 'cmp': -0.0923}\n",
      "[Iter 9000 Task dept] Val Loss: 0.0179\n",
      "{'abs_err': 0.022, 'rel_err': 0.3594, 'sigma_1.25': 64.9027, 'sigma_1.25^2': 84.0319, 'sigma_1.25^3': 92.1714, 'cmp': -0.0991}\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.3674\n",
      "[Iter 9200 Task dept] Train Loss: 0.0170\n",
      "[Iter 9200 Total] Train Loss: 0.1922\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 0.4122\n",
      "{'mIoU': 0.3235, 'Pixel Acc': 0.7275, 'cmp': -0.1107}\n",
      "[Iter 9200 Task dept] Val Loss: 0.0186\n",
      "{'abs_err': 0.0221, 'rel_err': 0.3356, 'sigma_1.25': 60.769, 'sigma_1.25^2': 82.0952, 'sigma_1.25^3': 91.5479, 'cmp': -0.1035}\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.3568\n",
      "[Iter 9400 Task dept] Train Loss: 0.0182\n",
      "[Iter 9400 Total] Train Loss: 0.1875\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 0.3900\n",
      "{'mIoU': 0.3275, 'Pixel Acc': 0.7299, 'cmp': -0.1042}\n",
      "[Iter 9400 Task dept] Val Loss: 0.0180\n",
      "{'abs_err': 0.0213, 'rel_err': 0.3706, 'sigma_1.25': 65.9167, 'sigma_1.25^2': 84.5126, 'sigma_1.25^3': 92.2461, 'cmp': -0.0937}\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Train Loss: 0.3566\n",
      "[Iter 9600 Task dept] Train Loss: 0.0174\n",
      "[Iter 9600 Total] Train Loss: 0.1870\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 0.5543\n",
      "{'mIoU': 0.2946, 'Pixel Acc': 0.6782, 'cmp': -0.1797}\n",
      "[Iter 9600 Task dept] Val Loss: 0.0180\n",
      "{'abs_err': 0.0191, 'rel_err': 0.3576, 'sigma_1.25': 67.0078, 'sigma_1.25^2': 84.4934, 'sigma_1.25^3': 92.234, 'cmp': -0.0573}\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.3660\n",
      "[Iter 9800 Task dept] Train Loss: 0.0178\n",
      "[Iter 9800 Total] Train Loss: 0.1919\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 0.3859\n",
      "{'mIoU': 0.3291, 'Pixel Acc': 0.7314, 'cmp': -0.1012}\n",
      "[Iter 9800 Task dept] Val Loss: 0.0172\n",
      "{'abs_err': 0.0205, 'rel_err': 0.3774, 'sigma_1.25': 67.2393, 'sigma_1.25^2': 84.9047, 'sigma_1.25^3': 92.382, 'cmp': -0.0843}\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.3553\n",
      "[Iter 10000 Task dept] Train Loss: 0.0176\n",
      "[Iter 10000 Total] Train Loss: 0.1865\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 0.4772\n",
      "{'mIoU': 0.2836, 'Pixel Acc': 0.714, 'cmp': -0.1694}\n",
      "[Iter 10000 Task dept] Val Loss: 0.0194\n",
      "{'abs_err': 0.0245, 'rel_err': 0.357, 'sigma_1.25': 57.698, 'sigma_1.25^2': 79.2613, 'sigma_1.25^3': 88.9574, 'cmp': -0.1658}\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Train Loss: 0.3571\n",
      "[Iter 10200 Task dept] Train Loss: 0.0175\n",
      "[Iter 10200 Total] Train Loss: 0.1873\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Val Loss: 0.4073\n",
      "{'mIoU': 0.3281, 'Pixel Acc': 0.724, 'cmp': -0.1073}\n",
      "[Iter 10200 Task dept] Val Loss: 0.0171\n",
      "{'abs_err': 0.0204, 'rel_err': 0.3508, 'sigma_1.25': 66.544, 'sigma_1.25^2': 84.754, 'sigma_1.25^3': 92.6253, 'cmp': -0.0689}\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Train Loss: 0.3521\n",
      "[Iter 10400 Task dept] Train Loss: 0.0171\n",
      "[Iter 10400 Total] Train Loss: 0.1846\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Val Loss: 0.3711\n",
      "{'mIoU': 0.3367, 'Pixel Acc': 0.7331, 'cmp': -0.0905}\n",
      "[Iter 10400 Task dept] Val Loss: 0.0172\n",
      "{'abs_err': 0.0197, 'rel_err': 0.3768, 'sigma_1.25': 67.154, 'sigma_1.25^2': 84.0725, 'sigma_1.25^3': 91.8028, 'cmp': -0.0773}\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Train Loss: 0.3509\n",
      "[Iter 10600 Task dept] Train Loss: 0.0174\n",
      "[Iter 10600 Total] Train Loss: 0.1842\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10600 Task segm] Val Loss: 0.3786\n",
      "{'mIoU': 0.3486, 'Pixel Acc': 0.7261, 'cmp': -0.0803}\n",
      "[Iter 10600 Task dept] Val Loss: 0.0170\n",
      "{'abs_err': 0.0206, 'rel_err': 0.3433, 'sigma_1.25': 66.1126, 'sigma_1.25^2': 85.0231, 'sigma_1.25^3': 92.7834, 'cmp': -0.0666}\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Train Loss: 0.3562\n",
      "[Iter 10800 Task dept] Train Loss: 0.0172\n",
      "[Iter 10800 Total] Train Loss: 0.1867\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Val Loss: 0.3780\n",
      "{'mIoU': 0.3268, 'Pixel Acc': 0.7337, 'cmp': -0.1025}\n",
      "[Iter 10800 Task dept] Val Loss: 0.0172\n",
      "{'abs_err': 0.0206, 'rel_err': 0.3322, 'sigma_1.25': 65.6702, 'sigma_1.25^2': 84.5124, 'sigma_1.25^3': 92.4751, 'cmp': -0.0628}\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Train Loss: 0.3390\n",
      "[Iter 11000 Task dept] Train Loss: 0.0172\n",
      "[Iter 11000 Total] Train Loss: 0.1781\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 0.3651\n",
      "{'mIoU': 0.3428, 'Pixel Acc': 0.7369, 'cmp': -0.0804}\n",
      "[Iter 11000 Task dept] Val Loss: 0.0178\n",
      "{'abs_err': 0.0197, 'rel_err': 0.3477, 'sigma_1.25': 64.9745, 'sigma_1.25^2': 83.938, 'sigma_1.25^3': 92.1423, 'cmp': -0.0655}\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Train Loss: 0.3489\n",
      "[Iter 11200 Task dept] Train Loss: 0.0175\n",
      "[Iter 11200 Total] Train Loss: 0.1832\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Val Loss: 0.4138\n",
      "{'mIoU': 0.324, 'Pixel Acc': 0.7199, 'cmp': -0.1152}\n",
      "[Iter 11200 Task dept] Val Loss: 0.0169\n",
      "{'abs_err': 0.0195, 'rel_err': 0.3769, 'sigma_1.25': 67.9194, 'sigma_1.25^2': 85.0554, 'sigma_1.25^3': 92.2787, 'cmp': -0.07}\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Train Loss: 0.3405\n",
      "[Iter 11400 Task dept] Train Loss: 0.0176\n",
      "[Iter 11400 Total] Train Loss: 0.1791\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Val Loss: 0.3593\n",
      "{'mIoU': 0.3455, 'Pixel Acc': 0.7305, 'cmp': -0.0813}\n",
      "[Iter 11400 Task dept] Val Loss: 0.0173\n",
      "{'abs_err': 0.02, 'rel_err': 0.3763, 'sigma_1.25': 66.9722, 'sigma_1.25^2': 84.5407, 'sigma_1.25^3': 92.1348, 'cmp': -0.0797}\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Train Loss: 0.3432\n",
      "[Iter 11600 Task dept] Train Loss: 0.0170\n",
      "[Iter 11600 Total] Train Loss: 0.1801\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Val Loss: 0.4729\n",
      "{'mIoU': 0.3114, 'Pixel Acc': 0.7065, 'cmp': -0.1398}\n",
      "[Iter 11600 Task dept] Val Loss: 0.0175\n",
      "{'abs_err': 0.0216, 'rel_err': 0.3392, 'sigma_1.25': 61.0986, 'sigma_1.25^2': 81.3052, 'sigma_1.25^3': 90.5622, 'cmp': -0.1036}\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Train Loss: 0.3347\n",
      "[Iter 11800 Task dept] Train Loss: 0.0167\n",
      "[Iter 11800 Total] Train Loss: 0.1757\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Val Loss: 0.3744\n",
      "{'mIoU': 0.3378, 'Pixel Acc': 0.7332, 'cmp': -0.089}\n",
      "[Iter 11800 Task dept] Val Loss: 0.0198\n",
      "{'abs_err': 0.0241, 'rel_err': 0.337, 'sigma_1.25': 57.6689, 'sigma_1.25^2': 79.5373, 'sigma_1.25^3': 89.6542, 'cmp': -0.1475}\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Train Loss: 0.3401\n",
      "[Iter 12000 Task dept] Train Loss: 0.0169\n",
      "[Iter 12000 Total] Train Loss: 0.1785\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 0.3749\n",
      "{'mIoU': 0.3373, 'Pixel Acc': 0.7313, 'cmp': -0.091}\n",
      "[Iter 12000 Task dept] Val Loss: 0.0177\n",
      "{'abs_err': 0.0218, 'rel_err': 0.3526, 'sigma_1.25': 67.0008, 'sigma_1.25^2': 85.3934, 'sigma_1.25^3': 92.6787, 'cmp': -0.0834}\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Train Loss: 0.3398\n",
      "[Iter 12200 Task dept] Train Loss: 0.0161\n",
      "[Iter 12200 Total] Train Loss: 0.1780\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Val Loss: 0.3625\n",
      "{'mIoU': 0.3533, 'Pixel Acc': 0.7346, 'cmp': -0.0689}\n",
      "[Iter 12200 Task dept] Val Loss: 0.0162\n",
      "{'abs_err': 0.0188, 'rel_err': 0.3538, 'sigma_1.25': 69.738, 'sigma_1.25^2': 86.3262, 'sigma_1.25^3': 93.1125, 'cmp': -0.037}\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Train Loss: 0.3213\n",
      "[Iter 12400 Task dept] Train Loss: 0.0162\n",
      "[Iter 12400 Total] Train Loss: 0.1688\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Val Loss: 0.3608\n",
      "{'mIoU': 0.3503, 'Pixel Acc': 0.7297, 'cmp': -0.0758}\n",
      "[Iter 12400 Task dept] Val Loss: 0.0174\n",
      "{'abs_err': 0.0216, 'rel_err': 0.341, 'sigma_1.25': 63.9784, 'sigma_1.25^2': 84.6051, 'sigma_1.25^3': 92.7702, 'cmp': -0.0833}\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Train Loss: 0.3180\n",
      "[Iter 12600 Task dept] Train Loss: 0.0164\n",
      "[Iter 12600 Total] Train Loss: 0.1672\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Val Loss: 0.4432\n",
      "{'mIoU': 0.3125, 'Pixel Acc': 0.7149, 'cmp': -0.1329}\n",
      "[Iter 12600 Task dept] Val Loss: 0.0160\n",
      "{'abs_err': 0.0194, 'rel_err': 0.3377, 'sigma_1.25': 68.377, 'sigma_1.25^2': 85.9833, 'sigma_1.25^3': 93.1441, 'cmp': -0.0396}\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Train Loss: 0.3196\n",
      "[Iter 12800 Task dept] Train Loss: 0.0159\n",
      "[Iter 12800 Total] Train Loss: 0.1677\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Val Loss: 0.3505\n",
      "{'mIoU': 0.3513, 'Pixel Acc': 0.7353, 'cmp': -0.0709}\n",
      "[Iter 12800 Task dept] Val Loss: 0.0164\n",
      "{'abs_err': 0.0198, 'rel_err': 0.3649, 'sigma_1.25': 68.4032, 'sigma_1.25^2': 86.0894, 'sigma_1.25^3': 93.0558, 'cmp': -0.0601}\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Train Loss: 0.3136\n",
      "[Iter 13000 Task dept] Train Loss: 0.0160\n",
      "[Iter 13000 Total] Train Loss: 0.1648\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Val Loss: 0.3724\n",
      "{'mIoU': 0.3521, 'Pixel Acc': 0.7286, 'cmp': -0.0744}\n",
      "[Iter 13000 Task dept] Val Loss: 0.0164\n",
      "{'abs_err': 0.0204, 'rel_err': 0.3415, 'sigma_1.25': 68.4724, 'sigma_1.25^2': 86.2637, 'sigma_1.25^3': 93.3451, 'cmp': -0.0519}\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Train Loss: 0.3090\n",
      "[Iter 13200 Task dept] Train Loss: 0.0158\n",
      "[Iter 13200 Total] Train Loss: 0.1624\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Val Loss: 0.3426\n",
      "{'mIoU': 0.3695, 'Pixel Acc': 0.7376, 'cmp': -0.0466}\n",
      "[Iter 13200 Task dept] Val Loss: 0.0162\n",
      "{'abs_err': 0.0184, 'rel_err': 0.3333, 'sigma_1.25': 68.7117, 'sigma_1.25^2': 86.1085, 'sigma_1.25^3': 93.2537, 'cmp': -0.0239}\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Train Loss: 0.3150\n",
      "[Iter 13400 Task dept] Train Loss: 0.0161\n",
      "[Iter 13400 Total] Train Loss: 0.1655\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Val Loss: 0.3324\n",
      "{'mIoU': 0.3749, 'Pixel Acc': 0.7388, 'cmp': -0.0392}\n",
      "[Iter 13400 Task dept] Val Loss: 0.0173\n",
      "{'abs_err': 0.0212, 'rel_err': 0.3336, 'sigma_1.25': 62.2535, 'sigma_1.25^2': 82.1917, 'sigma_1.25^3': 90.9456, 'cmp': -0.0886}\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Train Loss: 0.3141\n",
      "[Iter 13600 Task dept] Train Loss: 0.0160\n",
      "[Iter 13600 Total] Train Loss: 0.1651\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Val Loss: 0.3450\n",
      "{'mIoU': 0.3599, 'Pixel Acc': 0.7364, 'cmp': -0.0594}\n",
      "[Iter 13600 Task dept] Val Loss: 0.0161\n",
      "{'abs_err': 0.0182, 'rel_err': 0.3545, 'sigma_1.25': 70.1238, 'sigma_1.25^2': 86.1014, 'sigma_1.25^3': 92.9586, 'cmp': -0.0313}\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 13800 Task segm] Train Loss: 0.3141\n",
      "[Iter 13800 Task dept] Train Loss: 0.0161\n",
      "[Iter 13800 Total] Train Loss: 0.1651\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Val Loss: 0.3366\n",
      "{'mIoU': 0.3655, 'Pixel Acc': 0.738, 'cmp': -0.0514}\n",
      "[Iter 13800 Task dept] Val Loss: 0.0162\n",
      "{'abs_err': 0.0189, 'rel_err': 0.3294, 'sigma_1.25': 66.6395, 'sigma_1.25^2': 85.4088, 'sigma_1.25^3': 93.1426, 'cmp': -0.0349}\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Train Loss: 0.3042\n",
      "[Iter 14000 Task dept] Train Loss: 0.0159\n",
      "[Iter 14000 Total] Train Loss: 0.1601\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Val Loss: 0.3266\n",
      "{'mIoU': 0.3685, 'Pixel Acc': 0.7396, 'cmp': -0.0466}\n",
      "[Iter 14000 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0188, 'rel_err': 0.3317, 'sigma_1.25': 69.1491, 'sigma_1.25^2': 86.3202, 'sigma_1.25^3': 93.4108, 'cmp': -0.0246}\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Train Loss: 0.3179\n",
      "[Iter 14200 Task dept] Train Loss: 0.0158\n",
      "[Iter 14200 Total] Train Loss: 0.1669\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Val Loss: 0.3422\n",
      "{'mIoU': 0.3656, 'Pixel Acc': 0.7342, 'cmp': -0.0539}\n",
      "[Iter 14200 Task dept] Val Loss: 0.0172\n",
      "{'abs_err': 0.021, 'rel_err': 0.3662, 'sigma_1.25': 67.505, 'sigma_1.25^2': 85.5163, 'sigma_1.25^3': 92.6683, 'cmp': -0.0802}\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Train Loss: 0.2975\n",
      "[Iter 14400 Task dept] Train Loss: 0.0157\n",
      "[Iter 14400 Total] Train Loss: 0.1566\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Val Loss: 0.3245\n",
      "{'mIoU': 0.3679, 'Pixel Acc': 0.7396, 'cmp': -0.0473}\n",
      "[Iter 14400 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0187, 'rel_err': 0.3443, 'sigma_1.25': 69.1905, 'sigma_1.25^2': 86.3187, 'sigma_1.25^3': 93.2576, 'cmp': -0.0313}\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Train Loss: 0.3071\n",
      "[Iter 14600 Task dept] Train Loss: 0.0156\n",
      "[Iter 14600 Total] Train Loss: 0.1614\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Val Loss: 0.3364\n",
      "{'mIoU': 0.3743, 'Pixel Acc': 0.7394, 'cmp': -0.0395}\n",
      "[Iter 14600 Task dept] Val Loss: 0.0162\n",
      "{'abs_err': 0.0179, 'rel_err': 0.3447, 'sigma_1.25': 70.1825, 'sigma_1.25^2': 86.5367, 'sigma_1.25^3': 93.293, 'cmp': -0.0187}\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Train Loss: 0.3061\n",
      "[Iter 14800 Task dept] Train Loss: 0.0158\n",
      "[Iter 14800 Total] Train Loss: 0.1609\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Val Loss: 0.3667\n",
      "{'mIoU': 0.347, 'Pixel Acc': 0.7279, 'cmp': -0.0812}\n",
      "[Iter 14800 Task dept] Val Loss: 0.0187\n",
      "{'abs_err': 0.0177, 'rel_err': 0.3703, 'sigma_1.25': 70.1059, 'sigma_1.25^2': 85.8792, 'sigma_1.25^3': 92.9243, 'cmp': -0.0346}\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Train Loss: 0.3041\n",
      "[Iter 15000 Task dept] Train Loss: 0.0158\n",
      "[Iter 15000 Total] Train Loss: 0.1600\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Val Loss: 0.3475\n",
      "{'mIoU': 0.3595, 'Pixel Acc': 0.7349, 'cmp': -0.061}\n",
      "[Iter 15000 Task dept] Val Loss: 0.0163\n",
      "{'abs_err': 0.0201, 'rel_err': 0.3547, 'sigma_1.25': 68.4382, 'sigma_1.25^2': 86.3609, 'sigma_1.25^3': 93.3489, 'cmp': -0.0565}\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Train Loss: 0.3028\n",
      "[Iter 15200 Task dept] Train Loss: 0.0159\n",
      "[Iter 15200 Total] Train Loss: 0.1594\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Val Loss: 0.3299\n",
      "{'mIoU': 0.3646, 'Pixel Acc': 0.7403, 'cmp': -0.051}\n",
      "[Iter 15200 Task dept] Val Loss: 0.0161\n",
      "{'abs_err': 0.0199, 'rel_err': 0.3362, 'sigma_1.25': 65.0341, 'sigma_1.25^2': 83.4175, 'sigma_1.25^3': 91.9011, 'cmp': -0.0629}\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Train Loss: 0.3126\n",
      "[Iter 15400 Task dept] Train Loss: 0.0156\n",
      "[Iter 15400 Total] Train Loss: 0.1641\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Val Loss: 0.3627\n",
      "{'mIoU': 0.3668, 'Pixel Acc': 0.7335, 'cmp': -0.0528}\n",
      "[Iter 15400 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0198, 'rel_err': 0.3275, 'sigma_1.25': 65.8423, 'sigma_1.25^2': 85.1384, 'sigma_1.25^3': 93.0452, 'cmp': -0.047}\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Train Loss: 0.3064\n",
      "[Iter 15600 Task dept] Train Loss: 0.0156\n",
      "[Iter 15600 Total] Train Loss: 0.1610\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Val Loss: 0.3273\n",
      "{'mIoU': 0.3699, 'Pixel Acc': 0.739, 'cmp': -0.0453}\n",
      "[Iter 15600 Task dept] Val Loss: 0.0163\n",
      "{'abs_err': 0.0181, 'rel_err': 0.3608, 'sigma_1.25': 70.333, 'sigma_1.25^2': 86.1606, 'sigma_1.25^3': 92.9602, 'cmp': -0.0321}\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Train Loss: 0.3002\n",
      "[Iter 15800 Task dept] Train Loss: 0.0155\n",
      "[Iter 15800 Total] Train Loss: 0.1579\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Train Loss: 0.3012\n",
      "[Iter 16000 Task dept] Train Loss: 0.0158\n",
      "[Iter 16000 Total] Train Loss: 0.1585\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Val Loss: 0.3289\n",
      "{'mIoU': 0.37, 'Pixel Acc': 0.7349, 'cmp': -0.0479}\n",
      "[Iter 16000 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0189, 'rel_err': 0.3413, 'sigma_1.25': 68.5412, 'sigma_1.25^2': 86.1398, 'sigma_1.25^3': 93.2141, 'cmp': -0.0344}\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Train Loss: 0.2925\n",
      "[Iter 16200 Task dept] Train Loss: 0.0150\n",
      "[Iter 16200 Total] Train Loss: 0.1537\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Val Loss: 0.3246\n",
      "{'mIoU': 0.3844, 'Pixel Acc': 0.7398, 'cmp': -0.0267}\n",
      "[Iter 16200 Task dept] Val Loss: 0.0158\n",
      "{'abs_err': 0.0192, 'rel_err': 0.326, 'sigma_1.25': 67.8937, 'sigma_1.25^2': 85.7125, 'sigma_1.25^3': 93.1629, 'cmp': -0.032}\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Train Loss: 0.2877\n",
      "[Iter 16400 Task dept] Train Loss: 0.0150\n",
      "[Iter 16400 Total] Train Loss: 0.1514\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Val Loss: 0.3231\n",
      "{'mIoU': 0.3802, 'Pixel Acc': 0.7402, 'cmp': -0.0317}\n",
      "[Iter 16400 Task dept] Val Loss: 0.0157\n",
      "{'abs_err': 0.0198, 'rel_err': 0.3305, 'sigma_1.25': 69.1315, 'sigma_1.25^2': 86.4189, 'sigma_1.25^3': 93.4893, 'cmp': -0.0354}\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Train Loss: 0.2956\n",
      "[Iter 16600 Task dept] Train Loss: 0.0150\n",
      "[Iter 16600 Total] Train Loss: 0.1553\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Val Loss: 0.3151\n",
      "{'mIoU': 0.3867, 'Pixel Acc': 0.7415, 'cmp': -0.0227}\n",
      "[Iter 16600 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0182, 'rel_err': 0.3481, 'sigma_1.25': 70.6549, 'sigma_1.25^2': 86.7149, 'sigma_1.25^3': 93.3788, 'cmp': -0.0235}\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Train Loss: 0.2852\n",
      "[Iter 16800 Task dept] Train Loss: 0.0147\n",
      "[Iter 16800 Total] Train Loss: 0.1499\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Val Loss: 0.3382\n",
      "{'mIoU': 0.3751, 'Pixel Acc': 0.7354, 'cmp': -0.0412}\n",
      "[Iter 16800 Task dept] Val Loss: 0.0154\n",
      "{'abs_err': 0.0192, 'rel_err': 0.3285, 'sigma_1.25': 69.06, 'sigma_1.25^2': 86.6628, 'sigma_1.25^3': 93.746, 'cmp': -0.027}\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Train Loss: 0.2885\n",
      "[Iter 17000 Task dept] Train Loss: 0.0147\n",
      "[Iter 17000 Total] Train Loss: 0.1516\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 17000 Task segm] Val Loss: 0.3080\n",
      "{'mIoU': 0.3963, 'Pixel Acc': 0.744, 'cmp': -0.009}\n",
      "[Iter 17000 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0186, 'rel_err': 0.3319, 'sigma_1.25': 69.3965, 'sigma_1.25^2': 86.4887, 'sigma_1.25^3': 93.5736, 'cmp': -0.0218}\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Train Loss: 0.2873\n",
      "[Iter 17200 Task dept] Train Loss: 0.0151\n",
      "[Iter 17200 Total] Train Loss: 0.1512\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Val Loss: 0.3118\n",
      "{'mIoU': 0.3954, 'Pixel Acc': 0.7429, 'cmp': -0.0109}\n",
      "[Iter 17200 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0177, 'rel_err': 0.3619, 'sigma_1.25': 70.6397, 'sigma_1.25^2': 86.2008, 'sigma_1.25^3': 92.9214, 'cmp': -0.0279}\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Train Loss: 0.2860\n",
      "[Iter 17400 Task dept] Train Loss: 0.0148\n",
      "[Iter 17400 Total] Train Loss: 0.1504\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Val Loss: 0.3110\n",
      "{'mIoU': 0.3954, 'Pixel Acc': 0.7419, 'cmp': -0.0116}\n",
      "[Iter 17400 Task dept] Val Loss: 0.0154\n",
      "{'abs_err': 0.0185, 'rel_err': 0.3328, 'sigma_1.25': 70.3032, 'sigma_1.25^2': 87.0803, 'sigma_1.25^3': 93.7706, 'cmp': -0.017}\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Train Loss: 0.2815\n",
      "[Iter 17600 Task dept] Train Loss: 0.0150\n",
      "[Iter 17600 Total] Train Loss: 0.1482\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Val Loss: 0.3204\n",
      "{'mIoU': 0.384, 'Pixel Acc': 0.7397, 'cmp': -0.0273}\n",
      "[Iter 17600 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0176, 'rel_err': 0.3314, 'sigma_1.25': 71.2608, 'sigma_1.25^2': 87.288, 'sigma_1.25^3': 93.8549, 'cmp': -0.0014}\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Train Loss: 0.2790\n",
      "[Iter 17800 Task dept] Train Loss: 0.0149\n",
      "[Iter 17800 Total] Train Loss: 0.1470\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Val Loss: 0.3762\n",
      "{'mIoU': 0.3719, 'Pixel Acc': 0.7251, 'cmp': -0.0521}\n",
      "[Iter 17800 Task dept] Val Loss: 0.0159\n",
      "{'abs_err': 0.0174, 'rel_err': 0.3455, 'sigma_1.25': 71.0277, 'sigma_1.25^2': 86.7418, 'sigma_1.25^3': 93.3836, 'cmp': -0.0114}\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Train Loss: 0.2841\n",
      "[Iter 18000 Task dept] Train Loss: 0.0150\n",
      "[Iter 18000 Total] Train Loss: 0.1495\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Val Loss: 0.3328\n",
      "{'mIoU': 0.384, 'Pixel Acc': 0.7371, 'cmp': -0.029}\n",
      "[Iter 18000 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0179, 'rel_err': 0.339, 'sigma_1.25': 71.2377, 'sigma_1.25^2': 87.1663, 'sigma_1.25^3': 93.7028, 'cmp': -0.0107}\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Train Loss: 0.2853\n",
      "[Iter 18200 Task dept] Train Loss: 0.0151\n",
      "[Iter 18200 Total] Train Loss: 0.1502\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Val Loss: 0.3074\n",
      "{'mIoU': 0.3992, 'Pixel Acc': 0.7441, 'cmp': -0.0053}\n",
      "[Iter 18200 Task dept] Val Loss: 0.0157\n",
      "{'abs_err': 0.0168, 'rel_err': 0.336, 'sigma_1.25': 72.1083, 'sigma_1.25^2': 87.3527, 'sigma_1.25^3': 93.7791, 'cmp': 0.0068}\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Train Loss: 0.2777\n",
      "[Iter 18400 Task dept] Train Loss: 0.0152\n",
      "[Iter 18400 Total] Train Loss: 0.1464\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Val Loss: 0.3249\n",
      "{'mIoU': 0.3786, 'Pixel Acc': 0.7388, 'cmp': -0.0346}\n",
      "[Iter 18400 Task dept] Val Loss: 0.0155\n",
      "{'abs_err': 0.0194, 'rel_err': 0.3247, 'sigma_1.25': 67.5297, 'sigma_1.25^2': 85.7219, 'sigma_1.25^3': 93.2452, 'cmp': -0.0344}\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Train Loss: 0.2850\n",
      "[Iter 18600 Task dept] Train Loss: 0.0148\n",
      "[Iter 18600 Total] Train Loss: 0.1499\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Val Loss: 0.3086\n",
      "{'mIoU': 0.3935, 'Pixel Acc': 0.7412, 'cmp': -0.0145}\n",
      "[Iter 18600 Task dept] Val Loss: 0.0156\n",
      "{'abs_err': 0.0194, 'rel_err': 0.3315, 'sigma_1.25': 69.7209, 'sigma_1.25^2': 87.1405, 'sigma_1.25^3': 93.8557, 'cmp': -0.0281}\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Train Loss: 0.2788\n",
      "[Iter 18800 Task dept] Train Loss: 0.0146\n",
      "[Iter 18800 Total] Train Loss: 0.1467\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Val Loss: 0.3131\n",
      "{'mIoU': 0.3922, 'Pixel Acc': 0.7435, 'cmp': -0.0145}\n",
      "[Iter 18800 Task dept] Val Loss: 0.0155\n",
      "{'abs_err': 0.0197, 'rel_err': 0.34, 'sigma_1.25': 70.1215, 'sigma_1.25^2': 87.2661, 'sigma_1.25^3': 93.8417, 'cmp': -0.035}\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Train Loss: 0.2873\n",
      "[Iter 19000 Task dept] Train Loss: 0.0150\n",
      "[Iter 19000 Total] Train Loss: 0.1512\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Val Loss: 0.3112\n",
      "{'mIoU': 0.3944, 'Pixel Acc': 0.7412, 'cmp': -0.0133}\n",
      "[Iter 19000 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0171, 'rel_err': 0.3224, 'sigma_1.25': 71.3721, 'sigma_1.25^2': 87.2073, 'sigma_1.25^3': 93.8392, 'cmp': 0.0097}\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Train Loss: 0.2808\n",
      "[Iter 19200 Task dept] Train Loss: 0.0148\n",
      "[Iter 19200 Total] Train Loss: 0.1478\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Val Loss: 0.3106\n",
      "{'mIoU': 0.394, 'Pixel Acc': 0.7445, 'cmp': -0.0116}\n",
      "[Iter 19200 Task dept] Val Loss: 0.0157\n",
      "{'abs_err': 0.0199, 'rel_err': 0.3284, 'sigma_1.25': 67.3615, 'sigma_1.25^2': 86.0472, 'sigma_1.25^3': 93.5182, 'cmp': -0.0412}\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Train Loss: 0.2814\n",
      "[Iter 19400 Task dept] Train Loss: 0.0149\n",
      "[Iter 19400 Total] Train Loss: 0.1482\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Val Loss: 0.3132\n",
      "{'mIoU': 0.3984, 'Pixel Acc': 0.7408, 'cmp': -0.0086}\n",
      "[Iter 19400 Task dept] Val Loss: 0.0151\n",
      "{'abs_err': 0.0179, 'rel_err': 0.3273, 'sigma_1.25': 70.5635, 'sigma_1.25^2': 87.1214, 'sigma_1.25^3': 93.8078, 'cmp': -0.0056}\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Train Loss: 0.2749\n",
      "[Iter 19600 Task dept] Train Loss: 0.0144\n",
      "[Iter 19600 Total] Train Loss: 0.1447\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Val Loss: 0.3078\n",
      "{'mIoU': 0.3869, 'Pixel Acc': 0.7426, 'cmp': -0.0218}\n",
      "[Iter 19600 Task dept] Val Loss: 0.0152\n",
      "{'abs_err': 0.0172, 'rel_err': 0.324, 'sigma_1.25': 70.9457, 'sigma_1.25^2': 86.9308, 'sigma_1.25^3': 93.7477, 'cmp': 0.0057}\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Train Loss: 0.2759\n",
      "[Iter 19800 Task dept] Train Loss: 0.0146\n",
      "[Iter 19800 Total] Train Loss: 0.1452\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Val Loss: 0.3083\n",
      "{'mIoU': 0.3963, 'Pixel Acc': 0.7436, 'cmp': -0.0094}\n",
      "[Iter 19800 Task dept] Val Loss: 0.0155\n",
      "{'abs_err': 0.0197, 'rel_err': 0.3284, 'sigma_1.25': 69.2376, 'sigma_1.25^2': 86.9695, 'sigma_1.25^3': 93.8035, 'cmp': -0.0317}\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Train Loss: 0.2776\n",
      "[Iter 20000 Task dept] Train Loss: 0.0149\n",
      "[Iter 20000 Total] Train Loss: 0.1462\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Val Loss: 0.3131\n",
      "{'mIoU': 0.4009, 'Pixel Acc': 0.7425, 'cmp': -0.0044}\n",
      "[Iter 20000 Task dept] Val Loss: 0.0156\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3448, 'sigma_1.25': 71.9993, 'sigma_1.25^2': 87.2402, 'sigma_1.25^3': 93.5801, 'cmp': -0.0035}\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 20200 Task segm] Train Loss: 0.2774\n",
      "[Iter 20200 Task dept] Train Loss: 0.0143\n",
      "[Iter 20200 Total] Train Loss: 0.1459\n",
      "======================================================================\n",
      "[Iter 20200 Task segm] Val Loss: 0.3209\n",
      "{'mIoU': 0.391, 'Pixel Acc': 0.7412, 'cmp': -0.0175}\n",
      "[Iter 20200 Task dept] Val Loss: 0.0152\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3244, 'sigma_1.25': 71.405, 'sigma_1.25^2': 87.3056, 'sigma_1.25^3': 93.8951, 'cmp': 0.0076}\n",
      "======================================================================\n",
      "[Iter 20400 Task segm] Train Loss: 0.2717\n",
      "[Iter 20400 Task dept] Train Loss: 0.0142\n",
      "[Iter 20400 Total] Train Loss: 0.1429\n",
      "======================================================================\n",
      "[Iter 20400 Task segm] Val Loss: 0.3005\n",
      "{'mIoU': 0.4071, 'Pixel Acc': 0.7448, 'cmp': 0.0049}\n",
      "[Iter 20400 Task dept] Val Loss: 0.0150\n",
      "{'abs_err': 0.0181, 'rel_err': 0.3225, 'sigma_1.25': 70.8828, 'sigma_1.25^2': 87.3007, 'sigma_1.25^3': 93.9023, 'cmp': -0.0031}\n",
      "======================================================================\n",
      "[Iter 20600 Task segm] Train Loss: 0.2649\n",
      "[Iter 20600 Task dept] Train Loss: 0.0145\n",
      "[Iter 20600 Total] Train Loss: 0.1397\n",
      "======================================================================\n",
      "[Iter 20600 Task segm] Val Loss: 0.3001\n",
      "{'mIoU': 0.404, 'Pixel Acc': 0.7437, 'cmp': 0.0004}\n",
      "[Iter 20600 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0179, 'rel_err': 0.3321, 'sigma_1.25': 71.8903, 'sigma_1.25^2': 87.4326, 'sigma_1.25^3': 93.8263, 'cmp': -0.0035}\n",
      "======================================================================\n",
      "[Iter 20800 Task segm] Train Loss: 0.2722\n",
      "[Iter 20800 Task dept] Train Loss: 0.0144\n",
      "[Iter 20800 Total] Train Loss: 0.1433\n",
      "======================================================================\n",
      "[Iter 20800 Task segm] Val Loss: 0.3041\n",
      "{'mIoU': 0.3985, 'Pixel Acc': 0.7431, 'cmp': -0.007}\n",
      "[Iter 20800 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0182, 'rel_err': 0.3321, 'sigma_1.25': 71.2905, 'sigma_1.25^2': 87.3918, 'sigma_1.25^3': 93.8266, 'cmp': -0.0092}\n",
      "======================================================================\n",
      "[Iter 21000 Task segm] Train Loss: 0.2679\n",
      "[Iter 21000 Task dept] Train Loss: 0.0143\n",
      "[Iter 21000 Total] Train Loss: 0.1411\n",
      "======================================================================\n",
      "[Iter 21000 Task segm] Val Loss: 0.3045\n",
      "{'mIoU': 0.4012, 'Pixel Acc': 0.7425, 'cmp': -0.0039}\n",
      "[Iter 21000 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0178, 'rel_err': 0.324, 'sigma_1.25': 70.8748, 'sigma_1.25^2': 87.2125, 'sigma_1.25^3': 93.8554, 'cmp': -0.0008}\n",
      "======================================================================\n",
      "[Iter 21200 Task segm] Train Loss: 0.2690\n",
      "[Iter 21200 Task dept] Train Loss: 0.0141\n",
      "[Iter 21200 Total] Train Loss: 0.1416\n",
      "======================================================================\n",
      "[Iter 21200 Task segm] Val Loss: 0.3012\n",
      "{'mIoU': 0.4051, 'Pixel Acc': 0.7455, 'cmp': 0.0029}\n",
      "[Iter 21200 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0176, 'rel_err': 0.3386, 'sigma_1.25': 72.0541, 'sigma_1.25^2': 87.4336, 'sigma_1.25^3': 93.8177, 'cmp': -0.0039}\n",
      "======================================================================\n",
      "[Iter 21400 Task segm] Train Loss: 0.2666\n",
      "[Iter 21400 Task dept] Train Loss: 0.0143\n",
      "[Iter 21400 Total] Train Loss: 0.1404\n",
      "======================================================================\n",
      "[Iter 21400 Task segm] Val Loss: 0.3002\n",
      "{'mIoU': 0.4045, 'Pixel Acc': 0.7447, 'cmp': 0.0015}\n",
      "[Iter 21400 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0182, 'rel_err': 0.3264, 'sigma_1.25': 70.3548, 'sigma_1.25^2': 86.9374, 'sigma_1.25^3': 93.7565, 'cmp': -0.009}\n",
      "======================================================================\n",
      "[Iter 21600 Task segm] Train Loss: 0.2642\n",
      "[Iter 21600 Task dept] Train Loss: 0.0143\n",
      "[Iter 21600 Total] Train Loss: 0.1393\n",
      "======================================================================\n",
      "[Iter 21600 Task segm] Val Loss: 0.3030\n",
      "{'mIoU': 0.4045, 'Pixel Acc': 0.7445, 'cmp': 0.0014}\n",
      "[Iter 21600 Task dept] Val Loss: 0.0161\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3518, 'sigma_1.25': 72.136, 'sigma_1.25^2': 87.244, 'sigma_1.25^3': 93.6099, 'cmp': -0.0035}\n",
      "======================================================================\n",
      "[Iter 21800 Task segm] Train Loss: 0.2643\n",
      "[Iter 21800 Task dept] Train Loss: 0.0142\n",
      "[Iter 21800 Total] Train Loss: 0.1392\n",
      "======================================================================\n",
      "[Iter 21800 Task segm] Val Loss: 0.3027\n",
      "{'mIoU': 0.4031, 'Pixel Acc': 0.7446, 'cmp': -0.0003}\n",
      "[Iter 21800 Task dept] Val Loss: 0.0150\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3296, 'sigma_1.25': 72.0617, 'sigma_1.25^2': 87.5782, 'sigma_1.25^3': 93.9049, 'cmp': 0.0066}\n",
      "======================================================================\n",
      "[Iter 22000 Task segm] Train Loss: 0.2739\n",
      "[Iter 22000 Task dept] Train Loss: 0.0141\n",
      "[Iter 22000 Total] Train Loss: 0.1440\n",
      "======================================================================\n",
      "[Iter 22000 Task segm] Val Loss: 0.2986\n",
      "{'mIoU': 0.4052, 'Pixel Acc': 0.7444, 'cmp': 0.0023}\n",
      "[Iter 22000 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.018, 'rel_err': 0.3235, 'sigma_1.25': 71.1871, 'sigma_1.25^2': 87.4138, 'sigma_1.25^3': 93.8894, 'cmp': -0.0012}\n",
      "======================================================================\n",
      "[Iter 22200 Task segm] Train Loss: 0.2700\n",
      "[Iter 22200 Task dept] Train Loss: 0.0143\n",
      "[Iter 22200 Total] Train Loss: 0.1422\n",
      "======================================================================\n",
      "[Iter 22200 Task segm] Val Loss: 0.2964\n",
      "{'mIoU': 0.4103, 'Pixel Acc': 0.7453, 'cmp': 0.0092}\n",
      "[Iter 22200 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0175, 'rel_err': 0.3543, 'sigma_1.25': 71.1585, 'sigma_1.25^2': 86.7403, 'sigma_1.25^3': 93.3676, 'cmp': -0.0172}\n",
      "======================================================================\n",
      "[Iter 22400 Task segm] Train Loss: 0.2669\n",
      "[Iter 22400 Task dept] Train Loss: 0.0142\n",
      "[Iter 22400 Total] Train Loss: 0.1405\n",
      "======================================================================\n",
      "[Iter 22400 Task segm] Val Loss: 0.2954\n",
      "{'mIoU': 0.4141, 'Pixel Acc': 0.7461, 'cmp': 0.0144}\n",
      "[Iter 22400 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0178, 'rel_err': 0.3274, 'sigma_1.25': 71.3286, 'sigma_1.25^2': 87.421, 'sigma_1.25^3': 93.9508, 'cmp': -0.0009}\n",
      "======================================================================\n",
      "[Iter 22600 Task segm] Train Loss: 0.2704\n",
      "[Iter 22600 Task dept] Train Loss: 0.0146\n",
      "[Iter 22600 Total] Train Loss: 0.1425\n",
      "======================================================================\n",
      "[Iter 22600 Task segm] Val Loss: 0.3088\n",
      "{'mIoU': 0.4061, 'Pixel Acc': 0.741, 'cmp': 0.0011}\n",
      "[Iter 22600 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0182, 'rel_err': 0.328, 'sigma_1.25': 70.721, 'sigma_1.25^2': 87.3262, 'sigma_1.25^3': 93.9402, 'cmp': -0.0083}\n",
      "======================================================================\n",
      "[Iter 22800 Task segm] Train Loss: 0.2669\n",
      "[Iter 22800 Task dept] Train Loss: 0.0140\n",
      "[Iter 22800 Total] Train Loss: 0.1405\n",
      "======================================================================\n",
      "[Iter 22800 Task segm] Val Loss: 0.3068\n",
      "{'mIoU': 0.4034, 'Pixel Acc': 0.7425, 'cmp': -0.0012}\n",
      "[Iter 22800 Task dept] Val Loss: 0.0150\n",
      "{'abs_err': 0.0171, 'rel_err': 0.3364, 'sigma_1.25': 72.0893, 'sigma_1.25^2': 87.5558, 'sigma_1.25^3': 93.7892, 'cmp': 0.0036}\n",
      "======================================================================\n",
      "[Iter 23000 Task segm] Train Loss: 0.2627\n",
      "[Iter 23000 Task dept] Train Loss: 0.0138\n",
      "[Iter 23000 Total] Train Loss: 0.1382\n",
      "======================================================================\n",
      "[Iter 23000 Task segm] Val Loss: 0.2984\n",
      "{'mIoU': 0.4063, 'Pixel Acc': 0.7438, 'cmp': 0.0032}\n",
      "[Iter 23000 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.018, 'rel_err': 0.3293, 'sigma_1.25': 70.8796, 'sigma_1.25^2': 87.4107, 'sigma_1.25^3': 93.9322, 'cmp': -0.0061}\n",
      "======================================================================\n",
      "[Iter 23200 Task segm] Train Loss: 0.2705\n",
      "[Iter 23200 Task dept] Train Loss: 0.0143\n",
      "[Iter 23200 Total] Train Loss: 0.1424\n",
      "======================================================================\n",
      "[Iter 23200 Task segm] Val Loss: 0.2981\n",
      "{'mIoU': 0.408, 'Pixel Acc': 0.7461, 'cmp': 0.0069}\n",
      "[Iter 23200 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3465, 'sigma_1.25': 71.9611, 'sigma_1.25^2': 87.2019, 'sigma_1.25^3': 93.5452, 'cmp': -0.0048}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 23400 Task segm] Train Loss: 0.2709\n",
      "[Iter 23400 Task dept] Train Loss: 0.0140\n",
      "[Iter 23400 Total] Train Loss: 0.1425\n",
      "======================================================================\n",
      "[Iter 23400 Task segm] Val Loss: 0.3016\n",
      "{'mIoU': 0.4026, 'Pixel Acc': 0.744, 'cmp': -0.0013}\n",
      "[Iter 23400 Task dept] Val Loss: 0.0153\n",
      "{'abs_err': 0.0174, 'rel_err': 0.3593, 'sigma_1.25': 71.8721, 'sigma_1.25^2': 87.0133, 'sigma_1.25^3': 93.398, 'cmp': -0.0164}\n",
      "======================================================================\n",
      "[Iter 23600 Task segm] Train Loss: 0.2705\n",
      "[Iter 23600 Task dept] Train Loss: 0.0142\n",
      "[Iter 23600 Total] Train Loss: 0.1423\n",
      "======================================================================\n",
      "[Iter 23600 Task segm] Val Loss: 0.3032\n",
      "{'mIoU': 0.4004, 'Pixel Acc': 0.7443, 'cmp': -0.0038}\n",
      "[Iter 23600 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0173, 'rel_err': 0.3287, 'sigma_1.25': 71.6989, 'sigma_1.25^2': 87.5908, 'sigma_1.25^3': 93.9947, 'cmp': 0.0053}\n",
      "======================================================================\n",
      "[Iter 23800 Task segm] Train Loss: 0.2617\n",
      "[Iter 23800 Task dept] Train Loss: 0.0139\n",
      "[Iter 23800 Total] Train Loss: 0.1378\n",
      "======================================================================\n",
      "[Iter 23800 Task segm] Val Loss: 0.2967\n",
      "{'mIoU': 0.4081, 'Pixel Acc': 0.7455, 'cmp': 0.0066}\n",
      "[Iter 23800 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0184, 'rel_err': 0.3294, 'sigma_1.25': 69.4777, 'sigma_1.25^2': 86.6227, 'sigma_1.25^3': 93.6377, 'cmp': -0.0168}\n",
      "======================================================================\n",
      "[Iter 24000 Task segm] Train Loss: 0.2625\n",
      "[Iter 24000 Task dept] Train Loss: 0.0141\n",
      "[Iter 24000 Total] Train Loss: 0.1383\n",
      "======================================================================\n",
      "[Iter 24000 Task segm] Val Loss: 0.2967\n",
      "{'mIoU': 0.4062, 'Pixel Acc': 0.7462, 'cmp': 0.0047}\n",
      "[Iter 24000 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0175, 'rel_err': 0.3215, 'sigma_1.25': 70.5176, 'sigma_1.25^2': 87.0473, 'sigma_1.25^3': 93.8763, 'cmp': 0.0034}\n",
      "======================================================================\n",
      "[Iter 24200 Task segm] Train Loss: 0.2601\n",
      "[Iter 24200 Task dept] Train Loss: 0.0139\n",
      "[Iter 24200 Total] Train Loss: 0.1370\n",
      "======================================================================\n",
      "[Iter 24200 Task segm] Val Loss: 0.2977\n",
      "{'mIoU': 0.4051, 'Pixel Acc': 0.7459, 'cmp': 0.0032}\n",
      "[Iter 24200 Task dept] Val Loss: 0.0151\n",
      "{'abs_err': 0.0171, 'rel_err': 0.3369, 'sigma_1.25': 72.0138, 'sigma_1.25^2': 87.4989, 'sigma_1.25^3': 93.8431, 'cmp': 0.0029}\n",
      "======================================================================\n",
      "[Iter 24400 Task segm] Train Loss: 0.2574\n",
      "[Iter 24400 Task dept] Train Loss: 0.0140\n",
      "[Iter 24400 Total] Train Loss: 0.1357\n",
      "======================================================================\n",
      "[Iter 24400 Task segm] Val Loss: 0.3043\n",
      "{'mIoU': 0.4021, 'Pixel Acc': 0.7433, 'cmp': -0.0023}\n",
      "[Iter 24400 Task dept] Val Loss: 0.0151\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3301, 'sigma_1.25': 72.1912, 'sigma_1.25^2': 87.7077, 'sigma_1.25^3': 93.9823, 'cmp': 0.0109}\n",
      "======================================================================\n",
      "[Iter 24600 Task segm] Train Loss: 0.2611\n",
      "[Iter 24600 Task dept] Train Loss: 0.0139\n",
      "[Iter 24600 Total] Train Loss: 0.1375\n",
      "======================================================================\n",
      "[Iter 24600 Task segm] Val Loss: 0.2958\n",
      "{'mIoU': 0.4101, 'Pixel Acc': 0.7464, 'cmp': 0.0096}\n",
      "[Iter 24600 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0178, 'rel_err': 0.3319, 'sigma_1.25': 71.6114, 'sigma_1.25^2': 87.5156, 'sigma_1.25^3': 93.9496, 'cmp': -0.0026}\n",
      "======================================================================\n",
      "[Iter 24800 Task segm] Train Loss: 0.2662\n",
      "[Iter 24800 Task dept] Train Loss: 0.0139\n",
      "[Iter 24800 Total] Train Loss: 0.1401\n",
      "======================================================================\n",
      "[Iter 24800 Task segm] Val Loss: 0.2904\n",
      "{'mIoU': 0.4111, 'Pixel Acc': 0.7464, 'cmp': 0.0108}\n",
      "[Iter 24800 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3235, 'sigma_1.25': 71.7548, 'sigma_1.25^2': 87.5933, 'sigma_1.25^3': 94.0332, 'cmp': 0.0103}\n",
      "======================================================================\n",
      "[Iter 25000 Task segm] Train Loss: 0.2577\n",
      "[Iter 25000 Task dept] Train Loss: 0.0138\n",
      "[Iter 25000 Total] Train Loss: 0.1358\n",
      "======================================================================\n",
      "[Iter 25000 Task segm] Val Loss: 0.2975\n",
      "{'mIoU': 0.4102, 'Pixel Acc': 0.7463, 'cmp': 0.0097}\n",
      "[Iter 25000 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3314, 'sigma_1.25': 72.227, 'sigma_1.25^2': 87.69, 'sigma_1.25^3': 93.9875, 'cmp': 0.0102}\n",
      "======================================================================\n",
      "[Iter 25200 Task segm] Train Loss: 0.2575\n",
      "[Iter 25200 Task dept] Train Loss: 0.0137\n",
      "[Iter 25200 Total] Train Loss: 0.1356\n",
      "======================================================================\n",
      "[Iter 25200 Task segm] Val Loss: 0.2946\n",
      "{'mIoU': 0.4082, 'Pixel Acc': 0.7461, 'cmp': 0.0071}\n",
      "[Iter 25200 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3373, 'sigma_1.25': 72.5777, 'sigma_1.25^2': 87.7276, 'sigma_1.25^3': 93.9174, 'cmp': 0.0077}\n",
      "======================================================================\n",
      "[Iter 25400 Task segm] Train Loss: 0.2650\n",
      "[Iter 25400 Task dept] Train Loss: 0.0139\n",
      "[Iter 25400 Total] Train Loss: 0.1394\n",
      "======================================================================\n",
      "[Iter 25400 Task segm] Val Loss: 0.2966\n",
      "{'mIoU': 0.412, 'Pixel Acc': 0.7461, 'cmp': 0.0119}\n",
      "[Iter 25400 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0173, 'rel_err': 0.3298, 'sigma_1.25': 72.1516, 'sigma_1.25^2': 87.7891, 'sigma_1.25^3': 94.0549, 'cmp': 0.0065}\n",
      "======================================================================\n",
      "[Iter 25600 Task segm] Train Loss: 0.2600\n",
      "[Iter 25600 Task dept] Train Loss: 0.0139\n",
      "[Iter 25600 Total] Train Loss: 0.1369\n",
      "======================================================================\n",
      "[Iter 25600 Task segm] Val Loss: 0.2903\n",
      "{'mIoU': 0.4138, 'Pixel Acc': 0.7468, 'cmp': 0.0145}\n",
      "[Iter 25600 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0175, 'rel_err': 0.3285, 'sigma_1.25': 72.2286, 'sigma_1.25^2': 87.771, 'sigma_1.25^3': 94.0658, 'cmp': 0.005}\n",
      "======================================================================\n",
      "[Iter 25800 Task segm] Train Loss: 0.2657\n",
      "[Iter 25800 Task dept] Train Loss: 0.0135\n",
      "[Iter 25800 Total] Train Loss: 0.1396\n",
      "======================================================================\n",
      "[Iter 25800 Task segm] Val Loss: 0.2932\n",
      "{'mIoU': 0.4147, 'Pixel Acc': 0.7462, 'cmp': 0.0153}\n",
      "[Iter 25800 Task dept] Val Loss: 0.0151\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3416, 'sigma_1.25': 72.452, 'sigma_1.25^2': 87.5727, 'sigma_1.25^3': 93.7998, 'cmp': 0.0049}\n",
      "======================================================================\n",
      "[Iter 26000 Task segm] Train Loss: 0.2561\n",
      "[Iter 26000 Task dept] Train Loss: 0.0136\n",
      "[Iter 26000 Total] Train Loss: 0.1349\n",
      "======================================================================\n",
      "[Iter 26000 Task segm] Val Loss: 0.2927\n",
      "{'mIoU': 0.4159, 'Pixel Acc': 0.7468, 'cmp': 0.0171}\n",
      "[Iter 26000 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0173, 'rel_err': 0.3175, 'sigma_1.25': 71.6472, 'sigma_1.25^2': 87.6697, 'sigma_1.25^3': 94.0852, 'cmp': 0.0126}\n",
      "======================================================================\n",
      "[Iter 26200 Task segm] Train Loss: 0.2585\n",
      "[Iter 26200 Task dept] Train Loss: 0.0140\n",
      "[Iter 26200 Total] Train Loss: 0.1362\n",
      "======================================================================\n",
      "[Iter 26200 Task segm] Val Loss: 0.2956\n",
      "{'mIoU': 0.4137, 'Pixel Acc': 0.7467, 'cmp': 0.0144}\n",
      "[Iter 26200 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0177, 'rel_err': 0.3268, 'sigma_1.25': 71.5668, 'sigma_1.25^2': 87.5355, 'sigma_1.25^3': 94.0462, 'cmp': 0.0019}\n",
      "======================================================================\n",
      "[Iter 26400 Task segm] Train Loss: 0.2557\n",
      "[Iter 26400 Task dept] Train Loss: 0.0136\n",
      "[Iter 26400 Total] Train Loss: 0.1346\n",
      "======================================================================\n",
      "[Iter 26400 Task segm] Val Loss: 0.2962\n",
      "{'mIoU': 0.4108, 'Pixel Acc': 0.7465, 'cmp': 0.0107}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 26400 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0168, 'rel_err': 0.328, 'sigma_1.25': 72.2981, 'sigma_1.25^2': 87.7133, 'sigma_1.25^3': 94.0375, 'cmp': 0.0141}\n",
      "======================================================================\n",
      "[Iter 26600 Task segm] Train Loss: 0.2590\n",
      "[Iter 26600 Task dept] Train Loss: 0.0139\n",
      "[Iter 26600 Total] Train Loss: 0.1365\n",
      "======================================================================\n",
      "[Iter 26600 Task segm] Val Loss: 0.2960\n",
      "{'mIoU': 0.4117, 'Pixel Acc': 0.7458, 'cmp': 0.0113}\n",
      "[Iter 26600 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0168, 'rel_err': 0.3258, 'sigma_1.25': 72.4375, 'sigma_1.25^2': 87.7548, 'sigma_1.25^3': 94.045, 'cmp': 0.0155}\n",
      "======================================================================\n",
      "[Iter 26800 Task segm] Train Loss: 0.2582\n",
      "[Iter 26800 Task dept] Train Loss: 0.0137\n",
      "[Iter 26800 Total] Train Loss: 0.1359\n",
      "======================================================================\n",
      "[Iter 26800 Task segm] Val Loss: 0.2939\n",
      "{'mIoU': 0.4073, 'Pixel Acc': 0.7448, 'cmp': 0.0051}\n",
      "[Iter 26800 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0171, 'rel_err': 0.3301, 'sigma_1.25': 72.4705, 'sigma_1.25^2': 87.7753, 'sigma_1.25^3': 94.039, 'cmp': 0.0103}\n",
      "======================================================================\n",
      "[Iter 27000 Task segm] Train Loss: 0.2598\n",
      "[Iter 27000 Task dept] Train Loss: 0.0138\n",
      "[Iter 27000 Total] Train Loss: 0.1368\n",
      "======================================================================\n",
      "[Iter 27000 Task segm] Val Loss: 0.2957\n",
      "{'mIoU': 0.4082, 'Pixel Acc': 0.7448, 'cmp': 0.0063}\n",
      "[Iter 27000 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0177, 'rel_err': 0.3336, 'sigma_1.25': 71.8331, 'sigma_1.25^2': 87.5735, 'sigma_1.25^3': 93.9052, 'cmp': -0.0019}\n",
      "======================================================================\n",
      "[Iter 27200 Task segm] Train Loss: 0.2595\n",
      "[Iter 27200 Task dept] Train Loss: 0.0138\n",
      "[Iter 27200 Total] Train Loss: 0.1367\n",
      "======================================================================\n",
      "[Iter 27200 Task segm] Val Loss: 0.2911\n",
      "{'mIoU': 0.4118, 'Pixel Acc': 0.7456, 'cmp': 0.0113}\n",
      "[Iter 27200 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.018, 'rel_err': 0.3335, 'sigma_1.25': 71.9603, 'sigma_1.25^2': 87.7614, 'sigma_1.25^3': 94.0051, 'cmp': -0.004}\n",
      "======================================================================\n",
      "[Iter 27400 Task segm] Train Loss: 0.2614\n",
      "[Iter 27400 Task dept] Train Loss: 0.0138\n",
      "[Iter 27400 Total] Train Loss: 0.1376\n",
      "======================================================================\n",
      "[Iter 27400 Task segm] Val Loss: 0.2960\n",
      "{'mIoU': 0.413, 'Pixel Acc': 0.7462, 'cmp': 0.0131}\n",
      "[Iter 27400 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.017, 'rel_err': 0.3296, 'sigma_1.25': 72.2039, 'sigma_1.25^2': 87.6184, 'sigma_1.25^3': 93.9313, 'cmp': 0.0099}\n",
      "======================================================================\n",
      "[Iter 27600 Task segm] Train Loss: 0.2568\n",
      "[Iter 27600 Task dept] Train Loss: 0.0135\n",
      "[Iter 27600 Total] Train Loss: 0.1351\n",
      "======================================================================\n",
      "[Iter 27600 Task segm] Val Loss: 0.2925\n",
      "{'mIoU': 0.4139, 'Pixel Acc': 0.746, 'cmp': 0.0142}\n",
      "[Iter 27600 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0173, 'rel_err': 0.3344, 'sigma_1.25': 72.3352, 'sigma_1.25^2': 87.7023, 'sigma_1.25^3': 93.9686, 'cmp': 0.0047}\n",
      "======================================================================\n",
      "[Iter 27800 Task segm] Train Loss: 0.2546\n",
      "[Iter 27800 Task dept] Train Loss: 0.0136\n",
      "[Iter 27800 Total] Train Loss: 0.1341\n",
      "======================================================================\n",
      "[Iter 27800 Task segm] Val Loss: 0.2909\n",
      "{'mIoU': 0.4147, 'Pixel Acc': 0.7464, 'cmp': 0.0154}\n",
      "[Iter 27800 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3274, 'sigma_1.25': 72.6229, 'sigma_1.25^2': 87.8768, 'sigma_1.25^3': 94.076, 'cmp': 0.0143}\n",
      "======================================================================\n",
      "[Iter 28000 Task segm] Train Loss: 0.2576\n",
      "[Iter 28000 Task dept] Train Loss: 0.0141\n",
      "[Iter 28000 Total] Train Loss: 0.1358\n",
      "======================================================================\n",
      "[Iter 28000 Task segm] Val Loss: 0.2939\n",
      "{'mIoU': 0.4154, 'Pixel Acc': 0.7464, 'cmp': 0.0163}\n",
      "[Iter 28000 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3336, 'sigma_1.25': 72.2055, 'sigma_1.25^2': 87.7113, 'sigma_1.25^3': 93.9851, 'cmp': 0.0061}\n",
      "======================================================================\n",
      "[Iter 28200 Task segm] Train Loss: 0.2541\n",
      "[Iter 28200 Task dept] Train Loss: 0.0136\n",
      "[Iter 28200 Total] Train Loss: 0.1338\n",
      "======================================================================\n",
      "[Iter 28200 Task segm] Val Loss: 0.2938\n",
      "{'mIoU': 0.4155, 'Pixel Acc': 0.7468, 'cmp': 0.0166}\n",
      "[Iter 28200 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.017, 'rel_err': 0.3314, 'sigma_1.25': 72.3204, 'sigma_1.25^2': 87.7643, 'sigma_1.25^3': 94.0357, 'cmp': 0.0099}\n",
      "======================================================================\n",
      "[Iter 28400 Task segm] Train Loss: 0.2543\n",
      "[Iter 28400 Task dept] Train Loss: 0.0137\n",
      "[Iter 28400 Total] Train Loss: 0.1340\n",
      "======================================================================\n",
      "[Iter 28400 Task segm] Val Loss: 0.2956\n",
      "{'mIoU': 0.4179, 'Pixel Acc': 0.7471, 'cmp': 0.0198}\n",
      "[Iter 28400 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.017, 'rel_err': 0.3278, 'sigma_1.25': 72.2973, 'sigma_1.25^2': 87.6772, 'sigma_1.25^3': 93.9782, 'cmp': 0.0117}\n",
      "======================================================================\n",
      "[Iter 28600 Task segm] Train Loss: 0.2511\n",
      "[Iter 28600 Task dept] Train Loss: 0.0136\n",
      "[Iter 28600 Total] Train Loss: 0.1323\n",
      "======================================================================\n",
      "[Iter 28600 Task segm] Val Loss: 0.2924\n",
      "{'mIoU': 0.4138, 'Pixel Acc': 0.7465, 'cmp': 0.0143}\n",
      "[Iter 28600 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3363, 'sigma_1.25': 72.3978, 'sigma_1.25^2': 87.6217, 'sigma_1.25^3': 93.9114, 'cmp': 0.0077}\n",
      "======================================================================\n",
      "[Iter 28800 Task segm] Train Loss: 0.2496\n",
      "[Iter 28800 Task dept] Train Loss: 0.0134\n",
      "[Iter 28800 Total] Train Loss: 0.1315\n",
      "======================================================================\n",
      "[Iter 28800 Task segm] Val Loss: 0.2919\n",
      "{'mIoU': 0.417, 'Pixel Acc': 0.7464, 'cmp': 0.0183}\n",
      "[Iter 28800 Task dept] Val Loss: 0.0145\n",
      "{'abs_err': 0.0172, 'rel_err': 0.3327, 'sigma_1.25': 72.506, 'sigma_1.25^2': 87.7959, 'sigma_1.25^3': 94.006, 'cmp': 0.007}\n",
      "======================================================================\n",
      "[Iter 29000 Task segm] Train Loss: 0.2480\n",
      "[Iter 29000 Task dept] Train Loss: 0.0134\n",
      "[Iter 29000 Total] Train Loss: 0.1307\n",
      "======================================================================\n",
      "[Iter 29000 Task segm] Val Loss: 0.2919\n",
      "{'mIoU': 0.4163, 'Pixel Acc': 0.7471, 'cmp': 0.0179}\n",
      "[Iter 29000 Task dept] Val Loss: 0.0149\n",
      "{'abs_err': 0.0168, 'rel_err': 0.3308, 'sigma_1.25': 72.5943, 'sigma_1.25^2': 87.8085, 'sigma_1.25^3': 94.0299, 'cmp': 0.0138}\n",
      "======================================================================\n",
      "[Iter 29200 Task segm] Train Loss: 0.2551\n",
      "[Iter 29200 Task dept] Train Loss: 0.0137\n",
      "[Iter 29200 Total] Train Loss: 0.1344\n",
      "======================================================================\n",
      "[Iter 29200 Task segm] Val Loss: 0.2929\n",
      "{'mIoU': 0.4169, 'Pixel Acc': 0.747, 'cmp': 0.0185}\n",
      "[Iter 29200 Task dept] Val Loss: 0.0146\n",
      "{'abs_err': 0.017, 'rel_err': 0.3288, 'sigma_1.25': 72.4193, 'sigma_1.25^2': 87.8424, 'sigma_1.25^3': 94.0893, 'cmp': 0.0126}\n",
      "======================================================================\n",
      "[Iter 29400 Task segm] Train Loss: 0.2479\n",
      "[Iter 29400 Task dept] Train Loss: 0.0135\n",
      "[Iter 29400 Total] Train Loss: 0.1307\n",
      "======================================================================\n",
      "[Iter 29400 Task segm] Val Loss: 0.2896\n",
      "{'mIoU': 0.4145, 'Pixel Acc': 0.7461, 'cmp': 0.0149}\n",
      "[Iter 29400 Task dept] Val Loss: 0.0147\n",
      "{'abs_err': 0.0167, 'rel_err': 0.3321, 'sigma_1.25': 72.5499, 'sigma_1.25^2': 87.795, 'sigma_1.25^3': 94.0299, 'cmp': 0.0132}\n",
      "======================================================================\n",
      "[Iter 29600 Task segm] Train Loss: 0.2584\n",
      "[Iter 29600 Task dept] Train Loss: 0.0136\n",
      "[Iter 29600 Total] Train Loss: 0.1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 29600 Task segm] Val Loss: 0.2911\n",
      "{'mIoU': 0.4147, 'Pixel Acc': 0.7456, 'cmp': 0.0148}\n",
      "[Iter 29600 Task dept] Val Loss: 0.0150\n",
      "{'abs_err': 0.0167, 'rel_err': 0.3358, 'sigma_1.25': 72.4893, 'sigma_1.25^2': 87.6918, 'sigma_1.25^3': 93.9269, 'cmp': 0.0105}\n",
      "======================================================================\n",
      "[Iter 29800 Task segm] Train Loss: 0.2568\n",
      "[Iter 29800 Task dept] Train Loss: 0.0137\n",
      "[Iter 29800 Total] Train Loss: 0.1353\n",
      "======================================================================\n",
      "[Iter 29800 Task segm] Val Loss: 0.2883\n",
      "{'mIoU': 0.4161, 'Pixel Acc': 0.7462, 'cmp': 0.017}\n",
      "[Iter 29800 Task dept] Val Loss: 0.0148\n",
      "{'abs_err': 0.0169, 'rel_err': 0.3338, 'sigma_1.25': 72.7076, 'sigma_1.25^2': 87.8595, 'sigma_1.25^3': 94.0141, 'cmp': 0.0114}\n",
      "======================================================================\n",
      "[Iter 30000 Task segm] Train Loss: 0.2521\n",
      "[Iter 30000 Task dept] Train Loss: 0.0136\n",
      "[Iter 30000 Total] Train Loss: 0.1328\n",
      "======================================================================\n",
      "[Iter 30000 Task segm] Val Loss: 0.2968\n",
      "{'mIoU': 0.4168, 'Pixel Acc': 0.7466, 'cmp': 0.0181}\n",
      "[Iter 30000 Task dept] Val Loss: 0.0152\n",
      "{'abs_err': 0.0165, 'rel_err': 0.3322, 'sigma_1.25': 72.7433, 'sigma_1.25^2': 87.8028, 'sigma_1.25^3': 93.9861, 'cmp': 0.016}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer.post_train(iters=30000, task_iters=(100,100), lr=0.001,\n",
    "                   decay_lr_freq=4000, decay_lr_rate=0.5,\n",
    "                   savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-training/', reload='random_policy_with_bottom20_shared_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  )\n",
       "  (1): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (3): PoolNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): AbstractPool(\n",
       "      (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (5): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (6): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (7): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (8): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (9): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (10): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (11): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (12): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (13): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (14): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (15): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (16): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (17): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (18): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (19): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (20): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (21): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (22): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (23): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (24): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (25): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(1, 1), stride=(2, 2), padding=(0, 0))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(1, 1), stride=(2, 2), padding=(0, 0))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  )\n",
       "  (26): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (27): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): AvgPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (2): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (28): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (29): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (30): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (31): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (32): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (33): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (34): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (35): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (36): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (37): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (38): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (39): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (40): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (41): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (42): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (43): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (44): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (45): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (46): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (47): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (48): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (49): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (50): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (51): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (52): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (53): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (54): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (55): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (56): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (57): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (58): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (59): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (60): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (61): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (62): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (63): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (64): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (65): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (66): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (67): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (68): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (69): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (70): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (71): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (72): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (73): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (74): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (75): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (76): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (77): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (78): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (79): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (80): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (81): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (82): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (83): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (84): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (85): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (86): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (87): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (88): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (89): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (90): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (91): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (92): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (93): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (94): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (95): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (96): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (97): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (98): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (99): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (100): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (101): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (102): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (103): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (104): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (105): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (106): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (107): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (108): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (109): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (110): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (111): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (112): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (113): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (114): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       "  (115): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (116): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (117): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU(inplace=True)\n",
       "  )\n",
       "  (118): Conv2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (dsOp): ModuleDict(\n",
       "      (segment_semantic): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "      (depth_zbuffer): ModuleList(\n",
       "        (0): LazyLayer()\n",
       "      )\n",
       "    )\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  )\n",
       "  (119): BN2dNode(\n",
       "    (taskOp): ModuleDict(\n",
       "      (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict(\n",
       "        (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "        (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
       "    )\n",
       "    (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (120): EltNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): EltwiseOp(op=1)\n",
       "  )\n",
       "  (121): ReLUNode(\n",
       "    (taskOp): ModuleDict()\n",
       "    (dsOp): ModuleDict()\n",
       "    (policy): ParameterDict()\n",
       "    (basicOp): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL and Hard sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerBaselines(Trainer):\n",
    "    def __init__(self, model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters=50, val_iters=2000, save_iters=200, save_num=5, policy_update_iters=100):\n",
    "        super(TrainerBaselines, self).__init__(model, train_dataloader_dict, val_dataloader_dict, criterion_dict, metric_dict, \n",
    "                 print_iters, val_iters, save_iters,save_num, policy_update_iters)\n",
    "        \n",
    "    def stl_hard_sharing(self, iters, lr=0.001, decay_lr_freq=4000, decay_lr_rate=0.5, task=None, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        writer = None\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=0.0001)\n",
    "        start = 0\n",
    "        if reload is not None and savePath is not None:\n",
    "            state = torch.load(savePath + reload)\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            optimizer.load_state_dict(state['optimizer'])\n",
    "            start = state['iter'] + 1\n",
    "    \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_lr_freq, gamma=decay_lr_rate)\n",
    "        if task is None:\n",
    "            stage = 'hard_sharing'\n",
    "        else:\n",
    "            stage = 'task_specific'\n",
    "        \n",
    "        for i in range(start, iters):\n",
    "            if task is None:\n",
    "                self.train_step(stage, optimizer, scheduler)\n",
    "            else:\n",
    "                self.train_step_task(stage, task, optimizer, scheduler)\n",
    "\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss(i, writer)\n",
    "                self.reset_train_loss()\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                if task is None:\n",
    "                    self.validate(stage, i, writer=writer)\n",
    "                else:\n",
    "                    self.validate_task(stage, i, task, writer=writer)\n",
    "                \n",
    "                self.model.train()\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    state = {'iter': i,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict()}\n",
    "                    self.save_model(state, stage, savePath)\n",
    "\n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss_data_iter()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerBaselines(mtlmodel, trainDataloaderDict, valDataloaderDict, criterionDict, metricDict, \n",
    "                           val_iters=200, print_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 15100 Task segm] Train Loss: 0.3581\n",
      "[Iter 15100 Task dept] Train Loss: 0.0185\n",
      "[Iter 15100 Total] Train Loss: 0.1883\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Train Loss: 0.3678\n",
      "[Iter 15200 Task dept] Train Loss: 0.0185\n",
      "[Iter 15200 Total] Train Loss: 0.1931\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Val Loss: 0.3487\n",
      "{'mIoU': 0.2641, 'Pixel Acc': 0.6352, 'cmp': -0.2464}\n",
      "[Iter 15200 Task dept] Val Loss: 0.0222\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4903, 'sigma_1.25': 35.7539, 'sigma_1.25^2': 67.7806, 'sigma_1.25^3': 84.1385, 'cmp': -0.5369}\n",
      "======================================================================\n",
      "[Iter 15300 Task segm] Train Loss: 0.3498\n",
      "[Iter 15300 Task dept] Train Loss: 0.0188\n",
      "[Iter 15300 Total] Train Loss: 0.1843\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Train Loss: 0.3613\n",
      "[Iter 15400 Task dept] Train Loss: 0.0188\n",
      "[Iter 15400 Total] Train Loss: 0.1900\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Val Loss: 0.3480\n",
      "{'mIoU': 0.2669, 'Pixel Acc': 0.6362, 'cmp': -0.2423}\n",
      "[Iter 15400 Task dept] Val Loss: 0.0228\n",
      "{'abs_err': 0.0414, 'rel_err': 0.4757, 'sigma_1.25': 34.8103, 'sigma_1.25^2': 67.6426, 'sigma_1.25^3': 84.1337, 'cmp': -0.5396}\n",
      "======================================================================\n",
      "[Iter 15500 Task segm] Train Loss: 0.3549\n",
      "[Iter 15500 Task dept] Train Loss: 0.0187\n",
      "[Iter 15500 Total] Train Loss: 0.1868\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Train Loss: 0.3624\n",
      "[Iter 15600 Task dept] Train Loss: 0.0190\n",
      "[Iter 15600 Total] Train Loss: 0.1907\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Val Loss: 0.3456\n",
      "{'mIoU': 0.2663, 'Pixel Acc': 0.6359, 'cmp': -0.2432}\n",
      "[Iter 15600 Task dept] Val Loss: 0.0227\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4805, 'sigma_1.25': 35.676, 'sigma_1.25^2': 67.9678, 'sigma_1.25^3': 84.2429, 'cmp': -0.5332}\n",
      "======================================================================\n",
      "[Iter 15700 Task segm] Train Loss: 0.3510\n",
      "[Iter 15700 Task dept] Train Loss: 0.0186\n",
      "[Iter 15700 Total] Train Loss: 0.1848\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Train Loss: 0.3527\n",
      "[Iter 15800 Task dept] Train Loss: 0.0186\n",
      "[Iter 15800 Total] Train Loss: 0.1856\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Val Loss: 0.3433\n",
      "{'mIoU': 0.2657, 'Pixel Acc': 0.6354, 'cmp': -0.2442}\n",
      "[Iter 15800 Task dept] Val Loss: 0.0220\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4833, 'sigma_1.25': 36.4112, 'sigma_1.25^2': 68.5312, 'sigma_1.25^3': 84.6672, 'cmp': -0.5225}\n",
      "======================================================================\n",
      "[Iter 15900 Task segm] Train Loss: 0.3545\n",
      "[Iter 15900 Task dept] Train Loss: 0.0189\n",
      "[Iter 15900 Total] Train Loss: 0.1867\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Train Loss: 0.3564\n",
      "[Iter 16000 Task dept] Train Loss: 0.0187\n",
      "[Iter 16000 Total] Train Loss: 0.1875\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Val Loss: 0.3478\n",
      "{'mIoU': 0.2665, 'Pixel Acc': 0.6353, 'cmp': -0.2433}\n",
      "[Iter 16000 Task dept] Val Loss: 0.0238\n",
      "{'abs_err': 0.0422, 'rel_err': 0.4851, 'sigma_1.25': 33.8784, 'sigma_1.25^2': 66.6209, 'sigma_1.25^3': 83.9312, 'cmp': -0.5598}\n",
      "======================================================================\n",
      "[Iter 16100 Task segm] Train Loss: 0.3514\n",
      "[Iter 16100 Task dept] Train Loss: 0.0185\n",
      "[Iter 16100 Total] Train Loss: 0.1849\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Train Loss: 0.3597\n",
      "[Iter 16200 Task dept] Train Loss: 0.0186\n",
      "[Iter 16200 Total] Train Loss: 0.1891\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Val Loss: 0.3479\n",
      "{'mIoU': 0.2688, 'Pixel Acc': 0.6363, 'cmp': -0.2398}\n",
      "[Iter 16200 Task dept] Val Loss: 0.0219\n",
      "{'abs_err': 0.04, 'rel_err': 0.476, 'sigma_1.25': 36.7608, 'sigma_1.25^2': 68.7641, 'sigma_1.25^3': 84.7148, 'cmp': -0.5138}\n",
      "======================================================================\n",
      "[Iter 16300 Task segm] Train Loss: 0.3423\n",
      "[Iter 16300 Task dept] Train Loss: 0.0186\n",
      "[Iter 16300 Total] Train Loss: 0.1805\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Train Loss: 0.3536\n",
      "[Iter 16400 Task dept] Train Loss: 0.0185\n",
      "[Iter 16400 Total] Train Loss: 0.1861\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Val Loss: 0.3465\n",
      "{'mIoU': 0.2661, 'Pixel Acc': 0.6367, 'cmp': -0.2429}\n",
      "[Iter 16400 Task dept] Val Loss: 0.0225\n",
      "{'abs_err': 0.0411, 'rel_err': 0.4895, 'sigma_1.25': 35.2084, 'sigma_1.25^2': 67.4262, 'sigma_1.25^3': 84.07, 'cmp': -0.5431}\n",
      "======================================================================\n",
      "[Iter 16500 Task segm] Train Loss: 0.3577\n",
      "[Iter 16500 Task dept] Train Loss: 0.0189\n",
      "[Iter 16500 Total] Train Loss: 0.1883\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Train Loss: 0.3491\n",
      "[Iter 16600 Task dept] Train Loss: 0.0186\n",
      "[Iter 16600 Total] Train Loss: 0.1838\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Val Loss: 0.3448\n",
      "{'mIoU': 0.2669, 'Pixel Acc': 0.6355, 'cmp': -0.2427}\n",
      "[Iter 16600 Task dept] Val Loss: 0.0218\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4837, 'sigma_1.25': 36.1695, 'sigma_1.25^2': 67.899, 'sigma_1.25^3': 84.1806, 'cmp': -0.5275}\n",
      "======================================================================\n",
      "[Iter 16700 Task segm] Train Loss: 0.3572\n",
      "[Iter 16700 Task dept] Train Loss: 0.0179\n",
      "[Iter 16700 Total] Train Loss: 0.1876\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Train Loss: 0.3566\n",
      "[Iter 16800 Task dept] Train Loss: 0.0185\n",
      "[Iter 16800 Total] Train Loss: 0.1875\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Val Loss: 0.3479\n",
      "{'mIoU': 0.2692, 'Pixel Acc': 0.6364, 'cmp': -0.2392}\n",
      "[Iter 16800 Task dept] Val Loss: 0.0226\n",
      "{'abs_err': 0.041, 'rel_err': 0.482, 'sigma_1.25': 35.4828, 'sigma_1.25^2': 68.1563, 'sigma_1.25^3': 84.4826, 'cmp': -0.5342}\n",
      "======================================================================\n",
      "[Iter 16900 Task segm] Train Loss: 0.3535\n",
      "[Iter 16900 Task dept] Train Loss: 0.0193\n",
      "[Iter 16900 Total] Train Loss: 0.1864\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Train Loss: 0.3523\n",
      "[Iter 17000 Task dept] Train Loss: 0.0183\n",
      "[Iter 17000 Total] Train Loss: 0.1853\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Val Loss: 0.3423\n",
      "{'mIoU': 0.2678, 'Pixel Acc': 0.6364, 'cmp': -0.241}\n",
      "[Iter 17000 Task dept] Val Loss: 0.0222\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4741, 'sigma_1.25': 35.5391, 'sigma_1.25^2': 67.7387, 'sigma_1.25^3': 84.2506, 'cmp': -0.5303}\n",
      "======================================================================\n",
      "[Iter 17100 Task segm] Train Loss: 0.3586\n",
      "[Iter 17100 Task dept] Train Loss: 0.0186\n",
      "[Iter 17100 Total] Train Loss: 0.1886\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Train Loss: 0.3523\n",
      "[Iter 17200 Task dept] Train Loss: 0.0185\n",
      "[Iter 17200 Total] Train Loss: 0.1854\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Val Loss: 0.3439\n",
      "{'mIoU': 0.2503, 'Pixel Acc': 0.6356, 'cmp': -0.2633}\n",
      "[Iter 17200 Task dept] Val Loss: 0.0230\n",
      "{'abs_err': 0.0415, 'rel_err': 0.4908, 'sigma_1.25': 34.6819, 'sigma_1.25^2': 67.1914, 'sigma_1.25^3': 84.0678, 'cmp': -0.5507}\n",
      "======================================================================\n",
      "[Iter 17300 Task segm] Train Loss: 0.3505\n",
      "[Iter 17300 Task dept] Train Loss: 0.0186\n",
      "[Iter 17300 Total] Train Loss: 0.1846\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Train Loss: 0.3508\n",
      "[Iter 17400 Task dept] Train Loss: 0.0188\n",
      "[Iter 17400 Total] Train Loss: 0.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 17400 Task segm] Val Loss: 0.3449\n",
      "{'mIoU': 0.266, 'Pixel Acc': 0.6342, 'cmp': -0.2446}\n",
      "[Iter 17400 Task dept] Val Loss: 0.0228\n",
      "{'abs_err': 0.0412, 'rel_err': 0.4785, 'sigma_1.25': 35.1709, 'sigma_1.25^2': 67.6373, 'sigma_1.25^3': 84.2221, 'cmp': -0.537}\n",
      "======================================================================\n",
      "[Iter 17500 Task segm] Train Loss: 0.3612\n",
      "[Iter 17500 Task dept] Train Loss: 0.0189\n",
      "[Iter 17500 Total] Train Loss: 0.1901\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Train Loss: 0.3434\n",
      "[Iter 17600 Task dept] Train Loss: 0.0184\n",
      "[Iter 17600 Total] Train Loss: 0.1809\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Val Loss: 0.3452\n",
      "{'mIoU': 0.2675, 'Pixel Acc': 0.6356, 'cmp': -0.2418}\n",
      "[Iter 17600 Task dept] Val Loss: 0.0232\n",
      "{'abs_err': 0.0417, 'rel_err': 0.4851, 'sigma_1.25': 34.394, 'sigma_1.25^2': 67.0982, 'sigma_1.25^3': 84.0535, 'cmp': -0.5511}\n",
      "======================================================================\n",
      "[Iter 17700 Task segm] Train Loss: 0.3565\n",
      "[Iter 17700 Task dept] Train Loss: 0.0180\n",
      "[Iter 17700 Total] Train Loss: 0.1872\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Train Loss: 0.3633\n",
      "[Iter 17800 Task dept] Train Loss: 0.0190\n",
      "[Iter 17800 Total] Train Loss: 0.1911\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Val Loss: 0.3470\n",
      "{'mIoU': 0.2672, 'Pixel Acc': 0.6356, 'cmp': -0.2422}\n",
      "[Iter 17800 Task dept] Val Loss: 0.0230\n",
      "{'abs_err': 0.0415, 'rel_err': 0.4857, 'sigma_1.25': 34.7407, 'sigma_1.25^2': 67.0333, 'sigma_1.25^3': 83.9998, 'cmp': -0.5481}\n",
      "======================================================================\n",
      "[Iter 17900 Task segm] Train Loss: 0.3553\n",
      "[Iter 17900 Task dept] Train Loss: 0.0186\n",
      "[Iter 17900 Total] Train Loss: 0.1870\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Train Loss: 0.3524\n",
      "[Iter 18000 Task dept] Train Loss: 0.0183\n",
      "[Iter 18000 Total] Train Loss: 0.1853\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Val Loss: 0.3423\n",
      "{'mIoU': 0.2674, 'Pixel Acc': 0.6361, 'cmp': -0.2416}\n",
      "[Iter 18000 Task dept] Val Loss: 0.0221\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4772, 'sigma_1.25': 35.8701, 'sigma_1.25^2': 67.908, 'sigma_1.25^3': 84.252, 'cmp': -0.5272}\n",
      "======================================================================\n",
      "[Iter 18100 Task segm] Train Loss: 0.3477\n",
      "[Iter 18100 Task dept] Train Loss: 0.0185\n",
      "[Iter 18100 Total] Train Loss: 0.1831\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Train Loss: 0.3631\n",
      "[Iter 18200 Task dept] Train Loss: 0.0186\n",
      "[Iter 18200 Total] Train Loss: 0.1909\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Val Loss: 0.3410\n",
      "{'mIoU': 0.2512, 'Pixel Acc': 0.6352, 'cmp': -0.2624}\n",
      "[Iter 18200 Task dept] Val Loss: 0.0221\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4859, 'sigma_1.25': 35.7125, 'sigma_1.25^2': 67.928, 'sigma_1.25^3': 84.347, 'cmp': -0.5338}\n",
      "======================================================================\n",
      "[Iter 18300 Task segm] Train Loss: 0.3556\n",
      "[Iter 18300 Task dept] Train Loss: 0.0185\n",
      "[Iter 18300 Total] Train Loss: 0.1871\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Train Loss: 0.3648\n",
      "[Iter 18400 Task dept] Train Loss: 0.0188\n",
      "[Iter 18400 Total] Train Loss: 0.1918\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Val Loss: 0.3470\n",
      "{'mIoU': 0.2687, 'Pixel Acc': 0.6361, 'cmp': -0.24}\n",
      "[Iter 18400 Task dept] Val Loss: 0.0215\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4793, 'sigma_1.25': 36.5591, 'sigma_1.25^2': 68.4831, 'sigma_1.25^3': 84.4326, 'cmp': -0.519}\n",
      "======================================================================\n",
      "[Iter 18500 Task segm] Train Loss: 0.3522\n",
      "[Iter 18500 Task dept] Train Loss: 0.0189\n",
      "[Iter 18500 Total] Train Loss: 0.1855\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Train Loss: 0.3541\n",
      "[Iter 18600 Task dept] Train Loss: 0.0188\n",
      "[Iter 18600 Total] Train Loss: 0.1864\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Val Loss: 0.3512\n",
      "{'mIoU': 0.2533, 'Pixel Acc': 0.6356, 'cmp': -0.2595}\n",
      "[Iter 18600 Task dept] Val Loss: 0.0217\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4824, 'sigma_1.25': 36.5091, 'sigma_1.25^2': 68.2915, 'sigma_1.25^3': 84.5097, 'cmp': -0.5221}\n",
      "======================================================================\n",
      "[Iter 18700 Task segm] Train Loss: 0.3562\n",
      "[Iter 18700 Task dept] Train Loss: 0.0185\n",
      "[Iter 18700 Total] Train Loss: 0.1874\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Train Loss: 0.3446\n",
      "[Iter 18800 Task dept] Train Loss: 0.0181\n",
      "[Iter 18800 Total] Train Loss: 0.1814\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Val Loss: 0.3526\n",
      "{'mIoU': 0.2677, 'Pixel Acc': 0.6343, 'cmp': -0.2424}\n",
      "[Iter 18800 Task dept] Val Loss: 0.0219\n",
      "{'abs_err': 0.0404, 'rel_err': 0.479, 'sigma_1.25': 36.2235, 'sigma_1.25^2': 68.0813, 'sigma_1.25^3': 84.2644, 'cmp': -0.5243}\n",
      "======================================================================\n",
      "[Iter 18900 Task segm] Train Loss: 0.3535\n",
      "[Iter 18900 Task dept] Train Loss: 0.0182\n",
      "[Iter 18900 Total] Train Loss: 0.1858\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Train Loss: 0.3512\n",
      "[Iter 19000 Task dept] Train Loss: 0.0187\n",
      "[Iter 19000 Total] Train Loss: 0.1849\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Val Loss: 0.3447\n",
      "{'mIoU': 0.266, 'Pixel Acc': 0.6355, 'cmp': -0.2437}\n",
      "[Iter 19000 Task dept] Val Loss: 0.0233\n",
      "{'abs_err': 0.0419, 'rel_err': 0.4756, 'sigma_1.25': 34.1917, 'sigma_1.25^2': 67.0548, 'sigma_1.25^3': 84.0246, 'cmp': -0.5489}\n",
      "======================================================================\n",
      "[Iter 19100 Task segm] Train Loss: 0.3533\n",
      "[Iter 19100 Task dept] Train Loss: 0.0180\n",
      "[Iter 19100 Total] Train Loss: 0.1857\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Train Loss: 0.3527\n",
      "[Iter 19200 Task dept] Train Loss: 0.0182\n",
      "[Iter 19200 Total] Train Loss: 0.1855\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Val Loss: 0.3459\n",
      "{'mIoU': 0.2677, 'Pixel Acc': 0.6352, 'cmp': -0.2419}\n",
      "[Iter 19200 Task dept] Val Loss: 0.0225\n",
      "{'abs_err': 0.041, 'rel_err': 0.4783, 'sigma_1.25': 35.4063, 'sigma_1.25^2': 67.7539, 'sigma_1.25^3': 84.2912, 'cmp': -0.5343}\n",
      "======================================================================\n",
      "[Iter 19300 Task segm] Train Loss: 0.3596\n",
      "[Iter 19300 Task dept] Train Loss: 0.0184\n",
      "[Iter 19300 Total] Train Loss: 0.1890\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Train Loss: 0.3562\n",
      "[Iter 19400 Task dept] Train Loss: 0.0181\n",
      "[Iter 19400 Total] Train Loss: 0.1872\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Val Loss: 0.3435\n",
      "{'mIoU': 0.2684, 'Pixel Acc': 0.6363, 'cmp': -0.2403}\n",
      "[Iter 19400 Task dept] Val Loss: 0.0224\n",
      "{'abs_err': 0.0411, 'rel_err': 0.4774, 'sigma_1.25': 35.2775, 'sigma_1.25^2': 67.355, 'sigma_1.25^3': 83.9179, 'cmp': -0.537}\n",
      "======================================================================\n",
      "[Iter 19500 Task segm] Train Loss: 0.3640\n",
      "[Iter 19500 Task dept] Train Loss: 0.0187\n",
      "[Iter 19500 Total] Train Loss: 0.1914\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Train Loss: 0.3574\n",
      "[Iter 19600 Task dept] Train Loss: 0.0186\n",
      "[Iter 19600 Total] Train Loss: 0.1880\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Val Loss: 0.3432\n",
      "{'mIoU': 0.2675, 'Pixel Acc': 0.6351, 'cmp': -0.2422}\n",
      "[Iter 19600 Task dept] Val Loss: 0.0219\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4794, 'sigma_1.25': 36.3162, 'sigma_1.25^2': 68.1668, 'sigma_1.25^3': 84.3573, 'cmp': -0.5232}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 19700 Task segm] Train Loss: 0.3406\n",
      "[Iter 19700 Task dept] Train Loss: 0.0185\n",
      "[Iter 19700 Total] Train Loss: 0.1795\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Train Loss: 0.3573\n",
      "[Iter 19800 Task dept] Train Loss: 0.0188\n",
      "[Iter 19800 Total] Train Loss: 0.1880\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Val Loss: 0.3434\n",
      "{'mIoU': 0.2665, 'Pixel Acc': 0.6349, 'cmp': -0.2436}\n",
      "[Iter 19800 Task dept] Val Loss: 0.0217\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4842, 'sigma_1.25': 36.4919, 'sigma_1.25^2': 68.2217, 'sigma_1.25^3': 84.3036, 'cmp': -0.5234}\n",
      "======================================================================\n",
      "[Iter 19900 Task segm] Train Loss: 0.3461\n",
      "[Iter 19900 Task dept] Train Loss: 0.0184\n",
      "[Iter 19900 Total] Train Loss: 0.1823\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Train Loss: 0.3507\n",
      "[Iter 20000 Task dept] Train Loss: 0.0184\n",
      "[Iter 20000 Total] Train Loss: 0.1845\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Val Loss: 0.3431\n",
      "{'mIoU': 0.2514, 'Pixel Acc': 0.6352, 'cmp': -0.2622}\n",
      "[Iter 20000 Task dept] Val Loss: 0.0221\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4804, 'sigma_1.25': 35.9265, 'sigma_1.25^2': 67.8816, 'sigma_1.25^3': 84.2493, 'cmp': -0.5289}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hard sharing\n",
    "trainer.stl_hard_sharing(iters=20000, lr=0.001, decay_lr_freq=2000, decay_lr_rate=0.5, savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-mnasnet/', reload='hard_sharing_15000iter.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 100 Task dept] Train Loss: 0.1666\n",
      "[Iter 100 Total] Train Loss: 0.1666\n",
      "======================================================================\n",
      "[Iter 200 Task dept] Train Loss: 0.0381\n",
      "[Iter 200 Total] Train Loss: 0.0381\n",
      "======================================================================\n",
      "[Iter 200 Task dept] Val Loss: 0.0520\n",
      "{'abs_err': 0.0591, 'rel_err': 0.6419, 'sigma_1.25': 20.622, 'sigma_1.25^2': 48.2322, 'sigma_1.25^3': 75.0872, 'cmp': -0.9528}\n",
      "======================================================================\n",
      "[Iter 300 Task dept] Train Loss: 0.0363\n",
      "[Iter 300 Total] Train Loss: 0.0363\n",
      "======================================================================\n",
      "[Iter 400 Task dept] Train Loss: 0.0331\n",
      "[Iter 400 Total] Train Loss: 0.0331\n",
      "======================================================================\n",
      "[Iter 400 Task dept] Val Loss: 0.0493\n",
      "{'abs_err': 0.0579, 'rel_err': 0.7401, 'sigma_1.25': 19.9939, 'sigma_1.25^2': 50.0977, 'sigma_1.25^3': 75.8671, 'cmp': -0.9943}\n",
      "======================================================================\n",
      "[Iter 500 Task dept] Train Loss: 0.0323\n",
      "[Iter 500 Total] Train Loss: 0.0323\n",
      "======================================================================\n",
      "[Iter 600 Task dept] Train Loss: 0.0312\n",
      "[Iter 600 Total] Train Loss: 0.0312\n",
      "======================================================================\n",
      "[Iter 600 Task dept] Val Loss: 0.0406\n",
      "{'abs_err': 0.0505, 'rel_err': 0.5971, 'sigma_1.25': 24.8588, 'sigma_1.25^2': 60.0115, 'sigma_1.25^3': 81.0442, 'cmp': -0.7725}\n",
      "======================================================================\n",
      "[Iter 700 Task dept] Train Loss: 0.0296\n",
      "[Iter 700 Total] Train Loss: 0.0296\n",
      "======================================================================\n",
      "[Iter 800 Task dept] Train Loss: 0.0294\n",
      "[Iter 800 Total] Train Loss: 0.0294\n",
      "======================================================================\n",
      "[Iter 800 Task dept] Val Loss: 0.0436\n",
      "{'abs_err': 0.0517, 'rel_err': 0.6138, 'sigma_1.25': 24.8584, 'sigma_1.25^2': 59.5271, 'sigma_1.25^3': 82.0858, 'cmp': -0.7959}\n",
      "======================================================================\n",
      "[Iter 900 Task dept] Train Loss: 0.0298\n",
      "[Iter 900 Total] Train Loss: 0.0298\n",
      "======================================================================\n",
      "[Iter 1000 Task dept] Train Loss: 0.0273\n",
      "[Iter 1000 Total] Train Loss: 0.0273\n",
      "======================================================================\n",
      "[Iter 1000 Task dept] Val Loss: 0.0473\n",
      "{'abs_err': 0.0578, 'rel_err': 0.503, 'sigma_1.25': 18.976, 'sigma_1.25^2': 47.728, 'sigma_1.25^3': 77.2904, 'cmp': -0.8551}\n",
      "======================================================================\n",
      "[Iter 1100 Task dept] Train Loss: 0.0288\n",
      "[Iter 1100 Total] Train Loss: 0.0288\n",
      "======================================================================\n",
      "[Iter 1200 Task dept] Train Loss: 0.0278\n",
      "[Iter 1200 Total] Train Loss: 0.0278\n",
      "======================================================================\n",
      "[Iter 1200 Task dept] Val Loss: 0.0424\n",
      "{'abs_err': 0.0539, 'rel_err': 0.5699, 'sigma_1.25': 21.3476, 'sigma_1.25^2': 54.8053, 'sigma_1.25^3': 80.7291, 'cmp': -0.8182}\n",
      "======================================================================\n",
      "[Iter 1300 Task dept] Train Loss: 0.0270\n",
      "[Iter 1300 Total] Train Loss: 0.0270\n",
      "======================================================================\n",
      "[Iter 1400 Task dept] Train Loss: 0.0277\n",
      "[Iter 1400 Total] Train Loss: 0.0277\n",
      "======================================================================\n",
      "[Iter 1400 Task dept] Val Loss: 0.0420\n",
      "{'abs_err': 0.0532, 'rel_err': 0.5575, 'sigma_1.25': 21.8537, 'sigma_1.25^2': 56.2202, 'sigma_1.25^3': 82.2216, 'cmp': -0.7946}\n",
      "======================================================================\n",
      "[Iter 1500 Task dept] Train Loss: 0.0271\n",
      "[Iter 1500 Total] Train Loss: 0.0271\n",
      "======================================================================\n",
      "[Iter 1600 Task dept] Train Loss: 0.0272\n",
      "[Iter 1600 Total] Train Loss: 0.0272\n",
      "======================================================================\n",
      "[Iter 1600 Task dept] Val Loss: 0.0458\n",
      "{'abs_err': 0.0544, 'rel_err': 0.5546, 'sigma_1.25': 22.7517, 'sigma_1.25^2': 54.2929, 'sigma_1.25^3': 81.5283, 'cmp': -0.8114}\n",
      "======================================================================\n",
      "[Iter 1700 Task dept] Train Loss: 0.0263\n",
      "[Iter 1700 Total] Train Loss: 0.0263\n",
      "======================================================================\n",
      "[Iter 1800 Task dept] Train Loss: 0.0264\n",
      "[Iter 1800 Total] Train Loss: 0.0264\n",
      "======================================================================\n",
      "[Iter 1800 Task dept] Val Loss: 0.0389\n",
      "{'abs_err': 0.05, 'rel_err': 0.5022, 'sigma_1.25': 24.4066, 'sigma_1.25^2': 60.5973, 'sigma_1.25^3': 81.7522, 'cmp': -0.7073}\n",
      "======================================================================\n",
      "[Iter 1900 Task dept] Train Loss: 0.0278\n",
      "[Iter 1900 Total] Train Loss: 0.0278\n",
      "======================================================================\n",
      "[Iter 2000 Task dept] Train Loss: 0.0265\n",
      "[Iter 2000 Total] Train Loss: 0.0265\n",
      "======================================================================\n",
      "[Iter 2000 Task dept] Val Loss: 0.0427\n",
      "{'abs_err': 0.0536, 'rel_err': 0.5406, 'sigma_1.25': 21.016, 'sigma_1.25^2': 54.4287, 'sigma_1.25^3': 80.3438, 'cmp': -0.8002}\n",
      "======================================================================\n",
      "[Iter 2100 Task dept] Train Loss: 0.0265\n",
      "[Iter 2100 Total] Train Loss: 0.0265\n",
      "======================================================================\n",
      "[Iter 2200 Task dept] Train Loss: 0.0261\n",
      "[Iter 2200 Total] Train Loss: 0.0261\n",
      "======================================================================\n",
      "[Iter 2200 Task dept] Val Loss: 0.0414\n",
      "{'abs_err': 0.0525, 'rel_err': 0.5423, 'sigma_1.25': 22.6916, 'sigma_1.25^2': 56.7496, 'sigma_1.25^3': 80.2813, 'cmp': -0.7779}\n",
      "======================================================================\n",
      "[Iter 2300 Task dept] Train Loss: 0.0256\n",
      "[Iter 2300 Total] Train Loss: 0.0256\n",
      "======================================================================\n",
      "[Iter 2400 Task dept] Train Loss: 0.0257\n",
      "[Iter 2400 Total] Train Loss: 0.0257\n",
      "======================================================================\n",
      "[Iter 2400 Task dept] Val Loss: 0.0363\n",
      "{'abs_err': 0.0476, 'rel_err': 0.586, 'sigma_1.25': 27.7812, 'sigma_1.25^2': 64.0384, 'sigma_1.25^3': 83.0614, 'cmp': -0.7101}\n",
      "======================================================================\n",
      "[Iter 2500 Task dept] Train Loss: 0.0262\n",
      "[Iter 2500 Total] Train Loss: 0.0262\n",
      "======================================================================\n",
      "[Iter 2600 Task dept] Train Loss: 0.0250\n",
      "[Iter 2600 Total] Train Loss: 0.0250\n",
      "======================================================================\n",
      "[Iter 2600 Task dept] Val Loss: 0.0437\n",
      "{'abs_err': 0.0563, 'rel_err': 0.5206, 'sigma_1.25': 18.4359, 'sigma_1.25^2': 50.4049, 'sigma_1.25^3': 76.4098, 'cmp': -0.8445}\n",
      "======================================================================\n",
      "[Iter 2700 Task dept] Train Loss: 0.0246\n",
      "[Iter 2700 Total] Train Loss: 0.0246\n",
      "======================================================================\n",
      "[Iter 2800 Task dept] Train Loss: 0.0240\n",
      "[Iter 2800 Total] Train Loss: 0.0240\n",
      "======================================================================\n",
      "[Iter 2800 Task dept] Val Loss: 0.0401\n",
      "{'abs_err': 0.0487, 'rel_err': 0.5651, 'sigma_1.25': 28.267, 'sigma_1.25^2': 64.2391, 'sigma_1.25^3': 83.6381, 'cmp': -0.7069}\n",
      "======================================================================\n",
      "[Iter 2900 Task dept] Train Loss: 0.0243\n",
      "[Iter 2900 Total] Train Loss: 0.0243\n",
      "======================================================================\n",
      "[Iter 3000 Task dept] Train Loss: 0.0248\n",
      "[Iter 3000 Total] Train Loss: 0.0248\n",
      "======================================================================\n",
      "[Iter 3000 Task dept] Val Loss: 0.0506\n",
      "{'abs_err': 0.0626, 'rel_err': 0.525, 'sigma_1.25': 14.2877, 'sigma_1.25^2': 37.8775, 'sigma_1.25^3': 68.6355, 'cmp': -0.9788}\n",
      "======================================================================\n",
      "[Iter 3100 Task dept] Train Loss: 0.0236\n",
      "[Iter 3100 Total] Train Loss: 0.0236\n",
      "======================================================================\n",
      "[Iter 3200 Task dept] Train Loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3200 Total] Train Loss: 0.0241\n",
      "======================================================================\n",
      "[Iter 3200 Task dept] Val Loss: 0.0394\n",
      "{'abs_err': 0.0492, 'rel_err': 0.5092, 'sigma_1.25': 25.4155, 'sigma_1.25^2': 61.079, 'sigma_1.25^3': 81.1714, 'cmp': -0.6992}\n",
      "======================================================================\n",
      "[Iter 3300 Task dept] Train Loss: 0.0239\n",
      "[Iter 3300 Total] Train Loss: 0.0239\n",
      "======================================================================\n",
      "[Iter 3400 Task dept] Train Loss: 0.0233\n",
      "[Iter 3400 Total] Train Loss: 0.0233\n",
      "======================================================================\n",
      "[Iter 3400 Task dept] Val Loss: 0.0321\n",
      "{'abs_err': 0.045, 'rel_err': 0.5753, 'sigma_1.25': 30.2313, 'sigma_1.25^2': 65.9259, 'sigma_1.25^3': 82.8422, 'cmp': -0.6618}\n",
      "======================================================================\n",
      "[Iter 3500 Task dept] Train Loss: 0.0237\n",
      "[Iter 3500 Total] Train Loss: 0.0237\n",
      "======================================================================\n",
      "[Iter 3600 Task dept] Train Loss: 0.0240\n",
      "[Iter 3600 Total] Train Loss: 0.0240\n",
      "======================================================================\n",
      "[Iter 3600 Task dept] Val Loss: 0.0482\n",
      "{'abs_err': 0.0587, 'rel_err': 0.5668, 'sigma_1.25': 18.7002, 'sigma_1.25^2': 46.2936, 'sigma_1.25^3': 76.4962, 'cmp': -0.91}\n",
      "======================================================================\n",
      "[Iter 3700 Task dept] Train Loss: 0.0234\n",
      "[Iter 3700 Total] Train Loss: 0.0234\n",
      "======================================================================\n",
      "[Iter 3800 Task dept] Train Loss: 0.0230\n",
      "[Iter 3800 Total] Train Loss: 0.0230\n",
      "======================================================================\n",
      "[Iter 3800 Task dept] Val Loss: 0.0369\n",
      "{'abs_err': 0.0492, 'rel_err': 0.5496, 'sigma_1.25': 25.9657, 'sigma_1.25^2': 61.5712, 'sigma_1.25^3': 82.1356, 'cmp': -0.7194}\n",
      "======================================================================\n",
      "[Iter 3900 Task dept] Train Loss: 0.0227\n",
      "[Iter 3900 Total] Train Loss: 0.0227\n",
      "======================================================================\n",
      "[Iter 4000 Task dept] Train Loss: 0.0229\n",
      "[Iter 4000 Total] Train Loss: 0.0229\n",
      "======================================================================\n",
      "[Iter 4000 Task dept] Val Loss: 0.0394\n",
      "{'abs_err': 0.0489, 'rel_err': 0.4824, 'sigma_1.25': 26.4253, 'sigma_1.25^2': 62.6759, 'sigma_1.25^3': 82.8406, 'cmp': -0.6695}\n",
      "======================================================================\n",
      "[Iter 4100 Task dept] Train Loss: 0.0214\n",
      "[Iter 4100 Total] Train Loss: 0.0214\n",
      "======================================================================\n",
      "[Iter 4200 Task dept] Train Loss: 0.0212\n",
      "[Iter 4200 Total] Train Loss: 0.0212\n",
      "======================================================================\n",
      "[Iter 4200 Task dept] Val Loss: 0.0330\n",
      "{'abs_err': 0.0459, 'rel_err': 0.5249, 'sigma_1.25': 28.639, 'sigma_1.25^2': 66.9269, 'sigma_1.25^3': 84.3777, 'cmp': -0.6404}\n",
      "======================================================================\n",
      "[Iter 4300 Task dept] Train Loss: 0.0209\n",
      "[Iter 4300 Total] Train Loss: 0.0209\n",
      "======================================================================\n",
      "[Iter 4400 Task dept] Train Loss: 0.0203\n",
      "[Iter 4400 Total] Train Loss: 0.0203\n",
      "======================================================================\n",
      "[Iter 4400 Task dept] Val Loss: 0.0343\n",
      "{'abs_err': 0.0482, 'rel_err': 0.5196, 'sigma_1.25': 25.2514, 'sigma_1.25^2': 63.4422, 'sigma_1.25^3': 83.3242, 'cmp': -0.684}\n",
      "======================================================================\n",
      "[Iter 4500 Task dept] Train Loss: 0.0207\n",
      "[Iter 4500 Total] Train Loss: 0.0207\n",
      "======================================================================\n",
      "[Iter 4600 Task dept] Train Loss: 0.0210\n",
      "[Iter 4600 Total] Train Loss: 0.0210\n",
      "======================================================================\n",
      "[Iter 4600 Task dept] Val Loss: 0.0324\n",
      "{'abs_err': 0.046, 'rel_err': 0.5403, 'sigma_1.25': 28.5032, 'sigma_1.25^2': 65.417, 'sigma_1.25^3': 82.6978, 'cmp': -0.6592}\n",
      "======================================================================\n",
      "[Iter 4700 Task dept] Train Loss: 0.0202\n",
      "[Iter 4700 Total] Train Loss: 0.0202\n",
      "======================================================================\n",
      "[Iter 4800 Task dept] Train Loss: 0.0206\n",
      "[Iter 4800 Total] Train Loss: 0.0206\n",
      "======================================================================\n",
      "[Iter 4800 Task dept] Val Loss: 0.0312\n",
      "{'abs_err': 0.0452, 'rel_err': 0.5234, 'sigma_1.25': 29.6858, 'sigma_1.25^2': 67.7056, 'sigma_1.25^3': 83.9051, 'cmp': -0.6272}\n",
      "======================================================================\n",
      "[Iter 4900 Task dept] Train Loss: 0.0211\n",
      "[Iter 4900 Total] Train Loss: 0.0211\n",
      "======================================================================\n",
      "[Iter 5000 Task dept] Train Loss: 0.0201\n",
      "[Iter 5000 Total] Train Loss: 0.0201\n",
      "======================================================================\n",
      "[Iter 5000 Task dept] Val Loss: 0.0321\n",
      "{'abs_err': 0.045, 'rel_err': 0.5126, 'sigma_1.25': 29.628, 'sigma_1.25^2': 68.1662, 'sigma_1.25^3': 84.717, 'cmp': -0.6163}\n",
      "======================================================================\n",
      "[Iter 5100 Task dept] Train Loss: 0.0195\n",
      "[Iter 5100 Total] Train Loss: 0.0195\n",
      "======================================================================\n",
      "[Iter 5200 Task dept] Train Loss: 0.0203\n",
      "[Iter 5200 Total] Train Loss: 0.0203\n",
      "======================================================================\n",
      "[Iter 5200 Task dept] Val Loss: 0.0281\n",
      "{'abs_err': 0.0384, 'rel_err': 0.5151, 'sigma_1.25': 39.4011, 'sigma_1.25^2': 74.3529, 'sigma_1.25^3': 86.4681, 'cmp': -0.4945}\n",
      "======================================================================\n",
      "[Iter 5300 Task dept] Train Loss: 0.0200\n",
      "[Iter 5300 Total] Train Loss: 0.0200\n",
      "======================================================================\n",
      "[Iter 5400 Task dept] Train Loss: 0.0201\n",
      "[Iter 5400 Total] Train Loss: 0.0201\n",
      "======================================================================\n",
      "[Iter 5400 Task dept] Val Loss: 0.0280\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4972, 'sigma_1.25': 36.3143, 'sigma_1.25^2': 73.0891, 'sigma_1.25^3': 86.5132, 'cmp': -0.5183}\n",
      "======================================================================\n",
      "[Iter 5500 Task dept] Train Loss: 0.0204\n",
      "[Iter 5500 Total] Train Loss: 0.0204\n",
      "======================================================================\n",
      "[Iter 5600 Task dept] Train Loss: 0.0199\n",
      "[Iter 5600 Total] Train Loss: 0.0199\n",
      "======================================================================\n",
      "[Iter 5600 Task dept] Val Loss: 0.0279\n",
      "{'abs_err': 0.0383, 'rel_err': 0.5679, 'sigma_1.25': 40.7291, 'sigma_1.25^2': 74.0146, 'sigma_1.25^3': 85.5812, 'cmp': -0.5242}\n",
      "======================================================================\n",
      "[Iter 5700 Task dept] Train Loss: 0.0203\n",
      "[Iter 5700 Total] Train Loss: 0.0203\n",
      "======================================================================\n",
      "[Iter 5800 Task dept] Train Loss: 0.0196\n",
      "[Iter 5800 Total] Train Loss: 0.0196\n",
      "======================================================================\n",
      "[Iter 5800 Task dept] Val Loss: 0.0275\n",
      "{'abs_err': 0.0418, 'rel_err': 0.4832, 'sigma_1.25': 34.6078, 'sigma_1.25^2': 69.8651, 'sigma_1.25^3': 84.5748, 'cmp': -0.5433}\n",
      "======================================================================\n",
      "[Iter 5900 Task dept] Train Loss: 0.0200\n",
      "[Iter 5900 Total] Train Loss: 0.0200\n",
      "======================================================================\n",
      "[Iter 6000 Task dept] Train Loss: 0.0198\n",
      "[Iter 6000 Total] Train Loss: 0.0198\n",
      "======================================================================\n",
      "[Iter 6000 Task dept] Val Loss: 0.0305\n",
      "{'abs_err': 0.0438, 'rel_err': 0.5192, 'sigma_1.25': 31.3092, 'sigma_1.25^2': 70.1181, 'sigma_1.25^3': 85.8063, 'cmp': -0.595}\n",
      "======================================================================\n",
      "[Iter 6100 Task dept] Train Loss: 0.0195\n",
      "[Iter 6100 Total] Train Loss: 0.0195\n",
      "======================================================================\n",
      "[Iter 6200 Task dept] Train Loss: 0.0189\n",
      "[Iter 6200 Total] Train Loss: 0.0189\n",
      "======================================================================\n",
      "[Iter 6200 Task dept] Val Loss: 0.0274\n",
      "{'abs_err': 0.0378, 'rel_err': 0.5838, 'sigma_1.25': 40.7497, 'sigma_1.25^2': 73.5082, 'sigma_1.25^3': 84.9822, 'cmp': -0.5296}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 6300 Task dept] Train Loss: 0.0195\n",
      "[Iter 6300 Total] Train Loss: 0.0195\n",
      "======================================================================\n",
      "[Iter 6400 Task dept] Train Loss: 0.0206\n",
      "[Iter 6400 Total] Train Loss: 0.0206\n",
      "======================================================================\n",
      "[Iter 6400 Task dept] Val Loss: 0.0288\n",
      "{'abs_err': 0.0401, 'rel_err': 0.5434, 'sigma_1.25': 36.8277, 'sigma_1.25^2': 72.7663, 'sigma_1.25^3': 85.4464, 'cmp': -0.5443}\n",
      "======================================================================\n",
      "[Iter 6500 Task dept] Train Loss: 0.0193\n",
      "[Iter 6500 Total] Train Loss: 0.0193\n",
      "======================================================================\n",
      "[Iter 6600 Task dept] Train Loss: 0.0194\n",
      "[Iter 6600 Total] Train Loss: 0.0194\n",
      "======================================================================\n",
      "[Iter 6600 Task dept] Val Loss: 0.0278\n",
      "{'abs_err': 0.0381, 'rel_err': 0.5422, 'sigma_1.25': 40.099, 'sigma_1.25^2': 74.6477, 'sigma_1.25^3': 86.3194, 'cmp': -0.505}\n",
      "======================================================================\n",
      "[Iter 6700 Task dept] Train Loss: 0.0192\n",
      "[Iter 6700 Total] Train Loss: 0.0192\n",
      "======================================================================\n",
      "[Iter 6800 Task dept] Train Loss: 0.0192\n",
      "[Iter 6800 Total] Train Loss: 0.0192\n",
      "======================================================================\n",
      "[Iter 6800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0366, 'rel_err': 0.5079, 'sigma_1.25': 42.4101, 'sigma_1.25^2': 74.2339, 'sigma_1.25^3': 86.3195, 'cmp': -0.4603}\n",
      "======================================================================\n",
      "[Iter 6900 Task dept] Train Loss: 0.0191\n",
      "[Iter 6900 Total] Train Loss: 0.0191\n",
      "======================================================================\n",
      "[Iter 7000 Task dept] Train Loss: 0.0189\n",
      "[Iter 7000 Total] Train Loss: 0.0189\n",
      "======================================================================\n",
      "[Iter 7000 Task dept] Val Loss: 0.0259\n",
      "{'abs_err': 0.04, 'rel_err': 0.4405, 'sigma_1.25': 36.5631, 'sigma_1.25^2': 72.8288, 'sigma_1.25^3': 86.2384, 'cmp': -0.4802}\n",
      "======================================================================\n",
      "[Iter 7100 Task dept] Train Loss: 0.0192\n",
      "[Iter 7100 Total] Train Loss: 0.0192\n",
      "======================================================================\n",
      "[Iter 7200 Task dept] Train Loss: 0.0191\n",
      "[Iter 7200 Total] Train Loss: 0.0191\n",
      "======================================================================\n",
      "[Iter 7200 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0372, 'rel_err': 0.5157, 'sigma_1.25': 41.7042, 'sigma_1.25^2': 74.6057, 'sigma_1.25^3': 86.1976, 'cmp': -0.4736}\n",
      "======================================================================\n",
      "[Iter 7300 Task dept] Train Loss: 0.0196\n",
      "[Iter 7300 Total] Train Loss: 0.0196\n",
      "======================================================================\n",
      "[Iter 7400 Task dept] Train Loss: 0.0190\n",
      "[Iter 7400 Total] Train Loss: 0.0190\n",
      "======================================================================\n",
      "[Iter 7400 Task dept] Val Loss: 0.0261\n",
      "{'abs_err': 0.0384, 'rel_err': 0.545, 'sigma_1.25': 39.385, 'sigma_1.25^2': 72.5275, 'sigma_1.25^3': 85.0134, 'cmp': -0.5192}\n",
      "======================================================================\n",
      "[Iter 7500 Task dept] Train Loss: 0.0188\n",
      "[Iter 7500 Total] Train Loss: 0.0188\n",
      "======================================================================\n",
      "[Iter 7600 Task dept] Train Loss: 0.0186\n",
      "[Iter 7600 Total] Train Loss: 0.0186\n",
      "======================================================================\n",
      "[Iter 7600 Task dept] Val Loss: 0.0239\n",
      "{'abs_err': 0.0384, 'rel_err': 0.5071, 'sigma_1.25': 39.309, 'sigma_1.25^2': 71.5746, 'sigma_1.25^3': 85.2672, 'cmp': -0.4988}\n",
      "======================================================================\n",
      "[Iter 7700 Task dept] Train Loss: 0.0189\n",
      "[Iter 7700 Total] Train Loss: 0.0189\n",
      "======================================================================\n",
      "[Iter 7800 Task dept] Train Loss: 0.0185\n",
      "[Iter 7800 Total] Train Loss: 0.0185\n",
      "======================================================================\n",
      "[Iter 7800 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4987, 'sigma_1.25': 36.4771, 'sigma_1.25^2': 70.9079, 'sigma_1.25^3': 84.8532, 'cmp': -0.5261}\n",
      "======================================================================\n",
      "[Iter 7900 Task dept] Train Loss: 0.0190\n",
      "[Iter 7900 Total] Train Loss: 0.0190\n",
      "======================================================================\n",
      "[Iter 8000 Task dept] Train Loss: 0.0191\n",
      "[Iter 8000 Total] Train Loss: 0.0191\n",
      "======================================================================\n",
      "[Iter 8000 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4614, 'sigma_1.25': 36.1076, 'sigma_1.25^2': 70.7198, 'sigma_1.25^3': 84.6609, 'cmp': -0.5091}\n",
      "======================================================================\n",
      "[Iter 8100 Task dept] Train Loss: 0.0182\n",
      "[Iter 8100 Total] Train Loss: 0.0182\n",
      "======================================================================\n",
      "[Iter 8200 Task dept] Train Loss: 0.0176\n",
      "[Iter 8200 Total] Train Loss: 0.0176\n",
      "======================================================================\n",
      "[Iter 8200 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0365, 'rel_err': 0.4962, 'sigma_1.25': 42.4535, 'sigma_1.25^2': 75.8007, 'sigma_1.25^3': 87.0943, 'cmp': -0.4475}\n",
      "======================================================================\n",
      "[Iter 8300 Task dept] Train Loss: 0.0173\n",
      "[Iter 8300 Total] Train Loss: 0.0173\n",
      "======================================================================\n",
      "[Iter 8400 Task dept] Train Loss: 0.0175\n",
      "[Iter 8400 Total] Train Loss: 0.0175\n",
      "======================================================================\n",
      "[Iter 8400 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0377, 'rel_err': 0.5021, 'sigma_1.25': 40.252, 'sigma_1.25^2': 74.9389, 'sigma_1.25^3': 86.639, 'cmp': -0.4738}\n",
      "======================================================================\n",
      "[Iter 8500 Task dept] Train Loss: 0.0172\n",
      "[Iter 8500 Total] Train Loss: 0.0172\n",
      "======================================================================\n",
      "[Iter 8600 Task dept] Train Loss: 0.0172\n",
      "[Iter 8600 Total] Train Loss: 0.0172\n",
      "======================================================================\n",
      "[Iter 8600 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.038, 'rel_err': 0.5363, 'sigma_1.25': 39.7659, 'sigma_1.25^2': 73.7183, 'sigma_1.25^3': 85.8723, 'cmp': -0.5043}\n",
      "======================================================================\n",
      "[Iter 8700 Task dept] Train Loss: 0.0175\n",
      "[Iter 8700 Total] Train Loss: 0.0175\n",
      "======================================================================\n",
      "[Iter 8800 Task dept] Train Loss: 0.0169\n",
      "[Iter 8800 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 8800 Task dept] Val Loss: 0.0245\n",
      "{'abs_err': 0.0379, 'rel_err': 0.4993, 'sigma_1.25': 39.8765, 'sigma_1.25^2': 74.2677, 'sigma_1.25^3': 86.5269, 'cmp': -0.478}\n",
      "======================================================================\n",
      "[Iter 8900 Task dept] Train Loss: 0.0173\n",
      "[Iter 8900 Total] Train Loss: 0.0173\n",
      "======================================================================\n",
      "[Iter 9000 Task dept] Train Loss: 0.0170\n",
      "[Iter 9000 Total] Train Loss: 0.0170\n",
      "======================================================================\n",
      "[Iter 9000 Task dept] Val Loss: 0.0262\n",
      "{'abs_err': 0.0405, 'rel_err': 0.5047, 'sigma_1.25': 35.8037, 'sigma_1.25^2': 72.4236, 'sigma_1.25^3': 86.1748, 'cmp': -0.5277}\n",
      "======================================================================\n",
      "[Iter 9100 Task dept] Train Loss: 0.0174\n",
      "[Iter 9100 Total] Train Loss: 0.0174\n",
      "======================================================================\n",
      "[Iter 9200 Task dept] Train Loss: 0.0170\n",
      "[Iter 9200 Total] Train Loss: 0.0170\n",
      "======================================================================\n",
      "[Iter 9200 Task dept] Val Loss: 0.0280\n",
      "{'abs_err': 0.041, 'rel_err': 0.5221, 'sigma_1.25': 35.396, 'sigma_1.25^2': 72.9261, 'sigma_1.25^3': 86.5179, 'cmp': -0.5431}\n",
      "======================================================================\n",
      "[Iter 9300 Task dept] Train Loss: 0.0171\n",
      "[Iter 9300 Total] Train Loss: 0.0171\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 9400 Task dept] Train Loss: 0.0169\n",
      "[Iter 9400 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 9400 Task dept] Val Loss: 0.0228\n",
      "{'abs_err': 0.0353, 'rel_err': 0.5614, 'sigma_1.25': 44.4623, 'sigma_1.25^2': 74.3429, 'sigma_1.25^3': 85.9512, 'cmp': -0.4722}\n",
      "======================================================================\n",
      "[Iter 9500 Task dept] Train Loss: 0.0170\n",
      "[Iter 9500 Total] Train Loss: 0.0170\n",
      "======================================================================\n",
      "[Iter 9600 Task dept] Train Loss: 0.0169\n",
      "[Iter 9600 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 9600 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0382, 'rel_err': 0.5243, 'sigma_1.25': 39.5819, 'sigma_1.25^2': 73.729, 'sigma_1.25^3': 86.0707, 'cmp': -0.4988}\n",
      "======================================================================\n",
      "[Iter 9700 Task dept] Train Loss: 0.0172\n",
      "[Iter 9700 Total] Train Loss: 0.0172\n",
      "======================================================================\n",
      "[Iter 9800 Task dept] Train Loss: 0.0168\n",
      "[Iter 9800 Total] Train Loss: 0.0168\n",
      "======================================================================\n",
      "[Iter 9800 Task dept] Val Loss: 0.0241\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4744, 'sigma_1.25': 37.0179, 'sigma_1.25^2': 72.0167, 'sigma_1.25^3': 85.8489, 'cmp': -0.4997}\n",
      "======================================================================\n",
      "[Iter 9900 Task dept] Train Loss: 0.0169\n",
      "[Iter 9900 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 10000 Task dept] Train Loss: 0.0165\n",
      "[Iter 10000 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 10000 Task dept] Val Loss: 0.0266\n",
      "{'abs_err': 0.0416, 'rel_err': 0.484, 'sigma_1.25': 34.1641, 'sigma_1.25^2': 70.6341, 'sigma_1.25^3': 84.9264, 'cmp': -0.54}\n",
      "======================================================================\n",
      "[Iter 10100 Task dept] Train Loss: 0.0170\n",
      "[Iter 10100 Total] Train Loss: 0.0170\n",
      "======================================================================\n",
      "[Iter 10200 Task dept] Train Loss: 0.0170\n",
      "[Iter 10200 Total] Train Loss: 0.0170\n",
      "======================================================================\n",
      "[Iter 10200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0394, 'rel_err': 0.5204, 'sigma_1.25': 37.4686, 'sigma_1.25^2': 73.2362, 'sigma_1.25^3': 86.2459, 'cmp': -0.5179}\n",
      "======================================================================\n",
      "[Iter 10300 Task dept] Train Loss: 0.0169\n",
      "[Iter 10300 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 10400 Task dept] Train Loss: 0.0168\n",
      "[Iter 10400 Total] Train Loss: 0.0168\n",
      "======================================================================\n",
      "[Iter 10400 Task dept] Val Loss: 0.0262\n",
      "{'abs_err': 0.0415, 'rel_err': 0.4458, 'sigma_1.25': 34.5734, 'sigma_1.25^2': 71.3623, 'sigma_1.25^3': 85.461, 'cmp': -0.5113}\n",
      "======================================================================\n",
      "[Iter 10500 Task dept] Train Loss: 0.0165\n",
      "[Iter 10500 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 10600 Task dept] Train Loss: 0.0163\n",
      "[Iter 10600 Total] Train Loss: 0.0163\n",
      "======================================================================\n",
      "[Iter 10600 Task dept] Val Loss: 0.0238\n",
      "{'abs_err': 0.0394, 'rel_err': 0.5125, 'sigma_1.25': 37.6672, 'sigma_1.25^2': 73.0268, 'sigma_1.25^3': 86.0692, 'cmp': -0.5136}\n",
      "======================================================================\n",
      "[Iter 10700 Task dept] Train Loss: 0.0167\n",
      "[Iter 10700 Total] Train Loss: 0.0167\n",
      "======================================================================\n",
      "[Iter 10800 Task dept] Train Loss: 0.0169\n",
      "[Iter 10800 Total] Train Loss: 0.0169\n",
      "======================================================================\n",
      "[Iter 10800 Task dept] Val Loss: 0.0235\n",
      "{'abs_err': 0.0364, 'rel_err': 0.4901, 'sigma_1.25': 42.7438, 'sigma_1.25^2': 76.3088, 'sigma_1.25^3': 87.6639, 'cmp': -0.4387}\n",
      "======================================================================\n",
      "[Iter 10900 Task dept] Train Loss: 0.0165\n",
      "[Iter 10900 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 11000 Task dept] Train Loss: 0.0166\n",
      "[Iter 11000 Total] Train Loss: 0.0166\n",
      "======================================================================\n",
      "[Iter 11000 Task dept] Val Loss: 0.0245\n",
      "{'abs_err': 0.0375, 'rel_err': 0.4972, 'sigma_1.25': 40.6267, 'sigma_1.25^2': 75.0973, 'sigma_1.25^3': 87.0103, 'cmp': -0.4659}\n",
      "======================================================================\n",
      "[Iter 11100 Task dept] Train Loss: 0.0165\n",
      "[Iter 11100 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 11200 Task dept] Train Loss: 0.0163\n",
      "[Iter 11200 Total] Train Loss: 0.0163\n",
      "======================================================================\n",
      "[Iter 11200 Task dept] Val Loss: 0.0259\n",
      "{'abs_err': 0.0399, 'rel_err': 0.5632, 'sigma_1.25': 37.3411, 'sigma_1.25^2': 72.126, 'sigma_1.25^3': 84.9477, 'cmp': -0.5553}\n",
      "======================================================================\n",
      "[Iter 11300 Task dept] Train Loss: 0.0166\n",
      "[Iter 11300 Total] Train Loss: 0.0166\n",
      "======================================================================\n",
      "[Iter 11400 Task dept] Train Loss: 0.0167\n",
      "[Iter 11400 Total] Train Loss: 0.0167\n",
      "======================================================================\n",
      "[Iter 11400 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0373, 'rel_err': 0.5329, 'sigma_1.25': 41.0211, 'sigma_1.25^2': 75.2397, 'sigma_1.25^3': 86.8841, 'cmp': -0.4842}\n",
      "======================================================================\n",
      "[Iter 11500 Task dept] Train Loss: 0.0167\n",
      "[Iter 11500 Total] Train Loss: 0.0167\n",
      "======================================================================\n",
      "[Iter 11600 Task dept] Train Loss: 0.0165\n",
      "[Iter 11600 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 11600 Task dept] Val Loss: 0.0243\n",
      "{'abs_err': 0.0365, 'rel_err': 0.5348, 'sigma_1.25': 42.4, 'sigma_1.25^2': 75.5454, 'sigma_1.25^3': 87.071, 'cmp': -0.4706}\n",
      "======================================================================\n",
      "[Iter 11700 Task dept] Train Loss: 0.0166\n",
      "[Iter 11700 Total] Train Loss: 0.0166\n",
      "======================================================================\n",
      "[Iter 11800 Task dept] Train Loss: 0.0167\n",
      "[Iter 11800 Total] Train Loss: 0.0167\n",
      "======================================================================\n",
      "[Iter 11800 Task dept] Val Loss: 0.0258\n",
      "{'abs_err': 0.0407, 'rel_err': 0.5077, 'sigma_1.25': 35.01, 'sigma_1.25^2': 72.04, 'sigma_1.25^3': 86.3115, 'cmp': -0.5346}\n",
      "======================================================================\n",
      "[Iter 11900 Task dept] Train Loss: 0.0165\n",
      "[Iter 11900 Total] Train Loss: 0.0165\n",
      "======================================================================\n",
      "[Iter 12000 Task dept] Train Loss: 0.0163\n",
      "[Iter 12000 Total] Train Loss: 0.0163\n",
      "======================================================================\n",
      "[Iter 12000 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0397, 'rel_err': 0.4787, 'sigma_1.25': 37.4969, 'sigma_1.25^2': 72.6389, 'sigma_1.25^3': 85.9461, 'cmp': -0.4974}\n",
      "======================================================================\n",
      "[Iter 12100 Task dept] Train Loss: 0.0160\n",
      "[Iter 12100 Total] Train Loss: 0.0160\n",
      "======================================================================\n",
      "[Iter 12200 Task dept] Train Loss: 0.0156\n",
      "[Iter 12200 Total] Train Loss: 0.0156\n",
      "======================================================================\n",
      "[Iter 12200 Task dept] Val Loss: 0.0228\n",
      "{'abs_err': 0.0368, 'rel_err': 0.5106, 'sigma_1.25': 42.0536, 'sigma_1.25^2': 74.9, 'sigma_1.25^3': 86.6167, 'cmp': -0.4631}\n",
      "======================================================================\n",
      "[Iter 12300 Task dept] Train Loss: 0.0159\n",
      "[Iter 12300 Total] Train Loss: 0.0159\n",
      "======================================================================\n",
      "[Iter 12400 Task dept] Train Loss: 0.0155\n",
      "[Iter 12400 Total] Train Loss: 0.0155\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 12400 Task dept] Val Loss: 0.0239\n",
      "{'abs_err': 0.0382, 'rel_err': 0.479, 'sigma_1.25': 39.7024, 'sigma_1.25^2': 75.0633, 'sigma_1.25^3': 87.6458, 'cmp': -0.4654}\n",
      "======================================================================\n",
      "[Iter 12500 Task dept] Train Loss: 0.0160\n",
      "[Iter 12500 Total] Train Loss: 0.0160\n",
      "======================================================================\n",
      "[Iter 12600 Task dept] Train Loss: 0.0155\n",
      "[Iter 12600 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 12600 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4969, 'sigma_1.25': 36.5061, 'sigma_1.25^2': 73.3298, 'sigma_1.25^3': 86.5528, 'cmp': -0.5148}\n",
      "======================================================================\n",
      "[Iter 12700 Task dept] Train Loss: 0.0158\n",
      "[Iter 12700 Total] Train Loss: 0.0158\n",
      "======================================================================\n",
      "[Iter 12800 Task dept] Train Loss: 0.0153\n",
      "[Iter 12800 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 12800 Task dept] Val Loss: 0.0237\n",
      "{'abs_err': 0.0375, 'rel_err': 0.5184, 'sigma_1.25': 40.6465, 'sigma_1.25^2': 74.6043, 'sigma_1.25^3': 86.7784, 'cmp': -0.4808}\n",
      "======================================================================\n",
      "[Iter 12900 Task dept] Train Loss: 0.0156\n",
      "[Iter 12900 Total] Train Loss: 0.0156\n",
      "======================================================================\n",
      "[Iter 13000 Task dept] Train Loss: 0.0160\n",
      "[Iter 13000 Total] Train Loss: 0.0160\n",
      "======================================================================\n",
      "[Iter 13000 Task dept] Val Loss: 0.0262\n",
      "{'abs_err': 0.0388, 'rel_err': 0.5054, 'sigma_1.25': 38.8608, 'sigma_1.25^2': 75.6213, 'sigma_1.25^3': 87.8029, 'cmp': -0.489}\n",
      "======================================================================\n",
      "[Iter 13100 Task dept] Train Loss: 0.0153\n",
      "[Iter 13100 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 13200 Task dept] Train Loss: 0.0156\n",
      "[Iter 13200 Total] Train Loss: 0.0156\n",
      "======================================================================\n",
      "[Iter 13200 Task dept] Val Loss: 0.0259\n",
      "{'abs_err': 0.0389, 'rel_err': 0.5384, 'sigma_1.25': 38.6025, 'sigma_1.25^2': 74.41, 'sigma_1.25^3': 86.6008, 'cmp': -0.5164}\n",
      "======================================================================\n",
      "[Iter 13300 Task dept] Train Loss: 0.0156\n",
      "[Iter 13300 Total] Train Loss: 0.0156\n",
      "======================================================================\n",
      "[Iter 13400 Task dept] Train Loss: 0.0152\n",
      "[Iter 13400 Total] Train Loss: 0.0152\n",
      "======================================================================\n",
      "[Iter 13400 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4758, 'sigma_1.25': 35.4399, 'sigma_1.25^2': 71.4624, 'sigma_1.25^3': 85.5534, 'cmp': -0.5198}\n",
      "======================================================================\n",
      "[Iter 13500 Task dept] Train Loss: 0.0158\n",
      "[Iter 13500 Total] Train Loss: 0.0158\n",
      "======================================================================\n",
      "[Iter 13600 Task dept] Train Loss: 0.0154\n",
      "[Iter 13600 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 13600 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4796, 'sigma_1.25': 37.4209, 'sigma_1.25^2': 74.1716, 'sigma_1.25^3': 87.1746, 'cmp': -0.4933}\n",
      "======================================================================\n",
      "[Iter 13700 Task dept] Train Loss: 0.0156\n",
      "[Iter 13700 Total] Train Loss: 0.0156\n",
      "======================================================================\n",
      "[Iter 13800 Task dept] Train Loss: 0.0155\n",
      "[Iter 13800 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 13800 Task dept] Val Loss: 0.0274\n",
      "{'abs_err': 0.042, 'rel_err': 0.505, 'sigma_1.25': 33.9004, 'sigma_1.25^2': 71.7066, 'sigma_1.25^3': 86.1705, 'cmp': -0.5522}\n",
      "======================================================================\n",
      "[Iter 13900 Task dept] Train Loss: 0.0153\n",
      "[Iter 13900 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 14000 Task dept] Train Loss: 0.0155\n",
      "[Iter 14000 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 14000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0399, 'rel_err': 0.5001, 'sigma_1.25': 37.0329, 'sigma_1.25^2': 72.9033, 'sigma_1.25^3': 86.0534, 'cmp': -0.5141}\n",
      "======================================================================\n",
      "[Iter 14100 Task dept] Train Loss: 0.0153\n",
      "[Iter 14100 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 14200 Task dept] Train Loss: 0.0154\n",
      "[Iter 14200 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 14200 Task dept] Val Loss: 0.0265\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4833, 'sigma_1.25': 35.3695, 'sigma_1.25^2': 73.196, 'sigma_1.25^3': 87.1555, 'cmp': -0.5173}\n",
      "======================================================================\n",
      "[Iter 14300 Task dept] Train Loss: 0.0151\n",
      "[Iter 14300 Total] Train Loss: 0.0151\n",
      "======================================================================\n",
      "[Iter 14400 Task dept] Train Loss: 0.0155\n",
      "[Iter 14400 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 14400 Task dept] Val Loss: 0.0234\n",
      "{'abs_err': 0.0368, 'rel_err': 0.4991, 'sigma_1.25': 41.8839, 'sigma_1.25^2': 76.1185, 'sigma_1.25^3': 87.713, 'cmp': -0.4521}\n",
      "======================================================================\n",
      "[Iter 14500 Task dept] Train Loss: 0.0153\n",
      "[Iter 14500 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 14600 Task dept] Train Loss: 0.0154\n",
      "[Iter 14600 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 14600 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0405, 'rel_err': 0.5515, 'sigma_1.25': 36.3145, 'sigma_1.25^2': 71.6489, 'sigma_1.25^3': 85.2432, 'cmp': -0.5583}\n",
      "======================================================================\n",
      "[Iter 14700 Task dept] Train Loss: 0.0155\n",
      "[Iter 14700 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 14800 Task dept] Train Loss: 0.0152\n",
      "[Iter 14800 Total] Train Loss: 0.0152\n",
      "======================================================================\n",
      "[Iter 14800 Task dept] Val Loss: 0.0271\n",
      "{'abs_err': 0.0414, 'rel_err': 0.4954, 'sigma_1.25': 34.6361, 'sigma_1.25^2': 72.8176, 'sigma_1.25^3': 87.0861, 'cmp': -0.5335}\n",
      "======================================================================\n",
      "[Iter 14900 Task dept] Train Loss: 0.0154\n",
      "[Iter 14900 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 15000 Task dept] Train Loss: 0.0153\n",
      "[Iter 15000 Total] Train Loss: 0.0153\n",
      "======================================================================\n",
      "[Iter 15000 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0393, 'rel_err': 0.4875, 'sigma_1.25': 37.9839, 'sigma_1.25^2': 74.1035, 'sigma_1.25^3': 87.1843, 'cmp': -0.4914}\n",
      "======================================================================\n",
      "[Iter 15100 Task dept] Train Loss: 0.0155\n",
      "[Iter 15100 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 15200 Task dept] Train Loss: 0.0148\n",
      "[Iter 15200 Total] Train Loss: 0.0148\n",
      "======================================================================\n",
      "[Iter 15200 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0396, 'rel_err': 0.5064, 'sigma_1.25': 37.3088, 'sigma_1.25^2': 73.8028, 'sigma_1.25^3': 87.045, 'cmp': -0.5096}\n",
      "======================================================================\n",
      "[Iter 15300 Task dept] Train Loss: 0.0151\n",
      "[Iter 15300 Total] Train Loss: 0.0151\n",
      "======================================================================\n",
      "[Iter 15400 Task dept] Train Loss: 0.0155\n",
      "[Iter 15400 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 15400 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0394, 'rel_err': 0.4854, 'sigma_1.25': 37.7057, 'sigma_1.25^2': 74.3269, 'sigma_1.25^3': 87.3407, 'cmp': -0.4908}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 15500 Task dept] Train Loss: 0.0151\n",
      "[Iter 15500 Total] Train Loss: 0.0151\n",
      "======================================================================\n",
      "[Iter 15600 Task dept] Train Loss: 0.0150\n",
      "[Iter 15600 Total] Train Loss: 0.0150\n",
      "======================================================================\n",
      "[Iter 15600 Task dept] Val Loss: 0.0258\n",
      "{'abs_err': 0.0404, 'rel_err': 0.5101, 'sigma_1.25': 35.9949, 'sigma_1.25^2': 72.8512, 'sigma_1.25^3': 86.613, 'cmp': -0.5281}\n",
      "======================================================================\n",
      "[Iter 15700 Task dept] Train Loss: 0.0154\n",
      "[Iter 15700 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 15800 Task dept] Train Loss: 0.0155\n",
      "[Iter 15800 Total] Train Loss: 0.0155\n",
      "======================================================================\n",
      "[Iter 15800 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0403, 'rel_err': 0.5276, 'sigma_1.25': 36.0789, 'sigma_1.25^2': 72.0308, 'sigma_1.25^3': 85.8304, 'cmp': -0.5403}\n",
      "======================================================================\n",
      "[Iter 15900 Task dept] Train Loss: 0.0150\n",
      "[Iter 15900 Total] Train Loss: 0.0150\n",
      "======================================================================\n",
      "[Iter 16000 Task dept] Train Loss: 0.0150\n",
      "[Iter 16000 Total] Train Loss: 0.0150\n",
      "======================================================================\n",
      "[Iter 16000 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.04, 'rel_err': 0.5045, 'sigma_1.25': 36.4954, 'sigma_1.25^2': 73.48, 'sigma_1.25^3': 87.0587, 'cmp': -0.5159}\n",
      "======================================================================\n",
      "[Iter 16100 Task dept] Train Loss: 0.0154\n",
      "[Iter 16100 Total] Train Loss: 0.0154\n",
      "======================================================================\n",
      "[Iter 16200 Task dept] Train Loss: 0.0142\n",
      "[Iter 16200 Total] Train Loss: 0.0142\n",
      "======================================================================\n",
      "[Iter 16200 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.039, 'rel_err': 0.501, 'sigma_1.25': 38.2889, 'sigma_1.25^2': 74.7593, 'sigma_1.25^3': 87.4681, 'cmp': -0.4932}\n",
      "======================================================================\n",
      "[Iter 16300 Task dept] Train Loss: 0.0151\n",
      "[Iter 16300 Total] Train Loss: 0.0151\n",
      "======================================================================\n",
      "[Iter 16400 Task dept] Train Loss: 0.0146\n",
      "[Iter 16400 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 16400 Task dept] Val Loss: 0.0262\n",
      "{'abs_err': 0.0408, 'rel_err': 0.4988, 'sigma_1.25': 35.5921, 'sigma_1.25^2': 72.9236, 'sigma_1.25^3': 86.7395, 'cmp': -0.5257}\n",
      "======================================================================\n",
      "[Iter 16500 Task dept] Train Loss: 0.0150\n",
      "[Iter 16500 Total] Train Loss: 0.0150\n",
      "======================================================================\n",
      "[Iter 16600 Task dept] Train Loss: 0.0148\n",
      "[Iter 16600 Total] Train Loss: 0.0148\n",
      "======================================================================\n",
      "[Iter 16600 Task dept] Val Loss: 0.0243\n",
      "{'abs_err': 0.0392, 'rel_err': 0.5021, 'sigma_1.25': 38.2668, 'sigma_1.25^2': 74.1144, 'sigma_1.25^3': 87.0473, 'cmp': -0.4978}\n",
      "======================================================================\n",
      "[Iter 16700 Task dept] Train Loss: 0.0147\n",
      "[Iter 16700 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 16800 Task dept] Train Loss: 0.0146\n",
      "[Iter 16800 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 16800 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4902, 'sigma_1.25': 36.5991, 'sigma_1.25^2': 73.2388, 'sigma_1.25^3': 86.7091, 'cmp': -0.5095}\n",
      "======================================================================\n",
      "[Iter 16900 Task dept] Train Loss: 0.0144\n",
      "[Iter 16900 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 17000 Task dept] Train Loss: 0.0146\n",
      "[Iter 17000 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 17000 Task dept] Val Loss: 0.0255\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4928, 'sigma_1.25': 36.9044, 'sigma_1.25^2': 73.8536, 'sigma_1.25^3': 87.1795, 'cmp': -0.5069}\n",
      "======================================================================\n",
      "[Iter 17100 Task dept] Train Loss: 0.0143\n",
      "[Iter 17100 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 17200 Task dept] Train Loss: 0.0148\n",
      "[Iter 17200 Total] Train Loss: 0.0148\n",
      "======================================================================\n",
      "[Iter 17200 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0405, 'rel_err': 0.5015, 'sigma_1.25': 36.0037, 'sigma_1.25^2': 73.1543, 'sigma_1.25^3': 87.0031, 'cmp': -0.5223}\n",
      "======================================================================\n",
      "[Iter 17300 Task dept] Train Loss: 0.0145\n",
      "[Iter 17300 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 17400 Task dept] Train Loss: 0.0149\n",
      "[Iter 17400 Total] Train Loss: 0.0149\n",
      "======================================================================\n",
      "[Iter 17400 Task dept] Val Loss: 0.0244\n",
      "{'abs_err': 0.0395, 'rel_err': 0.4941, 'sigma_1.25': 37.8093, 'sigma_1.25^2': 73.8174, 'sigma_1.25^3': 87.0607, 'cmp': -0.4995}\n",
      "======================================================================\n",
      "[Iter 17500 Task dept] Train Loss: 0.0147\n",
      "[Iter 17500 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 17600 Task dept] Train Loss: 0.0141\n",
      "[Iter 17600 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 17600 Task dept] Val Loss: 0.0244\n",
      "{'abs_err': 0.0393, 'rel_err': 0.5053, 'sigma_1.25': 37.9482, 'sigma_1.25^2': 73.8876, 'sigma_1.25^3': 86.9956, 'cmp': -0.5031}\n",
      "======================================================================\n",
      "[Iter 17700 Task dept] Train Loss: 0.0147\n",
      "[Iter 17700 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 17800 Task dept] Train Loss: 0.0148\n",
      "[Iter 17800 Total] Train Loss: 0.0148\n",
      "======================================================================\n",
      "[Iter 17800 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4935, 'sigma_1.25': 37.2928, 'sigma_1.25^2': 74.0154, 'sigma_1.25^3': 87.2258, 'cmp': -0.5027}\n",
      "======================================================================\n",
      "[Iter 17900 Task dept] Train Loss: 0.0146\n",
      "[Iter 17900 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 18000 Task dept] Train Loss: 0.0145\n",
      "[Iter 18000 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 18000 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0393, 'rel_err': 0.4924, 'sigma_1.25': 38.0166, 'sigma_1.25^2': 74.5839, 'sigma_1.25^3': 87.5435, 'cmp': -0.4918}\n",
      "======================================================================\n",
      "[Iter 18100 Task dept] Train Loss: 0.0146\n",
      "[Iter 18100 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 18200 Task dept] Train Loss: 0.0146\n",
      "[Iter 18200 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 18200 Task dept] Val Loss: 0.0260\n",
      "{'abs_err': 0.0411, 'rel_err': 0.5028, 'sigma_1.25': 35.0742, 'sigma_1.25^2': 72.6095, 'sigma_1.25^3': 86.5145, 'cmp': -0.5353}\n",
      "======================================================================\n",
      "[Iter 18300 Task dept] Train Loss: 0.0145\n",
      "[Iter 18300 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 18400 Task dept] Train Loss: 0.0147\n",
      "[Iter 18400 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 18400 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0397, 'rel_err': 0.5022, 'sigma_1.25': 37.5302, 'sigma_1.25^2': 73.6437, 'sigma_1.25^3': 86.848, 'cmp': -0.5083}\n",
      "======================================================================\n",
      "[Iter 18500 Task dept] Train Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 18500 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 18600 Task dept] Train Loss: 0.0147\n",
      "[Iter 18600 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 18600 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4871, 'sigma_1.25': 37.2177, 'sigma_1.25^2': 73.8417, 'sigma_1.25^3': 87.0698, 'cmp': -0.5008}\n",
      "======================================================================\n",
      "[Iter 18700 Task dept] Train Loss: 0.0144\n",
      "[Iter 18700 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 18800 Task dept] Train Loss: 0.0145\n",
      "[Iter 18800 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 18800 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0396, 'rel_err': 0.4903, 'sigma_1.25': 37.7934, 'sigma_1.25^2': 74.2356, 'sigma_1.25^3': 87.4097, 'cmp': -0.4962}\n",
      "======================================================================\n",
      "[Iter 18900 Task dept] Train Loss: 0.0146\n",
      "[Iter 18900 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 19000 Task dept] Train Loss: 0.0143\n",
      "[Iter 19000 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 19000 Task dept] Val Loss: 0.0237\n",
      "{'abs_err': 0.0387, 'rel_err': 0.4977, 'sigma_1.25': 38.7412, 'sigma_1.25^2': 74.4437, 'sigma_1.25^3': 87.2881, 'cmp': -0.4875}\n",
      "======================================================================\n",
      "[Iter 19100 Task dept] Train Loss: 0.0146\n",
      "[Iter 19100 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 19200 Task dept] Train Loss: 0.0145\n",
      "[Iter 19200 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 19200 Task dept] Val Loss: 0.0244\n",
      "{'abs_err': 0.0396, 'rel_err': 0.4913, 'sigma_1.25': 37.6315, 'sigma_1.25^2': 73.843, 'sigma_1.25^3': 87.2572, 'cmp': -0.4984}\n",
      "======================================================================\n",
      "[Iter 19300 Task dept] Train Loss: 0.0148\n",
      "[Iter 19300 Total] Train Loss: 0.0148\n",
      "======================================================================\n",
      "[Iter 19400 Task dept] Train Loss: 0.0144\n",
      "[Iter 19400 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 19400 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4947, 'sigma_1.25': 36.8782, 'sigma_1.25^2': 72.9694, 'sigma_1.25^3': 86.9832, 'cmp': -0.5112}\n",
      "======================================================================\n",
      "[Iter 19500 Task dept] Train Loss: 0.0144\n",
      "[Iter 19500 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 19600 Task dept] Train Loss: 0.0147\n",
      "[Iter 19600 Total] Train Loss: 0.0147\n",
      "======================================================================\n",
      "[Iter 19600 Task dept] Val Loss: 0.0255\n",
      "{'abs_err': 0.0401, 'rel_err': 0.5114, 'sigma_1.25': 36.6131, 'sigma_1.25^2': 73.197, 'sigma_1.25^3': 86.9758, 'cmp': -0.522}\n",
      "======================================================================\n",
      "[Iter 19700 Task dept] Train Loss: 0.0149\n",
      "[Iter 19700 Total] Train Loss: 0.0149\n",
      "======================================================================\n",
      "[Iter 19800 Task dept] Train Loss: 0.0146\n",
      "[Iter 19800 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 19800 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.04, 'rel_err': 0.4999, 'sigma_1.25': 36.9219, 'sigma_1.25^2': 73.5915, 'sigma_1.25^3': 87.3497, 'cmp': -0.5106}\n",
      "======================================================================\n",
      "[Iter 19900 Task dept] Train Loss: 0.0142\n",
      "[Iter 19900 Total] Train Loss: 0.0142\n",
      "======================================================================\n",
      "[Iter 20000 Task dept] Train Loss: 0.0143\n",
      "[Iter 20000 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 20000 Task dept] Val Loss: 0.0259\n",
      "{'abs_err': 0.0408, 'rel_err': 0.5037, 'sigma_1.25': 35.5745, 'sigma_1.25^2': 72.8325, 'sigma_1.25^3': 87.0895, 'cmp': -0.5284}\n",
      "======================================================================\n",
      "[Iter 20100 Task dept] Train Loss: 0.0151\n",
      "[Iter 20100 Total] Train Loss: 0.0151\n",
      "======================================================================\n",
      "[Iter 20200 Task dept] Train Loss: 0.0140\n",
      "[Iter 20200 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 20200 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.04, 'rel_err': 0.4917, 'sigma_1.25': 36.9989, 'sigma_1.25^2': 73.73, 'sigma_1.25^3': 87.4992, 'cmp': -0.5055}\n",
      "======================================================================\n",
      "[Iter 20300 Task dept] Train Loss: 0.0144\n",
      "[Iter 20300 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 20400 Task dept] Train Loss: 0.0141\n",
      "[Iter 20400 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 20400 Task dept] Val Loss: 0.0242\n",
      "{'abs_err': 0.0394, 'rel_err': 0.4963, 'sigma_1.25': 37.8077, 'sigma_1.25^2': 73.5599, 'sigma_1.25^3': 87.2294, 'cmp': -0.4993}\n",
      "======================================================================\n",
      "[Iter 20500 Task dept] Train Loss: 0.0145\n",
      "[Iter 20500 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 20600 Task dept] Train Loss: 0.0140\n",
      "[Iter 20600 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 20600 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4998, 'sigma_1.25': 35.8376, 'sigma_1.25^2': 72.6979, 'sigma_1.25^3': 86.9171, 'cmp': -0.5246}\n",
      "======================================================================\n",
      "[Iter 20700 Task dept] Train Loss: 0.0141\n",
      "[Iter 20700 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 20800 Task dept] Train Loss: 0.0146\n",
      "[Iter 20800 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 20800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0396, 'rel_err': 0.4966, 'sigma_1.25': 37.4409, 'sigma_1.25^2': 73.9352, 'sigma_1.25^3': 87.5116, 'cmp': -0.5017}\n",
      "======================================================================\n",
      "[Iter 20900 Task dept] Train Loss: 0.0142\n",
      "[Iter 20900 Total] Train Loss: 0.0142\n",
      "======================================================================\n",
      "[Iter 21000 Task dept] Train Loss: 0.0146\n",
      "[Iter 21000 Total] Train Loss: 0.0146\n",
      "======================================================================\n",
      "[Iter 21000 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4995, 'sigma_1.25': 36.8096, 'sigma_1.25^2': 73.4579, 'sigma_1.25^3': 87.2797, 'cmp': -0.512}\n",
      "======================================================================\n",
      "[Iter 21100 Task dept] Train Loss: 0.0142\n",
      "[Iter 21100 Total] Train Loss: 0.0142\n",
      "======================================================================\n",
      "[Iter 21200 Task dept] Train Loss: 0.0143\n",
      "[Iter 21200 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 21200 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4961, 'sigma_1.25': 37.0707, 'sigma_1.25^2': 73.4484, 'sigma_1.25^3': 87.1062, 'cmp': -0.5081}\n",
      "======================================================================\n",
      "[Iter 21300 Task dept] Train Loss: 0.0138\n",
      "[Iter 21300 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 21400 Task dept] Train Loss: 0.0143\n",
      "[Iter 21400 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 21400 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4836, 'sigma_1.25': 36.6593, 'sigma_1.25^2': 73.7793, 'sigma_1.25^3': 87.6966, 'cmp': -0.5034}\n",
      "======================================================================\n",
      "[Iter 21500 Task dept] Train Loss: 0.0143\n",
      "[Iter 21500 Total] Train Loss: 0.0143\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 21600 Task dept] Train Loss: 0.0138\n",
      "[Iter 21600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 21600 Task dept] Val Loss: 0.0258\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4958, 'sigma_1.25': 35.6174, 'sigma_1.25^2': 72.7593, 'sigma_1.25^3': 87.1974, 'cmp': -0.5249}\n",
      "======================================================================\n",
      "[Iter 21700 Task dept] Train Loss: 0.0138\n",
      "[Iter 21700 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 21800 Task dept] Train Loss: 0.0138\n",
      "[Iter 21800 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 21800 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4951, 'sigma_1.25': 36.9513, 'sigma_1.25^2': 73.6175, 'sigma_1.25^3': 87.3884, 'cmp': -0.5083}\n",
      "======================================================================\n",
      "[Iter 21900 Task dept] Train Loss: 0.0140\n",
      "[Iter 21900 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 22000 Task dept] Train Loss: 0.0140\n",
      "[Iter 22000 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 22000 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0408, 'rel_err': 0.4921, 'sigma_1.25': 35.9436, 'sigma_1.25^2': 72.8117, 'sigma_1.25^3': 87.0457, 'cmp': -0.5203}\n",
      "======================================================================\n",
      "[Iter 22100 Task dept] Train Loss: 0.0143\n",
      "[Iter 22100 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 22200 Task dept] Train Loss: 0.0140\n",
      "[Iter 22200 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 22200 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4878, 'sigma_1.25': 36.2118, 'sigma_1.25^2': 73.4365, 'sigma_1.25^3': 87.3277, 'cmp': -0.5125}\n",
      "======================================================================\n",
      "[Iter 22300 Task dept] Train Loss: 0.0140\n",
      "[Iter 22300 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 22400 Task dept] Train Loss: 0.0141\n",
      "[Iter 22400 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 22400 Task dept] Val Loss: 0.0243\n",
      "{'abs_err': 0.0397, 'rel_err': 0.4947, 'sigma_1.25': 37.6465, 'sigma_1.25^2': 73.7733, 'sigma_1.25^3': 87.3642, 'cmp': -0.5013}\n",
      "======================================================================\n",
      "[Iter 22500 Task dept] Train Loss: 0.0145\n",
      "[Iter 22500 Total] Train Loss: 0.0145\n",
      "======================================================================\n",
      "[Iter 22600 Task dept] Train Loss: 0.0140\n",
      "[Iter 22600 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 22600 Task dept] Val Loss: 0.0255\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4909, 'sigma_1.25': 35.9529, 'sigma_1.25^2': 72.9423, 'sigma_1.25^3': 87.1999, 'cmp': -0.5174}\n",
      "======================================================================\n",
      "[Iter 22700 Task dept] Train Loss: 0.0144\n",
      "[Iter 22700 Total] Train Loss: 0.0144\n",
      "======================================================================\n",
      "[Iter 22800 Task dept] Train Loss: 0.0139\n",
      "[Iter 22800 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 22800 Task dept] Val Loss: 0.0257\n",
      "{'abs_err': 0.0409, 'rel_err': 0.4899, 'sigma_1.25': 35.745, 'sigma_1.25^2': 72.7908, 'sigma_1.25^3': 87.2631, 'cmp': -0.5203}\n",
      "======================================================================\n",
      "[Iter 22900 Task dept] Train Loss: 0.0140\n",
      "[Iter 22900 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 23000 Task dept] Train Loss: 0.0139\n",
      "[Iter 23000 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 23000 Task dept] Val Loss: 0.0257\n",
      "{'abs_err': 0.0416, 'rel_err': 0.4828, 'sigma_1.25': 34.728, 'sigma_1.25^2': 71.8931, 'sigma_1.25^3': 86.6562, 'cmp': -0.5304}\n",
      "======================================================================\n",
      "[Iter 23100 Task dept] Train Loss: 0.0140\n",
      "[Iter 23100 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 23200 Task dept] Train Loss: 0.0139\n",
      "[Iter 23200 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 23200 Task dept] Val Loss: 0.0259\n",
      "{'abs_err': 0.0407, 'rel_err': 0.5073, 'sigma_1.25': 35.7404, 'sigma_1.25^2': 72.9861, 'sigma_1.25^3': 87.2775, 'cmp': -0.5282}\n",
      "======================================================================\n",
      "[Iter 23300 Task dept] Train Loss: 0.0137\n",
      "[Iter 23300 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 23400 Task dept] Train Loss: 0.0143\n",
      "[Iter 23400 Total] Train Loss: 0.0143\n",
      "======================================================================\n",
      "[Iter 23400 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4894, 'sigma_1.25': 36.7964, 'sigma_1.25^2': 73.4844, 'sigma_1.25^3': 87.4121, 'cmp': -0.5073}\n",
      "======================================================================\n",
      "[Iter 23500 Task dept] Train Loss: 0.0139\n",
      "[Iter 23500 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 23600 Task dept] Train Loss: 0.0140\n",
      "[Iter 23600 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 23600 Task dept] Val Loss: 0.0260\n",
      "{'abs_err': 0.0407, 'rel_err': 0.5001, 'sigma_1.25': 35.821, 'sigma_1.25^2': 72.9932, 'sigma_1.25^3': 87.1707, 'cmp': -0.5242}\n",
      "======================================================================\n",
      "[Iter 23700 Task dept] Train Loss: 0.0139\n",
      "[Iter 23700 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 23800 Task dept] Train Loss: 0.0140\n",
      "[Iter 23800 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 23800 Task dept] Val Loss: 0.0241\n",
      "{'abs_err': 0.0394, 'rel_err': 0.4903, 'sigma_1.25': 38.024, 'sigma_1.25^2': 74.0458, 'sigma_1.25^3': 87.4385, 'cmp': -0.4937}\n",
      "======================================================================\n",
      "[Iter 23900 Task dept] Train Loss: 0.0140\n",
      "[Iter 23900 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 24000 Task dept] Train Loss: 0.0139\n",
      "[Iter 24000 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 24000 Task dept] Val Loss: 0.0240\n",
      "{'abs_err': 0.0395, 'rel_err': 0.4851, 'sigma_1.25': 37.9652, 'sigma_1.25^2': 73.9797, 'sigma_1.25^3': 87.7343, 'cmp': -0.4914}\n",
      "======================================================================\n",
      "[Iter 24100 Task dept] Train Loss: 0.0141\n",
      "[Iter 24100 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 24200 Task dept] Train Loss: 0.0138\n",
      "[Iter 24200 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 24200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.04, 'rel_err': 0.4902, 'sigma_1.25': 36.9728, 'sigma_1.25^2': 73.639, 'sigma_1.25^3': 87.384, 'cmp': -0.5049}\n",
      "======================================================================\n",
      "[Iter 24300 Task dept] Train Loss: 0.0139\n",
      "[Iter 24300 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 24400 Task dept] Train Loss: 0.0141\n",
      "[Iter 24400 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 24400 Task dept] Val Loss: 0.0254\n",
      "{'abs_err': 0.0408, 'rel_err': 0.4988, 'sigma_1.25': 35.6999, 'sigma_1.25^2': 72.7341, 'sigma_1.25^3': 87.1711, 'cmp': -0.5254}\n",
      "======================================================================\n",
      "[Iter 24500 Task dept] Train Loss: 0.0140\n",
      "[Iter 24500 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 24600 Task dept] Train Loss: 0.0138\n",
      "[Iter 24600 Total] Train Loss: 0.0138\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 24600 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0401, 'rel_err': 0.5017, 'sigma_1.25': 36.5962, 'sigma_1.25^2': 73.3623, 'sigma_1.25^3': 87.2823, 'cmp': -0.5151}\n",
      "======================================================================\n",
      "[Iter 24700 Task dept] Train Loss: 0.0142\n",
      "[Iter 24700 Total] Train Loss: 0.0142\n",
      "======================================================================\n",
      "[Iter 24800 Task dept] Train Loss: 0.0136\n",
      "[Iter 24800 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 24800 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.04, 'rel_err': 0.4928, 'sigma_1.25': 37.0407, 'sigma_1.25^2': 73.5328, 'sigma_1.25^3': 87.2884, 'cmp': -0.5062}\n",
      "======================================================================\n",
      "[Iter 24900 Task dept] Train Loss: 0.0137\n",
      "[Iter 24900 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 25000 Task dept] Train Loss: 0.0140\n",
      "[Iter 25000 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 25000 Task dept] Val Loss: 0.0255\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4856, 'sigma_1.25': 35.9549, 'sigma_1.25^2': 73.1722, 'sigma_1.25^3': 87.2795, 'cmp': -0.5144}\n",
      "======================================================================\n",
      "[Iter 25100 Task dept] Train Loss: 0.0138\n",
      "[Iter 25100 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 25200 Task dept] Train Loss: 0.0137\n",
      "[Iter 25200 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 25200 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4911, 'sigma_1.25': 36.2742, 'sigma_1.25^2': 72.8896, 'sigma_1.25^3': 87.0294, 'cmp': -0.515}\n",
      "======================================================================\n",
      "[Iter 25300 Task dept] Train Loss: 0.0138\n",
      "[Iter 25300 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 25400 Task dept] Train Loss: 0.0141\n",
      "[Iter 25400 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 25400 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4985, 'sigma_1.25': 36.238, 'sigma_1.25^2': 72.9132, 'sigma_1.25^3': 87.0965, 'cmp': -0.5196}\n",
      "======================================================================\n",
      "[Iter 25500 Task dept] Train Loss: 0.0139\n",
      "[Iter 25500 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 25600 Task dept] Train Loss: 0.0136\n",
      "[Iter 25600 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 25600 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4961, 'sigma_1.25': 36.6253, 'sigma_1.25^2': 73.1674, 'sigma_1.25^3': 87.2795, 'cmp': -0.5127}\n",
      "======================================================================\n",
      "[Iter 25700 Task dept] Train Loss: 0.0139\n",
      "[Iter 25700 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 25800 Task dept] Train Loss: 0.0139\n",
      "[Iter 25800 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 25800 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.04, 'rel_err': 0.5042, 'sigma_1.25': 36.8479, 'sigma_1.25^2': 73.4293, 'sigma_1.25^3': 87.2755, 'cmp': -0.5144}\n",
      "======================================================================\n",
      "[Iter 25900 Task dept] Train Loss: 0.0141\n",
      "[Iter 25900 Total] Train Loss: 0.0141\n",
      "======================================================================\n",
      "[Iter 26000 Task dept] Train Loss: 0.0135\n",
      "[Iter 26000 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 26000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4921, 'sigma_1.25': 36.6419, 'sigma_1.25^2': 73.2621, 'sigma_1.25^3': 87.338, 'cmp': -0.5107}\n",
      "======================================================================\n",
      "[Iter 26100 Task dept] Train Loss: 0.0140\n",
      "[Iter 26100 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 26200 Task dept] Train Loss: 0.0140\n",
      "[Iter 26200 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 26200 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4905, 'sigma_1.25': 36.0125, 'sigma_1.25^2': 73.1403, 'sigma_1.25^3': 87.368, 'cmp': -0.5162}\n",
      "======================================================================\n",
      "[Iter 26300 Task dept] Train Loss: 0.0136\n",
      "[Iter 26300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 26400 Task dept] Train Loss: 0.0135\n",
      "[Iter 26400 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 26400 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4842, 'sigma_1.25': 36.5642, 'sigma_1.25^2': 73.3036, 'sigma_1.25^3': 87.3797, 'cmp': -0.5064}\n",
      "======================================================================\n",
      "[Iter 26500 Task dept] Train Loss: 0.0137\n",
      "[Iter 26500 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 26600 Task dept] Train Loss: 0.0135\n",
      "[Iter 26600 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 26600 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4868, 'sigma_1.25': 36.0887, 'sigma_1.25^2': 73.0296, 'sigma_1.25^3': 87.3564, 'cmp': -0.5143}\n",
      "======================================================================\n",
      "[Iter 26700 Task dept] Train Loss: 0.0137\n",
      "[Iter 26700 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 26800 Task dept] Train Loss: 0.0138\n",
      "[Iter 26800 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 26800 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.04, 'rel_err': 0.4893, 'sigma_1.25': 36.9452, 'sigma_1.25^2': 73.5258, 'sigma_1.25^3': 87.5204, 'cmp': -0.504}\n",
      "======================================================================\n",
      "[Iter 26900 Task dept] Train Loss: 0.0139\n",
      "[Iter 26900 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 27000 Task dept] Train Loss: 0.0138\n",
      "[Iter 27000 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 27000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4873, 'sigma_1.25': 36.676, 'sigma_1.25^2': 73.3783, 'sigma_1.25^3': 87.428, 'cmp': -0.5072}\n",
      "======================================================================\n",
      "[Iter 27100 Task dept] Train Loss: 0.0139\n",
      "[Iter 27100 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 27200 Task dept] Train Loss: 0.0137\n",
      "[Iter 27200 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 27200 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4917, 'sigma_1.25': 37.0491, 'sigma_1.25^2': 73.601, 'sigma_1.25^3': 87.4619, 'cmp': -0.5044}\n",
      "======================================================================\n",
      "[Iter 27300 Task dept] Train Loss: 0.0136\n",
      "[Iter 27300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 27400 Task dept] Train Loss: 0.0137\n",
      "[Iter 27400 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 27400 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4925, 'sigma_1.25': 36.0981, 'sigma_1.25^2': 72.9863, 'sigma_1.25^3': 87.2802, 'cmp': -0.5163}\n",
      "======================================================================\n",
      "[Iter 27500 Task dept] Train Loss: 0.0139\n",
      "[Iter 27500 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 27600 Task dept] Train Loss: 0.0134\n",
      "[Iter 27600 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 27600 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4956, 'sigma_1.25': 35.9167, 'sigma_1.25^2': 72.7523, 'sigma_1.25^3': 87.0323, 'cmp': -0.5211}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 27700 Task dept] Train Loss: 0.0138\n",
      "[Iter 27700 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 27800 Task dept] Train Loss: 0.0137\n",
      "[Iter 27800 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 27800 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4904, 'sigma_1.25': 36.2751, 'sigma_1.25^2': 73.1831, 'sigma_1.25^3': 87.3563, 'cmp': -0.5137}\n",
      "======================================================================\n",
      "[Iter 27900 Task dept] Train Loss: 0.0139\n",
      "[Iter 27900 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 28000 Task dept] Train Loss: 0.0138\n",
      "[Iter 28000 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 28000 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4961, 'sigma_1.25': 36.4139, 'sigma_1.25^2': 73.1329, 'sigma_1.25^3': 87.2722, 'cmp': -0.5157}\n",
      "======================================================================\n",
      "[Iter 28100 Task dept] Train Loss: 0.0137\n",
      "[Iter 28100 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 28200 Task dept] Train Loss: 0.0137\n",
      "[Iter 28200 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 28200 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4964, 'sigma_1.25': 37.1765, 'sigma_1.25^2': 73.5652, 'sigma_1.25^3': 87.4054, 'cmp': -0.5067}\n",
      "======================================================================\n",
      "[Iter 28300 Task dept] Train Loss: 0.0136\n",
      "[Iter 28300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 28400 Task dept] Train Loss: 0.0136\n",
      "[Iter 28400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 28400 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4906, 'sigma_1.25': 36.4012, 'sigma_1.25^2': 73.2312, 'sigma_1.25^3': 87.3865, 'cmp': -0.5118}\n",
      "======================================================================\n",
      "[Iter 28500 Task dept] Train Loss: 0.0138\n",
      "[Iter 28500 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 28600 Task dept] Train Loss: 0.0138\n",
      "[Iter 28600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 28600 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4952, 'sigma_1.25': 36.6465, 'sigma_1.25^2': 73.1646, 'sigma_1.25^3': 87.3468, 'cmp': -0.5123}\n",
      "======================================================================\n",
      "[Iter 28700 Task dept] Train Loss: 0.0137\n",
      "[Iter 28700 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 28800 Task dept] Train Loss: 0.0135\n",
      "[Iter 28800 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 28800 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0405, 'rel_err': 0.498, 'sigma_1.25': 36.2361, 'sigma_1.25^2': 72.8934, 'sigma_1.25^3': 87.1912, 'cmp': -0.5189}\n",
      "======================================================================\n",
      "[Iter 28900 Task dept] Train Loss: 0.0137\n",
      "[Iter 28900 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 29000 Task dept] Train Loss: 0.0140\n",
      "[Iter 29000 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 29000 Task dept] Val Loss: 0.0242\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4889, 'sigma_1.25': 37.1184, 'sigma_1.25^2': 73.4156, 'sigma_1.25^3': 87.2926, 'cmp': -0.5034}\n",
      "======================================================================\n",
      "[Iter 29100 Task dept] Train Loss: 0.0138\n",
      "[Iter 29100 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 29200 Task dept] Train Loss: 0.0136\n",
      "[Iter 29200 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 29200 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4978, 'sigma_1.25': 36.2108, 'sigma_1.25^2': 72.9085, 'sigma_1.25^3': 87.1672, 'cmp': -0.5185}\n",
      "======================================================================\n",
      "[Iter 29300 Task dept] Train Loss: 0.0137\n",
      "[Iter 29300 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 29400 Task dept] Train Loss: 0.0136\n",
      "[Iter 29400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 29400 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4953, 'sigma_1.25': 36.7559, 'sigma_1.25^2': 73.256, 'sigma_1.25^3': 87.2177, 'cmp': -0.5109}\n",
      "======================================================================\n",
      "[Iter 29500 Task dept] Train Loss: 0.0138\n",
      "[Iter 29500 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 29600 Task dept] Train Loss: 0.0135\n",
      "[Iter 29600 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 29600 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0406, 'rel_err': 0.4935, 'sigma_1.25': 36.0879, 'sigma_1.25^2': 72.8889, 'sigma_1.25^3': 87.2391, 'cmp': -0.5178}\n",
      "======================================================================\n",
      "[Iter 29700 Task dept] Train Loss: 0.0139\n",
      "[Iter 29700 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 29800 Task dept] Train Loss: 0.0135\n",
      "[Iter 29800 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 29800 Task dept] Val Loss: 0.0256\n",
      "{'abs_err': 0.0408, 'rel_err': 0.4931, 'sigma_1.25': 35.7906, 'sigma_1.25^2': 72.8707, 'sigma_1.25^3': 87.2706, 'cmp': -0.5211}\n",
      "======================================================================\n",
      "[Iter 29900 Task dept] Train Loss: 0.0140\n",
      "[Iter 29900 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 30000 Task dept] Train Loss: 0.0134\n",
      "[Iter 30000 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 30000 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4926, 'sigma_1.25': 36.4899, 'sigma_1.25^2': 73.2149, 'sigma_1.25^3': 87.335, 'cmp': -0.5122}\n",
      "======================================================================\n",
      "[Iter 30100 Task dept] Train Loss: 0.0135\n",
      "[Iter 30100 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 30200 Task dept] Train Loss: 0.0139\n",
      "[Iter 30200 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 30200 Task dept] Val Loss: 0.0252\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4927, 'sigma_1.25': 36.233, 'sigma_1.25^2': 73.1531, 'sigma_1.25^3': 87.3263, 'cmp': -0.5149}\n",
      "======================================================================\n",
      "[Iter 30300 Task dept] Train Loss: 0.0136\n",
      "[Iter 30300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 30400 Task dept] Train Loss: 0.0136\n",
      "[Iter 30400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 30400 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4935, 'sigma_1.25': 36.2576, 'sigma_1.25^2': 73.1785, 'sigma_1.25^3': 87.3206, 'cmp': -0.5146}\n",
      "======================================================================\n",
      "[Iter 30500 Task dept] Train Loss: 0.0136\n",
      "[Iter 30500 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 30600 Task dept] Train Loss: 0.0138\n",
      "[Iter 30600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 30600 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4948, 'sigma_1.25': 36.6229, 'sigma_1.25^2': 73.4213, 'sigma_1.25^3': 87.4671, 'cmp': -0.511}\n",
      "======================================================================\n",
      "[Iter 30700 Task dept] Train Loss: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 30700 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 30800 Task dept] Train Loss: 0.0139\n",
      "[Iter 30800 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 30800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4992, 'sigma_1.25': 36.6255, 'sigma_1.25^2': 73.2033, 'sigma_1.25^3': 87.2396, 'cmp': -0.5142}\n",
      "======================================================================\n",
      "[Iter 30900 Task dept] Train Loss: 0.0138\n",
      "[Iter 30900 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 31000 Task dept] Train Loss: 0.0138\n",
      "[Iter 31000 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 31000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4997, 'sigma_1.25': 36.5447, 'sigma_1.25^2': 73.2798, 'sigma_1.25^3': 87.3936, 'cmp': -0.5147}\n",
      "======================================================================\n",
      "[Iter 31100 Task dept] Train Loss: 0.0135\n",
      "[Iter 31100 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 31200 Task dept] Train Loss: 0.0135\n",
      "[Iter 31200 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 31200 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4914, 'sigma_1.25': 36.4149, 'sigma_1.25^2': 73.3261, 'sigma_1.25^3': 87.4393, 'cmp': -0.5116}\n",
      "======================================================================\n",
      "[Iter 31300 Task dept] Train Loss: 0.0138\n",
      "[Iter 31300 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 31400 Task dept] Train Loss: 0.0139\n",
      "[Iter 31400 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 31400 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0407, 'rel_err': 0.4994, 'sigma_1.25': 35.8557, 'sigma_1.25^2': 72.8133, 'sigma_1.25^3': 87.2534, 'cmp': -0.5238}\n",
      "======================================================================\n",
      "[Iter 31500 Task dept] Train Loss: 0.0140\n",
      "[Iter 31500 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 31600 Task dept] Train Loss: 0.0136\n",
      "[Iter 31600 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 31600 Task dept] Val Loss: 0.0253\n",
      "{'abs_err': 0.0408, 'rel_err': 0.5012, 'sigma_1.25': 35.7065, 'sigma_1.25^2': 72.661, 'sigma_1.25^3': 87.1121, 'cmp': -0.5265}\n",
      "======================================================================\n",
      "[Iter 31700 Task dept] Train Loss: 0.0134\n",
      "[Iter 31700 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 31800 Task dept] Train Loss: 0.0137\n",
      "[Iter 31800 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 31800 Task dept] Val Loss: 0.0245\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4991, 'sigma_1.25': 37.2418, 'sigma_1.25^2': 73.5532, 'sigma_1.25^3': 87.3624, 'cmp': -0.507}\n",
      "======================================================================\n",
      "[Iter 31900 Task dept] Train Loss: 0.0136\n",
      "[Iter 31900 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 32000 Task dept] Train Loss: 0.0136\n",
      "[Iter 32000 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 32000 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.04, 'rel_err': 0.4955, 'sigma_1.25': 36.987, 'sigma_1.25^2': 73.5108, 'sigma_1.25^3': 87.3774, 'cmp': -0.5077}\n",
      "======================================================================\n",
      "[Iter 32100 Task dept] Train Loss: 0.0136\n",
      "[Iter 32100 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 32200 Task dept] Train Loss: 0.0137\n",
      "[Iter 32200 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 32200 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4924, 'sigma_1.25': 36.794, 'sigma_1.25^2': 73.4401, 'sigma_1.25^3': 87.4317, 'cmp': -0.5077}\n",
      "======================================================================\n",
      "[Iter 32300 Task dept] Train Loss: 0.0136\n",
      "[Iter 32300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 32400 Task dept] Train Loss: 0.0137\n",
      "[Iter 32400 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 32400 Task dept] Val Loss: 0.0251\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4939, 'sigma_1.25': 36.4485, 'sigma_1.25^2': 73.3236, 'sigma_1.25^3': 87.4691, 'cmp': -0.513}\n",
      "======================================================================\n",
      "[Iter 32500 Task dept] Train Loss: 0.0135\n",
      "[Iter 32500 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 32600 Task dept] Train Loss: 0.0138\n",
      "[Iter 32600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 32600 Task dept] Val Loss: 0.0244\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4869, 'sigma_1.25': 37.318, 'sigma_1.25^2': 73.6707, 'sigma_1.25^3': 87.4816, 'cmp': -0.5}\n",
      "======================================================================\n",
      "[Iter 32700 Task dept] Train Loss: 0.0138\n",
      "[Iter 32700 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 32800 Task dept] Train Loss: 0.0140\n",
      "[Iter 32800 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 32800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4916, 'sigma_1.25': 37.4007, 'sigma_1.25^2': 73.9106, 'sigma_1.25^3': 87.596, 'cmp': -0.5004}\n",
      "======================================================================\n",
      "[Iter 32900 Task dept] Train Loss: 0.0136\n",
      "[Iter 32900 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 33000 Task dept] Train Loss: 0.0137\n",
      "[Iter 33000 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 33000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4927, 'sigma_1.25': 36.8595, 'sigma_1.25^2': 73.6391, 'sigma_1.25^3': 87.5156, 'cmp': -0.5078}\n",
      "======================================================================\n",
      "[Iter 33100 Task dept] Train Loss: 0.0134\n",
      "[Iter 33100 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 33200 Task dept] Train Loss: 0.0135\n",
      "[Iter 33200 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 33200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0401, 'rel_err': 0.486, 'sigma_1.25': 37.0513, 'sigma_1.25^2': 73.7374, 'sigma_1.25^3': 87.6255, 'cmp': -0.5017}\n",
      "======================================================================\n",
      "[Iter 33300 Task dept] Train Loss: 0.0138\n",
      "[Iter 33300 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 33400 Task dept] Train Loss: 0.0135\n",
      "[Iter 33400 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 33400 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4938, 'sigma_1.25': 36.8117, 'sigma_1.25^2': 73.6125, 'sigma_1.25^3': 87.4829, 'cmp': -0.5086}\n",
      "======================================================================\n",
      "[Iter 33500 Task dept] Train Loss: 0.0135\n",
      "[Iter 33500 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 33600 Task dept] Train Loss: 0.0138\n",
      "[Iter 33600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 33600 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4945, 'sigma_1.25': 36.5284, 'sigma_1.25^2': 73.2105, 'sigma_1.25^3': 87.3582, 'cmp': -0.5131}\n",
      "======================================================================\n",
      "[Iter 33700 Task dept] Train Loss: 0.0137\n",
      "[Iter 33700 Total] Train Loss: 0.0137\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 33800 Task dept] Train Loss: 0.0135\n",
      "[Iter 33800 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 33800 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0404, 'rel_err': 0.4967, 'sigma_1.25': 36.3591, 'sigma_1.25^2': 73.1184, 'sigma_1.25^3': 87.3185, 'cmp': -0.5164}\n",
      "======================================================================\n",
      "[Iter 33900 Task dept] Train Loss: 0.0139\n",
      "[Iter 33900 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 34000 Task dept] Train Loss: 0.0135\n",
      "[Iter 34000 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 34000 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0405, 'rel_err': 0.5028, 'sigma_1.25': 36.1728, 'sigma_1.25^2': 72.9185, 'sigma_1.25^3': 87.1404, 'cmp': -0.5224}\n",
      "======================================================================\n",
      "[Iter 34100 Task dept] Train Loss: 0.0137\n",
      "[Iter 34100 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 34200 Task dept] Train Loss: 0.0135\n",
      "[Iter 34200 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 34200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0403, 'rel_err': 0.5064, 'sigma_1.25': 36.5195, 'sigma_1.25^2': 73.1582, 'sigma_1.25^3': 87.1469, 'cmp': -0.5202}\n",
      "======================================================================\n",
      "[Iter 34300 Task dept] Train Loss: 0.0136\n",
      "[Iter 34300 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 34400 Task dept] Train Loss: 0.0136\n",
      "[Iter 34400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 34400 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.04, 'rel_err': 0.4979, 'sigma_1.25': 36.8175, 'sigma_1.25^2': 73.5258, 'sigma_1.25^3': 87.4609, 'cmp': -0.5102}\n",
      "======================================================================\n",
      "[Iter 34500 Task dept] Train Loss: 0.0136\n",
      "[Iter 34500 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 34600 Task dept] Train Loss: 0.0135\n",
      "[Iter 34600 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 34600 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4971, 'sigma_1.25': 36.6216, 'sigma_1.25^2': 73.3941, 'sigma_1.25^3': 87.3453, 'cmp': -0.5125}\n",
      "======================================================================\n",
      "[Iter 34700 Task dept] Train Loss: 0.0136\n",
      "[Iter 34700 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 34800 Task dept] Train Loss: 0.0140\n",
      "[Iter 34800 Total] Train Loss: 0.0140\n",
      "======================================================================\n",
      "[Iter 34800 Task dept] Val Loss: 0.0245\n",
      "{'abs_err': 0.04, 'rel_err': 0.4915, 'sigma_1.25': 36.9361, 'sigma_1.25^2': 73.5117, 'sigma_1.25^3': 87.4297, 'cmp': -0.5058}\n",
      "======================================================================\n",
      "[Iter 34900 Task dept] Train Loss: 0.0137\n",
      "[Iter 34900 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 35000 Task dept] Train Loss: 0.0136\n",
      "[Iter 35000 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 35000 Task dept] Val Loss: 0.0242\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4913, 'sigma_1.25': 37.3014, 'sigma_1.25^2': 73.716, 'sigma_1.25^3': 87.4905, 'cmp': -0.5022}\n",
      "======================================================================\n",
      "[Iter 35100 Task dept] Train Loss: 0.0136\n",
      "[Iter 35100 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 35200 Task dept] Train Loss: 0.0130\n",
      "[Iter 35200 Total] Train Loss: 0.0130\n",
      "======================================================================\n",
      "[Iter 35200 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.04, 'rel_err': 0.4901, 'sigma_1.25': 37.1064, 'sigma_1.25^2': 73.7145, 'sigma_1.25^3': 87.5359, 'cmp': -0.5032}\n",
      "======================================================================\n",
      "[Iter 35300 Task dept] Train Loss: 0.0135\n",
      "[Iter 35300 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 35400 Task dept] Train Loss: 0.0135\n",
      "[Iter 35400 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 35400 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4979, 'sigma_1.25': 36.6569, 'sigma_1.25^2': 73.4583, 'sigma_1.25^3': 87.4517, 'cmp': -0.5131}\n",
      "======================================================================\n",
      "[Iter 35500 Task dept] Train Loss: 0.0138\n",
      "[Iter 35500 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 35600 Task dept] Train Loss: 0.0136\n",
      "[Iter 35600 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 35600 Task dept] Val Loss: 0.0244\n",
      "{'abs_err': 0.0398, 'rel_err': 0.4982, 'sigma_1.25': 37.3719, 'sigma_1.25^2': 73.6468, 'sigma_1.25^3': 87.4236, 'cmp': -0.5055}\n",
      "======================================================================\n",
      "[Iter 35700 Task dept] Train Loss: 0.0137\n",
      "[Iter 35700 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 35800 Task dept] Train Loss: 0.0134\n",
      "[Iter 35800 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 35800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.04, 'rel_err': 0.4985, 'sigma_1.25': 37.0788, 'sigma_1.25^2': 73.6657, 'sigma_1.25^3': 87.4301, 'cmp': -0.5086}\n",
      "======================================================================\n",
      "[Iter 35900 Task dept] Train Loss: 0.0135\n",
      "[Iter 35900 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 36000 Task dept] Train Loss: 0.0134\n",
      "[Iter 36000 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 36000 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4894, 'sigma_1.25': 36.4988, 'sigma_1.25^2': 73.4074, 'sigma_1.25^3': 87.4797, 'cmp': -0.5094}\n",
      "======================================================================\n",
      "[Iter 36100 Task dept] Train Loss: 0.0135\n",
      "[Iter 36100 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 36200 Task dept] Train Loss: 0.0136\n",
      "[Iter 36200 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 36200 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4928, 'sigma_1.25': 36.6191, 'sigma_1.25^2': 73.3952, 'sigma_1.25^3': 87.4259, 'cmp': -0.5106}\n",
      "======================================================================\n",
      "[Iter 36300 Task dept] Train Loss: 0.0135\n",
      "[Iter 36300 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 36400 Task dept] Train Loss: 0.0136\n",
      "[Iter 36400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 36400 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4995, 'sigma_1.25': 36.845, 'sigma_1.25^2': 73.4059, 'sigma_1.25^3': 87.3479, 'cmp': -0.5128}\n",
      "======================================================================\n",
      "[Iter 36500 Task dept] Train Loss: 0.0138\n",
      "[Iter 36500 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 36600 Task dept] Train Loss: 0.0138\n",
      "[Iter 36600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 36600 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4906, 'sigma_1.25': 36.4739, 'sigma_1.25^2': 73.2477, 'sigma_1.25^3': 87.2894, 'cmp': -0.5114}\n",
      "======================================================================\n",
      "[Iter 36700 Task dept] Train Loss: 0.0133\n",
      "[Iter 36700 Total] Train Loss: 0.0133\n",
      "======================================================================\n",
      "[Iter 36800 Task dept] Train Loss: 0.0135\n",
      "[Iter 36800 Total] Train Loss: 0.0135\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 36800 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0404, 'rel_err': 0.5021, 'sigma_1.25': 36.3434, 'sigma_1.25^2': 73.0756, 'sigma_1.25^3': 87.1722, 'cmp': -0.5202}\n",
      "======================================================================\n",
      "[Iter 36900 Task dept] Train Loss: 0.0139\n",
      "[Iter 36900 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 37000 Task dept] Train Loss: 0.0136\n",
      "[Iter 37000 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 37000 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4979, 'sigma_1.25': 37.0931, 'sigma_1.25^2': 73.5569, 'sigma_1.25^3': 87.382, 'cmp': -0.5079}\n",
      "======================================================================\n",
      "[Iter 37100 Task dept] Train Loss: 0.0135\n",
      "[Iter 37100 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 37200 Task dept] Train Loss: 0.0135\n",
      "[Iter 37200 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 37200 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4973, 'sigma_1.25': 36.7245, 'sigma_1.25^2': 73.3463, 'sigma_1.25^3': 87.3391, 'cmp': -0.5121}\n",
      "======================================================================\n",
      "[Iter 37300 Task dept] Train Loss: 0.0138\n",
      "[Iter 37300 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 37400 Task dept] Train Loss: 0.0134\n",
      "[Iter 37400 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 37400 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0401, 'rel_err': 0.4941, 'sigma_1.25': 36.778, 'sigma_1.25^2': 73.4547, 'sigma_1.25^3': 87.4314, 'cmp': -0.5094}\n",
      "======================================================================\n",
      "[Iter 37500 Task dept] Train Loss: 0.0135\n",
      "[Iter 37500 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 37600 Task dept] Train Loss: 0.0135\n",
      "[Iter 37600 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 37600 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4876, 'sigma_1.25': 36.6247, 'sigma_1.25^2': 73.4682, 'sigma_1.25^3': 87.462, 'cmp': -0.5073}\n",
      "======================================================================\n",
      "[Iter 37700 Task dept] Train Loss: 0.0135\n",
      "[Iter 37700 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 37800 Task dept] Train Loss: 0.0133\n",
      "[Iter 37800 Total] Train Loss: 0.0133\n",
      "======================================================================\n",
      "[Iter 37800 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4903, 'sigma_1.25': 36.5925, 'sigma_1.25^2': 73.4453, 'sigma_1.25^3': 87.4798, 'cmp': -0.5094}\n",
      "======================================================================\n",
      "[Iter 37900 Task dept] Train Loss: 0.0136\n",
      "[Iter 37900 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 38000 Task dept] Train Loss: 0.0135\n",
      "[Iter 38000 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 38000 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4947, 'sigma_1.25': 36.667, 'sigma_1.25^2': 73.4547, 'sigma_1.25^3': 87.4, 'cmp': -0.5107}\n",
      "======================================================================\n",
      "[Iter 38100 Task dept] Train Loss: 0.0134\n",
      "[Iter 38100 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 38200 Task dept] Train Loss: 0.0136\n",
      "[Iter 38200 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 38200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0401, 'rel_err': 0.494, 'sigma_1.25': 36.88, 'sigma_1.25^2': 73.5372, 'sigma_1.25^3': 87.4315, 'cmp': -0.5086}\n",
      "======================================================================\n",
      "[Iter 38300 Task dept] Train Loss: 0.0139\n",
      "[Iter 38300 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 38400 Task dept] Train Loss: 0.0136\n",
      "[Iter 38400 Total] Train Loss: 0.0136\n",
      "======================================================================\n",
      "[Iter 38400 Task dept] Val Loss: 0.0249\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4968, 'sigma_1.25': 36.458, 'sigma_1.25^2': 73.225, 'sigma_1.25^3': 87.3259, 'cmp': -0.5147}\n",
      "======================================================================\n",
      "[Iter 38500 Task dept] Train Loss: 0.0138\n",
      "[Iter 38500 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 38600 Task dept] Train Loss: 0.0137\n",
      "[Iter 38600 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 38600 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4973, 'sigma_1.25': 36.6216, 'sigma_1.25^2': 73.2193, 'sigma_1.25^3': 87.2992, 'cmp': -0.5137}\n",
      "======================================================================\n",
      "[Iter 38700 Task dept] Train Loss: 0.0135\n",
      "[Iter 38700 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 38800 Task dept] Train Loss: 0.0134\n",
      "[Iter 38800 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 38800 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4876, 'sigma_1.25': 36.6962, 'sigma_1.25^2': 73.3942, 'sigma_1.25^3': 87.4659, 'cmp': -0.5067}\n",
      "======================================================================\n",
      "[Iter 38900 Task dept] Train Loss: 0.0134\n",
      "[Iter 38900 Total] Train Loss: 0.0134\n",
      "======================================================================\n",
      "[Iter 39000 Task dept] Train Loss: 0.0135\n",
      "[Iter 39000 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 39000 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0402, 'rel_err': 0.5, 'sigma_1.25': 36.6831, 'sigma_1.25^2': 73.2371, 'sigma_1.25^3': 87.3193, 'cmp': -0.5147}\n",
      "======================================================================\n",
      "[Iter 39100 Task dept] Train Loss: 0.0138\n",
      "[Iter 39100 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 39200 Task dept] Train Loss: 0.0132\n",
      "[Iter 39200 Total] Train Loss: 0.0132\n",
      "======================================================================\n",
      "[Iter 39200 Task dept] Val Loss: 0.0248\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4962, 'sigma_1.25': 36.5739, 'sigma_1.25^2': 73.3055, 'sigma_1.25^3': 87.3463, 'cmp': -0.513}\n",
      "======================================================================\n",
      "[Iter 39300 Task dept] Train Loss: 0.0137\n",
      "[Iter 39300 Total] Train Loss: 0.0137\n",
      "======================================================================\n",
      "[Iter 39400 Task dept] Train Loss: 0.0135\n",
      "[Iter 39400 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 39400 Task dept] Val Loss: 0.0247\n",
      "{'abs_err': 0.0403, 'rel_err': 0.4911, 'sigma_1.25': 36.5607, 'sigma_1.25^2': 73.2152, 'sigma_1.25^3': 87.345, 'cmp': -0.5109}\n",
      "======================================================================\n",
      "[Iter 39500 Task dept] Train Loss: 0.0135\n",
      "[Iter 39500 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 39600 Task dept] Train Loss: 0.0138\n",
      "[Iter 39600 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 39600 Task dept] Val Loss: 0.0242\n",
      "{'abs_err': 0.0399, 'rel_err': 0.4978, 'sigma_1.25': 37.1965, 'sigma_1.25^2': 73.3512, 'sigma_1.25^3': 87.3096, 'cmp': -0.5086}\n",
      "======================================================================\n",
      "[Iter 39700 Task dept] Train Loss: 0.0138\n",
      "[Iter 39700 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 39800 Task dept] Train Loss: 0.0135\n",
      "[Iter 39800 Total] Train Loss: 0.0135\n",
      "======================================================================\n",
      "[Iter 39800 Task dept] Val Loss: 0.0250\n",
      "{'abs_err': 0.0405, 'rel_err': 0.4937, 'sigma_1.25': 36.321, 'sigma_1.25^2': 73.1327, 'sigma_1.25^3': 87.2389, 'cmp': -0.5155}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 39900 Task dept] Train Loss: 0.0139\n",
      "[Iter 39900 Total] Train Loss: 0.0139\n",
      "======================================================================\n",
      "[Iter 40000 Task dept] Train Loss: 0.0138\n",
      "[Iter 40000 Total] Train Loss: 0.0138\n",
      "======================================================================\n",
      "[Iter 40000 Task dept] Val Loss: 0.0246\n",
      "{'abs_err': 0.0402, 'rel_err': 0.4922, 'sigma_1.25': 36.7302, 'sigma_1.25^2': 73.3696, 'sigma_1.25^3': 87.3876, 'cmp': -0.5093}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# STL\n",
    "trainer.stl_hard_sharing(iters=40000, task=tasks[1], lr=0.001, savePath='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-mnasnet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-training/' + 'alter_train_with_reg_bottom_0_20000iter.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cityscapes 2 tasks\n",
    "reg = 0\n",
    "scale = 0.1\n",
    "policy_list = {'segment_semantic': [], 'depth_zbuffer': []}\n",
    "for name, param in mtlmodel.named_parameters():\n",
    "    if 'policy' in name and not torch.eq(param, torch.tensor([0., 0., 0.]).cuda()).all():\n",
    "        policy = param.data.cpu().detach().numpy()\n",
    "        distribution = softmax(policy, axis=-1)\n",
    "        if 'segment_semantic' in name:\n",
    "            policy_list['segment_semantic'].append(distribution)\n",
    "            reg += np.exp(scale*(distribution[1]-distribution[0])) + np.exp(scale*(distribution[2]-distribution[0]))\n",
    "        elif 'depth_zbuffer' in name:\n",
    "            policy_list['depth_zbuffer'].append(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': [array([0.81585205, 0.12374424, 0.06040373], dtype=float32),\n",
       "  array([0.758998  , 0.21949278, 0.02150919], dtype=float32),\n",
       "  array([0.8140948 , 0.14867303, 0.03723225], dtype=float32),\n",
       "  array([0.8038684 , 0.14644457, 0.04968708], dtype=float32),\n",
       "  array([0.7577983 , 0.162201  , 0.08000076], dtype=float32),\n",
       "  array([0.77264184, 0.14677525, 0.08058287], dtype=float32),\n",
       "  array([0.7542199 , 0.1509845 , 0.09479564], dtype=float32),\n",
       "  array([0.7384771 , 0.16428354, 0.09723931], dtype=float32),\n",
       "  array([0.82094985, 0.12500876, 0.05404134], dtype=float32),\n",
       "  array([0.83006936, 0.14355645, 0.02637413], dtype=float32),\n",
       "  array([0.7831882 , 0.13583544, 0.08097637], dtype=float32),\n",
       "  array([0.77991194, 0.1456214 , 0.07446675], dtype=float32),\n",
       "  array([0.7290306 , 0.14990358, 0.12106574], dtype=float32),\n",
       "  array([0.71494323, 0.1690584 , 0.11599829], dtype=float32),\n",
       "  array([0.6406387 , 0.1868925 , 0.17246875], dtype=float32),\n",
       "  array([0.66410047, 0.19099551, 0.14490391], dtype=float32),\n",
       "  array([0.74907494, 0.17034058, 0.08058447], dtype=float32),\n",
       "  array([0.740306  , 0.19359681, 0.06609716], dtype=float32),\n",
       "  array([0.809907  , 0.16535321, 0.02473975], dtype=float32),\n",
       "  array([0.7281919 , 0.18989214, 0.08191593], dtype=float32),\n",
       "  array([0.69667655, 0.19733478, 0.10598876], dtype=float32),\n",
       "  array([0.6247592, 0.2041171, 0.1711238], dtype=float32),\n",
       "  array([0.5731949 , 0.21680433, 0.2100008 ], dtype=float32),\n",
       "  array([0.5424828 , 0.23999496, 0.2175222 ], dtype=float32),\n",
       "  array([0.533945  , 0.23775573, 0.22829914], dtype=float32),\n",
       "  array([0.54798996, 0.24167444, 0.21033554], dtype=float32),\n",
       "  array([0.46368742, 0.24777532, 0.28853717], dtype=float32),\n",
       "  array([0.46293792, 0.27082127, 0.26624072], dtype=float32),\n",
       "  array([0.44321838, 0.2743459 , 0.28243575], dtype=float32),\n",
       "  array([0.75119185, 0.17449576, 0.07431234], dtype=float32),\n",
       "  array([0.5238558 , 0.31142938, 0.16471472], dtype=float32),\n",
       "  array([0.52270436, 0.32587835, 0.15141736], dtype=float32),\n",
       "  array([0.51559645, 0.37411636, 0.11028731], dtype=float32),\n",
       "  array([0.48642665, 0.3777132 , 0.13586012], dtype=float32),\n",
       "  array([0.41643175, 0.35474065, 0.2288275 ], dtype=float32),\n",
       "  array([0.36576   , 0.39431527, 0.23992476], dtype=float32)],\n",
       " 'depth_zbuffer': [array([0.75842774, 0.12196152, 0.11961082], dtype=float32),\n",
       "  array([0.7248882 , 0.14383735, 0.13127442], dtype=float32),\n",
       "  array([0.75117165, 0.12976457, 0.11906371], dtype=float32),\n",
       "  array([0.69116044, 0.15722056, 0.15161908], dtype=float32),\n",
       "  array([0.70826685, 0.14974841, 0.14198475], dtype=float32),\n",
       "  array([0.69195515, 0.1541509 , 0.1538939 ], dtype=float32),\n",
       "  array([0.6974007 , 0.15037553, 0.15222375], dtype=float32),\n",
       "  array([0.67768544, 0.15555291, 0.1667617 ], dtype=float32),\n",
       "  array([0.6801322 , 0.15737437, 0.16249341], dtype=float32),\n",
       "  array([0.70982563, 0.15857132, 0.13160306], dtype=float32),\n",
       "  array([0.6844135 , 0.16022733, 0.15535924], dtype=float32),\n",
       "  array([0.6466189 , 0.17619956, 0.1771815 ], dtype=float32),\n",
       "  array([0.6565433 , 0.16829756, 0.17515908], dtype=float32),\n",
       "  array([0.63917255, 0.1809921 , 0.17983532], dtype=float32),\n",
       "  array([0.6214819 , 0.19288002, 0.18563809], dtype=float32),\n",
       "  array([0.61406505, 0.19353533, 0.19239971], dtype=float32),\n",
       "  array([0.5939304 , 0.20325392, 0.20281576], dtype=float32),\n",
       "  array([0.63639253, 0.19392785, 0.16967954], dtype=float32),\n",
       "  array([0.6578581 , 0.18655041, 0.15559141], dtype=float32),\n",
       "  array([0.587468  , 0.21255976, 0.1999722 ], dtype=float32),\n",
       "  array([0.5648078 , 0.21533857, 0.21985361], dtype=float32),\n",
       "  array([0.5682023 , 0.21626413, 0.21553351], dtype=float32),\n",
       "  array([0.524717  , 0.2346869 , 0.24059613], dtype=float32),\n",
       "  array([0.5253877 , 0.23669891, 0.23791331], dtype=float32),\n",
       "  array([0.517285  , 0.2385556 , 0.24415955], dtype=float32),\n",
       "  array([0.4910428 , 0.25478855, 0.25416866], dtype=float32),\n",
       "  array([0.4652436 , 0.27178052, 0.26297584], dtype=float32),\n",
       "  array([0.46208128, 0.2700507 , 0.26786807], dtype=float32),\n",
       "  array([0.42745477, 0.28622383, 0.28632137], dtype=float32),\n",
       "  array([0.44323626, 0.25200614, 0.3047576 ], dtype=float32),\n",
       "  array([0.4687049 , 0.2892273 , 0.24206784], dtype=float32),\n",
       "  array([0.47227907, 0.31045905, 0.21726198], dtype=float32),\n",
       "  array([0.41947794, 0.3166095 , 0.2639126 ], dtype=float32),\n",
       "  array([0.42605913, 0.29918975, 0.27475113], dtype=float32),\n",
       "  array([0.37261498, 0.32401624, 0.30336884], dtype=float32),\n",
       "  array([0.3662574 , 0.33545798, 0.29828462], dtype=float32)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph(comment='Policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make nodes\n",
    "layer_num = len(policy_list['segment_semantic'])\n",
    "for i in range(layer_num):\n",
    "    with dot.subgraph(name='cluster_L'+str(i),node_attr={'rank':'same'}) as c:\n",
    "        c.attr(rankdir='LR')\n",
    "        c.node('L'+str(i)+'B0', 'Shared')\n",
    "        c.node('L'+str(i)+'B1', 'Specific')\n",
    "        c.node('L'+str(i)+'B2', 'Skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make edges\n",
    "colors = {'segment_semantic': 'blue', 'depth_zbuffer': 'red'}\n",
    "for task in tasks:\n",
    "    for i in range(layer_num-1):\n",
    "        prev = np.argmax(policy_list[task][i])\n",
    "        nxt = np.argmax(policy_list[task][i+1])\n",
    "        dot.edge('L'+str(i)+'B'+str(prev), 'L'+str(i+1)+'B'+str(nxt), color=colors[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Policy\n",
      "digraph {\n",
      "\tsubgraph cluster_L0 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL0B0 [label=Shared]\n",
      "\t\tL0B1 [label=Specific]\n",
      "\t\tL0B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L1 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL1B0 [label=Shared]\n",
      "\t\tL1B1 [label=Specific]\n",
      "\t\tL1B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L2 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL2B0 [label=Shared]\n",
      "\t\tL2B1 [label=Specific]\n",
      "\t\tL2B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L3 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL3B0 [label=Shared]\n",
      "\t\tL3B1 [label=Specific]\n",
      "\t\tL3B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L4 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL4B0 [label=Shared]\n",
      "\t\tL4B1 [label=Specific]\n",
      "\t\tL4B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L5 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL5B0 [label=Shared]\n",
      "\t\tL5B1 [label=Specific]\n",
      "\t\tL5B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L6 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL6B0 [label=Shared]\n",
      "\t\tL6B1 [label=Specific]\n",
      "\t\tL6B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L7 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL7B0 [label=Shared]\n",
      "\t\tL7B1 [label=Specific]\n",
      "\t\tL7B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L8 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL8B0 [label=Shared]\n",
      "\t\tL8B1 [label=Specific]\n",
      "\t\tL8B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L9 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL9B0 [label=Shared]\n",
      "\t\tL9B1 [label=Specific]\n",
      "\t\tL9B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L10 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL10B0 [label=Shared]\n",
      "\t\tL10B1 [label=Specific]\n",
      "\t\tL10B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L11 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL11B0 [label=Shared]\n",
      "\t\tL11B1 [label=Specific]\n",
      "\t\tL11B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L12 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL12B0 [label=Shared]\n",
      "\t\tL12B1 [label=Specific]\n",
      "\t\tL12B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L13 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL13B0 [label=Shared]\n",
      "\t\tL13B1 [label=Specific]\n",
      "\t\tL13B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L14 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL14B0 [label=Shared]\n",
      "\t\tL14B1 [label=Specific]\n",
      "\t\tL14B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L15 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL15B0 [label=Shared]\n",
      "\t\tL15B1 [label=Specific]\n",
      "\t\tL15B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L16 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL16B0 [label=Shared]\n",
      "\t\tL16B1 [label=Specific]\n",
      "\t\tL16B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L17 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL17B0 [label=Shared]\n",
      "\t\tL17B1 [label=Specific]\n",
      "\t\tL17B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L18 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL18B0 [label=Shared]\n",
      "\t\tL18B1 [label=Specific]\n",
      "\t\tL18B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L19 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL19B0 [label=Shared]\n",
      "\t\tL19B1 [label=Specific]\n",
      "\t\tL19B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L20 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL20B0 [label=Shared]\n",
      "\t\tL20B1 [label=Specific]\n",
      "\t\tL20B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L21 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL21B0 [label=Shared]\n",
      "\t\tL21B1 [label=Specific]\n",
      "\t\tL21B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L22 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL22B0 [label=Shared]\n",
      "\t\tL22B1 [label=Specific]\n",
      "\t\tL22B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L23 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL23B0 [label=Shared]\n",
      "\t\tL23B1 [label=Specific]\n",
      "\t\tL23B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L24 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL24B0 [label=Shared]\n",
      "\t\tL24B1 [label=Specific]\n",
      "\t\tL24B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L25 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL25B0 [label=Shared]\n",
      "\t\tL25B1 [label=Specific]\n",
      "\t\tL25B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L26 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL26B0 [label=Shared]\n",
      "\t\tL26B1 [label=Specific]\n",
      "\t\tL26B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L27 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL27B0 [label=Shared]\n",
      "\t\tL27B1 [label=Specific]\n",
      "\t\tL27B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L28 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL28B0 [label=Shared]\n",
      "\t\tL28B1 [label=Specific]\n",
      "\t\tL28B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L29 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL29B0 [label=Shared]\n",
      "\t\tL29B1 [label=Specific]\n",
      "\t\tL29B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L30 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL30B0 [label=Shared]\n",
      "\t\tL30B1 [label=Specific]\n",
      "\t\tL30B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L31 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL31B0 [label=Shared]\n",
      "\t\tL31B1 [label=Specific]\n",
      "\t\tL31B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L32 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL32B0 [label=Shared]\n",
      "\t\tL32B1 [label=Specific]\n",
      "\t\tL32B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L33 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL33B0 [label=Shared]\n",
      "\t\tL33B1 [label=Specific]\n",
      "\t\tL33B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L34 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL34B0 [label=Shared]\n",
      "\t\tL34B1 [label=Specific]\n",
      "\t\tL34B2 [label=Skip]\n",
      "\t}\n",
      "\tsubgraph cluster_L35 {\n",
      "\t\tnode [rank=same]\n",
      "\t\trankdir=LR\n",
      "\t\tL35B0 [label=Shared]\n",
      "\t\tL35B1 [label=Specific]\n",
      "\t\tL35B2 [label=Skip]\n",
      "\t}\n",
      "\tL0B0 -> L1B1 [color=blue]\n",
      "\tL1B1 -> L2B1 [color=blue]\n",
      "\tL2B1 -> L3B1 [color=blue]\n",
      "\tL3B1 -> L4B1 [color=blue]\n",
      "\tL4B1 -> L5B1 [color=blue]\n",
      "\tL5B1 -> L6B2 [color=blue]\n",
      "\tL6B2 -> L7B1 [color=blue]\n",
      "\tL7B1 -> L8B0 [color=blue]\n",
      "\tL8B0 -> L9B1 [color=blue]\n",
      "\tL9B1 -> L10B0 [color=blue]\n",
      "\tL10B0 -> L11B0 [color=blue]\n",
      "\tL11B0 -> L12B0 [color=blue]\n",
      "\tL12B0 -> L13B1 [color=blue]\n",
      "\tL13B1 -> L14B0 [color=blue]\n",
      "\tL14B0 -> L15B0 [color=blue]\n",
      "\tL15B0 -> L16B2 [color=blue]\n",
      "\tL16B2 -> L17B0 [color=blue]\n",
      "\tL17B0 -> L18B0 [color=blue]\n",
      "\tL18B0 -> L19B0 [color=blue]\n",
      "\tL19B0 -> L20B0 [color=blue]\n",
      "\tL20B0 -> L21B1 [color=blue]\n",
      "\tL21B1 -> L22B1 [color=blue]\n",
      "\tL22B1 -> L23B1 [color=blue]\n",
      "\tL23B1 -> L24B1 [color=blue]\n",
      "\tL24B1 -> L25B2 [color=blue]\n",
      "\tL25B2 -> L26B0 [color=blue]\n",
      "\tL26B0 -> L27B0 [color=blue]\n",
      "\tL27B0 -> L28B0 [color=blue]\n",
      "\tL28B0 -> L29B0 [color=blue]\n",
      "\tL29B0 -> L30B2 [color=blue]\n",
      "\tL30B2 -> L31B1 [color=blue]\n",
      "\tL31B1 -> L32B1 [color=blue]\n",
      "\tL32B1 -> L33B1 [color=blue]\n",
      "\tL33B1 -> L34B1 [color=blue]\n",
      "\tL34B1 -> L35B0 [color=blue]\n",
      "\tL0B1 -> L1B0 [color=red]\n",
      "\tL1B0 -> L2B1 [color=red]\n",
      "\tL2B1 -> L3B1 [color=red]\n",
      "\tL3B1 -> L4B0 [color=red]\n",
      "\tL4B0 -> L5B0 [color=red]\n",
      "\tL5B0 -> L6B2 [color=red]\n",
      "\tL6B2 -> L7B1 [color=red]\n",
      "\tL7B1 -> L8B1 [color=red]\n",
      "\tL8B1 -> L9B0 [color=red]\n",
      "\tL9B0 -> L10B2 [color=red]\n",
      "\tL10B2 -> L11B0 [color=red]\n",
      "\tL11B0 -> L12B2 [color=red]\n",
      "\tL12B2 -> L13B0 [color=red]\n",
      "\tL13B0 -> L14B2 [color=red]\n",
      "\tL14B2 -> L15B2 [color=red]\n",
      "\tL15B2 -> L16B1 [color=red]\n",
      "\tL16B1 -> L17B0 [color=red]\n",
      "\tL17B0 -> L18B0 [color=red]\n",
      "\tL18B0 -> L19B1 [color=red]\n",
      "\tL19B1 -> L20B0 [color=red]\n",
      "\tL20B0 -> L21B1 [color=red]\n",
      "\tL21B1 -> L22B0 [color=red]\n",
      "\tL22B0 -> L23B2 [color=red]\n",
      "\tL23B2 -> L24B0 [color=red]\n",
      "\tL24B0 -> L25B0 [color=red]\n",
      "\tL25B0 -> L26B2 [color=red]\n",
      "\tL26B2 -> L27B0 [color=red]\n",
      "\tL27B0 -> L28B2 [color=red]\n",
      "\tL28B2 -> L29B2 [color=red]\n",
      "\tL29B2 -> L30B0 [color=red]\n",
      "\tL30B0 -> L31B0 [color=red]\n",
      "\tL31B0 -> L32B2 [color=red]\n",
      "\tL32B2 -> L33B0 [color=red]\n",
      "\tL33B0 -> L34B2 [color=red]\n",
      "\tL34B2 -> L35B2 [color=red]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dot.source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policy/temp.gv.pdf'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render('policy/temp.gv', view=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab6adb3d30>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rgbnorm(rgb):\n",
    "    rgb -= rgb.min()\n",
    "    rgb /= rgb.max()+0.01\n",
    "    return rgb\n",
    "\n",
    "spectrum_list = []\n",
    "for task in tasks:\n",
    "    policies = policy_list[task]    \n",
    "    spectrum = np.stack([rgbnorm(policy) for policy in policies])\n",
    "    spectrum = np.repeat(spectrum[np.newaxis,:,:],1,axis=0)\n",
    "    spectrum_list.append(spectrum)\n",
    "plt.figure(figsize=(16,2))\n",
    "plt.imshow(np.concatenate(spectrum_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab62b3c2b0>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spectrum_list = []\n",
    "for task in tasks:\n",
    "    policies = policy_list[task]   \n",
    "    idx = np.argmax(policies,axis=1)\n",
    "    spectrum = np.zeros([len(idx),3])\n",
    "    spectrum[np.arange(len(idx)),idx] = 1.0\n",
    "    spectrum[np.arange(len(idx)),(idx+1)%3] = 0.2\n",
    "    spectrum = np.repeat(spectrum[np.newaxis,:,:],1,axis=0)\n",
    "    spectrum_list.append(spectrum)\n",
    "\n",
    "plt.figure(figsize=(16,2))\n",
    "plt.imshow(np.concatenate(spectrum_list,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-mnasnet/' + 'alter_train_with_reg_0005_20000iter.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_list = {'segment_semantic': [], 'depth_zbuffer': []}\n",
    "name_list = {'segment_semantic': [], 'depth_zbuffer': []}\n",
    "for name, param in mtlmodel.named_parameters():\n",
    "    if 'policy' in name and not torch.eq(param, torch.tensor([0., 0., 0.]).cuda()).all():\n",
    "        if 'segment_semantic' in name:\n",
    "            policy_list['segment_semantic'].append(param.data.cpu().detach().numpy())\n",
    "            name_list['segment_semantic'].append(name)\n",
    "        elif 'depth_zbuffer' in name:\n",
    "            policy_list['depth_zbuffer'].append(param.data.cpu().detach().numpy())\n",
    "            name_list['depth_zbuffer'].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(98)\n",
    "\n",
    "# shuffle from existed policy randomly\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    temp = policy_list[task].copy()\n",
    "    random.shuffle(temp)\n",
    "    \n",
    "    count = 0\n",
    "    for name in name_list[task]:\n",
    "        random_policy_dict[name] = torch.tensor(temp[count]).cuda()\n",
    "        count += 1\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, 'checkpoints/Cityscapes/' + 'random_policy_as_task_alter_train_13600iter_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(98)\n",
    "\n",
    "# random initilization\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    for name in name_list[task]:\n",
    "        random_policy_dict[name] = torch.rand(3).cuda()\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, 'checkpoints/Cityscapes/' + 'random_policy_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(98)\n",
    "\n",
    "# The first 20 Conv to be shared\n",
    "shared = 20\n",
    "random_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    count = 0\n",
    "    for name in name_list[task]:\n",
    "        if count < shared:\n",
    "            random_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        else:\n",
    "            random_policy_dict[name] = torch.rand(3).cuda()\n",
    "        count += 1\n",
    "random_state = {'state_dict': random_policy_dict}\n",
    "torch.save(random_state, '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes-mnasnet/' + 'random_policy_with_bottom20_shared_seed98.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "\n",
    "# sample from trained policy\n",
    "sample_policy_dict = OrderedDict()\n",
    "for task in tasks:\n",
    "    for name, policy in zip(name_list[task], policy_list[task]):\n",
    "        distribution = softmax(policy, axis=-1)\n",
    "        choice = np.random.choice((0,1,2), p=distribution)\n",
    "        if choice == 0:\n",
    "            sample_policy_dict[name] = torch.tensor([1.0,0.0,0.0]).cuda()\n",
    "        elif choice == 1:\n",
    "            sample_policy_dict[name] = torch.tensor([0.0,1.0,0.0]).cuda()\n",
    "        elif choice == 2:\n",
    "            sample_policy_dict[name] = torch.tensor([0.0,0.0,1.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['headsDict.segment_semantic.fc1.conv1.weight', 'headsDict.segment_semantic.fc1.conv1.bias', 'headsDict.segment_semantic.fc1.conv2.weight', 'headsDict.segment_semantic.fc1.conv2.bias', 'headsDict.segment_semantic.fc1.conv3.weight', 'headsDict.segment_semantic.fc1.conv3.bias', 'headsDict.segment_semantic.fc2.conv1.weight', 'headsDict.segment_semantic.fc2.conv1.bias', 'headsDict.segment_semantic.fc2.conv2.weight', 'headsDict.segment_semantic.fc2.conv2.bias', 'headsDict.segment_semantic.fc2.conv3.weight', 'headsDict.segment_semantic.fc2.conv3.bias', 'headsDict.segment_semantic.fc3.conv1.weight', 'headsDict.segment_semantic.fc3.conv1.bias', 'headsDict.segment_semantic.fc3.conv2.weight', 'headsDict.segment_semantic.fc3.conv2.bias', 'headsDict.segment_semantic.fc3.conv3.weight', 'headsDict.segment_semantic.fc3.conv3.bias', 'headsDict.segment_semantic.fc4.conv1.weight', 'headsDict.segment_semantic.fc4.conv1.bias', 'headsDict.segment_semantic.fc4.conv2.weight', 'headsDict.segment_semantic.fc4.conv2.bias', 'headsDict.segment_semantic.fc4.conv3.weight', 'headsDict.segment_semantic.fc4.conv3.bias', 'headsDict.depth_zbuffer.fc1.conv1.weight', 'headsDict.depth_zbuffer.fc1.conv1.bias', 'headsDict.depth_zbuffer.fc1.conv2.weight', 'headsDict.depth_zbuffer.fc1.conv2.bias', 'headsDict.depth_zbuffer.fc1.conv3.weight', 'headsDict.depth_zbuffer.fc1.conv3.bias', 'headsDict.depth_zbuffer.fc2.conv1.weight', 'headsDict.depth_zbuffer.fc2.conv1.bias', 'headsDict.depth_zbuffer.fc2.conv2.weight', 'headsDict.depth_zbuffer.fc2.conv2.bias', 'headsDict.depth_zbuffer.fc2.conv3.weight', 'headsDict.depth_zbuffer.fc2.conv3.bias', 'headsDict.depth_zbuffer.fc3.conv1.weight', 'headsDict.depth_zbuffer.fc3.conv1.bias', 'headsDict.depth_zbuffer.fc3.conv2.weight', 'headsDict.depth_zbuffer.fc3.conv2.bias', 'headsDict.depth_zbuffer.fc3.conv3.weight', 'headsDict.depth_zbuffer.fc3.conv3.bias', 'headsDict.depth_zbuffer.fc4.conv1.weight', 'headsDict.depth_zbuffer.fc4.conv1.bias', 'headsDict.depth_zbuffer.fc4.conv2.weight', 'headsDict.depth_zbuffer.fc4.conv2.bias', 'headsDict.depth_zbuffer.fc4.conv3.weight', 'headsDict.depth_zbuffer.fc4.conv3.bias', 'net.0.taskOp.segment_semantic.weight', 'net.0.taskOp.depth_zbuffer.weight', 'net.0.dsOp.segment_semantic.0.weight', 'net.0.dsOp.segment_semantic.1.weight', 'net.0.dsOp.segment_semantic.1.bias', 'net.0.dsOp.segment_semantic.1.running_mean', 'net.0.dsOp.segment_semantic.1.running_var', 'net.0.dsOp.depth_zbuffer.0.weight', 'net.0.dsOp.depth_zbuffer.1.weight', 'net.0.dsOp.depth_zbuffer.1.bias', 'net.0.dsOp.depth_zbuffer.1.running_mean', 'net.0.dsOp.depth_zbuffer.1.running_var', 'net.0.basicOp.weight', 'net.1.taskOp.segment_semantic.weight', 'net.1.taskOp.segment_semantic.bias', 'net.1.taskOp.segment_semantic.running_mean', 'net.1.taskOp.segment_semantic.running_var', 'net.1.taskOp.depth_zbuffer.weight', 'net.1.taskOp.depth_zbuffer.bias', 'net.1.taskOp.depth_zbuffer.running_mean', 'net.1.taskOp.depth_zbuffer.running_var', 'net.1.policy.segment_semantic', 'net.1.policy.depth_zbuffer', 'net.1.basicOp.weight', 'net.1.basicOp.bias', 'net.1.basicOp.running_mean', 'net.1.basicOp.running_var', 'net.4.taskOp.segment_semantic.weight', 'net.4.taskOp.depth_zbuffer.weight', 'net.4.basicOp.weight', 'net.5.taskOp.segment_semantic.weight', 'net.5.taskOp.segment_semantic.bias', 'net.5.taskOp.segment_semantic.running_mean', 'net.5.taskOp.segment_semantic.running_var', 'net.5.taskOp.depth_zbuffer.weight', 'net.5.taskOp.depth_zbuffer.bias', 'net.5.taskOp.depth_zbuffer.running_mean', 'net.5.taskOp.depth_zbuffer.running_var', 'net.5.policy.segment_semantic', 'net.5.policy.depth_zbuffer', 'net.5.basicOp.weight', 'net.5.basicOp.bias', 'net.5.basicOp.running_mean', 'net.5.basicOp.running_var', 'net.7.taskOp.segment_semantic.weight', 'net.7.taskOp.depth_zbuffer.weight', 'net.7.basicOp.weight', 'net.8.taskOp.segment_semantic.weight', 'net.8.taskOp.segment_semantic.bias', 'net.8.taskOp.segment_semantic.running_mean', 'net.8.taskOp.segment_semantic.running_var', 'net.8.taskOp.depth_zbuffer.weight', 'net.8.taskOp.depth_zbuffer.bias', 'net.8.taskOp.depth_zbuffer.running_mean', 'net.8.taskOp.depth_zbuffer.running_var', 'net.8.policy.segment_semantic', 'net.8.policy.depth_zbuffer', 'net.8.basicOp.weight', 'net.8.basicOp.bias', 'net.8.basicOp.running_mean', 'net.8.basicOp.running_var', 'net.11.taskOp.segment_semantic.weight', 'net.11.taskOp.depth_zbuffer.weight', 'net.11.basicOp.weight', 'net.12.taskOp.segment_semantic.weight', 'net.12.taskOp.segment_semantic.bias', 'net.12.taskOp.segment_semantic.running_mean', 'net.12.taskOp.segment_semantic.running_var', 'net.12.taskOp.depth_zbuffer.weight', 'net.12.taskOp.depth_zbuffer.bias', 'net.12.taskOp.depth_zbuffer.running_mean', 'net.12.taskOp.depth_zbuffer.running_var', 'net.12.policy.segment_semantic', 'net.12.policy.depth_zbuffer', 'net.12.basicOp.weight', 'net.12.basicOp.bias', 'net.12.basicOp.running_mean', 'net.12.basicOp.running_var', 'net.14.taskOp.segment_semantic.weight', 'net.14.taskOp.depth_zbuffer.weight', 'net.14.basicOp.weight', 'net.15.taskOp.segment_semantic.weight', 'net.15.taskOp.segment_semantic.bias', 'net.15.taskOp.segment_semantic.running_mean', 'net.15.taskOp.segment_semantic.running_var', 'net.15.taskOp.depth_zbuffer.weight', 'net.15.taskOp.depth_zbuffer.bias', 'net.15.taskOp.depth_zbuffer.running_mean', 'net.15.taskOp.depth_zbuffer.running_var', 'net.15.policy.segment_semantic', 'net.15.policy.depth_zbuffer', 'net.15.basicOp.weight', 'net.15.basicOp.bias', 'net.15.basicOp.running_mean', 'net.15.basicOp.running_var', 'net.18.taskOp.segment_semantic.weight', 'net.18.taskOp.depth_zbuffer.weight', 'net.18.basicOp.weight', 'net.19.taskOp.segment_semantic.weight', 'net.19.taskOp.segment_semantic.bias', 'net.19.taskOp.segment_semantic.running_mean', 'net.19.taskOp.segment_semantic.running_var', 'net.19.taskOp.depth_zbuffer.weight', 'net.19.taskOp.depth_zbuffer.bias', 'net.19.taskOp.depth_zbuffer.running_mean', 'net.19.taskOp.depth_zbuffer.running_var', 'net.19.policy.segment_semantic', 'net.19.policy.depth_zbuffer', 'net.19.basicOp.weight', 'net.19.basicOp.bias', 'net.19.basicOp.running_mean', 'net.19.basicOp.running_var', 'net.21.taskOp.segment_semantic.weight', 'net.21.taskOp.depth_zbuffer.weight', 'net.21.basicOp.weight', 'net.22.taskOp.segment_semantic.weight', 'net.22.taskOp.segment_semantic.bias', 'net.22.taskOp.segment_semantic.running_mean', 'net.22.taskOp.segment_semantic.running_var', 'net.22.taskOp.depth_zbuffer.weight', 'net.22.taskOp.depth_zbuffer.bias', 'net.22.taskOp.depth_zbuffer.running_mean', 'net.22.taskOp.depth_zbuffer.running_var', 'net.22.policy.segment_semantic', 'net.22.policy.depth_zbuffer', 'net.22.basicOp.weight', 'net.22.basicOp.bias', 'net.22.basicOp.running_mean', 'net.22.basicOp.running_var', 'net.25.taskOp.segment_semantic.weight', 'net.25.taskOp.depth_zbuffer.weight', 'net.25.dsOp.segment_semantic.0.weight', 'net.25.dsOp.segment_semantic.1.weight', 'net.25.dsOp.segment_semantic.1.bias', 'net.25.dsOp.segment_semantic.1.running_mean', 'net.25.dsOp.segment_semantic.1.running_var', 'net.25.dsOp.depth_zbuffer.0.weight', 'net.25.dsOp.depth_zbuffer.1.weight', 'net.25.dsOp.depth_zbuffer.1.bias', 'net.25.dsOp.depth_zbuffer.1.running_mean', 'net.25.dsOp.depth_zbuffer.1.running_var', 'net.25.basicOp.weight', 'net.26.taskOp.segment_semantic.weight', 'net.26.taskOp.segment_semantic.bias', 'net.26.taskOp.segment_semantic.running_mean', 'net.26.taskOp.segment_semantic.running_var', 'net.26.taskOp.depth_zbuffer.weight', 'net.26.taskOp.depth_zbuffer.bias', 'net.26.taskOp.depth_zbuffer.running_mean', 'net.26.taskOp.depth_zbuffer.running_var', 'net.26.policy.segment_semantic', 'net.26.policy.depth_zbuffer', 'net.26.basicOp.weight', 'net.26.basicOp.bias', 'net.26.basicOp.running_mean', 'net.26.basicOp.running_var', 'net.27.taskOp.segment_semantic.weight', 'net.27.taskOp.depth_zbuffer.weight', 'net.27.dsOp.segment_semantic.0.weight', 'net.27.dsOp.segment_semantic.1.weight', 'net.27.dsOp.segment_semantic.1.bias', 'net.27.dsOp.segment_semantic.1.running_mean', 'net.27.dsOp.segment_semantic.1.running_var', 'net.27.dsOp.depth_zbuffer.0.weight', 'net.27.dsOp.depth_zbuffer.1.weight', 'net.27.dsOp.depth_zbuffer.1.bias', 'net.27.dsOp.depth_zbuffer.1.running_mean', 'net.27.dsOp.depth_zbuffer.1.running_var', 'net.27.basicOp.weight', 'net.28.taskOp.segment_semantic.weight', 'net.28.taskOp.segment_semantic.bias', 'net.28.taskOp.segment_semantic.running_mean', 'net.28.taskOp.segment_semantic.running_var', 'net.28.taskOp.depth_zbuffer.weight', 'net.28.taskOp.depth_zbuffer.bias', 'net.28.taskOp.depth_zbuffer.running_mean', 'net.28.taskOp.depth_zbuffer.running_var', 'net.28.policy.segment_semantic', 'net.28.policy.depth_zbuffer', 'net.28.basicOp.weight', 'net.28.basicOp.bias', 'net.28.basicOp.running_mean', 'net.28.basicOp.running_var', 'net.30.taskOp.segment_semantic.weight', 'net.30.taskOp.depth_zbuffer.weight', 'net.30.basicOp.weight', 'net.31.taskOp.segment_semantic.weight', 'net.31.taskOp.segment_semantic.bias', 'net.31.taskOp.segment_semantic.running_mean', 'net.31.taskOp.segment_semantic.running_var', 'net.31.taskOp.depth_zbuffer.weight', 'net.31.taskOp.depth_zbuffer.bias', 'net.31.taskOp.depth_zbuffer.running_mean', 'net.31.taskOp.depth_zbuffer.running_var', 'net.31.policy.segment_semantic', 'net.31.policy.depth_zbuffer', 'net.31.basicOp.weight', 'net.31.basicOp.bias', 'net.31.basicOp.running_mean', 'net.31.basicOp.running_var', 'net.34.taskOp.segment_semantic.weight', 'net.34.taskOp.depth_zbuffer.weight', 'net.34.basicOp.weight', 'net.35.taskOp.segment_semantic.weight', 'net.35.taskOp.segment_semantic.bias', 'net.35.taskOp.segment_semantic.running_mean', 'net.35.taskOp.segment_semantic.running_var', 'net.35.taskOp.depth_zbuffer.weight', 'net.35.taskOp.depth_zbuffer.bias', 'net.35.taskOp.depth_zbuffer.running_mean', 'net.35.taskOp.depth_zbuffer.running_var', 'net.35.policy.segment_semantic', 'net.35.policy.depth_zbuffer', 'net.35.basicOp.weight', 'net.35.basicOp.bias', 'net.35.basicOp.running_mean', 'net.35.basicOp.running_var', 'net.37.taskOp.segment_semantic.weight', 'net.37.taskOp.depth_zbuffer.weight', 'net.37.basicOp.weight', 'net.38.taskOp.segment_semantic.weight', 'net.38.taskOp.segment_semantic.bias', 'net.38.taskOp.segment_semantic.running_mean', 'net.38.taskOp.segment_semantic.running_var', 'net.38.taskOp.depth_zbuffer.weight', 'net.38.taskOp.depth_zbuffer.bias', 'net.38.taskOp.depth_zbuffer.running_mean', 'net.38.taskOp.depth_zbuffer.running_var', 'net.38.policy.segment_semantic', 'net.38.policy.depth_zbuffer', 'net.38.basicOp.weight', 'net.38.basicOp.bias', 'net.38.basicOp.running_mean', 'net.38.basicOp.running_var', 'net.41.taskOp.segment_semantic.weight', 'net.41.taskOp.depth_zbuffer.weight', 'net.41.basicOp.weight', 'net.42.taskOp.segment_semantic.weight', 'net.42.taskOp.segment_semantic.bias', 'net.42.taskOp.segment_semantic.running_mean', 'net.42.taskOp.segment_semantic.running_var', 'net.42.taskOp.depth_zbuffer.weight', 'net.42.taskOp.depth_zbuffer.bias', 'net.42.taskOp.depth_zbuffer.running_mean', 'net.42.taskOp.depth_zbuffer.running_var', 'net.42.policy.segment_semantic', 'net.42.policy.depth_zbuffer', 'net.42.basicOp.weight', 'net.42.basicOp.bias', 'net.42.basicOp.running_mean', 'net.42.basicOp.running_var', 'net.44.taskOp.segment_semantic.weight', 'net.44.taskOp.depth_zbuffer.weight', 'net.44.basicOp.weight', 'net.45.taskOp.segment_semantic.weight', 'net.45.taskOp.segment_semantic.bias', 'net.45.taskOp.segment_semantic.running_mean', 'net.45.taskOp.segment_semantic.running_var', 'net.45.taskOp.depth_zbuffer.weight', 'net.45.taskOp.depth_zbuffer.bias', 'net.45.taskOp.depth_zbuffer.running_mean', 'net.45.taskOp.depth_zbuffer.running_var', 'net.45.policy.segment_semantic', 'net.45.policy.depth_zbuffer', 'net.45.basicOp.weight', 'net.45.basicOp.bias', 'net.45.basicOp.running_mean', 'net.45.basicOp.running_var', 'net.48.taskOp.segment_semantic.weight', 'net.48.taskOp.depth_zbuffer.weight', 'net.48.basicOp.weight', 'net.49.taskOp.segment_semantic.weight', 'net.49.taskOp.segment_semantic.bias', 'net.49.taskOp.segment_semantic.running_mean', 'net.49.taskOp.segment_semantic.running_var', 'net.49.taskOp.depth_zbuffer.weight', 'net.49.taskOp.depth_zbuffer.bias', 'net.49.taskOp.depth_zbuffer.running_mean', 'net.49.taskOp.depth_zbuffer.running_var', 'net.49.policy.segment_semantic', 'net.49.policy.depth_zbuffer', 'net.49.basicOp.weight', 'net.49.basicOp.bias', 'net.49.basicOp.running_mean', 'net.49.basicOp.running_var', 'net.51.taskOp.segment_semantic.weight', 'net.51.taskOp.depth_zbuffer.weight', 'net.51.basicOp.weight', 'net.52.taskOp.segment_semantic.weight', 'net.52.taskOp.segment_semantic.bias', 'net.52.taskOp.segment_semantic.running_mean', 'net.52.taskOp.segment_semantic.running_var', 'net.52.taskOp.depth_zbuffer.weight', 'net.52.taskOp.depth_zbuffer.bias', 'net.52.taskOp.depth_zbuffer.running_mean', 'net.52.taskOp.depth_zbuffer.running_var', 'net.52.policy.segment_semantic', 'net.52.policy.depth_zbuffer', 'net.52.basicOp.weight', 'net.52.basicOp.bias', 'net.52.basicOp.running_mean', 'net.52.basicOp.running_var', 'net.55.taskOp.segment_semantic.weight', 'net.55.taskOp.depth_zbuffer.weight', 'net.55.dsOp.segment_semantic.0.weight', 'net.55.dsOp.segment_semantic.1.weight', 'net.55.dsOp.segment_semantic.1.bias', 'net.55.dsOp.segment_semantic.1.running_mean', 'net.55.dsOp.segment_semantic.1.running_var', 'net.55.dsOp.depth_zbuffer.0.weight', 'net.55.dsOp.depth_zbuffer.1.weight', 'net.55.dsOp.depth_zbuffer.1.bias', 'net.55.dsOp.depth_zbuffer.1.running_mean', 'net.55.dsOp.depth_zbuffer.1.running_var', 'net.55.basicOp.weight', 'net.56.taskOp.segment_semantic.weight', 'net.56.taskOp.segment_semantic.bias', 'net.56.taskOp.segment_semantic.running_mean', 'net.56.taskOp.segment_semantic.running_var', 'net.56.taskOp.depth_zbuffer.weight', 'net.56.taskOp.depth_zbuffer.bias', 'net.56.taskOp.depth_zbuffer.running_mean', 'net.56.taskOp.depth_zbuffer.running_var', 'net.56.policy.segment_semantic', 'net.56.policy.depth_zbuffer', 'net.56.basicOp.weight', 'net.56.basicOp.bias', 'net.56.basicOp.running_mean', 'net.56.basicOp.running_var', 'net.57.taskOp.segment_semantic.weight', 'net.57.taskOp.depth_zbuffer.weight', 'net.57.dsOp.segment_semantic.0.weight', 'net.57.dsOp.segment_semantic.1.weight', 'net.57.dsOp.segment_semantic.1.bias', 'net.57.dsOp.segment_semantic.1.running_mean', 'net.57.dsOp.segment_semantic.1.running_var', 'net.57.dsOp.depth_zbuffer.0.weight', 'net.57.dsOp.depth_zbuffer.1.weight', 'net.57.dsOp.depth_zbuffer.1.bias', 'net.57.dsOp.depth_zbuffer.1.running_mean', 'net.57.dsOp.depth_zbuffer.1.running_var', 'net.57.basicOp.weight', 'net.58.taskOp.segment_semantic.weight', 'net.58.taskOp.segment_semantic.bias', 'net.58.taskOp.segment_semantic.running_mean', 'net.58.taskOp.segment_semantic.running_var', 'net.58.taskOp.depth_zbuffer.weight', 'net.58.taskOp.depth_zbuffer.bias', 'net.58.taskOp.depth_zbuffer.running_mean', 'net.58.taskOp.depth_zbuffer.running_var', 'net.58.policy.segment_semantic', 'net.58.policy.depth_zbuffer', 'net.58.basicOp.weight', 'net.58.basicOp.bias', 'net.58.basicOp.running_mean', 'net.58.basicOp.running_var', 'net.60.taskOp.segment_semantic.weight', 'net.60.taskOp.depth_zbuffer.weight', 'net.60.basicOp.weight', 'net.61.taskOp.segment_semantic.weight', 'net.61.taskOp.segment_semantic.bias', 'net.61.taskOp.segment_semantic.running_mean', 'net.61.taskOp.segment_semantic.running_var', 'net.61.taskOp.depth_zbuffer.weight', 'net.61.taskOp.depth_zbuffer.bias', 'net.61.taskOp.depth_zbuffer.running_mean', 'net.61.taskOp.depth_zbuffer.running_var', 'net.61.policy.segment_semantic', 'net.61.policy.depth_zbuffer', 'net.61.basicOp.weight', 'net.61.basicOp.bias', 'net.61.basicOp.running_mean', 'net.61.basicOp.running_var', 'net.64.taskOp.segment_semantic.weight', 'net.64.taskOp.depth_zbuffer.weight', 'net.64.basicOp.weight', 'net.65.taskOp.segment_semantic.weight', 'net.65.taskOp.segment_semantic.bias', 'net.65.taskOp.segment_semantic.running_mean', 'net.65.taskOp.segment_semantic.running_var', 'net.65.taskOp.depth_zbuffer.weight', 'net.65.taskOp.depth_zbuffer.bias', 'net.65.taskOp.depth_zbuffer.running_mean', 'net.65.taskOp.depth_zbuffer.running_var', 'net.65.policy.segment_semantic', 'net.65.policy.depth_zbuffer', 'net.65.basicOp.weight', 'net.65.basicOp.bias', 'net.65.basicOp.running_mean', 'net.65.basicOp.running_var', 'net.67.taskOp.segment_semantic.weight', 'net.67.taskOp.depth_zbuffer.weight', 'net.67.basicOp.weight', 'net.68.taskOp.segment_semantic.weight', 'net.68.taskOp.segment_semantic.bias', 'net.68.taskOp.segment_semantic.running_mean', 'net.68.taskOp.segment_semantic.running_var', 'net.68.taskOp.depth_zbuffer.weight', 'net.68.taskOp.depth_zbuffer.bias', 'net.68.taskOp.depth_zbuffer.running_mean', 'net.68.taskOp.depth_zbuffer.running_var', 'net.68.policy.segment_semantic', 'net.68.policy.depth_zbuffer', 'net.68.basicOp.weight', 'net.68.basicOp.bias', 'net.68.basicOp.running_mean', 'net.68.basicOp.running_var', 'net.71.taskOp.segment_semantic.weight', 'net.71.taskOp.depth_zbuffer.weight', 'net.71.basicOp.weight', 'net.72.taskOp.segment_semantic.weight', 'net.72.taskOp.segment_semantic.bias', 'net.72.taskOp.segment_semantic.running_mean', 'net.72.taskOp.segment_semantic.running_var', 'net.72.taskOp.depth_zbuffer.weight', 'net.72.taskOp.depth_zbuffer.bias', 'net.72.taskOp.depth_zbuffer.running_mean', 'net.72.taskOp.depth_zbuffer.running_var', 'net.72.policy.segment_semantic', 'net.72.policy.depth_zbuffer', 'net.72.basicOp.weight', 'net.72.basicOp.bias', 'net.72.basicOp.running_mean', 'net.72.basicOp.running_var', 'net.74.taskOp.segment_semantic.weight', 'net.74.taskOp.depth_zbuffer.weight', 'net.74.basicOp.weight', 'net.75.taskOp.segment_semantic.weight', 'net.75.taskOp.segment_semantic.bias', 'net.75.taskOp.segment_semantic.running_mean', 'net.75.taskOp.segment_semantic.running_var', 'net.75.taskOp.depth_zbuffer.weight', 'net.75.taskOp.depth_zbuffer.bias', 'net.75.taskOp.depth_zbuffer.running_mean', 'net.75.taskOp.depth_zbuffer.running_var', 'net.75.policy.segment_semantic', 'net.75.policy.depth_zbuffer', 'net.75.basicOp.weight', 'net.75.basicOp.bias', 'net.75.basicOp.running_mean', 'net.75.basicOp.running_var', 'net.78.taskOp.segment_semantic.weight', 'net.78.taskOp.depth_zbuffer.weight', 'net.78.basicOp.weight', 'net.79.taskOp.segment_semantic.weight', 'net.79.taskOp.segment_semantic.bias', 'net.79.taskOp.segment_semantic.running_mean', 'net.79.taskOp.segment_semantic.running_var', 'net.79.taskOp.depth_zbuffer.weight', 'net.79.taskOp.depth_zbuffer.bias', 'net.79.taskOp.depth_zbuffer.running_mean', 'net.79.taskOp.depth_zbuffer.running_var', 'net.79.policy.segment_semantic', 'net.79.policy.depth_zbuffer', 'net.79.basicOp.weight', 'net.79.basicOp.bias', 'net.79.basicOp.running_mean', 'net.79.basicOp.running_var', 'net.81.taskOp.segment_semantic.weight', 'net.81.taskOp.depth_zbuffer.weight', 'net.81.basicOp.weight', 'net.82.taskOp.segment_semantic.weight', 'net.82.taskOp.segment_semantic.bias', 'net.82.taskOp.segment_semantic.running_mean', 'net.82.taskOp.segment_semantic.running_var', 'net.82.taskOp.depth_zbuffer.weight', 'net.82.taskOp.depth_zbuffer.bias', 'net.82.taskOp.depth_zbuffer.running_mean', 'net.82.taskOp.depth_zbuffer.running_var', 'net.82.policy.segment_semantic', 'net.82.policy.depth_zbuffer', 'net.82.basicOp.weight', 'net.82.basicOp.bias', 'net.82.basicOp.running_mean', 'net.82.basicOp.running_var', 'net.85.taskOp.segment_semantic.weight', 'net.85.taskOp.depth_zbuffer.weight', 'net.85.basicOp.weight', 'net.86.taskOp.segment_semantic.weight', 'net.86.taskOp.segment_semantic.bias', 'net.86.taskOp.segment_semantic.running_mean', 'net.86.taskOp.segment_semantic.running_var', 'net.86.taskOp.depth_zbuffer.weight', 'net.86.taskOp.depth_zbuffer.bias', 'net.86.taskOp.depth_zbuffer.running_mean', 'net.86.taskOp.depth_zbuffer.running_var', 'net.86.policy.segment_semantic', 'net.86.policy.depth_zbuffer', 'net.86.basicOp.weight', 'net.86.basicOp.bias', 'net.86.basicOp.running_mean', 'net.86.basicOp.running_var', 'net.88.taskOp.segment_semantic.weight', 'net.88.taskOp.depth_zbuffer.weight', 'net.88.basicOp.weight', 'net.89.taskOp.segment_semantic.weight', 'net.89.taskOp.segment_semantic.bias', 'net.89.taskOp.segment_semantic.running_mean', 'net.89.taskOp.segment_semantic.running_var', 'net.89.taskOp.depth_zbuffer.weight', 'net.89.taskOp.depth_zbuffer.bias', 'net.89.taskOp.depth_zbuffer.running_mean', 'net.89.taskOp.depth_zbuffer.running_var', 'net.89.policy.segment_semantic', 'net.89.policy.depth_zbuffer', 'net.89.basicOp.weight', 'net.89.basicOp.bias', 'net.89.basicOp.running_mean', 'net.89.basicOp.running_var', 'net.92.taskOp.segment_semantic.weight', 'net.92.taskOp.depth_zbuffer.weight', 'net.92.basicOp.weight', 'net.93.taskOp.segment_semantic.weight', 'net.93.taskOp.segment_semantic.bias', 'net.93.taskOp.segment_semantic.running_mean', 'net.93.taskOp.segment_semantic.running_var', 'net.93.taskOp.depth_zbuffer.weight', 'net.93.taskOp.depth_zbuffer.bias', 'net.93.taskOp.depth_zbuffer.running_mean', 'net.93.taskOp.depth_zbuffer.running_var', 'net.93.policy.segment_semantic', 'net.93.policy.depth_zbuffer', 'net.93.basicOp.weight', 'net.93.basicOp.bias', 'net.93.basicOp.running_mean', 'net.93.basicOp.running_var', 'net.95.taskOp.segment_semantic.weight', 'net.95.taskOp.depth_zbuffer.weight', 'net.95.basicOp.weight', 'net.96.taskOp.segment_semantic.weight', 'net.96.taskOp.segment_semantic.bias', 'net.96.taskOp.segment_semantic.running_mean', 'net.96.taskOp.segment_semantic.running_var', 'net.96.taskOp.depth_zbuffer.weight', 'net.96.taskOp.depth_zbuffer.bias', 'net.96.taskOp.depth_zbuffer.running_mean', 'net.96.taskOp.depth_zbuffer.running_var', 'net.96.policy.segment_semantic', 'net.96.policy.depth_zbuffer', 'net.96.basicOp.weight', 'net.96.basicOp.bias', 'net.96.basicOp.running_mean', 'net.96.basicOp.running_var', 'net.99.taskOp.segment_semantic.weight', 'net.99.taskOp.depth_zbuffer.weight', 'net.99.dsOp.segment_semantic.0.weight', 'net.99.dsOp.segment_semantic.1.weight', 'net.99.dsOp.segment_semantic.1.bias', 'net.99.dsOp.segment_semantic.1.running_mean', 'net.99.dsOp.segment_semantic.1.running_var', 'net.99.dsOp.depth_zbuffer.0.weight', 'net.99.dsOp.depth_zbuffer.1.weight', 'net.99.dsOp.depth_zbuffer.1.bias', 'net.99.dsOp.depth_zbuffer.1.running_mean', 'net.99.dsOp.depth_zbuffer.1.running_var', 'net.99.basicOp.weight', 'net.100.taskOp.segment_semantic.weight', 'net.100.taskOp.segment_semantic.bias', 'net.100.taskOp.segment_semantic.running_mean', 'net.100.taskOp.segment_semantic.running_var', 'net.100.taskOp.depth_zbuffer.weight', 'net.100.taskOp.depth_zbuffer.bias', 'net.100.taskOp.depth_zbuffer.running_mean', 'net.100.taskOp.depth_zbuffer.running_var', 'net.100.policy.segment_semantic', 'net.100.policy.depth_zbuffer', 'net.100.basicOp.weight', 'net.100.basicOp.bias', 'net.100.basicOp.running_mean', 'net.100.basicOp.running_var', 'net.101.taskOp.segment_semantic.weight', 'net.101.taskOp.depth_zbuffer.weight', 'net.101.dsOp.segment_semantic.0.weight', 'net.101.dsOp.segment_semantic.1.weight', 'net.101.dsOp.segment_semantic.1.bias', 'net.101.dsOp.segment_semantic.1.running_mean', 'net.101.dsOp.segment_semantic.1.running_var', 'net.101.dsOp.depth_zbuffer.0.weight', 'net.101.dsOp.depth_zbuffer.1.weight', 'net.101.dsOp.depth_zbuffer.1.bias', 'net.101.dsOp.depth_zbuffer.1.running_mean', 'net.101.dsOp.depth_zbuffer.1.running_var', 'net.101.basicOp.weight', 'net.102.taskOp.segment_semantic.weight', 'net.102.taskOp.segment_semantic.bias', 'net.102.taskOp.segment_semantic.running_mean', 'net.102.taskOp.segment_semantic.running_var', 'net.102.taskOp.depth_zbuffer.weight', 'net.102.taskOp.depth_zbuffer.bias', 'net.102.taskOp.depth_zbuffer.running_mean', 'net.102.taskOp.depth_zbuffer.running_var', 'net.102.policy.segment_semantic', 'net.102.policy.depth_zbuffer', 'net.102.basicOp.weight', 'net.102.basicOp.bias', 'net.102.basicOp.running_mean', 'net.102.basicOp.running_var', 'net.104.taskOp.segment_semantic.weight', 'net.104.taskOp.depth_zbuffer.weight', 'net.104.basicOp.weight', 'net.105.taskOp.segment_semantic.weight', 'net.105.taskOp.segment_semantic.bias', 'net.105.taskOp.segment_semantic.running_mean', 'net.105.taskOp.segment_semantic.running_var', 'net.105.taskOp.depth_zbuffer.weight', 'net.105.taskOp.depth_zbuffer.bias', 'net.105.taskOp.depth_zbuffer.running_mean', 'net.105.taskOp.depth_zbuffer.running_var', 'net.105.policy.segment_semantic', 'net.105.policy.depth_zbuffer', 'net.105.basicOp.weight', 'net.105.basicOp.bias', 'net.105.basicOp.running_mean', 'net.105.basicOp.running_var', 'net.108.taskOp.segment_semantic.weight', 'net.108.taskOp.depth_zbuffer.weight', 'net.108.basicOp.weight', 'net.109.taskOp.segment_semantic.weight', 'net.109.taskOp.segment_semantic.bias', 'net.109.taskOp.segment_semantic.running_mean', 'net.109.taskOp.segment_semantic.running_var', 'net.109.taskOp.depth_zbuffer.weight', 'net.109.taskOp.depth_zbuffer.bias', 'net.109.taskOp.depth_zbuffer.running_mean', 'net.109.taskOp.depth_zbuffer.running_var', 'net.109.policy.segment_semantic', 'net.109.policy.depth_zbuffer', 'net.109.basicOp.weight', 'net.109.basicOp.bias', 'net.109.basicOp.running_mean', 'net.109.basicOp.running_var', 'net.111.taskOp.segment_semantic.weight', 'net.111.taskOp.depth_zbuffer.weight', 'net.111.basicOp.weight', 'net.112.taskOp.segment_semantic.weight', 'net.112.taskOp.segment_semantic.bias', 'net.112.taskOp.segment_semantic.running_mean', 'net.112.taskOp.segment_semantic.running_var', 'net.112.taskOp.depth_zbuffer.weight', 'net.112.taskOp.depth_zbuffer.bias', 'net.112.taskOp.depth_zbuffer.running_mean', 'net.112.taskOp.depth_zbuffer.running_var', 'net.112.policy.segment_semantic', 'net.112.policy.depth_zbuffer', 'net.112.basicOp.weight', 'net.112.basicOp.bias', 'net.112.basicOp.running_mean', 'net.112.basicOp.running_var', 'net.115.taskOp.segment_semantic.weight', 'net.115.taskOp.depth_zbuffer.weight', 'net.115.basicOp.weight', 'net.116.taskOp.segment_semantic.weight', 'net.116.taskOp.segment_semantic.bias', 'net.116.taskOp.segment_semantic.running_mean', 'net.116.taskOp.segment_semantic.running_var', 'net.116.taskOp.depth_zbuffer.weight', 'net.116.taskOp.depth_zbuffer.bias', 'net.116.taskOp.depth_zbuffer.running_mean', 'net.116.taskOp.depth_zbuffer.running_var', 'net.116.policy.segment_semantic', 'net.116.policy.depth_zbuffer', 'net.116.basicOp.weight', 'net.116.basicOp.bias', 'net.116.basicOp.running_mean', 'net.116.basicOp.running_var', 'net.118.taskOp.segment_semantic.weight', 'net.118.taskOp.depth_zbuffer.weight', 'net.118.basicOp.weight', 'net.119.taskOp.segment_semantic.weight', 'net.119.taskOp.segment_semantic.bias', 'net.119.taskOp.segment_semantic.running_mean', 'net.119.taskOp.segment_semantic.running_var', 'net.119.taskOp.depth_zbuffer.weight', 'net.119.taskOp.depth_zbuffer.bias', 'net.119.taskOp.depth_zbuffer.running_mean', 'net.119.taskOp.depth_zbuffer.running_var', 'net.119.policy.segment_semantic', 'net.119.policy.depth_zbuffer', 'net.119.basicOp.weight', 'net.119.basicOp.bias', 'net.119.basicOp.running_mean', 'net.119.basicOp.running_var'], unexpected_keys=[])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "random_state = torch.load('checkpoints/Cityscapes/' + 'random_policy_seed98.model')\n",
    "mtlmodel.load_state_dict(random_state['state_dict'],  strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_dict': OrderedDict([('net.0.policy.segment_semantic',\n",
       "               tensor([0.8013, 0.9743, 0.0132], device='cuda:0')),\n",
       "              ('net.4.policy.segment_semantic',\n",
       "               tensor([0.1849, 0.2576, 0.4162], device='cuda:0')),\n",
       "              ('net.7.policy.segment_semantic',\n",
       "               tensor([0.5283, 0.6112, 0.3682], device='cuda:0')),\n",
       "              ('net.11.policy.segment_semantic',\n",
       "               tensor([0.8037, 0.5521, 0.1797], device='cuda:0')),\n",
       "              ('net.14.policy.segment_semantic',\n",
       "               tensor([0.5865, 0.1435, 0.1253], device='cuda:0')),\n",
       "              ('net.18.policy.segment_semantic',\n",
       "               tensor([0.0908, 0.2993, 0.4109], device='cuda:0')),\n",
       "              ('net.21.policy.segment_semantic',\n",
       "               tensor([0.0246, 0.2858, 0.5702], device='cuda:0')),\n",
       "              ('net.25.policy.segment_semantic',\n",
       "               tensor([0.7914, 0.7014, 0.4357], device='cuda:0')),\n",
       "              ('net.27.policy.segment_semantic',\n",
       "               tensor([0.7049, 0.6594, 0.2567], device='cuda:0')),\n",
       "              ('net.30.policy.segment_semantic',\n",
       "               tensor([0.6766, 0.8575, 0.5775], device='cuda:0')),\n",
       "              ('net.34.policy.segment_semantic',\n",
       "               tensor([0.2790, 0.8382, 0.0333], device='cuda:0')),\n",
       "              ('net.37.policy.segment_semantic',\n",
       "               tensor([0.6352, 0.6431, 0.9880], device='cuda:0')),\n",
       "              ('net.41.policy.segment_semantic',\n",
       "               tensor([0.6996, 0.4078, 0.1015], device='cuda:0')),\n",
       "              ('net.44.policy.segment_semantic',\n",
       "               tensor([0.1410, 0.3959, 0.7326], device='cuda:0')),\n",
       "              ('net.48.policy.segment_semantic',\n",
       "               tensor([0.8880, 0.9432, 0.6873], device='cuda:0')),\n",
       "              ('net.51.policy.segment_semantic',\n",
       "               tensor([0.9427, 0.7679, 0.3888], device='cuda:0')),\n",
       "              ('net.55.policy.segment_semantic',\n",
       "               tensor([0.0136, 0.2464, 0.7609], device='cuda:0')),\n",
       "              ('net.57.policy.segment_semantic',\n",
       "               tensor([0.4940, 0.8463, 0.0324], device='cuda:0')),\n",
       "              ('net.60.policy.segment_semantic',\n",
       "               tensor([0.5068, 0.2518, 0.2477], device='cuda:0')),\n",
       "              ('net.64.policy.segment_semantic',\n",
       "               tensor([0.3053, 0.6100, 0.9996], device='cuda:0')),\n",
       "              ('net.67.policy.segment_semantic',\n",
       "               tensor([0.6072, 0.8496, 0.4890], device='cuda:0')),\n",
       "              ('net.71.policy.segment_semantic',\n",
       "               tensor([0.0961, 0.8070, 0.6575], device='cuda:0')),\n",
       "              ('net.74.policy.segment_semantic',\n",
       "               tensor([0.0041, 0.2041, 0.2028], device='cuda:0')),\n",
       "              ('net.78.policy.segment_semantic',\n",
       "               tensor([0.5338, 0.4242, 0.9883], device='cuda:0')),\n",
       "              ('net.81.policy.segment_semantic',\n",
       "               tensor([0.1981, 0.5251, 0.6922], device='cuda:0')),\n",
       "              ('net.85.policy.segment_semantic',\n",
       "               tensor([0.1511, 0.2406, 0.5841], device='cuda:0')),\n",
       "              ('net.88.policy.segment_semantic',\n",
       "               tensor([0.6771, 0.3479, 0.8644], device='cuda:0')),\n",
       "              ('net.92.policy.segment_semantic',\n",
       "               tensor([0.5812, 0.9064, 0.2832], device='cuda:0')),\n",
       "              ('net.95.policy.segment_semantic',\n",
       "               tensor([0.3638, 0.6208, 0.9081], device='cuda:0')),\n",
       "              ('net.99.policy.segment_semantic',\n",
       "               tensor([0.5171, 0.3676, 0.4089], device='cuda:0')),\n",
       "              ('net.101.policy.segment_semantic',\n",
       "               tensor([0.0201, 0.0684, 0.9333], device='cuda:0')),\n",
       "              ('net.104.policy.segment_semantic',\n",
       "               tensor([0.4210, 0.4657, 0.3852], device='cuda:0')),\n",
       "              ('net.108.policy.segment_semantic',\n",
       "               tensor([0.0853, 0.9036, 0.6229], device='cuda:0')),\n",
       "              ('net.111.policy.segment_semantic',\n",
       "               tensor([0.0791, 0.6441, 0.0496], device='cuda:0')),\n",
       "              ('net.115.policy.segment_semantic',\n",
       "               tensor([0.3585, 0.8501, 0.9563], device='cuda:0')),\n",
       "              ('net.118.policy.segment_semantic',\n",
       "               tensor([0.9398, 0.8635, 0.3529], device='cuda:0')),\n",
       "              ('net.0.policy.depth_zbuffer',\n",
       "               tensor([0.2986, 0.0129, 0.2851], device='cuda:0')),\n",
       "              ('net.4.policy.depth_zbuffer',\n",
       "               tensor([0.2785, 0.5316, 0.9822], device='cuda:0')),\n",
       "              ('net.7.policy.depth_zbuffer',\n",
       "               tensor([0.5180, 0.5230, 0.4106], device='cuda:0')),\n",
       "              ('net.11.policy.depth_zbuffer',\n",
       "               tensor([0.5729, 0.5666, 0.3400], device='cuda:0')),\n",
       "              ('net.14.policy.depth_zbuffer',\n",
       "               tensor([0.0705, 0.8648, 0.1862], device='cuda:0')),\n",
       "              ('net.18.policy.depth_zbuffer',\n",
       "               tensor([0.9367, 0.9191, 0.1087], device='cuda:0')),\n",
       "              ('net.21.policy.depth_zbuffer',\n",
       "               tensor([0.8490, 0.5278, 0.6581], device='cuda:0')),\n",
       "              ('net.25.policy.depth_zbuffer',\n",
       "               tensor([0.5205, 0.8426, 0.7122], device='cuda:0')),\n",
       "              ('net.27.policy.depth_zbuffer',\n",
       "               tensor([0.5586, 0.8733, 0.1552], device='cuda:0')),\n",
       "              ('net.30.policy.depth_zbuffer',\n",
       "               tensor([0.2275, 0.1199, 0.1899], device='cuda:0')),\n",
       "              ('net.34.policy.depth_zbuffer',\n",
       "               tensor([0.4547, 0.5875, 0.7764], device='cuda:0')),\n",
       "              ('net.37.policy.depth_zbuffer',\n",
       "               tensor([0.0707, 0.4299, 0.1713], device='cuda:0')),\n",
       "              ('net.41.policy.depth_zbuffer',\n",
       "               tensor([0.3681, 0.9895, 0.6250], device='cuda:0')),\n",
       "              ('net.44.policy.depth_zbuffer',\n",
       "               tensor([0.9086, 0.8344, 0.0051], device='cuda:0')),\n",
       "              ('net.48.policy.depth_zbuffer',\n",
       "               tensor([0.8104, 0.6201, 0.5329], device='cuda:0')),\n",
       "              ('net.51.policy.depth_zbuffer',\n",
       "               tensor([0.2319, 0.2718, 0.2945], device='cuda:0')),\n",
       "              ('net.55.policy.depth_zbuffer',\n",
       "               tensor([0.9045, 0.3321, 0.4307], device='cuda:0')),\n",
       "              ('net.57.policy.depth_zbuffer',\n",
       "               tensor([0.2477, 0.0208, 0.0551], device='cuda:0')),\n",
       "              ('net.60.policy.depth_zbuffer',\n",
       "               tensor([0.5236, 0.2080, 0.3754], device='cuda:0')),\n",
       "              ('net.64.policy.depth_zbuffer',\n",
       "               tensor([0.6481, 0.7825, 0.1003], device='cuda:0')),\n",
       "              ('net.67.policy.depth_zbuffer',\n",
       "               tensor([0.3755, 0.4327, 0.1096], device='cuda:0')),\n",
       "              ('net.71.policy.depth_zbuffer',\n",
       "               tensor([0.1480, 0.3582, 0.2645], device='cuda:0')),\n",
       "              ('net.74.policy.depth_zbuffer',\n",
       "               tensor([0.0662, 0.2986, 0.4912], device='cuda:0')),\n",
       "              ('net.78.policy.depth_zbuffer',\n",
       "               tensor([0.4837, 0.2779, 0.1885], device='cuda:0')),\n",
       "              ('net.81.policy.depth_zbuffer',\n",
       "               tensor([0.0760, 0.3008, 0.7057], device='cuda:0')),\n",
       "              ('net.85.policy.depth_zbuffer',\n",
       "               tensor([0.8320, 0.5214, 0.9113], device='cuda:0')),\n",
       "              ('net.88.policy.depth_zbuffer',\n",
       "               tensor([0.9624, 0.8612, 0.0973], device='cuda:0')),\n",
       "              ('net.92.policy.depth_zbuffer',\n",
       "               tensor([0.2196, 0.1946, 0.4857], device='cuda:0')),\n",
       "              ('net.95.policy.depth_zbuffer',\n",
       "               tensor([0.8987, 0.0590, 0.7320], device='cuda:0')),\n",
       "              ('net.99.policy.depth_zbuffer',\n",
       "               tensor([0.1820, 0.2932, 0.7846], device='cuda:0')),\n",
       "              ('net.101.policy.depth_zbuffer',\n",
       "               tensor([0.1984, 0.7761, 0.8488], device='cuda:0')),\n",
       "              ('net.104.policy.depth_zbuffer',\n",
       "               tensor([0.7607, 0.1147, 0.9929], device='cuda:0')),\n",
       "              ('net.108.policy.depth_zbuffer',\n",
       "               tensor([0.8426, 0.7638, 0.6738], device='cuda:0')),\n",
       "              ('net.111.policy.depth_zbuffer',\n",
       "               tensor([0.5203, 0.2665, 0.5983], device='cuda:0')),\n",
       "              ('net.115.policy.depth_zbuffer',\n",
       "               tensor([0.8187, 0.9307, 0.8956], device='cuda:0')),\n",
       "              ('net.118.policy.depth_zbuffer',\n",
       "               tensor([0.1201, 0.0644, 0.6865], device='cuda:0'))])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['headsDict.segment_semantic.fc1.conv1.weight', 'headsDict.segment_semantic.fc1.conv1.bias', 'headsDict.segment_semantic.fc1.conv2.weight', 'headsDict.segment_semantic.fc1.conv2.bias', 'headsDict.segment_semantic.fc1.conv3.weight', 'headsDict.segment_semantic.fc1.conv3.bias', 'headsDict.segment_semantic.fc2.conv1.weight', 'headsDict.segment_semantic.fc2.conv1.bias', 'headsDict.segment_semantic.fc2.conv2.weight', 'headsDict.segment_semantic.fc2.conv2.bias', 'headsDict.segment_semantic.fc2.conv3.weight', 'headsDict.segment_semantic.fc2.conv3.bias', 'headsDict.segment_semantic.fc3.conv1.weight', 'headsDict.segment_semantic.fc3.conv1.bias', 'headsDict.segment_semantic.fc3.conv2.weight', 'headsDict.segment_semantic.fc3.conv2.bias', 'headsDict.segment_semantic.fc3.conv3.weight', 'headsDict.segment_semantic.fc3.conv3.bias', 'headsDict.segment_semantic.fc4.conv1.weight', 'headsDict.segment_semantic.fc4.conv1.bias', 'headsDict.segment_semantic.fc4.conv2.weight', 'headsDict.segment_semantic.fc4.conv2.bias', 'headsDict.segment_semantic.fc4.conv3.weight', 'headsDict.segment_semantic.fc4.conv3.bias', 'headsDict.depth_zbuffer.fc1.conv1.weight', 'headsDict.depth_zbuffer.fc1.conv1.bias', 'headsDict.depth_zbuffer.fc1.conv2.weight', 'headsDict.depth_zbuffer.fc1.conv2.bias', 'headsDict.depth_zbuffer.fc1.conv3.weight', 'headsDict.depth_zbuffer.fc1.conv3.bias', 'headsDict.depth_zbuffer.fc2.conv1.weight', 'headsDict.depth_zbuffer.fc2.conv1.bias', 'headsDict.depth_zbuffer.fc2.conv2.weight', 'headsDict.depth_zbuffer.fc2.conv2.bias', 'headsDict.depth_zbuffer.fc2.conv3.weight', 'headsDict.depth_zbuffer.fc2.conv3.bias', 'headsDict.depth_zbuffer.fc3.conv1.weight', 'headsDict.depth_zbuffer.fc3.conv1.bias', 'headsDict.depth_zbuffer.fc3.conv2.weight', 'headsDict.depth_zbuffer.fc3.conv2.bias', 'headsDict.depth_zbuffer.fc3.conv3.weight', 'headsDict.depth_zbuffer.fc3.conv3.bias', 'headsDict.depth_zbuffer.fc4.conv1.weight', 'headsDict.depth_zbuffer.fc4.conv1.bias', 'headsDict.depth_zbuffer.fc4.conv2.weight', 'headsDict.depth_zbuffer.fc4.conv2.bias', 'headsDict.depth_zbuffer.fc4.conv3.weight', 'headsDict.depth_zbuffer.fc4.conv3.bias', 'net.0.taskOp.segment_semantic.weight', 'net.0.taskOp.depth_zbuffer.weight', 'net.0.dsOp.segment_semantic.0.weight', 'net.0.dsOp.segment_semantic.1.weight', 'net.0.dsOp.segment_semantic.1.bias', 'net.0.dsOp.segment_semantic.1.running_mean', 'net.0.dsOp.segment_semantic.1.running_var', 'net.0.dsOp.depth_zbuffer.0.weight', 'net.0.dsOp.depth_zbuffer.1.weight', 'net.0.dsOp.depth_zbuffer.1.bias', 'net.0.dsOp.depth_zbuffer.1.running_mean', 'net.0.dsOp.depth_zbuffer.1.running_var', 'net.0.basicOp.weight', 'net.1.taskOp.segment_semantic.weight', 'net.1.taskOp.segment_semantic.bias', 'net.1.taskOp.segment_semantic.running_mean', 'net.1.taskOp.segment_semantic.running_var', 'net.1.taskOp.depth_zbuffer.weight', 'net.1.taskOp.depth_zbuffer.bias', 'net.1.taskOp.depth_zbuffer.running_mean', 'net.1.taskOp.depth_zbuffer.running_var', 'net.1.policy.segment_semantic', 'net.1.policy.depth_zbuffer', 'net.1.basicOp.weight', 'net.1.basicOp.bias', 'net.1.basicOp.running_mean', 'net.1.basicOp.running_var', 'net.4.taskOp.segment_semantic.weight', 'net.4.taskOp.depth_zbuffer.weight', 'net.4.basicOp.weight', 'net.5.taskOp.segment_semantic.weight', 'net.5.taskOp.segment_semantic.bias', 'net.5.taskOp.segment_semantic.running_mean', 'net.5.taskOp.segment_semantic.running_var', 'net.5.taskOp.depth_zbuffer.weight', 'net.5.taskOp.depth_zbuffer.bias', 'net.5.taskOp.depth_zbuffer.running_mean', 'net.5.taskOp.depth_zbuffer.running_var', 'net.5.policy.segment_semantic', 'net.5.policy.depth_zbuffer', 'net.5.basicOp.weight', 'net.5.basicOp.bias', 'net.5.basicOp.running_mean', 'net.5.basicOp.running_var', 'net.7.taskOp.segment_semantic.weight', 'net.7.taskOp.depth_zbuffer.weight', 'net.7.basicOp.weight', 'net.8.taskOp.segment_semantic.weight', 'net.8.taskOp.segment_semantic.bias', 'net.8.taskOp.segment_semantic.running_mean', 'net.8.taskOp.segment_semantic.running_var', 'net.8.taskOp.depth_zbuffer.weight', 'net.8.taskOp.depth_zbuffer.bias', 'net.8.taskOp.depth_zbuffer.running_mean', 'net.8.taskOp.depth_zbuffer.running_var', 'net.8.policy.segment_semantic', 'net.8.policy.depth_zbuffer', 'net.8.basicOp.weight', 'net.8.basicOp.bias', 'net.8.basicOp.running_mean', 'net.8.basicOp.running_var', 'net.11.taskOp.segment_semantic.weight', 'net.11.taskOp.depth_zbuffer.weight', 'net.11.basicOp.weight', 'net.12.taskOp.segment_semantic.weight', 'net.12.taskOp.segment_semantic.bias', 'net.12.taskOp.segment_semantic.running_mean', 'net.12.taskOp.segment_semantic.running_var', 'net.12.taskOp.depth_zbuffer.weight', 'net.12.taskOp.depth_zbuffer.bias', 'net.12.taskOp.depth_zbuffer.running_mean', 'net.12.taskOp.depth_zbuffer.running_var', 'net.12.policy.segment_semantic', 'net.12.policy.depth_zbuffer', 'net.12.basicOp.weight', 'net.12.basicOp.bias', 'net.12.basicOp.running_mean', 'net.12.basicOp.running_var', 'net.14.taskOp.segment_semantic.weight', 'net.14.taskOp.depth_zbuffer.weight', 'net.14.basicOp.weight', 'net.15.taskOp.segment_semantic.weight', 'net.15.taskOp.segment_semantic.bias', 'net.15.taskOp.segment_semantic.running_mean', 'net.15.taskOp.segment_semantic.running_var', 'net.15.taskOp.depth_zbuffer.weight', 'net.15.taskOp.depth_zbuffer.bias', 'net.15.taskOp.depth_zbuffer.running_mean', 'net.15.taskOp.depth_zbuffer.running_var', 'net.15.policy.segment_semantic', 'net.15.policy.depth_zbuffer', 'net.15.basicOp.weight', 'net.15.basicOp.bias', 'net.15.basicOp.running_mean', 'net.15.basicOp.running_var', 'net.18.taskOp.segment_semantic.weight', 'net.18.taskOp.depth_zbuffer.weight', 'net.18.basicOp.weight', 'net.19.taskOp.segment_semantic.weight', 'net.19.taskOp.segment_semantic.bias', 'net.19.taskOp.segment_semantic.running_mean', 'net.19.taskOp.segment_semantic.running_var', 'net.19.taskOp.depth_zbuffer.weight', 'net.19.taskOp.depth_zbuffer.bias', 'net.19.taskOp.depth_zbuffer.running_mean', 'net.19.taskOp.depth_zbuffer.running_var', 'net.19.policy.segment_semantic', 'net.19.policy.depth_zbuffer', 'net.19.basicOp.weight', 'net.19.basicOp.bias', 'net.19.basicOp.running_mean', 'net.19.basicOp.running_var', 'net.21.taskOp.segment_semantic.weight', 'net.21.taskOp.depth_zbuffer.weight', 'net.21.basicOp.weight', 'net.22.taskOp.segment_semantic.weight', 'net.22.taskOp.segment_semantic.bias', 'net.22.taskOp.segment_semantic.running_mean', 'net.22.taskOp.segment_semantic.running_var', 'net.22.taskOp.depth_zbuffer.weight', 'net.22.taskOp.depth_zbuffer.bias', 'net.22.taskOp.depth_zbuffer.running_mean', 'net.22.taskOp.depth_zbuffer.running_var', 'net.22.policy.segment_semantic', 'net.22.policy.depth_zbuffer', 'net.22.basicOp.weight', 'net.22.basicOp.bias', 'net.22.basicOp.running_mean', 'net.22.basicOp.running_var', 'net.25.taskOp.segment_semantic.weight', 'net.25.taskOp.depth_zbuffer.weight', 'net.25.dsOp.segment_semantic.0.weight', 'net.25.dsOp.segment_semantic.1.weight', 'net.25.dsOp.segment_semantic.1.bias', 'net.25.dsOp.segment_semantic.1.running_mean', 'net.25.dsOp.segment_semantic.1.running_var', 'net.25.dsOp.depth_zbuffer.0.weight', 'net.25.dsOp.depth_zbuffer.1.weight', 'net.25.dsOp.depth_zbuffer.1.bias', 'net.25.dsOp.depth_zbuffer.1.running_mean', 'net.25.dsOp.depth_zbuffer.1.running_var', 'net.25.basicOp.weight', 'net.26.taskOp.segment_semantic.weight', 'net.26.taskOp.segment_semantic.bias', 'net.26.taskOp.segment_semantic.running_mean', 'net.26.taskOp.segment_semantic.running_var', 'net.26.taskOp.depth_zbuffer.weight', 'net.26.taskOp.depth_zbuffer.bias', 'net.26.taskOp.depth_zbuffer.running_mean', 'net.26.taskOp.depth_zbuffer.running_var', 'net.26.policy.segment_semantic', 'net.26.policy.depth_zbuffer', 'net.26.basicOp.weight', 'net.26.basicOp.bias', 'net.26.basicOp.running_mean', 'net.26.basicOp.running_var', 'net.27.taskOp.segment_semantic.weight', 'net.27.taskOp.depth_zbuffer.weight', 'net.27.dsOp.segment_semantic.0.weight', 'net.27.dsOp.segment_semantic.1.weight', 'net.27.dsOp.segment_semantic.1.bias', 'net.27.dsOp.segment_semantic.1.running_mean', 'net.27.dsOp.segment_semantic.1.running_var', 'net.27.dsOp.depth_zbuffer.0.weight', 'net.27.dsOp.depth_zbuffer.1.weight', 'net.27.dsOp.depth_zbuffer.1.bias', 'net.27.dsOp.depth_zbuffer.1.running_mean', 'net.27.dsOp.depth_zbuffer.1.running_var', 'net.27.basicOp.weight', 'net.28.taskOp.segment_semantic.weight', 'net.28.taskOp.segment_semantic.bias', 'net.28.taskOp.segment_semantic.running_mean', 'net.28.taskOp.segment_semantic.running_var', 'net.28.taskOp.depth_zbuffer.weight', 'net.28.taskOp.depth_zbuffer.bias', 'net.28.taskOp.depth_zbuffer.running_mean', 'net.28.taskOp.depth_zbuffer.running_var', 'net.28.policy.segment_semantic', 'net.28.policy.depth_zbuffer', 'net.28.basicOp.weight', 'net.28.basicOp.bias', 'net.28.basicOp.running_mean', 'net.28.basicOp.running_var', 'net.30.taskOp.segment_semantic.weight', 'net.30.taskOp.depth_zbuffer.weight', 'net.30.basicOp.weight', 'net.31.taskOp.segment_semantic.weight', 'net.31.taskOp.segment_semantic.bias', 'net.31.taskOp.segment_semantic.running_mean', 'net.31.taskOp.segment_semantic.running_var', 'net.31.taskOp.depth_zbuffer.weight', 'net.31.taskOp.depth_zbuffer.bias', 'net.31.taskOp.depth_zbuffer.running_mean', 'net.31.taskOp.depth_zbuffer.running_var', 'net.31.policy.segment_semantic', 'net.31.policy.depth_zbuffer', 'net.31.basicOp.weight', 'net.31.basicOp.bias', 'net.31.basicOp.running_mean', 'net.31.basicOp.running_var', 'net.34.taskOp.segment_semantic.weight', 'net.34.taskOp.depth_zbuffer.weight', 'net.34.basicOp.weight', 'net.35.taskOp.segment_semantic.weight', 'net.35.taskOp.segment_semantic.bias', 'net.35.taskOp.segment_semantic.running_mean', 'net.35.taskOp.segment_semantic.running_var', 'net.35.taskOp.depth_zbuffer.weight', 'net.35.taskOp.depth_zbuffer.bias', 'net.35.taskOp.depth_zbuffer.running_mean', 'net.35.taskOp.depth_zbuffer.running_var', 'net.35.policy.segment_semantic', 'net.35.policy.depth_zbuffer', 'net.35.basicOp.weight', 'net.35.basicOp.bias', 'net.35.basicOp.running_mean', 'net.35.basicOp.running_var', 'net.37.taskOp.segment_semantic.weight', 'net.37.taskOp.depth_zbuffer.weight', 'net.37.basicOp.weight', 'net.38.taskOp.segment_semantic.weight', 'net.38.taskOp.segment_semantic.bias', 'net.38.taskOp.segment_semantic.running_mean', 'net.38.taskOp.segment_semantic.running_var', 'net.38.taskOp.depth_zbuffer.weight', 'net.38.taskOp.depth_zbuffer.bias', 'net.38.taskOp.depth_zbuffer.running_mean', 'net.38.taskOp.depth_zbuffer.running_var', 'net.38.policy.segment_semantic', 'net.38.policy.depth_zbuffer', 'net.38.basicOp.weight', 'net.38.basicOp.bias', 'net.38.basicOp.running_mean', 'net.38.basicOp.running_var', 'net.41.taskOp.segment_semantic.weight', 'net.41.taskOp.depth_zbuffer.weight', 'net.41.basicOp.weight', 'net.42.taskOp.segment_semantic.weight', 'net.42.taskOp.segment_semantic.bias', 'net.42.taskOp.segment_semantic.running_mean', 'net.42.taskOp.segment_semantic.running_var', 'net.42.taskOp.depth_zbuffer.weight', 'net.42.taskOp.depth_zbuffer.bias', 'net.42.taskOp.depth_zbuffer.running_mean', 'net.42.taskOp.depth_zbuffer.running_var', 'net.42.policy.segment_semantic', 'net.42.policy.depth_zbuffer', 'net.42.basicOp.weight', 'net.42.basicOp.bias', 'net.42.basicOp.running_mean', 'net.42.basicOp.running_var', 'net.44.taskOp.segment_semantic.weight', 'net.44.taskOp.depth_zbuffer.weight', 'net.44.basicOp.weight', 'net.45.taskOp.segment_semantic.weight', 'net.45.taskOp.segment_semantic.bias', 'net.45.taskOp.segment_semantic.running_mean', 'net.45.taskOp.segment_semantic.running_var', 'net.45.taskOp.depth_zbuffer.weight', 'net.45.taskOp.depth_zbuffer.bias', 'net.45.taskOp.depth_zbuffer.running_mean', 'net.45.taskOp.depth_zbuffer.running_var', 'net.45.policy.segment_semantic', 'net.45.policy.depth_zbuffer', 'net.45.basicOp.weight', 'net.45.basicOp.bias', 'net.45.basicOp.running_mean', 'net.45.basicOp.running_var', 'net.48.taskOp.segment_semantic.weight', 'net.48.taskOp.depth_zbuffer.weight', 'net.48.basicOp.weight', 'net.49.taskOp.segment_semantic.weight', 'net.49.taskOp.segment_semantic.bias', 'net.49.taskOp.segment_semantic.running_mean', 'net.49.taskOp.segment_semantic.running_var', 'net.49.taskOp.depth_zbuffer.weight', 'net.49.taskOp.depth_zbuffer.bias', 'net.49.taskOp.depth_zbuffer.running_mean', 'net.49.taskOp.depth_zbuffer.running_var', 'net.49.policy.segment_semantic', 'net.49.policy.depth_zbuffer', 'net.49.basicOp.weight', 'net.49.basicOp.bias', 'net.49.basicOp.running_mean', 'net.49.basicOp.running_var', 'net.51.taskOp.segment_semantic.weight', 'net.51.taskOp.depth_zbuffer.weight', 'net.51.basicOp.weight', 'net.52.taskOp.segment_semantic.weight', 'net.52.taskOp.segment_semantic.bias', 'net.52.taskOp.segment_semantic.running_mean', 'net.52.taskOp.segment_semantic.running_var', 'net.52.taskOp.depth_zbuffer.weight', 'net.52.taskOp.depth_zbuffer.bias', 'net.52.taskOp.depth_zbuffer.running_mean', 'net.52.taskOp.depth_zbuffer.running_var', 'net.52.policy.segment_semantic', 'net.52.policy.depth_zbuffer', 'net.52.basicOp.weight', 'net.52.basicOp.bias', 'net.52.basicOp.running_mean', 'net.52.basicOp.running_var', 'net.55.taskOp.segment_semantic.weight', 'net.55.taskOp.depth_zbuffer.weight', 'net.55.dsOp.segment_semantic.0.weight', 'net.55.dsOp.segment_semantic.1.weight', 'net.55.dsOp.segment_semantic.1.bias', 'net.55.dsOp.segment_semantic.1.running_mean', 'net.55.dsOp.segment_semantic.1.running_var', 'net.55.dsOp.depth_zbuffer.0.weight', 'net.55.dsOp.depth_zbuffer.1.weight', 'net.55.dsOp.depth_zbuffer.1.bias', 'net.55.dsOp.depth_zbuffer.1.running_mean', 'net.55.dsOp.depth_zbuffer.1.running_var', 'net.55.basicOp.weight', 'net.56.taskOp.segment_semantic.weight', 'net.56.taskOp.segment_semantic.bias', 'net.56.taskOp.segment_semantic.running_mean', 'net.56.taskOp.segment_semantic.running_var', 'net.56.taskOp.depth_zbuffer.weight', 'net.56.taskOp.depth_zbuffer.bias', 'net.56.taskOp.depth_zbuffer.running_mean', 'net.56.taskOp.depth_zbuffer.running_var', 'net.56.policy.segment_semantic', 'net.56.policy.depth_zbuffer', 'net.56.basicOp.weight', 'net.56.basicOp.bias', 'net.56.basicOp.running_mean', 'net.56.basicOp.running_var', 'net.57.taskOp.segment_semantic.weight', 'net.57.taskOp.depth_zbuffer.weight', 'net.57.dsOp.segment_semantic.0.weight', 'net.57.dsOp.segment_semantic.1.weight', 'net.57.dsOp.segment_semantic.1.bias', 'net.57.dsOp.segment_semantic.1.running_mean', 'net.57.dsOp.segment_semantic.1.running_var', 'net.57.dsOp.depth_zbuffer.0.weight', 'net.57.dsOp.depth_zbuffer.1.weight', 'net.57.dsOp.depth_zbuffer.1.bias', 'net.57.dsOp.depth_zbuffer.1.running_mean', 'net.57.dsOp.depth_zbuffer.1.running_var', 'net.57.basicOp.weight', 'net.58.taskOp.segment_semantic.weight', 'net.58.taskOp.segment_semantic.bias', 'net.58.taskOp.segment_semantic.running_mean', 'net.58.taskOp.segment_semantic.running_var', 'net.58.taskOp.depth_zbuffer.weight', 'net.58.taskOp.depth_zbuffer.bias', 'net.58.taskOp.depth_zbuffer.running_mean', 'net.58.taskOp.depth_zbuffer.running_var', 'net.58.policy.segment_semantic', 'net.58.policy.depth_zbuffer', 'net.58.basicOp.weight', 'net.58.basicOp.bias', 'net.58.basicOp.running_mean', 'net.58.basicOp.running_var', 'net.60.taskOp.segment_semantic.weight', 'net.60.taskOp.depth_zbuffer.weight', 'net.60.basicOp.weight', 'net.61.taskOp.segment_semantic.weight', 'net.61.taskOp.segment_semantic.bias', 'net.61.taskOp.segment_semantic.running_mean', 'net.61.taskOp.segment_semantic.running_var', 'net.61.taskOp.depth_zbuffer.weight', 'net.61.taskOp.depth_zbuffer.bias', 'net.61.taskOp.depth_zbuffer.running_mean', 'net.61.taskOp.depth_zbuffer.running_var', 'net.61.policy.segment_semantic', 'net.61.policy.depth_zbuffer', 'net.61.basicOp.weight', 'net.61.basicOp.bias', 'net.61.basicOp.running_mean', 'net.61.basicOp.running_var', 'net.64.taskOp.segment_semantic.weight', 'net.64.taskOp.depth_zbuffer.weight', 'net.64.basicOp.weight', 'net.65.taskOp.segment_semantic.weight', 'net.65.taskOp.segment_semantic.bias', 'net.65.taskOp.segment_semantic.running_mean', 'net.65.taskOp.segment_semantic.running_var', 'net.65.taskOp.depth_zbuffer.weight', 'net.65.taskOp.depth_zbuffer.bias', 'net.65.taskOp.depth_zbuffer.running_mean', 'net.65.taskOp.depth_zbuffer.running_var', 'net.65.policy.segment_semantic', 'net.65.policy.depth_zbuffer', 'net.65.basicOp.weight', 'net.65.basicOp.bias', 'net.65.basicOp.running_mean', 'net.65.basicOp.running_var', 'net.67.taskOp.segment_semantic.weight', 'net.67.taskOp.depth_zbuffer.weight', 'net.67.basicOp.weight', 'net.68.taskOp.segment_semantic.weight', 'net.68.taskOp.segment_semantic.bias', 'net.68.taskOp.segment_semantic.running_mean', 'net.68.taskOp.segment_semantic.running_var', 'net.68.taskOp.depth_zbuffer.weight', 'net.68.taskOp.depth_zbuffer.bias', 'net.68.taskOp.depth_zbuffer.running_mean', 'net.68.taskOp.depth_zbuffer.running_var', 'net.68.policy.segment_semantic', 'net.68.policy.depth_zbuffer', 'net.68.basicOp.weight', 'net.68.basicOp.bias', 'net.68.basicOp.running_mean', 'net.68.basicOp.running_var', 'net.71.taskOp.segment_semantic.weight', 'net.71.taskOp.depth_zbuffer.weight', 'net.71.basicOp.weight', 'net.72.taskOp.segment_semantic.weight', 'net.72.taskOp.segment_semantic.bias', 'net.72.taskOp.segment_semantic.running_mean', 'net.72.taskOp.segment_semantic.running_var', 'net.72.taskOp.depth_zbuffer.weight', 'net.72.taskOp.depth_zbuffer.bias', 'net.72.taskOp.depth_zbuffer.running_mean', 'net.72.taskOp.depth_zbuffer.running_var', 'net.72.policy.segment_semantic', 'net.72.policy.depth_zbuffer', 'net.72.basicOp.weight', 'net.72.basicOp.bias', 'net.72.basicOp.running_mean', 'net.72.basicOp.running_var', 'net.74.taskOp.segment_semantic.weight', 'net.74.taskOp.depth_zbuffer.weight', 'net.74.basicOp.weight', 'net.75.taskOp.segment_semantic.weight', 'net.75.taskOp.segment_semantic.bias', 'net.75.taskOp.segment_semantic.running_mean', 'net.75.taskOp.segment_semantic.running_var', 'net.75.taskOp.depth_zbuffer.weight', 'net.75.taskOp.depth_zbuffer.bias', 'net.75.taskOp.depth_zbuffer.running_mean', 'net.75.taskOp.depth_zbuffer.running_var', 'net.75.policy.segment_semantic', 'net.75.policy.depth_zbuffer', 'net.75.basicOp.weight', 'net.75.basicOp.bias', 'net.75.basicOp.running_mean', 'net.75.basicOp.running_var', 'net.78.taskOp.segment_semantic.weight', 'net.78.taskOp.depth_zbuffer.weight', 'net.78.basicOp.weight', 'net.79.taskOp.segment_semantic.weight', 'net.79.taskOp.segment_semantic.bias', 'net.79.taskOp.segment_semantic.running_mean', 'net.79.taskOp.segment_semantic.running_var', 'net.79.taskOp.depth_zbuffer.weight', 'net.79.taskOp.depth_zbuffer.bias', 'net.79.taskOp.depth_zbuffer.running_mean', 'net.79.taskOp.depth_zbuffer.running_var', 'net.79.policy.segment_semantic', 'net.79.policy.depth_zbuffer', 'net.79.basicOp.weight', 'net.79.basicOp.bias', 'net.79.basicOp.running_mean', 'net.79.basicOp.running_var', 'net.81.taskOp.segment_semantic.weight', 'net.81.taskOp.depth_zbuffer.weight', 'net.81.basicOp.weight', 'net.82.taskOp.segment_semantic.weight', 'net.82.taskOp.segment_semantic.bias', 'net.82.taskOp.segment_semantic.running_mean', 'net.82.taskOp.segment_semantic.running_var', 'net.82.taskOp.depth_zbuffer.weight', 'net.82.taskOp.depth_zbuffer.bias', 'net.82.taskOp.depth_zbuffer.running_mean', 'net.82.taskOp.depth_zbuffer.running_var', 'net.82.policy.segment_semantic', 'net.82.policy.depth_zbuffer', 'net.82.basicOp.weight', 'net.82.basicOp.bias', 'net.82.basicOp.running_mean', 'net.82.basicOp.running_var', 'net.85.taskOp.segment_semantic.weight', 'net.85.taskOp.depth_zbuffer.weight', 'net.85.basicOp.weight', 'net.86.taskOp.segment_semantic.weight', 'net.86.taskOp.segment_semantic.bias', 'net.86.taskOp.segment_semantic.running_mean', 'net.86.taskOp.segment_semantic.running_var', 'net.86.taskOp.depth_zbuffer.weight', 'net.86.taskOp.depth_zbuffer.bias', 'net.86.taskOp.depth_zbuffer.running_mean', 'net.86.taskOp.depth_zbuffer.running_var', 'net.86.policy.segment_semantic', 'net.86.policy.depth_zbuffer', 'net.86.basicOp.weight', 'net.86.basicOp.bias', 'net.86.basicOp.running_mean', 'net.86.basicOp.running_var', 'net.88.taskOp.segment_semantic.weight', 'net.88.taskOp.depth_zbuffer.weight', 'net.88.basicOp.weight', 'net.89.taskOp.segment_semantic.weight', 'net.89.taskOp.segment_semantic.bias', 'net.89.taskOp.segment_semantic.running_mean', 'net.89.taskOp.segment_semantic.running_var', 'net.89.taskOp.depth_zbuffer.weight', 'net.89.taskOp.depth_zbuffer.bias', 'net.89.taskOp.depth_zbuffer.running_mean', 'net.89.taskOp.depth_zbuffer.running_var', 'net.89.policy.segment_semantic', 'net.89.policy.depth_zbuffer', 'net.89.basicOp.weight', 'net.89.basicOp.bias', 'net.89.basicOp.running_mean', 'net.89.basicOp.running_var', 'net.92.taskOp.segment_semantic.weight', 'net.92.taskOp.depth_zbuffer.weight', 'net.92.basicOp.weight', 'net.93.taskOp.segment_semantic.weight', 'net.93.taskOp.segment_semantic.bias', 'net.93.taskOp.segment_semantic.running_mean', 'net.93.taskOp.segment_semantic.running_var', 'net.93.taskOp.depth_zbuffer.weight', 'net.93.taskOp.depth_zbuffer.bias', 'net.93.taskOp.depth_zbuffer.running_mean', 'net.93.taskOp.depth_zbuffer.running_var', 'net.93.policy.segment_semantic', 'net.93.policy.depth_zbuffer', 'net.93.basicOp.weight', 'net.93.basicOp.bias', 'net.93.basicOp.running_mean', 'net.93.basicOp.running_var', 'net.95.taskOp.segment_semantic.weight', 'net.95.taskOp.depth_zbuffer.weight', 'net.95.basicOp.weight', 'net.96.taskOp.segment_semantic.weight', 'net.96.taskOp.segment_semantic.bias', 'net.96.taskOp.segment_semantic.running_mean', 'net.96.taskOp.segment_semantic.running_var', 'net.96.taskOp.depth_zbuffer.weight', 'net.96.taskOp.depth_zbuffer.bias', 'net.96.taskOp.depth_zbuffer.running_mean', 'net.96.taskOp.depth_zbuffer.running_var', 'net.96.policy.segment_semantic', 'net.96.policy.depth_zbuffer', 'net.96.basicOp.weight', 'net.96.basicOp.bias', 'net.96.basicOp.running_mean', 'net.96.basicOp.running_var', 'net.99.taskOp.segment_semantic.weight', 'net.99.taskOp.depth_zbuffer.weight', 'net.99.dsOp.segment_semantic.0.weight', 'net.99.dsOp.segment_semantic.1.weight', 'net.99.dsOp.segment_semantic.1.bias', 'net.99.dsOp.segment_semantic.1.running_mean', 'net.99.dsOp.segment_semantic.1.running_var', 'net.99.dsOp.depth_zbuffer.0.weight', 'net.99.dsOp.depth_zbuffer.1.weight', 'net.99.dsOp.depth_zbuffer.1.bias', 'net.99.dsOp.depth_zbuffer.1.running_mean', 'net.99.dsOp.depth_zbuffer.1.running_var', 'net.99.basicOp.weight', 'net.100.taskOp.segment_semantic.weight', 'net.100.taskOp.segment_semantic.bias', 'net.100.taskOp.segment_semantic.running_mean', 'net.100.taskOp.segment_semantic.running_var', 'net.100.taskOp.depth_zbuffer.weight', 'net.100.taskOp.depth_zbuffer.bias', 'net.100.taskOp.depth_zbuffer.running_mean', 'net.100.taskOp.depth_zbuffer.running_var', 'net.100.policy.segment_semantic', 'net.100.policy.depth_zbuffer', 'net.100.basicOp.weight', 'net.100.basicOp.bias', 'net.100.basicOp.running_mean', 'net.100.basicOp.running_var', 'net.101.taskOp.segment_semantic.weight', 'net.101.taskOp.depth_zbuffer.weight', 'net.101.dsOp.segment_semantic.0.weight', 'net.101.dsOp.segment_semantic.1.weight', 'net.101.dsOp.segment_semantic.1.bias', 'net.101.dsOp.segment_semantic.1.running_mean', 'net.101.dsOp.segment_semantic.1.running_var', 'net.101.dsOp.depth_zbuffer.0.weight', 'net.101.dsOp.depth_zbuffer.1.weight', 'net.101.dsOp.depth_zbuffer.1.bias', 'net.101.dsOp.depth_zbuffer.1.running_mean', 'net.101.dsOp.depth_zbuffer.1.running_var', 'net.101.basicOp.weight', 'net.102.taskOp.segment_semantic.weight', 'net.102.taskOp.segment_semantic.bias', 'net.102.taskOp.segment_semantic.running_mean', 'net.102.taskOp.segment_semantic.running_var', 'net.102.taskOp.depth_zbuffer.weight', 'net.102.taskOp.depth_zbuffer.bias', 'net.102.taskOp.depth_zbuffer.running_mean', 'net.102.taskOp.depth_zbuffer.running_var', 'net.102.policy.segment_semantic', 'net.102.policy.depth_zbuffer', 'net.102.basicOp.weight', 'net.102.basicOp.bias', 'net.102.basicOp.running_mean', 'net.102.basicOp.running_var', 'net.104.taskOp.segment_semantic.weight', 'net.104.taskOp.depth_zbuffer.weight', 'net.104.basicOp.weight', 'net.105.taskOp.segment_semantic.weight', 'net.105.taskOp.segment_semantic.bias', 'net.105.taskOp.segment_semantic.running_mean', 'net.105.taskOp.segment_semantic.running_var', 'net.105.taskOp.depth_zbuffer.weight', 'net.105.taskOp.depth_zbuffer.bias', 'net.105.taskOp.depth_zbuffer.running_mean', 'net.105.taskOp.depth_zbuffer.running_var', 'net.105.policy.segment_semantic', 'net.105.policy.depth_zbuffer', 'net.105.basicOp.weight', 'net.105.basicOp.bias', 'net.105.basicOp.running_mean', 'net.105.basicOp.running_var', 'net.108.taskOp.segment_semantic.weight', 'net.108.taskOp.depth_zbuffer.weight', 'net.108.basicOp.weight', 'net.109.taskOp.segment_semantic.weight', 'net.109.taskOp.segment_semantic.bias', 'net.109.taskOp.segment_semantic.running_mean', 'net.109.taskOp.segment_semantic.running_var', 'net.109.taskOp.depth_zbuffer.weight', 'net.109.taskOp.depth_zbuffer.bias', 'net.109.taskOp.depth_zbuffer.running_mean', 'net.109.taskOp.depth_zbuffer.running_var', 'net.109.policy.segment_semantic', 'net.109.policy.depth_zbuffer', 'net.109.basicOp.weight', 'net.109.basicOp.bias', 'net.109.basicOp.running_mean', 'net.109.basicOp.running_var', 'net.111.taskOp.segment_semantic.weight', 'net.111.taskOp.depth_zbuffer.weight', 'net.111.basicOp.weight', 'net.112.taskOp.segment_semantic.weight', 'net.112.taskOp.segment_semantic.bias', 'net.112.taskOp.segment_semantic.running_mean', 'net.112.taskOp.segment_semantic.running_var', 'net.112.taskOp.depth_zbuffer.weight', 'net.112.taskOp.depth_zbuffer.bias', 'net.112.taskOp.depth_zbuffer.running_mean', 'net.112.taskOp.depth_zbuffer.running_var', 'net.112.policy.segment_semantic', 'net.112.policy.depth_zbuffer', 'net.112.basicOp.weight', 'net.112.basicOp.bias', 'net.112.basicOp.running_mean', 'net.112.basicOp.running_var', 'net.115.taskOp.segment_semantic.weight', 'net.115.taskOp.depth_zbuffer.weight', 'net.115.basicOp.weight', 'net.116.taskOp.segment_semantic.weight', 'net.116.taskOp.segment_semantic.bias', 'net.116.taskOp.segment_semantic.running_mean', 'net.116.taskOp.segment_semantic.running_var', 'net.116.taskOp.depth_zbuffer.weight', 'net.116.taskOp.depth_zbuffer.bias', 'net.116.taskOp.depth_zbuffer.running_mean', 'net.116.taskOp.depth_zbuffer.running_var', 'net.116.policy.segment_semantic', 'net.116.policy.depth_zbuffer', 'net.116.basicOp.weight', 'net.116.basicOp.bias', 'net.116.basicOp.running_mean', 'net.116.basicOp.running_var', 'net.118.taskOp.segment_semantic.weight', 'net.118.taskOp.depth_zbuffer.weight', 'net.118.basicOp.weight', 'net.119.taskOp.segment_semantic.weight', 'net.119.taskOp.segment_semantic.bias', 'net.119.taskOp.segment_semantic.running_mean', 'net.119.taskOp.segment_semantic.running_var', 'net.119.taskOp.depth_zbuffer.weight', 'net.119.taskOp.depth_zbuffer.bias', 'net.119.taskOp.depth_zbuffer.running_mean', 'net.119.taskOp.depth_zbuffer.running_var', 'net.119.policy.segment_semantic', 'net.119.policy.depth_zbuffer', 'net.119.basicOp.weight', 'net.119.basicOp.bias', 'net.119.basicOp.running_mean', 'net.119.basicOp.running_var'], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('/mnt/nfs/work1/huiguan/lijunzhang/policymtl/checkpoint/Cityscapes/' + 'sample_design3/0-60/sample_policy_seed60.model')\n",
    "mtlmodel.load_state_dict(state['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['segment_semantic', 'depth_zbuffer']\n",
    "\n",
    "singleParam = 0\n",
    "mtlParam = 0\n",
    "for node in mtlmodel.net:\n",
    "    if node.taskSp and not node.assumeSp:\n",
    "        shared = False\n",
    "        \n",
    "        params = node.basicOp.weight.data.nelement()\n",
    "        if conv.bias is not None:\n",
    "            params += node.basicOp.bias.data.nelement()\n",
    "        singleParam += params\n",
    "        \n",
    "        for task in name_list:\n",
    "            policy = node.policy[task].data.cpu().detach().numpy()\n",
    "            if np.array_equal(policy, np.array([1.,0.,0.])):\n",
    "                if not shared:\n",
    "                    mtlParam += params\n",
    "                    shared = True\n",
    "            elif np.array_equal(policy, np.array([0.,1.,0.])):\n",
    "                mtlParam += params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mtlParam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2dcac88f9d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtlParam\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msingleParam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mtlParam' is not defined"
     ]
    }
   ],
   "source": [
    "mtlParam / (singleParam * len(name_list)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "class RegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegModel, self).__init__()\n",
    "        self.policy = nn.Parameter(torch.tensor([0.0,0.0,0.0]))\n",
    "        \n",
    "    def forward(self):\n",
    "        possiblity = nn.functional.gumbel_softmax(self.policy, tau=5, hard=False)\n",
    "#         possiblity = nn.functional.softmax(self.policy)\n",
    "#         loss = torch.exp(scale * (possiblity[1]-possiblity[0])) + torch.exp(scale * (possiblity[2]-possiblity[0]))\n",
    "        loss = torch.log(1+torch.exp(scale * (possiblity[1]-possiblity[0]))) + \\\n",
    "               torch.log(1+torch.exp(scale * (possiblity[2]-possiblity[0])))\n",
    "        print(self.policy)\n",
    "        print(possiblity)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regM = RegModel()\n",
    "optimizer = torch.optim.SGD(regM.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "tensor([0.4721, 0.2448, 0.2831], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1890517473220825\n",
      "Parameter containing:\n",
      "tensor([ 0.0007, -0.0003, -0.0004], requires_grad=True)\n",
      "tensor([0.2924, 0.3744, 0.3333], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4488097429275513\n",
      "Parameter containing:\n",
      "tensor([ 0.0013, -0.0007, -0.0007], requires_grad=True)\n",
      "tensor([0.2130, 0.4115, 0.3755], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5750212669372559\n",
      "Parameter containing:\n",
      "tensor([ 0.0019, -0.0009, -0.0009], requires_grad=True)\n",
      "tensor([0.2897, 0.3058, 0.4046], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4534697532653809\n",
      "Parameter containing:\n",
      "tensor([ 0.0025, -0.0012, -0.0013], requires_grad=True)\n",
      "tensor([0.4019, 0.2974, 0.3007], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2860963344573975\n",
      "Parameter containing:\n",
      "tensor([ 0.0032, -0.0015, -0.0016], requires_grad=True)\n",
      "tensor([0.4381, 0.3021, 0.2599], grad_fn=<SoftmaxBackward>)\n",
      "output:1.235487461090088\n",
      "Parameter containing:\n",
      "tensor([ 0.0039, -0.0019, -0.0019], requires_grad=True)\n",
      "tensor([0.3936, 0.3318, 0.2746], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2981393337249756\n",
      "Parameter containing:\n",
      "tensor([ 0.0045, -0.0023, -0.0023], requires_grad=True)\n",
      "tensor([0.3844, 0.2802, 0.3354], grad_fn=<SoftmaxBackward>)\n",
      "output:1.311346173286438\n",
      "Parameter containing:\n",
      "tensor([ 0.0052, -0.0026, -0.0026], requires_grad=True)\n",
      "tensor([0.2671, 0.4999, 0.2330], grad_fn=<SoftmaxBackward>)\n",
      "output:1.492544174194336\n",
      "Parameter containing:\n",
      "tensor([ 0.0058, -0.0030, -0.0028], requires_grad=True)\n",
      "tensor([0.2342, 0.4724, 0.2934], grad_fn=<SoftmaxBackward>)\n",
      "output:1.542464256286621\n",
      "Parameter containing:\n",
      "tensor([ 0.0064, -0.0034, -0.0030], requires_grad=True)\n",
      "tensor([0.2119, 0.5493, 0.2388], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5827680826187134\n",
      "Parameter containing:\n",
      "tensor([ 0.0070, -0.0038, -0.0032], requires_grad=True)\n",
      "tensor([0.3325, 0.3076, 0.3599], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3877246379852295\n",
      "Parameter containing:\n",
      "tensor([ 0.0076, -0.0041, -0.0035], requires_grad=True)\n",
      "tensor([0.3944, 0.2880, 0.3176], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2968647480010986\n",
      "Parameter containing:\n",
      "tensor([ 0.0083, -0.0045, -0.0039], requires_grad=True)\n",
      "tensor([0.2765, 0.4309, 0.2926], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4745492935180664\n",
      "Parameter containing:\n",
      "tensor([ 0.0090, -0.0048, -0.0041], requires_grad=True)\n",
      "tensor([0.3542, 0.2352, 0.4107], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3571754693984985\n",
      "Parameter containing:\n",
      "tensor([ 0.0096, -0.0051, -0.0046], requires_grad=True)\n",
      "tensor([0.3154, 0.3454, 0.3392], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4134092330932617\n",
      "Parameter containing:\n",
      "tensor([ 0.0103, -0.0054, -0.0049], requires_grad=True)\n",
      "tensor([0.3363, 0.3802, 0.2835], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3824872970581055\n",
      "Parameter containing:\n",
      "tensor([ 0.0110, -0.0058, -0.0052], requires_grad=True)\n",
      "tensor([0.3257, 0.3231, 0.3512], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3978310823440552\n",
      "Parameter containing:\n",
      "tensor([ 0.0116, -0.0061, -0.0055], requires_grad=True)\n",
      "tensor([0.2608, 0.4346, 0.3046], grad_fn=<SoftmaxBackward>)\n",
      "output:1.499119758605957\n",
      "Parameter containing:\n",
      "tensor([ 0.0122, -0.0065, -0.0058], requires_grad=True)\n",
      "tensor([0.2978, 0.2712, 0.4310], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4419159889221191\n",
      "Parameter containing:\n",
      "tensor([ 0.0129, -0.0067, -0.0062], requires_grad=True)\n",
      "tensor([0.3654, 0.2416, 0.3930], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3401434421539307\n",
      "Parameter containing:\n",
      "tensor([ 0.0136, -0.0070, -0.0066], requires_grad=True)\n",
      "tensor([0.3179, 0.3219, 0.3601], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4096312522888184\n",
      "Parameter containing:\n",
      "tensor([ 0.0142, -0.0073, -0.0069], requires_grad=True)\n",
      "tensor([0.3688, 0.3132, 0.3180], grad_fn=<SoftmaxBackward>)\n",
      "output:1.333802342414856\n",
      "Parameter containing:\n",
      "tensor([ 0.0149, -0.0076, -0.0073], requires_grad=True)\n",
      "tensor([0.3373, 0.3584, 0.3042], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3805031776428223\n",
      "Parameter containing:\n",
      "tensor([ 0.0156, -0.0080, -0.0076], requires_grad=True)\n",
      "tensor([0.4071, 0.3007, 0.2922], grad_fn=<SoftmaxBackward>)\n",
      "output:1.278753399848938\n",
      "Parameter containing:\n",
      "tensor([ 0.0163, -0.0083, -0.0079], requires_grad=True)\n",
      "tensor([0.3969, 0.2354, 0.3677], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2943179607391357\n",
      "Parameter containing:\n",
      "tensor([ 0.0169, -0.0086, -0.0084], requires_grad=True)\n",
      "tensor([0.3419, 0.2561, 0.4020], grad_fn=<SoftmaxBackward>)\n",
      "output:1.374863862991333\n",
      "Parameter containing:\n",
      "tensor([ 0.0176, -0.0088, -0.0088], requires_grad=True)\n",
      "tensor([0.4210, 0.3146, 0.2644], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2592110633850098\n",
      "Parameter containing:\n",
      "tensor([ 0.0183, -0.0092, -0.0091], requires_grad=True)\n",
      "tensor([0.3055, 0.3851, 0.3093], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4287710189819336\n",
      "Parameter containing:\n",
      "tensor([ 0.0189, -0.0096, -0.0094], requires_grad=True)\n",
      "tensor([0.3384, 0.2653, 0.3964], grad_fn=<SoftmaxBackward>)\n",
      "output:1.379805088043213\n",
      "Parameter containing:\n",
      "tensor([ 0.0196, -0.0098, -0.0098], requires_grad=True)\n",
      "tensor([0.4299, 0.2675, 0.3026], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2467079162597656\n",
      "Parameter containing:\n",
      "tensor([ 0.0203, -0.0102, -0.0101], requires_grad=True)\n",
      "tensor([0.2629, 0.4163, 0.3208], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4952609539031982\n",
      "Parameter containing:\n",
      "tensor([ 0.0209, -0.0105, -0.0104], requires_grad=True)\n",
      "tensor([0.2806, 0.3268, 0.3926], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4671874046325684\n",
      "Parameter containing:\n",
      "tensor([ 0.0215, -0.0108, -0.0108], requires_grad=True)\n",
      "tensor([0.3208, 0.1921, 0.4870], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4105424880981445\n",
      "Parameter containing:\n",
      "tensor([ 0.0222, -0.0110, -0.0113], requires_grad=True)\n",
      "tensor([0.3235, 0.3212, 0.3553], grad_fn=<SoftmaxBackward>)\n",
      "output:1.401136875152588\n",
      "Parameter containing:\n",
      "tensor([ 0.0229, -0.0113, -0.0116], requires_grad=True)\n",
      "tensor([0.3685, 0.3296, 0.3018], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3342244625091553\n",
      "Parameter containing:\n",
      "tensor([ 0.0235, -0.0116, -0.0119], requires_grad=True)\n",
      "tensor([0.3756, 0.3410, 0.2834], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3241233825683594\n",
      "Parameter containing:\n",
      "tensor([ 0.0242, -0.0120, -0.0122], requires_grad=True)\n",
      "tensor([0.2159, 0.5858, 0.1983], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5795013904571533\n",
      "Parameter containing:\n",
      "tensor([ 0.0248, -0.0124, -0.0123], requires_grad=True)\n",
      "tensor([0.3464, 0.3390, 0.3147], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3668758869171143\n",
      "Parameter containing:\n",
      "tensor([ 0.0255, -0.0128, -0.0127], requires_grad=True)\n",
      "tensor([0.3564, 0.3013, 0.3423], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3521173000335693\n",
      "Parameter containing:\n",
      "tensor([ 0.0261, -0.0131, -0.0130], requires_grad=True)\n",
      "tensor([0.2689, 0.3348, 0.3962], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4855003356933594\n",
      "Parameter containing:\n",
      "tensor([ 0.0268, -0.0134, -0.0134], requires_grad=True)\n",
      "tensor([0.3128, 0.3733, 0.3139], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4175409078598022\n",
      "Parameter containing:\n",
      "tensor([ 0.0274, -0.0137, -0.0137], requires_grad=True)\n",
      "tensor([0.3407, 0.3169, 0.3424], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3753831386566162\n",
      "Parameter containing:\n",
      "tensor([ 0.0281, -0.0141, -0.0140], requires_grad=True)\n",
      "tensor([0.3005, 0.3421, 0.3574], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4361777305603027\n",
      "Parameter containing:\n",
      "tensor([ 0.0287, -0.0144, -0.0143], requires_grad=True)\n",
      "tensor([0.2957, 0.3481, 0.3562], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4435737133026123\n",
      "Parameter containing:\n",
      "tensor([ 0.0294, -0.0147, -0.0147], requires_grad=True)\n",
      "tensor([0.3333, 0.3397, 0.3270], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3863264322280884\n",
      "Parameter containing:\n",
      "tensor([ 0.0300, -0.0150, -0.0150], requires_grad=True)\n",
      "tensor([0.3235, 0.3102, 0.3663], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4012572765350342\n",
      "Parameter containing:\n",
      "tensor([ 0.0307, -0.0153, -0.0154], requires_grad=True)\n",
      "tensor([0.3695, 0.2348, 0.3957], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3343567848205566\n",
      "Parameter containing:\n",
      "tensor([ 0.0314, -0.0156, -0.0158], requires_grad=True)\n",
      "tensor([0.2000, 0.4011, 0.3989], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5963118076324463\n",
      "Parameter containing:\n",
      "tensor([ 0.0319, -0.0158, -0.0161], requires_grad=True)\n",
      "tensor([0.4151, 0.2924, 0.2925], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2673842906951904\n",
      "Parameter containing:\n",
      "tensor([ 0.0326, -0.0162, -0.0164], requires_grad=True)\n",
      "tensor([0.3575, 0.2811, 0.3615], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3508336544036865\n",
      "Parameter containing:\n",
      "tensor([ 0.0333, -0.0165, -0.0168], requires_grad=True)\n",
      "tensor([0.2618, 0.3239, 0.4143], grad_fn=<SoftmaxBackward>)\n",
      "output:1.497049331665039\n",
      "Parameter containing:\n",
      "tensor([ 0.0339, -0.0167, -0.0171], requires_grad=True)\n",
      "tensor([0.3228, 0.4178, 0.2594], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4037156105041504\n",
      "Parameter containing:\n",
      "tensor([ 0.0345, -0.0172, -0.0174], requires_grad=True)\n",
      "tensor([0.3385, 0.3562, 0.3053], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3786911964416504\n",
      "Parameter containing:\n",
      "tensor([ 0.0352, -0.0175, -0.0177], requires_grad=True)\n",
      "tensor([0.3405, 0.2856, 0.3739], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3760511875152588\n",
      "Parameter containing:\n",
      "tensor([ 0.0359, -0.0178, -0.0181], requires_grad=True)\n",
      "tensor([0.3582, 0.2812, 0.3606], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3497331142425537\n",
      "Parameter containing:\n",
      "tensor([ 0.0366, -0.0181, -0.0185], requires_grad=True)\n",
      "tensor([0.2140, 0.4049, 0.3811], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5733208656311035\n",
      "Parameter containing:\n",
      "tensor([ 0.0371, -0.0184, -0.0187], requires_grad=True)\n",
      "tensor([0.2578, 0.3242, 0.4180], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5034027099609375\n",
      "Parameter containing:\n",
      "tensor([ 0.0377, -0.0186, -0.0191], requires_grad=True)\n",
      "tensor([0.4079, 0.3267, 0.2654], grad_fn=<SoftmaxBackward>)\n",
      "output:1.277836561203003\n",
      "Parameter containing:\n",
      "tensor([ 0.0384, -0.0190, -0.0194], requires_grad=True)\n",
      "tensor([0.4092, 0.3634, 0.2274], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2768752574920654\n",
      "Parameter containing:\n",
      "tensor([ 0.0391, -0.0195, -0.0196], requires_grad=True)\n",
      "tensor([0.3508, 0.2796, 0.3696], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3607463836669922\n",
      "Parameter containing:\n",
      "tensor([ 0.0398, -0.0197, -0.0200], requires_grad=True)\n",
      "tensor([0.4201, 0.2729, 0.3070], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2604713439941406\n",
      "Parameter containing:\n",
      "tensor([ 0.0404, -0.0201, -0.0204], requires_grad=True)\n",
      "tensor([0.3317, 0.3522, 0.3161], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3887946605682373\n",
      "Parameter containing:\n",
      "tensor([ 0.0411, -0.0204, -0.0207], requires_grad=True)\n",
      "tensor([0.3680, 0.2192, 0.4127], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3372761011123657\n",
      "Parameter containing:\n",
      "tensor([ 0.0418, -0.0206, -0.0212], requires_grad=True)\n",
      "tensor([0.2875, 0.3130, 0.3995], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4567217826843262\n",
      "Parameter containing:\n",
      "tensor([ 0.0424, -0.0209, -0.0215], requires_grad=True)\n",
      "tensor([0.3726, 0.3390, 0.2884], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3283843994140625\n",
      "Parameter containing:\n",
      "tensor([ 0.0431, -0.0213, -0.0218], requires_grad=True)\n",
      "tensor([0.2409, 0.5120, 0.2471], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5340849161148071\n",
      "Parameter containing:\n",
      "tensor([ 0.0437, -0.0217, -0.0220], requires_grad=True)\n",
      "tensor([0.3022, 0.4160, 0.2818], grad_fn=<SoftmaxBackward>)\n",
      "output:1.434661865234375\n",
      "Parameter containing:\n",
      "tensor([ 0.0444, -0.0221, -0.0223], requires_grad=True)\n",
      "tensor([0.3341, 0.3377, 0.3282], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3851522207260132\n",
      "Parameter containing:\n",
      "tensor([ 0.0450, -0.0224, -0.0226], requires_grad=True)\n",
      "tensor([0.3124, 0.3514, 0.3362], grad_fn=<SoftmaxBackward>)\n",
      "output:1.41795015335083\n",
      "Parameter containing:\n",
      "tensor([ 0.0457, -0.0228, -0.0229], requires_grad=True)\n",
      "tensor([0.2957, 0.3760, 0.3283], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4437389373779297\n",
      "Parameter containing:\n",
      "tensor([ 0.0463, -0.0231, -0.0232], requires_grad=True)\n",
      "tensor([0.3435, 0.3389, 0.3176], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3711082935333252\n",
      "Parameter containing:\n",
      "tensor([ 0.0470, -0.0235, -0.0235], requires_grad=True)\n",
      "tensor([0.3119, 0.3720, 0.3161], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4189718961715698\n",
      "Parameter containing:\n",
      "tensor([ 0.0476, -0.0238, -0.0238], requires_grad=True)\n",
      "tensor([0.4582, 0.2222, 0.3197], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2083730697631836\n",
      "Parameter containing:\n",
      "tensor([ 0.0483, -0.0241, -0.0242], requires_grad=True)\n",
      "tensor([0.3042, 0.4144, 0.2814], grad_fn=<SoftmaxBackward>)\n",
      "output:1.431631326675415\n",
      "Parameter containing:\n",
      "tensor([ 0.0490, -0.0245, -0.0245], requires_grad=True)\n",
      "tensor([0.3477, 0.2273, 0.4250], grad_fn=<SoftmaxBackward>)\n",
      "output:1.367309331893921\n",
      "Parameter containing:\n",
      "tensor([ 0.0496, -0.0247, -0.0249], requires_grad=True)\n",
      "tensor([0.4470, 0.2563, 0.2966], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2231056690216064\n",
      "Parameter containing:\n",
      "tensor([ 0.0503, -0.0250, -0.0253], requires_grad=True)\n",
      "tensor([0.2987, 0.3628, 0.3385], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4389491081237793\n",
      "Parameter containing:\n",
      "tensor([ 0.0510, -0.0254, -0.0256], requires_grad=True)\n",
      "tensor([0.2659, 0.2600, 0.4741], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4929336309432983\n",
      "Parameter containing:\n",
      "tensor([ 0.0516, -0.0256, -0.0260], requires_grad=True)\n",
      "tensor([0.2269, 0.2478, 0.5253], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5570343732833862\n",
      "Parameter containing:\n",
      "tensor([ 0.0522, -0.0257, -0.0264], requires_grad=True)\n",
      "tensor([0.2606, 0.4286, 0.3108], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4991960525512695\n",
      "Parameter containing:\n",
      "tensor([ 0.0528, -0.0261, -0.0267], requires_grad=True)\n",
      "tensor([0.4322, 0.2124, 0.3554], grad_fn=<SoftmaxBackward>)\n",
      "output:1.244701623916626\n",
      "Parameter containing:\n",
      "tensor([ 0.0535, -0.0263, -0.0271], requires_grad=True)\n",
      "tensor([0.4107, 0.3179, 0.2714], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2737061977386475\n",
      "Parameter containing:\n",
      "tensor([ 0.0541, -0.0267, -0.0274], requires_grad=True)\n",
      "tensor([0.2278, 0.2869, 0.4853], grad_fn=<SoftmaxBackward>)\n",
      "output:1.553367257118225\n",
      "Parameter containing:\n",
      "tensor([ 0.0547, -0.0269, -0.0278], requires_grad=True)\n",
      "tensor([0.3464, 0.3281, 0.3255], grad_fn=<SoftmaxBackward>)\n",
      "output:1.366800308227539\n",
      "Parameter containing:\n",
      "tensor([ 0.0554, -0.0272, -0.0281], requires_grad=True)\n",
      "tensor([0.3574, 0.3411, 0.3016], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3506804704666138\n",
      "Parameter containing:\n",
      "tensor([ 0.0561, -0.0276, -0.0285], requires_grad=True)\n",
      "tensor([0.4299, 0.2748, 0.2954], grad_fn=<SoftmaxBackward>)\n",
      "output:1.246772289276123\n",
      "Parameter containing:\n",
      "tensor([ 0.0567, -0.0279, -0.0288], requires_grad=True)\n",
      "tensor([0.3185, 0.2914, 0.3901], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4092564582824707\n",
      "Parameter containing:\n",
      "tensor([ 0.0574, -0.0282, -0.0292], requires_grad=True)\n",
      "tensor([0.5002, 0.2845, 0.2153], grad_fn=<SoftmaxBackward>)\n",
      "output:1.151899814605713\n",
      "Parameter containing:\n",
      "tensor([ 0.0581, -0.0286, -0.0295], requires_grad=True)\n",
      "tensor([0.2910, 0.3119, 0.3970], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4511892795562744\n",
      "Parameter containing:\n",
      "tensor([ 0.0587, -0.0289, -0.0298], requires_grad=True)\n",
      "tensor([0.3017, 0.3722, 0.3261], grad_fn=<SoftmaxBackward>)\n",
      "output:1.434486985206604\n",
      "Parameter containing:\n",
      "tensor([ 0.0593, -0.0292, -0.0301], requires_grad=True)\n",
      "tensor([0.3443, 0.2928, 0.3629], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3701972961425781\n",
      "Parameter containing:\n",
      "tensor([ 0.0600, -0.0295, -0.0305], requires_grad=True)\n",
      "tensor([0.3203, 0.3969, 0.2829], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4067891836166382\n",
      "Parameter containing:\n",
      "tensor([ 0.0607, -0.0299, -0.0308], requires_grad=True)\n",
      "tensor([0.3270, 0.3120, 0.3609], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3959364891052246\n",
      "Parameter containing:\n",
      "tensor([ 0.0613, -0.0302, -0.0311], requires_grad=True)\n",
      "tensor([0.3730, 0.2735, 0.3535], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3281184434890747\n",
      "Parameter containing:\n",
      "tensor([ 0.0620, -0.0305, -0.0315], requires_grad=True)\n",
      "tensor([0.3246, 0.4404, 0.2350], grad_fn=<SoftmaxBackward>)\n",
      "output:1.40205979347229\n",
      "Parameter containing:\n",
      "tensor([ 0.0627, -0.0309, -0.0317], requires_grad=True)\n",
      "tensor([0.4947, 0.2919, 0.2134], grad_fn=<SoftmaxBackward>)\n",
      "output:1.159273624420166\n",
      "Parameter containing:\n",
      "tensor([ 0.0633, -0.0313, -0.0320], requires_grad=True)\n",
      "tensor([0.3276, 0.3484, 0.3240], grad_fn=<SoftmaxBackward>)\n",
      "output:1.394966721534729\n",
      "Parameter containing:\n",
      "tensor([ 0.0640, -0.0317, -0.0323], requires_grad=True)\n",
      "tensor([0.3304, 0.3299, 0.3397], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3907482624053955\n",
      "Parameter containing:\n",
      "tensor([ 0.0647, -0.0320, -0.0327], requires_grad=True)\n",
      "tensor([0.3055, 0.2689, 0.4255], grad_fn=<SoftmaxBackward>)\n",
      "output:1.429941177368164\n",
      "Parameter containing:\n",
      "tensor([ 0.0653, -0.0322, -0.0331], requires_grad=True)\n",
      "tensor([0.2989, 0.3031, 0.3981], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4392344951629639\n",
      "Parameter containing:\n",
      "tensor([ 0.0660, -0.0325, -0.0335], requires_grad=True)\n",
      "tensor([0.3178, 0.4084, 0.2738], grad_fn=<SoftmaxBackward>)\n",
      "output:1.41086745262146\n",
      "Parameter containing:\n",
      "tensor([ 0.0666, -0.0329, -0.0337], requires_grad=True)\n",
      "tensor([0.3465, 0.3089, 0.3446], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3667871952056885\n",
      "Parameter containing:\n",
      "tensor([ 0.0673, -0.0332, -0.0341], requires_grad=True)\n",
      "tensor([0.3841, 0.2910, 0.3249], grad_fn=<SoftmaxBackward>)\n",
      "output:1.311682939529419\n",
      "Parameter containing:\n",
      "tensor([ 0.0680, -0.0335, -0.0344], requires_grad=True)\n",
      "tensor([0.3283, 0.4260, 0.2456], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3958688974380493\n",
      "Parameter containing:\n",
      "tensor([ 0.0687, -0.0340, -0.0347], requires_grad=True)\n",
      "tensor([0.3965, 0.2727, 0.3308], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2940434217453003\n",
      "Parameter containing:\n",
      "tensor([ 0.0693, -0.0343, -0.0350], requires_grad=True)\n",
      "tensor([0.2588, 0.3745, 0.3667], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5012273788452148\n",
      "Parameter containing:\n",
      "tensor([ 0.0699, -0.0346, -0.0353], requires_grad=True)\n",
      "tensor([0.2419, 0.2645, 0.4936], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5313303470611572\n",
      "Parameter containing:\n",
      "tensor([ 0.0705, -0.0348, -0.0358], requires_grad=True)\n",
      "tensor([0.3123, 0.3283, 0.3594], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4182041883468628\n",
      "Parameter containing:\n",
      "tensor([ 0.0712, -0.0351, -0.0361], requires_grad=True)\n",
      "tensor([0.3496, 0.2657, 0.3847], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3629549741744995\n",
      "Parameter containing:\n",
      "tensor([ 0.0719, -0.0354, -0.0365], requires_grad=True)\n",
      "tensor([0.2159, 0.2382, 0.5459], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5760226249694824\n",
      "Parameter containing:\n",
      "tensor([ 0.0724, -0.0355, -0.0369], requires_grad=True)\n",
      "tensor([0.3256, 0.3732, 0.3012], grad_fn=<SoftmaxBackward>)\n",
      "output:1.398291826248169\n",
      "Parameter containing:\n",
      "tensor([ 0.0731, -0.0359, -0.0372], requires_grad=True)\n",
      "tensor([0.4778, 0.3476, 0.1745], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1830976009368896\n",
      "Parameter containing:\n",
      "tensor([ 0.0738, -0.0363, -0.0374], requires_grad=True)\n",
      "tensor([0.1297, 0.6342, 0.2362], grad_fn=<SoftmaxBackward>)\n",
      "output:1.724700689315796\n",
      "Parameter containing:\n",
      "tensor([ 0.0742, -0.0367, -0.0375], requires_grad=True)\n",
      "tensor([0.3000, 0.2390, 0.4610], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4400486946105957\n",
      "Parameter containing:\n",
      "tensor([ 0.0748, -0.0369, -0.0379], requires_grad=True)\n",
      "tensor([0.3187, 0.2561, 0.4252], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4101123809814453\n",
      "Parameter containing:\n",
      "tensor([ 0.0755, -0.0371, -0.0384], requires_grad=True)\n",
      "tensor([0.3242, 0.3074, 0.3684], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4002922773361206\n",
      "Parameter containing:\n",
      "tensor([ 0.0761, -0.0374, -0.0387], requires_grad=True)\n",
      "tensor([0.4858, 0.2200, 0.2942], grad_fn=<SoftmaxBackward>)\n",
      "output:1.170990228652954\n",
      "Parameter containing:\n",
      "tensor([ 0.0768, -0.0377, -0.0391], requires_grad=True)\n",
      "tensor([0.2847, 0.3782, 0.3371], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4606139659881592\n",
      "Parameter containing:\n",
      "tensor([ 0.0774, -0.0380, -0.0394], requires_grad=True)\n",
      "tensor([0.2988, 0.3944, 0.3069], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4392770528793335\n",
      "Parameter containing:\n",
      "tensor([ 0.0781, -0.0384, -0.0397], requires_grad=True)\n",
      "tensor([0.3164, 0.2876, 0.3959], grad_fn=<SoftmaxBackward>)\n",
      "output:1.412543535232544\n",
      "Parameter containing:\n",
      "tensor([ 0.0787, -0.0386, -0.0401], requires_grad=True)\n",
      "tensor([0.3360, 0.3337, 0.3304], grad_fn=<SoftmaxBackward>)\n",
      "output:1.382367730140686\n",
      "Parameter containing:\n",
      "tensor([ 0.0794, -0.0390, -0.0404], requires_grad=True)\n",
      "tensor([0.4557, 0.2708, 0.2735], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2112131118774414\n",
      "Parameter containing:\n",
      "tensor([ 0.0801, -0.0393, -0.0408], requires_grad=True)\n",
      "tensor([0.2956, 0.3672, 0.3372], grad_fn=<SoftmaxBackward>)\n",
      "output:1.443693995475769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0807, -0.0397, -0.0411], requires_grad=True)\n",
      "tensor([0.4961, 0.2465, 0.2574], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1569557189941406\n",
      "Parameter containing:\n",
      "tensor([ 0.0814, -0.0400, -0.0414], requires_grad=True)\n",
      "tensor([0.2993, 0.4298, 0.2710], grad_fn=<SoftmaxBackward>)\n",
      "output:1.439603567123413\n",
      "Parameter containing:\n",
      "tensor([ 0.0820, -0.0404, -0.0416], requires_grad=True)\n",
      "tensor([0.3189, 0.2958, 0.3854], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4086323976516724\n",
      "Parameter containing:\n",
      "tensor([ 0.0827, -0.0407, -0.0420], requires_grad=True)\n",
      "tensor([0.3041, 0.2757, 0.4203], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4319849014282227\n",
      "Parameter containing:\n",
      "tensor([ 0.0833, -0.0409, -0.0424], requires_grad=True)\n",
      "tensor([0.4234, 0.2869, 0.2897], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2557528018951416\n",
      "Parameter containing:\n",
      "tensor([ 0.0840, -0.0413, -0.0428], requires_grad=True)\n",
      "tensor([0.3519, 0.3796, 0.2685], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3594114780426025\n",
      "Parameter containing:\n",
      "tensor([ 0.0847, -0.0417, -0.0430], requires_grad=True)\n",
      "tensor([0.3691, 0.2812, 0.3497], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3336608409881592\n",
      "Parameter containing:\n",
      "tensor([ 0.0854, -0.0420, -0.0434], requires_grad=True)\n",
      "tensor([0.3619, 0.3362, 0.3019], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3439520597457886\n",
      "Parameter containing:\n",
      "tensor([ 0.0860, -0.0423, -0.0437], requires_grad=True)\n",
      "tensor([0.3124, 0.4082, 0.2794], grad_fn=<SoftmaxBackward>)\n",
      "output:1.418977975845337\n",
      "Parameter containing:\n",
      "tensor([ 0.0867, -0.0427, -0.0440], requires_grad=True)\n",
      "tensor([0.2972, 0.3340, 0.3688], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4413425922393799\n",
      "Parameter containing:\n",
      "tensor([ 0.0873, -0.0430, -0.0443], requires_grad=True)\n",
      "tensor([0.4641, 0.3105, 0.2255], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2002328634262085\n",
      "Parameter containing:\n",
      "tensor([ 0.0880, -0.0434, -0.0446], requires_grad=True)\n",
      "tensor([0.3136, 0.4173, 0.2690], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4174232482910156\n",
      "Parameter containing:\n",
      "tensor([ 0.0887, -0.0438, -0.0449], requires_grad=True)\n",
      "tensor([0.2922, 0.4031, 0.3048], grad_fn=<SoftmaxBackward>)\n",
      "output:1.449573040008545\n",
      "Parameter containing:\n",
      "tensor([ 0.0893, -0.0442, -0.0451], requires_grad=True)\n",
      "tensor([0.2836, 0.2022, 0.5141], grad_fn=<SoftmaxBackward>)\n",
      "output:1.468282699584961\n",
      "Parameter containing:\n",
      "tensor([ 0.0900, -0.0444, -0.0456], requires_grad=True)\n",
      "tensor([0.3384, 0.2920, 0.3697], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3791403770446777\n",
      "Parameter containing:\n",
      "tensor([ 0.0906, -0.0446, -0.0460], requires_grad=True)\n",
      "tensor([0.3000, 0.2714, 0.4285], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4383862018585205\n",
      "Parameter containing:\n",
      "tensor([ 0.0913, -0.0449, -0.0464], requires_grad=True)\n",
      "tensor([0.2548, 0.3639, 0.3812], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5075147151947021\n",
      "Parameter containing:\n",
      "tensor([ 0.0919, -0.0452, -0.0467], requires_grad=True)\n",
      "tensor([0.4118, 0.2546, 0.3336], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2724404335021973\n",
      "Parameter containing:\n",
      "tensor([ 0.0926, -0.0455, -0.0471], requires_grad=True)\n",
      "tensor([0.3277, 0.3173, 0.3550], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3948546648025513\n",
      "Parameter containing:\n",
      "tensor([ 0.0932, -0.0458, -0.0474], requires_grad=True)\n",
      "tensor([0.3271, 0.2363, 0.4366], grad_fn=<SoftmaxBackward>)\n",
      "output:1.398179292678833\n",
      "Parameter containing:\n",
      "tensor([ 0.0939, -0.0460, -0.0479], requires_grad=True)\n",
      "tensor([0.4118, 0.2697, 0.3185], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2722413539886475\n",
      "Parameter containing:\n",
      "tensor([ 0.0946, -0.0463, -0.0483], requires_grad=True)\n",
      "tensor([0.2520, 0.1911, 0.5569], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5203953981399536\n",
      "Parameter containing:\n",
      "tensor([ 0.0952, -0.0464, -0.0487], requires_grad=True)\n",
      "tensor([0.3416, 0.3043, 0.3541], grad_fn=<SoftmaxBackward>)\n",
      "output:1.374032974243164\n",
      "Parameter containing:\n",
      "tensor([ 0.0959, -0.0467, -0.0491], requires_grad=True)\n",
      "tensor([0.3542, 0.3882, 0.2577], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3563475608825684\n",
      "Parameter containing:\n",
      "tensor([ 0.0965, -0.0472, -0.0494], requires_grad=True)\n",
      "tensor([0.3144, 0.4173, 0.2683], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4162652492523193\n",
      "Parameter containing:\n",
      "tensor([ 0.0972, -0.0476, -0.0496], requires_grad=True)\n",
      "tensor([0.3061, 0.2259, 0.4680], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4312243461608887\n",
      "Parameter containing:\n",
      "tensor([ 0.0978, -0.0478, -0.0501], requires_grad=True)\n",
      "tensor([0.3375, 0.3206, 0.3419], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3801350593566895\n",
      "Parameter containing:\n",
      "tensor([ 0.0985, -0.0481, -0.0504], requires_grad=True)\n",
      "tensor([0.3245, 0.3039, 0.3716], grad_fn=<SoftmaxBackward>)\n",
      "output:1.399827480316162\n",
      "Parameter containing:\n",
      "tensor([ 0.0992, -0.0484, -0.0508], requires_grad=True)\n",
      "tensor([0.4063, 0.3654, 0.2283], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2810231447219849\n",
      "Parameter containing:\n",
      "tensor([ 0.0999, -0.0488, -0.0510], requires_grad=True)\n",
      "tensor([0.3709, 0.3167, 0.3124], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3307467699050903\n",
      "Parameter containing:\n",
      "tensor([ 0.1005, -0.0492, -0.0514], requires_grad=True)\n",
      "tensor([0.3723, 0.3089, 0.3188], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3287231922149658\n",
      "Parameter containing:\n",
      "tensor([ 0.1012, -0.0495, -0.0517], requires_grad=True)\n",
      "tensor([0.3041, 0.2876, 0.4083], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4315369129180908\n",
      "Parameter containing:\n",
      "tensor([ 0.1019, -0.0497, -0.0521], requires_grad=True)\n",
      "tensor([0.5227, 0.2271, 0.2502], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1224253177642822\n",
      "Parameter containing:\n",
      "tensor([ 0.1025, -0.0501, -0.0525], requires_grad=True)\n",
      "tensor([0.2487, 0.3791, 0.3722], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5172460079193115\n",
      "Parameter containing:\n",
      "tensor([ 0.1031, -0.0504, -0.0528], requires_grad=True)\n",
      "tensor([0.3448, 0.3277, 0.3275], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3691017627716064\n",
      "Parameter containing:\n",
      "tensor([ 0.1038, -0.0507, -0.0531], requires_grad=True)\n",
      "tensor([0.2504, 0.3578, 0.3918], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5146522521972656\n",
      "Parameter containing:\n",
      "tensor([ 0.1044, -0.0510, -0.0534], requires_grad=True)\n",
      "tensor([0.2361, 0.2510, 0.5130], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5417969226837158\n",
      "Parameter containing:\n",
      "tensor([ 0.1050, -0.0511, -0.0538], requires_grad=True)\n",
      "tensor([0.5922, 0.2518, 0.1560], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0359957218170166\n",
      "Parameter containing:\n",
      "tensor([ 0.1056, -0.0515, -0.0540], requires_grad=True)\n",
      "tensor([0.3245, 0.3316, 0.3438], grad_fn=<SoftmaxBackward>)\n",
      "output:1.399533987045288\n",
      "Parameter containing:\n",
      "tensor([ 0.1062, -0.0518, -0.0544], requires_grad=True)\n",
      "tensor([0.2973, 0.3856, 0.3171], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4413330554962158\n",
      "Parameter containing:\n",
      "tensor([ 0.1069, -0.0522, -0.0547], requires_grad=True)\n",
      "tensor([0.3845, 0.4140, 0.2016], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3138937950134277\n",
      "Parameter containing:\n",
      "tensor([ 0.1075, -0.0527, -0.0549], requires_grad=True)\n",
      "tensor([0.3363, 0.3189, 0.3448], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3818321228027344\n",
      "Parameter containing:\n",
      "tensor([ 0.1082, -0.0530, -0.0552], requires_grad=True)\n",
      "tensor([0.3036, 0.2769, 0.4196], grad_fn=<SoftmaxBackward>)\n",
      "output:1.432720422744751\n",
      "Parameter containing:\n",
      "tensor([ 0.1089, -0.0532, -0.0556], requires_grad=True)\n",
      "tensor([0.3490, 0.3648, 0.2862], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3632973432540894\n",
      "Parameter containing:\n",
      "tensor([ 0.1095, -0.0536, -0.0559], requires_grad=True)\n",
      "tensor([0.3302, 0.3805, 0.2893], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3914774656295776\n",
      "Parameter containing:\n",
      "tensor([ 0.1102, -0.0540, -0.0562], requires_grad=True)\n",
      "tensor([0.2722, 0.4354, 0.2923], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4813010692596436\n",
      "Parameter containing:\n",
      "tensor([ 0.1108, -0.0544, -0.0564], requires_grad=True)\n",
      "tensor([0.3746, 0.3380, 0.2874], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3255221843719482\n",
      "Parameter containing:\n",
      "tensor([ 0.1115, -0.0548, -0.0567], requires_grad=True)\n",
      "tensor([0.2901, 0.2690, 0.4409], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4540208578109741\n",
      "Parameter containing:\n",
      "tensor([ 0.1121, -0.0550, -0.0572], requires_grad=True)\n",
      "tensor([0.3717, 0.3285, 0.2998], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3295812606811523\n",
      "Parameter containing:\n",
      "tensor([ 0.1128, -0.0553, -0.0575], requires_grad=True)\n",
      "tensor([0.2755, 0.2842, 0.4403], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4764604568481445\n",
      "Parameter containing:\n",
      "tensor([ 0.1135, -0.0556, -0.0579], requires_grad=True)\n",
      "tensor([0.3669, 0.3079, 0.3252], grad_fn=<SoftmaxBackward>)\n",
      "output:1.33665931224823\n",
      "Parameter containing:\n",
      "tensor([ 0.1141, -0.0559, -0.0582], requires_grad=True)\n",
      "tensor([0.4027, 0.3038, 0.2934], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2849104404449463\n",
      "Parameter containing:\n",
      "tensor([ 0.1148, -0.0563, -0.0586], requires_grad=True)\n",
      "tensor([0.3511, 0.2931, 0.3558], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3601269721984863\n",
      "Parameter containing:\n",
      "tensor([ 0.1155, -0.0566, -0.0589], requires_grad=True)\n",
      "tensor([0.2974, 0.3429, 0.3597], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4409880638122559\n",
      "Parameter containing:\n",
      "tensor([ 0.1161, -0.0569, -0.0593], requires_grad=True)\n",
      "tensor([0.2634, 0.2310, 0.5056], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4987030029296875\n",
      "Parameter containing:\n",
      "tensor([ 0.1168, -0.0570, -0.0597], requires_grad=True)\n",
      "tensor([0.3357, 0.3477, 0.3166], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3827486038208008\n",
      "Parameter containing:\n",
      "tensor([ 0.1174, -0.0574, -0.0600], requires_grad=True)\n",
      "tensor([0.3084, 0.3152, 0.3765], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4243091344833374\n",
      "Parameter containing:\n",
      "tensor([ 0.1181, -0.0577, -0.0604], requires_grad=True)\n",
      "tensor([0.3422, 0.3418, 0.3160], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3730766773223877\n",
      "Parameter containing:\n",
      "tensor([ 0.1187, -0.0580, -0.0607], requires_grad=True)\n",
      "tensor([0.2975, 0.3055, 0.3969], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4412744045257568\n",
      "Parameter containing:\n",
      "tensor([ 0.1194, -0.0583, -0.0611], requires_grad=True)\n",
      "tensor([0.3036, 0.3196, 0.3768], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4315476417541504\n",
      "Parameter containing:\n",
      "tensor([ 0.1200, -0.0586, -0.0614], requires_grad=True)\n",
      "tensor([0.3544, 0.3196, 0.3260], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3550033569335938\n",
      "Parameter containing:\n",
      "tensor([ 0.1207, -0.0589, -0.0618], requires_grad=True)\n",
      "tensor([0.3092, 0.3936, 0.2972], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4234154224395752\n",
      "Parameter containing:\n",
      "tensor([ 0.1214, -0.0593, -0.0621], requires_grad=True)\n",
      "tensor([0.4025, 0.2948, 0.3027], grad_fn=<SoftmaxBackward>)\n",
      "output:1.285238265991211\n",
      "Parameter containing:\n",
      "tensor([ 0.1221, -0.0597, -0.0624], requires_grad=True)\n",
      "tensor([0.3527, 0.3762, 0.2711], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3581085205078125\n",
      "Parameter containing:\n",
      "tensor([ 0.1227, -0.0601, -0.0627], requires_grad=True)\n",
      "tensor([0.3305, 0.3577, 0.3118], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3907179832458496\n",
      "Parameter containing:\n",
      "tensor([ 0.1234, -0.0604, -0.0630], requires_grad=True)\n",
      "tensor([0.3598, 0.2826, 0.3575], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3472766876220703\n",
      "Parameter containing:\n",
      "tensor([ 0.1241, -0.0607, -0.0634], requires_grad=True)\n",
      "tensor([0.2545, 0.2617, 0.4837], grad_fn=<SoftmaxBackward>)\n",
      "output:1.511037826538086\n",
      "Parameter containing:\n",
      "tensor([ 0.1247, -0.0609, -0.0638], requires_grad=True)\n",
      "tensor([0.3340, 0.2845, 0.3815], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3858439922332764\n",
      "Parameter containing:\n",
      "tensor([ 0.1253, -0.0612, -0.0642], requires_grad=True)\n",
      "tensor([0.2869, 0.3236, 0.3895], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4574118852615356\n",
      "Parameter containing:\n",
      "tensor([ 0.1260, -0.0615, -0.0645], requires_grad=True)\n",
      "tensor([0.3213, 0.3984, 0.2803], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4052700996398926\n",
      "Parameter containing:\n",
      "tensor([ 0.1266, -0.0619, -0.0648], requires_grad=True)\n",
      "tensor([0.3774, 0.2685, 0.3541], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3217025995254517\n",
      "Parameter containing:\n",
      "tensor([ 0.1273, -0.0621, -0.0652], requires_grad=True)\n",
      "tensor([0.3189, 0.3386, 0.3425], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4080684185028076\n",
      "Parameter containing:\n",
      "tensor([ 0.1280, -0.0625, -0.0655], requires_grad=True)\n",
      "tensor([0.4384, 0.2625, 0.2990], grad_fn=<SoftmaxBackward>)\n",
      "output:1.234924554824829\n",
      "Parameter containing:\n",
      "tensor([ 0.1287, -0.0628, -0.0659], requires_grad=True)\n",
      "tensor([0.3997, 0.1905, 0.4098], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2921854257583618\n",
      "Parameter containing:\n",
      "tensor([ 0.1294, -0.0630, -0.0664], requires_grad=True)\n",
      "tensor([0.3873, 0.2324, 0.3804], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3083782196044922\n",
      "Parameter containing:\n",
      "tensor([ 0.1300, -0.0632, -0.0668], requires_grad=True)\n",
      "tensor([0.3587, 0.2623, 0.3790], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3494977951049805\n",
      "Parameter containing:\n",
      "tensor([ 0.1307, -0.0635, -0.0672], requires_grad=True)\n",
      "tensor([0.5091, 0.2443, 0.2466], grad_fn=<SoftmaxBackward>)\n",
      "output:1.139948844909668\n",
      "Parameter containing:\n",
      "tensor([ 0.1314, -0.0638, -0.0675], requires_grad=True)\n",
      "tensor([0.2757, 0.3391, 0.3852], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4747965335845947\n",
      "Parameter containing:\n",
      "tensor([ 0.1320, -0.0641, -0.0679], requires_grad=True)\n",
      "tensor([0.4566, 0.2260, 0.3174], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2103915214538574\n",
      "Parameter containing:\n",
      "tensor([ 0.1327, -0.0644, -0.0683], requires_grad=True)\n",
      "tensor([0.3927, 0.2378, 0.3695], grad_fn=<SoftmaxBackward>)\n",
      "output:1.300297737121582\n",
      "Parameter containing:\n",
      "tensor([ 0.1334, -0.0647, -0.0687], requires_grad=True)\n",
      "tensor([0.3342, 0.3337, 0.3321], grad_fn=<SoftmaxBackward>)\n",
      "output:1.384960412979126\n",
      "Parameter containing:\n",
      "tensor([ 0.1340, -0.0650, -0.0690], requires_grad=True)\n",
      "tensor([0.2628, 0.4280, 0.3092], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4957269430160522\n",
      "Parameter containing:\n",
      "tensor([ 0.1346, -0.0654, -0.0693], requires_grad=True)\n",
      "tensor([0.2975, 0.2975, 0.4050], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4415191411972046\n",
      "Parameter containing:\n",
      "tensor([ 0.1353, -0.0656, -0.0697], requires_grad=True)\n",
      "tensor([0.4348, 0.2495, 0.3156], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2401020526885986\n",
      "Parameter containing:\n",
      "tensor([ 0.1360, -0.0659, -0.0700], requires_grad=True)\n",
      "tensor([0.3074, 0.3381, 0.3545], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4256410598754883\n",
      "Parameter containing:\n",
      "tensor([ 0.1366, -0.0662, -0.0704], requires_grad=True)\n",
      "tensor([0.3011, 0.4433, 0.2556], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4374922513961792\n",
      "Parameter containing:\n",
      "tensor([ 0.1373, -0.0667, -0.0706], requires_grad=True)\n",
      "tensor([0.3575, 0.2539, 0.3886], grad_fn=<SoftmaxBackward>)\n",
      "output:1.351466417312622\n",
      "Parameter containing:\n",
      "tensor([ 0.1379, -0.0669, -0.0710], requires_grad=True)\n",
      "tensor([0.3205, 0.3393, 0.3402], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4056556224822998\n",
      "Parameter containing:\n",
      "tensor([ 0.1386, -0.0672, -0.0713], requires_grad=True)\n",
      "tensor([0.5860, 0.2055, 0.2085], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0430169105529785\n",
      "Parameter containing:\n",
      "tensor([ 0.1392, -0.0675, -0.0716], requires_grad=True)\n",
      "tensor([0.2428, 0.4154, 0.3418], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5270006656646729\n",
      "Parameter containing:\n",
      "tensor([ 0.1398, -0.0679, -0.0719], requires_grad=True)\n",
      "tensor([0.3623, 0.2979, 0.3398], grad_fn=<SoftmaxBackward>)\n",
      "output:1.343469262123108\n",
      "Parameter containing:\n",
      "tensor([ 0.1405, -0.0682, -0.0723], requires_grad=True)\n",
      "tensor([0.2976, 0.3601, 0.3423], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4407048225402832\n",
      "Parameter containing:\n",
      "tensor([ 0.1411, -0.0685, -0.0726], requires_grad=True)\n",
      "tensor([0.3127, 0.3042, 0.3831], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4178804159164429\n",
      "Parameter containing:\n",
      "tensor([ 0.1418, -0.0688, -0.0730], requires_grad=True)\n",
      "tensor([0.3063, 0.2744, 0.4193], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4285757541656494\n",
      "Parameter containing:\n",
      "tensor([ 0.1424, -0.0690, -0.0734], requires_grad=True)\n",
      "tensor([0.3629, 0.2969, 0.3402], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:1.3425955772399902\n",
      "Parameter containing:\n",
      "tensor([ 0.1431, -0.0694, -0.0737], requires_grad=True)\n",
      "tensor([0.3290, 0.3379, 0.3331], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3928425312042236\n",
      "Parameter containing:\n",
      "tensor([ 0.1438, -0.0697, -0.0741], requires_grad=True)\n",
      "tensor([0.3170, 0.3056, 0.3773], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4112019538879395\n",
      "Parameter containing:\n",
      "tensor([ 0.1444, -0.0700, -0.0744], requires_grad=True)\n",
      "tensor([0.3502, 0.3059, 0.3439], grad_fn=<SoftmaxBackward>)\n",
      "output:1.361180067062378\n",
      "Parameter containing:\n",
      "tensor([ 0.1451, -0.0703, -0.0748], requires_grad=True)\n",
      "tensor([0.4980, 0.2025, 0.2995], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1550649404525757\n",
      "Parameter containing:\n",
      "tensor([ 0.1457, -0.0706, -0.0752], requires_grad=True)\n",
      "tensor([0.3223, 0.4398, 0.2380], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4055206775665283\n",
      "Parameter containing:\n",
      "tensor([ 0.1464, -0.0710, -0.0754], requires_grad=True)\n",
      "tensor([0.3835, 0.2271, 0.3894], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3141353130340576\n",
      "Parameter containing:\n",
      "tensor([ 0.1471, -0.0712, -0.0758], requires_grad=True)\n",
      "tensor([0.2504, 0.3695, 0.3801], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5145601034164429\n",
      "Parameter containing:\n",
      "tensor([ 0.1477, -0.0715, -0.0761], requires_grad=True)\n",
      "tensor([0.3263, 0.3740, 0.2996], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3972158432006836\n",
      "Parameter containing:\n",
      "tensor([ 0.1484, -0.0719, -0.0764], requires_grad=True)\n",
      "tensor([0.3220, 0.2881, 0.3899], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4039814472198486\n",
      "Parameter containing:\n",
      "tensor([ 0.1490, -0.0722, -0.0768], requires_grad=True)\n",
      "tensor([0.3254, 0.3131, 0.3616], grad_fn=<SoftmaxBackward>)\n",
      "output:1.398420810699463\n",
      "Parameter containing:\n",
      "tensor([ 0.1497, -0.0725, -0.0772], requires_grad=True)\n",
      "tensor([0.3306, 0.2431, 0.4263], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3924823999404907\n",
      "Parameter containing:\n",
      "tensor([ 0.1503, -0.0727, -0.0776], requires_grad=True)\n",
      "tensor([0.2875, 0.3601, 0.3524], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4561591148376465\n",
      "Parameter containing:\n",
      "tensor([ 0.1510, -0.0730, -0.0779], requires_grad=True)\n",
      "tensor([0.3345, 0.3343, 0.3312], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3845818042755127\n",
      "Parameter containing:\n",
      "tensor([ 0.1516, -0.0734, -0.0783], requires_grad=True)\n",
      "tensor([0.3805, 0.2212, 0.3982], grad_fn=<SoftmaxBackward>)\n",
      "output:1.318718671798706\n",
      "Parameter containing:\n",
      "tensor([ 0.1523, -0.0736, -0.0787], requires_grad=True)\n",
      "tensor([0.2591, 0.3943, 0.3467], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5009584426879883\n",
      "Parameter containing:\n",
      "tensor([ 0.1529, -0.0739, -0.0790], requires_grad=True)\n",
      "tensor([0.3253, 0.4026, 0.2720], grad_fn=<SoftmaxBackward>)\n",
      "output:1.399406909942627\n",
      "Parameter containing:\n",
      "tensor([ 0.1536, -0.0743, -0.0793], requires_grad=True)\n",
      "tensor([0.3638, 0.2840, 0.3522], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3414522409439087\n",
      "Parameter containing:\n",
      "tensor([ 0.1543, -0.0746, -0.0796], requires_grad=True)\n",
      "tensor([0.3077, 0.2857, 0.4066], grad_fn=<SoftmaxBackward>)\n",
      "output:1.426027536392212\n",
      "Parameter containing:\n",
      "tensor([ 0.1549, -0.0749, -0.0800], requires_grad=True)\n",
      "tensor([0.3228, 0.3552, 0.3219], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4021958112716675\n",
      "Parameter containing:\n",
      "tensor([ 0.1556, -0.0752, -0.0803], requires_grad=True)\n",
      "tensor([0.4206, 0.3163, 0.2631], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2598345279693604\n",
      "Parameter containing:\n",
      "tensor([ 0.1563, -0.0756, -0.0807], requires_grad=True)\n",
      "tensor([0.5586, 0.2311, 0.2103], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0768601894378662\n",
      "Parameter containing:\n",
      "tensor([ 0.1569, -0.0759, -0.0809], requires_grad=True)\n",
      "tensor([0.3263, 0.3154, 0.3583], grad_fn=<SoftmaxBackward>)\n",
      "output:1.396996259689331\n",
      "Parameter containing:\n",
      "tensor([ 0.1576, -0.0763, -0.0813], requires_grad=True)\n",
      "tensor([0.3013, 0.2983, 0.4004], grad_fn=<SoftmaxBackward>)\n",
      "output:1.435516595840454\n",
      "Parameter containing:\n",
      "tensor([ 0.1582, -0.0765, -0.0817], requires_grad=True)\n",
      "tensor([0.3217, 0.3514, 0.3269], grad_fn=<SoftmaxBackward>)\n",
      "output:1.40391206741333\n",
      "Parameter containing:\n",
      "tensor([ 0.1589, -0.0769, -0.0820], requires_grad=True)\n",
      "tensor([0.2995, 0.2905, 0.4100], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4386317729949951\n",
      "Parameter containing:\n",
      "tensor([ 0.1595, -0.0771, -0.0824], requires_grad=True)\n",
      "tensor([0.3643, 0.3030, 0.3327], grad_fn=<SoftmaxBackward>)\n",
      "output:1.340498685836792\n",
      "Parameter containing:\n",
      "tensor([ 0.1602, -0.0774, -0.0827], requires_grad=True)\n",
      "tensor([0.3562, 0.2919, 0.3519], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3524789810180664\n",
      "Parameter containing:\n",
      "tensor([ 0.1609, -0.0777, -0.0831], requires_grad=True)\n",
      "tensor([0.3581, 0.3344, 0.3074], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3494858741760254\n",
      "Parameter containing:\n",
      "tensor([ 0.1615, -0.0781, -0.0834], requires_grad=True)\n",
      "tensor([0.3786, 0.2773, 0.3440], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3197627067565918\n",
      "Parameter containing:\n",
      "tensor([ 0.1622, -0.0784, -0.0838], requires_grad=True)\n",
      "tensor([0.3820, 0.3292, 0.2888], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3147786855697632\n",
      "Parameter containing:\n",
      "tensor([ 0.1629, -0.0788, -0.0841], requires_grad=True)\n",
      "tensor([0.4671, 0.3188, 0.2142], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1964282989501953\n",
      "Parameter containing:\n",
      "tensor([ 0.1636, -0.0792, -0.0844], requires_grad=True)\n",
      "tensor([0.2959, 0.4831, 0.2210], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4475364685058594\n",
      "Parameter containing:\n",
      "tensor([ 0.1642, -0.0796, -0.0846], requires_grad=True)\n",
      "tensor([0.3750, 0.3584, 0.2665], grad_fn=<SoftmaxBackward>)\n",
      "output:1.32523512840271\n",
      "Parameter containing:\n",
      "tensor([ 0.1649, -0.0800, -0.0849], requires_grad=True)\n",
      "tensor([0.3274, 0.2901, 0.3826], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3958160877227783\n",
      "Parameter containing:\n",
      "tensor([ 0.1656, -0.0803, -0.0853], requires_grad=True)\n",
      "tensor([0.3046, 0.3303, 0.3651], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4298772811889648\n",
      "Parameter containing:\n",
      "tensor([ 0.1662, -0.0806, -0.0856], requires_grad=True)\n",
      "tensor([0.2928, 0.3418, 0.3654], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4480957984924316\n",
      "Parameter containing:\n",
      "tensor([ 0.1669, -0.0809, -0.0859], requires_grad=True)\n",
      "tensor([0.3633, 0.3304, 0.3064], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3419246673583984\n",
      "Parameter containing:\n",
      "tensor([ 0.1675, -0.0813, -0.0863], requires_grad=True)\n",
      "tensor([0.4302, 0.2667, 0.3031], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2463488578796387\n",
      "Parameter containing:\n",
      "tensor([ 0.1682, -0.0816, -0.0866], requires_grad=True)\n",
      "tensor([0.3052, 0.2320, 0.4627], grad_fn=<SoftmaxBackward>)\n",
      "output:1.432190179824829\n",
      "Parameter containing:\n",
      "tensor([ 0.1689, -0.0818, -0.0871], requires_grad=True)\n",
      "tensor([0.3803, 0.3738, 0.2460], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3181493282318115\n",
      "Parameter containing:\n",
      "tensor([ 0.1696, -0.0822, -0.0873], requires_grad=True)\n",
      "tensor([0.2915, 0.4236, 0.2849], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4512386322021484\n",
      "Parameter containing:\n",
      "tensor([ 0.1702, -0.0826, -0.0876], requires_grad=True)\n",
      "tensor([0.4625, 0.2498, 0.2877], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2020504474639893\n",
      "Parameter containing:\n",
      "tensor([ 0.1709, -0.0829, -0.0879], requires_grad=True)\n",
      "tensor([0.4068, 0.3073, 0.2859], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2791922092437744\n",
      "Parameter containing:\n",
      "tensor([ 0.1716, -0.0833, -0.0883], requires_grad=True)\n",
      "tensor([0.3024, 0.3682, 0.3294], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4333528280258179\n",
      "Parameter containing:\n",
      "tensor([ 0.1722, -0.0836, -0.0886], requires_grad=True)\n",
      "tensor([0.3661, 0.2782, 0.3557], grad_fn=<SoftmaxBackward>)\n",
      "output:1.338106393814087\n",
      "Parameter containing:\n",
      "tensor([ 0.1729, -0.0839, -0.0890], requires_grad=True)\n",
      "tensor([0.4106, 0.2538, 0.3356], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2742156982421875\n",
      "Parameter containing:\n",
      "tensor([ 0.1736, -0.0842, -0.0894], requires_grad=True)\n",
      "tensor([0.3221, 0.3407, 0.3372], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4032191038131714\n",
      "Parameter containing:\n",
      "tensor([ 0.1742, -0.0845, -0.0897], requires_grad=True)\n",
      "tensor([0.4525, 0.2824, 0.2651], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2154721021652222\n",
      "Parameter containing:\n",
      "tensor([ 0.1749, -0.0849, -0.0900], requires_grad=True)\n",
      "tensor([0.5301, 0.2182, 0.2517], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1129298210144043\n",
      "Parameter containing:\n",
      "tensor([ 0.1756, -0.0852, -0.0904], requires_grad=True)\n",
      "tensor([0.3258, 0.3484, 0.3259], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3977097272872925\n",
      "Parameter containing:\n",
      "tensor([ 0.1762, -0.0855, -0.0907], requires_grad=True)\n",
      "tensor([0.5578, 0.1840, 0.2582], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0781464576721191\n",
      "Parameter containing:\n",
      "tensor([ 0.1768, -0.0858, -0.0910], requires_grad=True)\n",
      "tensor([0.3761, 0.2917, 0.3322], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3232783079147339\n",
      "Parameter containing:\n",
      "tensor([ 0.1775, -0.0861, -0.0914], requires_grad=True)\n",
      "tensor([0.3147, 0.2735, 0.4118], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4155664443969727\n",
      "Parameter containing:\n",
      "tensor([ 0.1782, -0.0864, -0.0918], requires_grad=True)\n",
      "tensor([0.3233, 0.3383, 0.3383], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4013822078704834\n",
      "Parameter containing:\n",
      "tensor([ 0.1788, -0.0867, -0.0921], requires_grad=True)\n",
      "tensor([0.3274, 0.3481, 0.3245], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3952090740203857\n",
      "Parameter containing:\n",
      "tensor([ 0.1795, -0.0870, -0.0925], requires_grad=True)\n",
      "tensor([0.5003, 0.1671, 0.3326], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1531734466552734\n",
      "Parameter containing:\n",
      "tensor([ 0.1802, -0.0872, -0.0929], requires_grad=True)\n",
      "tensor([0.3536, 0.3656, 0.2808], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3566365242004395\n",
      "Parameter containing:\n",
      "tensor([ 0.1808, -0.0876, -0.0932], requires_grad=True)\n",
      "tensor([0.2862, 0.4105, 0.3033], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4589496850967407\n",
      "Parameter containing:\n",
      "tensor([ 0.1815, -0.0880, -0.0935], requires_grad=True)\n",
      "tensor([0.2029, 0.4527, 0.3444], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5922740697860718\n",
      "Parameter containing:\n",
      "tensor([ 0.1820, -0.0883, -0.0937], requires_grad=True)\n",
      "tensor([0.3478, 0.3221, 0.3300], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3646655082702637\n",
      "Parameter containing:\n",
      "tensor([ 0.1827, -0.0887, -0.0940], requires_grad=True)\n",
      "tensor([0.3629, 0.2495, 0.3876], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3436460494995117\n",
      "Parameter containing:\n",
      "tensor([ 0.1834, -0.0889, -0.0944], requires_grad=True)\n",
      "tensor([0.3335, 0.3338, 0.3327], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3860976696014404\n",
      "Parameter containing:\n",
      "tensor([ 0.1840, -0.0892, -0.0948], requires_grad=True)\n",
      "tensor([0.3068, 0.2233, 0.4699], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4303017854690552\n",
      "Parameter containing:\n",
      "tensor([ 0.1847, -0.0894, -0.0952], requires_grad=True)\n",
      "tensor([0.2978, 0.4489, 0.2533], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4426995515823364\n",
      "Parameter containing:\n",
      "tensor([ 0.1853, -0.0899, -0.0955], requires_grad=True)\n",
      "tensor([0.3245, 0.2930, 0.3825], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4000518321990967\n",
      "Parameter containing:\n",
      "tensor([ 0.1860, -0.0901, -0.0958], requires_grad=True)\n",
      "tensor([0.2445, 0.3783, 0.3773], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5240144729614258\n",
      "Parameter containing:\n",
      "tensor([ 0.1866, -0.0904, -0.0961], requires_grad=True)\n",
      "tensor([0.3698, 0.3465, 0.2838], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3326475620269775\n",
      "Parameter containing:\n",
      "tensor([ 0.1873, -0.0908, -0.0964], requires_grad=True)\n",
      "tensor([0.3666, 0.3281, 0.3052], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3370280265808105\n",
      "Parameter containing:\n",
      "tensor([ 0.1879, -0.0912, -0.0968], requires_grad=True)\n",
      "tensor([0.2896, 0.3929, 0.3175], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4533300399780273\n",
      "Parameter containing:\n",
      "tensor([ 0.1886, -0.0915, -0.0970], requires_grad=True)\n",
      "tensor([0.3030, 0.3138, 0.3832], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4326190948486328\n",
      "Parameter containing:\n",
      "tensor([ 0.1892, -0.0918, -0.0974], requires_grad=True)\n",
      "tensor([0.3135, 0.3975, 0.2891], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4170591831207275\n",
      "Parameter containing:\n",
      "tensor([ 0.1899, -0.0922, -0.0977], requires_grad=True)\n",
      "tensor([0.4125, 0.3188, 0.2688], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2712316513061523\n",
      "Parameter containing:\n",
      "tensor([ 0.1906, -0.0926, -0.0980], requires_grad=True)\n",
      "tensor([0.3814, 0.2518, 0.3668], grad_fn=<SoftmaxBackward>)\n",
      "output:1.316348671913147\n",
      "Parameter containing:\n",
      "tensor([ 0.1912, -0.0928, -0.0984], requires_grad=True)\n",
      "tensor([0.2873, 0.3561, 0.3566], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4564967155456543\n",
      "Parameter containing:\n",
      "tensor([ 0.1919, -0.0932, -0.0987], requires_grad=True)\n",
      "tensor([0.3825, 0.3081, 0.3094], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3139569759368896\n",
      "Parameter containing:\n",
      "tensor([ 0.1926, -0.0935, -0.0991], requires_grad=True)\n",
      "tensor([0.4052, 0.2933, 0.3015], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2814373970031738\n",
      "Parameter containing:\n",
      "tensor([ 0.1932, -0.0938, -0.0994], requires_grad=True)\n",
      "tensor([0.2568, 0.3718, 0.3714], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5043199062347412\n",
      "Parameter containing:\n",
      "tensor([ 0.1939, -0.0941, -0.0997], requires_grad=True)\n",
      "tensor([0.3818, 0.2368, 0.3814], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3162105083465576\n",
      "Parameter containing:\n",
      "tensor([ 0.1945, -0.0944, -0.1001], requires_grad=True)\n",
      "tensor([0.3553, 0.4426, 0.2021], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3572125434875488\n",
      "Parameter containing:\n",
      "tensor([ 0.1952, -0.0949, -0.1003], requires_grad=True)\n",
      "tensor([0.2608, 0.3998, 0.3394], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4982476234436035\n",
      "Parameter containing:\n",
      "tensor([ 0.1958, -0.0952, -0.1006], requires_grad=True)\n",
      "tensor([0.3862, 0.3740, 0.2397], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3096630573272705\n",
      "Parameter containing:\n",
      "tensor([ 0.1965, -0.0956, -0.1009], requires_grad=True)\n",
      "tensor([0.4067, 0.2657, 0.3276], grad_fn=<SoftmaxBackward>)\n",
      "output:1.279496669769287\n",
      "Parameter containing:\n",
      "tensor([ 0.1972, -0.0959, -0.1012], requires_grad=True)\n",
      "tensor([0.2460, 0.4274, 0.3266], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5222597122192383\n",
      "Parameter containing:\n",
      "tensor([ 0.1978, -0.0963, -0.1015], requires_grad=True)\n",
      "tensor([0.2913, 0.3973, 0.3114], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4508333206176758\n",
      "Parameter containing:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1984, -0.0967, -0.1018], requires_grad=True)\n",
      "tensor([0.3568, 0.3653, 0.2779], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3518402576446533\n",
      "Parameter containing:\n",
      "tensor([ 0.1991, -0.0971, -0.1021], requires_grad=True)\n",
      "tensor([0.4589, 0.3088, 0.2323], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2071961164474487\n",
      "Parameter containing:\n",
      "tensor([ 0.1998, -0.0974, -0.1023], requires_grad=True)\n",
      "tensor([0.2474, 0.2215, 0.5311], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5252362489700317\n",
      "Parameter containing:\n",
      "tensor([ 0.2004, -0.0976, -0.1028], requires_grad=True)\n",
      "tensor([0.3455, 0.3653, 0.2893], grad_fn=<SoftmaxBackward>)\n",
      "output:1.368540644645691\n",
      "Parameter containing:\n",
      "tensor([ 0.2011, -0.0980, -0.1031], requires_grad=True)\n",
      "tensor([0.3851, 0.3139, 0.3010], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3101621866226196\n",
      "Parameter containing:\n",
      "tensor([ 0.2017, -0.0983, -0.1034], requires_grad=True)\n",
      "tensor([0.2901, 0.3243, 0.3856], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4524662494659424\n",
      "Parameter containing:\n",
      "tensor([ 0.2024, -0.0986, -0.1038], requires_grad=True)\n",
      "tensor([0.3366, 0.3413, 0.3221], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3814140558242798\n",
      "Parameter containing:\n",
      "tensor([ 0.2030, -0.0990, -0.1041], requires_grad=True)\n",
      "tensor([0.3657, 0.3289, 0.3055], grad_fn=<SoftmaxBackward>)\n",
      "output:1.338435411453247\n",
      "Parameter containing:\n",
      "tensor([ 0.2037, -0.0993, -0.1044], requires_grad=True)\n",
      "tensor([0.3388, 0.3225, 0.3387], grad_fn=<SoftmaxBackward>)\n",
      "output:1.378152847290039\n",
      "Parameter containing:\n",
      "tensor([ 0.2044, -0.0996, -0.1048], requires_grad=True)\n",
      "tensor([0.3389, 0.2623, 0.3988], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3790879249572754\n",
      "Parameter containing:\n",
      "tensor([ 0.2051, -0.0999, -0.1052], requires_grad=True)\n",
      "tensor([0.2443, 0.3910, 0.3647], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5242974758148193\n",
      "Parameter containing:\n",
      "tensor([ 0.2057, -0.1002, -0.1055], requires_grad=True)\n",
      "tensor([0.3575, 0.3014, 0.3411], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3503994941711426\n",
      "Parameter containing:\n",
      "tensor([ 0.2063, -0.1005, -0.1058], requires_grad=True)\n",
      "tensor([0.3064, 0.4551, 0.2385], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4299989938735962\n",
      "Parameter containing:\n",
      "tensor([ 0.2070, -0.1010, -0.1060], requires_grad=True)\n",
      "tensor([0.3441, 0.3881, 0.2678], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3711271286010742\n",
      "Parameter containing:\n",
      "tensor([ 0.2077, -0.1014, -0.1063], requires_grad=True)\n",
      "tensor([0.4100, 0.3570, 0.2330], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2755985260009766\n",
      "Parameter containing:\n",
      "tensor([ 0.2083, -0.1018, -0.1066], requires_grad=True)\n",
      "tensor([0.4884, 0.2710, 0.2406], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1671977043151855\n",
      "Parameter containing:\n",
      "tensor([ 0.2090, -0.1021, -0.1069], requires_grad=True)\n",
      "tensor([0.3086, 0.4026, 0.2888], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4245890378952026\n",
      "Parameter containing:\n",
      "tensor([ 0.2097, -0.1025, -0.1071], requires_grad=True)\n",
      "tensor([0.3766, 0.2673, 0.3561], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3229448795318604\n",
      "Parameter containing:\n",
      "tensor([ 0.2103, -0.1028, -0.1075], requires_grad=True)\n",
      "tensor([0.2947, 0.4082, 0.2972], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4459245204925537\n",
      "Parameter containing:\n",
      "tensor([ 0.2110, -0.1032, -0.1078], requires_grad=True)\n",
      "tensor([0.2777, 0.3656, 0.3567], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4714813232421875\n",
      "Parameter containing:\n",
      "tensor([ 0.2116, -0.1035, -0.1081], requires_grad=True)\n",
      "tensor([0.3645, 0.2677, 0.3678], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3407273292541504\n",
      "Parameter containing:\n",
      "tensor([ 0.2123, -0.1038, -0.1085], requires_grad=True)\n",
      "tensor([0.2729, 0.4107, 0.3164], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4795405864715576\n",
      "Parameter containing:\n",
      "tensor([ 0.2129, -0.1042, -0.1088], requires_grad=True)\n",
      "tensor([0.3022, 0.3139, 0.3839], grad_fn=<SoftmaxBackward>)\n",
      "output:1.433894157409668\n",
      "Parameter containing:\n",
      "tensor([ 0.2136, -0.1044, -0.1091], requires_grad=True)\n",
      "tensor([0.4594, 0.2553, 0.2852], grad_fn=<SoftmaxBackward>)\n",
      "output:1.206108570098877\n",
      "Parameter containing:\n",
      "tensor([ 0.2142, -0.1048, -0.1095], requires_grad=True)\n",
      "tensor([0.3866, 0.3188, 0.2946], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3080352544784546\n",
      "Parameter containing:\n",
      "tensor([ 0.2149, -0.1051, -0.1098], requires_grad=True)\n",
      "tensor([0.3953, 0.2494, 0.3553], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2961392402648926\n",
      "Parameter containing:\n",
      "tensor([ 0.2156, -0.1054, -0.1102], requires_grad=True)\n",
      "tensor([0.2346, 0.3143, 0.4511], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5410751104354858\n",
      "Parameter containing:\n",
      "tensor([ 0.2162, -0.1056, -0.1106], requires_grad=True)\n",
      "tensor([0.3911, 0.2908, 0.3181], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3015906810760498\n",
      "Parameter containing:\n",
      "tensor([ 0.2169, -0.1059, -0.1109], requires_grad=True)\n",
      "tensor([0.3255, 0.3006, 0.3738], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3983848094940186\n",
      "Parameter containing:\n",
      "tensor([ 0.2175, -0.1062, -0.1113], requires_grad=True)\n",
      "tensor([0.3432, 0.3909, 0.2659], grad_fn=<SoftmaxBackward>)\n",
      "output:1.372535228729248\n",
      "Parameter containing:\n",
      "tensor([ 0.2182, -0.1066, -0.1116], requires_grad=True)\n",
      "tensor([0.2988, 0.2903, 0.4108], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4396281242370605\n",
      "Parameter containing:\n",
      "tensor([ 0.2188, -0.1069, -0.1120], requires_grad=True)\n",
      "tensor([0.3318, 0.3881, 0.2801], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3893619775772095\n",
      "Parameter containing:\n",
      "tensor([ 0.2195, -0.1073, -0.1122], requires_grad=True)\n",
      "tensor([0.2877, 0.2720, 0.4403], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4576804637908936\n",
      "Parameter containing:\n",
      "tensor([ 0.2202, -0.1075, -0.1126], requires_grad=True)\n",
      "tensor([0.3313, 0.3231, 0.3456], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3893389701843262\n",
      "Parameter containing:\n",
      "tensor([ 0.2208, -0.1078, -0.1130], requires_grad=True)\n",
      "tensor([0.3449, 0.3338, 0.3213], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3689601421356201\n",
      "Parameter containing:\n",
      "tensor([ 0.2215, -0.1082, -0.1133], requires_grad=True)\n",
      "tensor([0.3170, 0.3398, 0.3432], grad_fn=<SoftmaxBackward>)\n",
      "output:1.410984992980957\n",
      "Parameter containing:\n",
      "tensor([ 0.2221, -0.1085, -0.1136], requires_grad=True)\n",
      "tensor([0.4805, 0.2328, 0.2867], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1779195070266724\n",
      "Parameter containing:\n",
      "tensor([ 0.2228, -0.1088, -0.1140], requires_grad=True)\n",
      "tensor([0.2503, 0.3051, 0.4447], grad_fn=<SoftmaxBackward>)\n",
      "output:1.515998125076294\n",
      "Parameter containing:\n",
      "tensor([ 0.2234, -0.1090, -0.1144], requires_grad=True)\n",
      "tensor([0.3540, 0.3186, 0.3273], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3554680347442627\n",
      "Parameter containing:\n",
      "tensor([ 0.2241, -0.1094, -0.1147], requires_grad=True)\n",
      "tensor([0.3521, 0.3485, 0.2994], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3584537506103516\n",
      "Parameter containing:\n",
      "tensor([ 0.2248, -0.1097, -0.1150], requires_grad=True)\n",
      "tensor([0.3019, 0.3220, 0.3761], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4342284202575684\n",
      "Parameter containing:\n",
      "tensor([ 0.2254, -0.1100, -0.1154], requires_grad=True)\n",
      "tensor([0.4100, 0.2502, 0.3398], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2751067876815796\n",
      "Parameter containing:\n",
      "tensor([ 0.2261, -0.1103, -0.1158], requires_grad=True)\n",
      "tensor([0.3997, 0.2583, 0.3420], grad_fn=<SoftmaxBackward>)\n",
      "output:1.289629578590393\n",
      "Parameter containing:\n",
      "tensor([ 0.2268, -0.1106, -0.1162], requires_grad=True)\n",
      "tensor([0.3796, 0.3725, 0.2480], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3191368579864502\n",
      "Parameter containing:\n",
      "tensor([ 0.2275, -0.1110, -0.1164], requires_grad=True)\n",
      "tensor([0.3127, 0.3753, 0.3119], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4176926612854004\n",
      "Parameter containing:\n",
      "tensor([ 0.2281, -0.1114, -0.1167], requires_grad=True)\n",
      "tensor([0.2795, 0.3360, 0.3846], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4688835144042969\n",
      "Parameter containing:\n",
      "tensor([ 0.2287, -0.1117, -0.1171], requires_grad=True)\n",
      "tensor([0.2923, 0.2577, 0.4500], grad_fn=<SoftmaxBackward>)\n",
      "output:1.451121211051941\n",
      "Parameter containing:\n",
      "tensor([ 0.2294, -0.1119, -0.1175], requires_grad=True)\n",
      "tensor([0.4019, 0.2947, 0.3034], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2860888242721558\n",
      "Parameter containing:\n",
      "tensor([ 0.2301, -0.1122, -0.1178], requires_grad=True)\n",
      "tensor([0.3396, 0.3694, 0.2910], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3773479461669922\n",
      "Parameter containing:\n",
      "tensor([ 0.2307, -0.1126, -0.1181], requires_grad=True)\n",
      "tensor([0.4406, 0.2567, 0.3027], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2320029735565186\n",
      "Parameter containing:\n",
      "tensor([ 0.2314, -0.1129, -0.1185], requires_grad=True)\n",
      "tensor([0.3435, 0.3978, 0.2587], grad_fn=<SoftmaxBackward>)\n",
      "output:1.372355341911316\n",
      "Parameter containing:\n",
      "tensor([ 0.2321, -0.1133, -0.1188], requires_grad=True)\n",
      "tensor([0.5491, 0.2350, 0.2160], grad_fn=<SoftmaxBackward>)\n",
      "output:1.088777780532837\n",
      "Parameter containing:\n",
      "tensor([ 0.2327, -0.1137, -0.1191], requires_grad=True)\n",
      "tensor([0.2485, 0.3369, 0.4147], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5180450677871704\n",
      "Parameter containing:\n",
      "tensor([ 0.2333, -0.1139, -0.1194], requires_grad=True)\n",
      "tensor([0.3233, 0.4541, 0.2227], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4047839641571045\n",
      "Parameter containing:\n",
      "tensor([ 0.2340, -0.1144, -0.1196], requires_grad=True)\n",
      "tensor([0.6158, 0.1803, 0.2039], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0071771144866943\n",
      "Parameter containing:\n",
      "tensor([ 0.2345, -0.1147, -0.1199], requires_grad=True)\n",
      "tensor([0.3746, 0.3455, 0.2799], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3255759477615356\n",
      "Parameter containing:\n",
      "tensor([ 0.2352, -0.1150, -0.1202], requires_grad=True)\n",
      "tensor([0.3583, 0.3366, 0.3051], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3492820262908936\n",
      "Parameter containing:\n",
      "tensor([ 0.2359, -0.1154, -0.1205], requires_grad=True)\n",
      "tensor([0.3695, 0.3553, 0.2752], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3331425189971924\n",
      "Parameter containing:\n",
      "tensor([ 0.2366, -0.1158, -0.1208], requires_grad=True)\n",
      "tensor([0.2204, 0.3253, 0.4543], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5638792514801025\n",
      "Parameter containing:\n",
      "tensor([ 0.2371, -0.1160, -0.1211], requires_grad=True)\n",
      "tensor([0.3454, 0.2739, 0.3807], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3690576553344727\n",
      "Parameter containing:\n",
      "tensor([ 0.2378, -0.1163, -0.1215], requires_grad=True)\n",
      "tensor([0.3228, 0.3841, 0.2931], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4026305675506592\n",
      "Parameter containing:\n",
      "tensor([ 0.2385, -0.1167, -0.1218], requires_grad=True)\n",
      "tensor([0.3293, 0.3795, 0.2912], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3927879333496094\n",
      "Parameter containing:\n",
      "tensor([ 0.2391, -0.1170, -0.1221], requires_grad=True)\n",
      "tensor([0.3382, 0.4180, 0.2439], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3809661865234375\n",
      "Parameter containing:\n",
      "tensor([ 0.2398, -0.1175, -0.1223], requires_grad=True)\n",
      "tensor([0.3211, 0.3090, 0.3699], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4049307107925415\n",
      "Parameter containing:\n",
      "tensor([ 0.2405, -0.1178, -0.1227], requires_grad=True)\n",
      "tensor([0.3710, 0.3351, 0.2939], grad_fn=<SoftmaxBackward>)\n",
      "output:1.33077073097229\n",
      "Parameter containing:\n",
      "tensor([ 0.2412, -0.1181, -0.1230], requires_grad=True)\n",
      "tensor([0.2632, 0.3803, 0.3566], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4943387508392334\n",
      "Parameter containing:\n",
      "tensor([ 0.2418, -0.1185, -0.1233], requires_grad=True)\n",
      "tensor([0.4651, 0.2591, 0.2758], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1984121799468994\n",
      "Parameter containing:\n",
      "tensor([ 0.2424, -0.1188, -0.1237], requires_grad=True)\n",
      "tensor([0.4150, 0.2353, 0.3497], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2683920860290527\n",
      "Parameter containing:\n",
      "tensor([ 0.2431, -0.1191, -0.1241], requires_grad=True)\n",
      "tensor([0.3573, 0.3136, 0.3291], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3506965637207031\n",
      "Parameter containing:\n",
      "tensor([ 0.2438, -0.1194, -0.1244], requires_grad=True)\n",
      "tensor([0.2297, 0.3326, 0.4378], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5485433340072632\n",
      "Parameter containing:\n",
      "tensor([ 0.2444, -0.1196, -0.1248], requires_grad=True)\n",
      "tensor([0.3157, 0.4680, 0.2163], grad_fn=<SoftmaxBackward>)\n",
      "output:1.416914939880371\n",
      "Parameter containing:\n",
      "tensor([ 0.2450, -0.1201, -0.1249], requires_grad=True)\n",
      "tensor([0.3266, 0.3446, 0.3288], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3964455127716064\n",
      "Parameter containing:\n",
      "tensor([ 0.2457, -0.1204, -0.1253], requires_grad=True)\n",
      "tensor([0.4540, 0.2958, 0.2502], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2136144638061523\n",
      "Parameter containing:\n",
      "tensor([ 0.2464, -0.1208, -0.1256], requires_grad=True)\n",
      "tensor([0.2773, 0.2078, 0.5149], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4779729843139648\n",
      "Parameter containing:\n",
      "tensor([ 0.2470, -0.1210, -0.1261], requires_grad=True)\n",
      "tensor([0.4085, 0.2768, 0.3148], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2768430709838867\n",
      "Parameter containing:\n",
      "tensor([ 0.2477, -0.1213, -0.1264], requires_grad=True)\n",
      "tensor([0.3279, 0.4101, 0.2620], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3959025144577026\n",
      "Parameter containing:\n",
      "tensor([ 0.2484, -0.1217, -0.1267], requires_grad=True)\n",
      "tensor([0.4241, 0.1712, 0.4048], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2582008838653564\n",
      "Parameter containing:\n",
      "tensor([ 0.2491, -0.1219, -0.1272], requires_grad=True)\n",
      "tensor([0.3532, 0.3688, 0.2780], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3571871519088745\n",
      "Parameter containing:\n",
      "tensor([ 0.2497, -0.1223, -0.1274], requires_grad=True)\n",
      "tensor([0.3008, 0.4147, 0.2845], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4368106126785278\n",
      "Parameter containing:\n",
      "tensor([ 0.2504, -0.1227, -0.1277], requires_grad=True)\n",
      "tensor([0.4324, 0.2873, 0.2803], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2431551218032837\n",
      "Parameter containing:\n",
      "tensor([ 0.2511, -0.1230, -0.1280], requires_grad=True)\n",
      "tensor([0.4669, 0.2505, 0.2826], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1959633827209473\n",
      "Parameter containing:\n",
      "tensor([ 0.2517, -0.1233, -0.1284], requires_grad=True)\n",
      "tensor([0.3414, 0.2603, 0.3984], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3754332065582275\n",
      "Parameter containing:\n",
      "tensor([ 0.2524, -0.1236, -0.1288], requires_grad=True)\n",
      "tensor([0.3100, 0.3480, 0.3421], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4216504096984863\n",
      "Parameter containing:\n",
      "tensor([ 0.2531, -0.1239, -0.1291], requires_grad=True)\n",
      "tensor([0.3728, 0.3157, 0.3115], grad_fn=<SoftmaxBackward>)\n",
      "output:1.327932596206665\n",
      "Parameter containing:\n",
      "tensor([ 0.2537, -0.1243, -0.1295], requires_grad=True)\n",
      "tensor([0.5077, 0.2875, 0.2047], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1421921253204346\n",
      "Parameter containing:\n",
      "tensor([ 0.2544, -0.1246, -0.1297], requires_grad=True)\n",
      "tensor([0.2694, 0.4230, 0.3076], grad_fn=<SoftmaxBackward>)\n",
      "output:1.485321283340454\n",
      "Parameter containing:\n",
      "tensor([ 0.2550, -0.1250, -0.1300], requires_grad=True)\n",
      "tensor([0.3088, 0.3218, 0.3694], grad_fn=<SoftmaxBackward>)\n",
      "output:1.423581600189209\n",
      "Parameter containing:\n",
      "tensor([ 0.2557, -0.1253, -0.1303], requires_grad=True)\n",
      "tensor([0.3857, 0.3048, 0.3095], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3092625141143799\n",
      "Parameter containing:\n",
      "tensor([ 0.2563, -0.1257, -0.1307], requires_grad=True)\n",
      "tensor([0.3818, 0.3431, 0.2751], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3151824474334717\n",
      "Parameter containing:\n",
      "tensor([ 0.2570, -0.1260, -0.1310], requires_grad=True)\n",
      "tensor([0.4051, 0.2988, 0.2961], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2815405130386353\n",
      "Parameter containing:\n",
      "tensor([ 0.2577, -0.1264, -0.1313], requires_grad=True)\n",
      "tensor([0.3019, 0.2992, 0.3988], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4345929622650146\n",
      "Parameter containing:\n",
      "tensor([ 0.2584, -0.1267, -0.1317], requires_grad=True)\n",
      "tensor([0.2800, 0.3347, 0.3854], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4681320190429688\n",
      "Parameter containing:\n",
      "tensor([ 0.2590, -0.1269, -0.1320], requires_grad=True)\n",
      "tensor([0.3465, 0.3811, 0.2724], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3673440217971802\n",
      "Parameter containing:\n",
      "tensor([ 0.2597, -0.1273, -0.1323], requires_grad=True)\n",
      "tensor([0.3077, 0.4647, 0.2276], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4286251068115234\n",
      "Parameter containing:\n",
      "tensor([ 0.2603, -0.1278, -0.1325], requires_grad=True)\n",
      "tensor([0.2733, 0.3766, 0.3501], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4784305095672607\n",
      "Parameter containing:\n",
      "tensor([ 0.2609, -0.1281, -0.1328], requires_grad=True)\n",
      "tensor([0.3391, 0.2647, 0.3962], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3787879943847656\n",
      "Parameter containing:\n",
      "tensor([ 0.2616, -0.1284, -0.1332], requires_grad=True)\n",
      "tensor([0.2446, 0.3293, 0.4262], grad_fn=<SoftmaxBackward>)\n",
      "output:1.524474024772644\n",
      "Parameter containing:\n",
      "tensor([ 0.2622, -0.1286, -0.1336], requires_grad=True)\n",
      "tensor([0.2648, 0.3628, 0.3724], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4917478561401367\n",
      "Parameter containing:\n",
      "tensor([ 0.2628, -0.1289, -0.1339], requires_grad=True)\n",
      "tensor([0.3002, 0.2962, 0.4036], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4372992515563965\n",
      "Parameter containing:\n",
      "tensor([ 0.2635, -0.1292, -0.1343], requires_grad=True)\n",
      "tensor([0.3094, 0.2142, 0.4764], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4268267154693604\n",
      "Parameter containing:\n",
      "tensor([ 0.2641, -0.1294, -0.1347], requires_grad=True)\n",
      "tensor([0.3645, 0.2835, 0.3520], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3403832912445068\n",
      "Parameter containing:\n",
      "tensor([ 0.2648, -0.1297, -0.1351], requires_grad=True)\n",
      "tensor([0.3883, 0.3862, 0.2255], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3071396350860596\n",
      "Parameter containing:\n",
      "tensor([ 0.2655, -0.1301, -0.1354], requires_grad=True)\n",
      "tensor([0.3637, 0.2998, 0.3365], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3413728475570679\n",
      "Parameter containing:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2662, -0.1304, -0.1357], requires_grad=True)\n",
      "tensor([0.2827, 0.3876, 0.3296], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4638503789901733\n",
      "Parameter containing:\n",
      "tensor([ 0.2668, -0.1308, -0.1360], requires_grad=True)\n",
      "tensor([0.2973, 0.3621, 0.3406], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4410946369171143\n",
      "Parameter containing:\n",
      "tensor([ 0.2674, -0.1311, -0.1363], requires_grad=True)\n",
      "tensor([0.4024, 0.3189, 0.2787], grad_fn=<SoftmaxBackward>)\n",
      "output:1.285436749458313\n",
      "Parameter containing:\n",
      "tensor([ 0.2681, -0.1315, -0.1366], requires_grad=True)\n",
      "tensor([0.2624, 0.4437, 0.2939], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4969500303268433\n",
      "Parameter containing:\n",
      "tensor([ 0.2687, -0.1319, -0.1369], requires_grad=True)\n",
      "tensor([0.4099, 0.2594, 0.3307], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2750602960586548\n",
      "Parameter containing:\n",
      "tensor([ 0.2694, -0.1322, -0.1373], requires_grad=True)\n",
      "tensor([0.3038, 0.2794, 0.4168], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4323145151138306\n",
      "Parameter containing:\n",
      "tensor([ 0.2701, -0.1324, -0.1377], requires_grad=True)\n",
      "tensor([0.3145, 0.3302, 0.3553], grad_fn=<SoftmaxBackward>)\n",
      "output:1.414851427078247\n",
      "Parameter containing:\n",
      "tensor([ 0.2707, -0.1327, -0.1380], requires_grad=True)\n",
      "tensor([0.5518, 0.2423, 0.2059], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0853619575500488\n",
      "Parameter containing:\n",
      "tensor([ 0.2713, -0.1331, -0.1383], requires_grad=True)\n",
      "tensor([0.4141, 0.2747, 0.3112], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2688491344451904\n",
      "Parameter containing:\n",
      "tensor([ 0.2720, -0.1334, -0.1386], requires_grad=True)\n",
      "tensor([0.2708, 0.4383, 0.2909], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4836394786834717\n",
      "Parameter containing:\n",
      "tensor([ 0.2727, -0.1338, -0.1389], requires_grad=True)\n",
      "tensor([0.3473, 0.2890, 0.3637], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3658183813095093\n",
      "Parameter containing:\n",
      "tensor([ 0.2733, -0.1341, -0.1393], requires_grad=True)\n",
      "tensor([0.3246, 0.4024, 0.2730], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4004297256469727\n",
      "Parameter containing:\n",
      "tensor([ 0.2740, -0.1345, -0.1395], requires_grad=True)\n",
      "tensor([0.4608, 0.1973, 0.3419], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2055280208587646\n",
      "Parameter containing:\n",
      "tensor([ 0.2747, -0.1347, -0.1400], requires_grad=True)\n",
      "tensor([0.2957, 0.3743, 0.3299], grad_fn=<SoftmaxBackward>)\n",
      "output:1.443587303161621\n",
      "Parameter containing:\n",
      "tensor([ 0.2753, -0.1351, -0.1403], requires_grad=True)\n",
      "tensor([0.2851, 0.3845, 0.3304], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4601949453353882\n",
      "Parameter containing:\n",
      "tensor([ 0.2759, -0.1354, -0.1405], requires_grad=True)\n",
      "tensor([0.3528, 0.3689, 0.2784], grad_fn=<SoftmaxBackward>)\n",
      "output:1.357837200164795\n",
      "Parameter containing:\n",
      "tensor([ 0.2766, -0.1358, -0.1408], requires_grad=True)\n",
      "tensor([0.3935, 0.3353, 0.2711], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2983098030090332\n",
      "Parameter containing:\n",
      "tensor([ 0.2773, -0.1362, -0.1411], requires_grad=True)\n",
      "tensor([0.4696, 0.3143, 0.2160], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1928560733795166\n",
      "Parameter containing:\n",
      "tensor([ 0.2780, -0.1366, -0.1414], requires_grad=True)\n",
      "tensor([0.3410, 0.4046, 0.2544], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3761749267578125\n",
      "Parameter containing:\n",
      "tensor([ 0.2786, -0.1370, -0.1416], requires_grad=True)\n",
      "tensor([0.4882, 0.3096, 0.2023], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1682193279266357\n",
      "Parameter containing:\n",
      "tensor([ 0.2793, -0.1374, -0.1419], requires_grad=True)\n",
      "tensor([0.4985, 0.2547, 0.2468], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1538339853286743\n",
      "Parameter containing:\n",
      "tensor([ 0.2800, -0.1377, -0.1422], requires_grad=True)\n",
      "tensor([0.3354, 0.2732, 0.3914], grad_fn=<SoftmaxBackward>)\n",
      "output:1.384036898612976\n",
      "Parameter containing:\n",
      "tensor([ 0.2806, -0.1380, -0.1426], requires_grad=True)\n",
      "tensor([0.3540, 0.2959, 0.3501], grad_fn=<SoftmaxBackward>)\n",
      "output:1.355760097503662\n",
      "Parameter containing:\n",
      "tensor([ 0.2813, -0.1383, -0.1430], requires_grad=True)\n",
      "tensor([0.3512, 0.3009, 0.3479], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3598589897155762\n",
      "Parameter containing:\n",
      "tensor([ 0.2820, -0.1386, -0.1434], requires_grad=True)\n",
      "tensor([0.4286, 0.2898, 0.2815], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2484421730041504\n",
      "Parameter containing:\n",
      "tensor([ 0.2827, -0.1390, -0.1437], requires_grad=True)\n",
      "tensor([0.2883, 0.3801, 0.3316], grad_fn=<SoftmaxBackward>)\n",
      "output:1.455064058303833\n",
      "Parameter containing:\n",
      "tensor([ 0.2833, -0.1393, -0.1440], requires_grad=True)\n",
      "tensor([0.3840, 0.3299, 0.2861], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3117892742156982\n",
      "Parameter containing:\n",
      "tensor([ 0.2840, -0.1397, -0.1443], requires_grad=True)\n",
      "tensor([0.4333, 0.3185, 0.2482], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2423181533813477\n",
      "Parameter containing:\n",
      "tensor([ 0.2847, -0.1401, -0.1446], requires_grad=True)\n",
      "tensor([0.3077, 0.2658, 0.4265], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4266679286956787\n",
      "Parameter containing:\n",
      "tensor([ 0.2853, -0.1403, -0.1450], requires_grad=True)\n",
      "tensor([0.3282, 0.2795, 0.3924], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3948644399642944\n",
      "Parameter containing:\n",
      "tensor([ 0.2860, -0.1406, -0.1454], requires_grad=True)\n",
      "tensor([0.4266, 0.3458, 0.2276], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2521212100982666\n",
      "Parameter containing:\n",
      "tensor([ 0.2867, -0.1410, -0.1457], requires_grad=True)\n",
      "tensor([0.2446, 0.4103, 0.3452], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5241585969924927\n",
      "Parameter containing:\n",
      "tensor([ 0.2873, -0.1413, -0.1459], requires_grad=True)\n",
      "tensor([0.4184, 0.3079, 0.2737], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2627990245819092\n",
      "Parameter containing:\n",
      "tensor([ 0.2879, -0.1417, -0.1463], requires_grad=True)\n",
      "tensor([0.3575, 0.3903, 0.2523], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3516244888305664\n",
      "Parameter containing:\n",
      "tensor([ 0.2886, -0.1421, -0.1465], requires_grad=True)\n",
      "tensor([0.3445, 0.3668, 0.2887], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3699254989624023\n",
      "Parameter containing:\n",
      "tensor([ 0.2893, -0.1425, -0.1468], requires_grad=True)\n",
      "tensor([0.3777, 0.3621, 0.2602], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3214586973190308\n",
      "Parameter containing:\n",
      "tensor([ 0.2900, -0.1429, -0.1471], requires_grad=True)\n",
      "tensor([0.2908, 0.2845, 0.4247], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4523248672485352\n",
      "Parameter containing:\n",
      "tensor([ 0.2906, -0.1431, -0.1475], requires_grad=True)\n",
      "tensor([0.3856, 0.3347, 0.2797], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3095976114273071\n",
      "Parameter containing:\n",
      "tensor([ 0.2913, -0.1435, -0.1478], requires_grad=True)\n",
      "tensor([0.2470, 0.5142, 0.2388], grad_fn=<SoftmaxBackward>)\n",
      "output:1.524705410003662\n",
      "Parameter containing:\n",
      "tensor([ 0.2919, -0.1440, -0.1479], requires_grad=True)\n",
      "tensor([0.4669, 0.2834, 0.2498], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1960469484329224\n",
      "Parameter containing:\n",
      "tensor([ 0.2926, -0.1443, -0.1483], requires_grad=True)\n",
      "tensor([0.2091, 0.5318, 0.2592], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5859791040420532\n",
      "Parameter containing:\n",
      "tensor([ 0.2931, -0.1447, -0.1484], requires_grad=True)\n",
      "tensor([0.3196, 0.3210, 0.3594], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4070370197296143\n",
      "Parameter containing:\n",
      "tensor([ 0.2938, -0.1450, -0.1488], requires_grad=True)\n",
      "tensor([0.3646, 0.3236, 0.3118], grad_fn=<SoftmaxBackward>)\n",
      "output:1.339966058731079\n",
      "Parameter containing:\n",
      "tensor([ 0.2945, -0.1454, -0.1491], requires_grad=True)\n",
      "tensor([0.3315, 0.3579, 0.3106], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3892097473144531\n",
      "Parameter containing:\n",
      "tensor([ 0.2951, -0.1457, -0.1494], requires_grad=True)\n",
      "tensor([0.2917, 0.2960, 0.4123], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4505506753921509\n",
      "Parameter containing:\n",
      "tensor([ 0.2958, -0.1460, -0.1498], requires_grad=True)\n",
      "tensor([0.2589, 0.2818, 0.4592], grad_fn=<SoftmaxBackward>)\n",
      "output:1.50294828414917\n",
      "Parameter containing:\n",
      "tensor([ 0.2964, -0.1462, -0.1502], requires_grad=True)\n",
      "tensor([0.2750, 0.5096, 0.2154], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4810292720794678\n",
      "Parameter containing:\n",
      "tensor([ 0.2970, -0.1467, -0.1503], requires_grad=True)\n",
      "tensor([0.2996, 0.2329, 0.4675], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4409139156341553\n",
      "Parameter containing:\n",
      "tensor([ 0.2977, -0.1469, -0.1508], requires_grad=True)\n",
      "tensor([0.3083, 0.2932, 0.3985], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4248714447021484\n",
      "Parameter containing:\n",
      "tensor([ 0.2983, -0.1471, -0.1512], requires_grad=True)\n",
      "tensor([0.4455, 0.2720, 0.2825], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2250912189483643\n",
      "Parameter containing:\n",
      "tensor([ 0.2990, -0.1475, -0.1515], requires_grad=True)\n",
      "tensor([0.3226, 0.4224, 0.2550], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4041941165924072\n",
      "Parameter containing:\n",
      "tensor([ 0.2996, -0.1479, -0.1518], requires_grad=True)\n",
      "tensor([0.3170, 0.3434, 0.3397], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4109618663787842\n",
      "Parameter containing:\n",
      "tensor([ 0.3003, -0.1482, -0.1521], requires_grad=True)\n",
      "tensor([0.4964, 0.2712, 0.2324], grad_fn=<SoftmaxBackward>)\n",
      "output:1.15665602684021\n",
      "Parameter containing:\n",
      "tensor([ 0.3010, -0.1486, -0.1524], requires_grad=True)\n",
      "tensor([0.3870, 0.3629, 0.2502], grad_fn=<SoftmaxBackward>)\n",
      "output:1.308237075805664\n",
      "Parameter containing:\n",
      "tensor([ 0.3017, -0.1490, -0.1527], requires_grad=True)\n",
      "tensor([0.3693, 0.2713, 0.3594], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3334884643554688\n",
      "Parameter containing:\n",
      "tensor([ 0.3023, -0.1493, -0.1531], requires_grad=True)\n",
      "tensor([0.4038, 0.3072, 0.2890], grad_fn=<SoftmaxBackward>)\n",
      "output:1.283393144607544\n",
      "Parameter containing:\n",
      "tensor([ 0.3030, -0.1496, -0.1534], requires_grad=True)\n",
      "tensor([0.2511, 0.4095, 0.3395], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5138177871704102\n",
      "Parameter containing:\n",
      "tensor([ 0.3036, -0.1500, -0.1537], requires_grad=True)\n",
      "tensor([0.3325, 0.3510, 0.3165], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3875867128372192\n",
      "Parameter containing:\n",
      "tensor([ 0.3043, -0.1503, -0.1540], requires_grad=True)\n",
      "tensor([0.3299, 0.2956, 0.3745], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3918452262878418\n",
      "Parameter containing:\n",
      "tensor([ 0.3049, -0.1506, -0.1543], requires_grad=True)\n",
      "tensor([0.4834, 0.2669, 0.2498], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1739147901535034\n",
      "Parameter containing:\n",
      "tensor([ 0.3056, -0.1509, -0.1547], requires_grad=True)\n",
      "tensor([0.4375, 0.3423, 0.2201], grad_fn=<SoftmaxBackward>)\n",
      "output:1.237004280090332\n",
      "Parameter containing:\n",
      "tensor([ 0.3063, -0.1514, -0.1549], requires_grad=True)\n",
      "tensor([0.3075, 0.3979, 0.2945], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4260401725769043\n",
      "Parameter containing:\n",
      "tensor([ 0.3069, -0.1518, -0.1552], requires_grad=True)\n",
      "tensor([0.3629, 0.3217, 0.3154], grad_fn=<SoftmaxBackward>)\n",
      "output:1.342391014099121\n",
      "Parameter containing:\n",
      "tensor([ 0.3076, -0.1521, -0.1555], requires_grad=True)\n",
      "tensor([0.3636, 0.2953, 0.3411], grad_fn=<SoftmaxBackward>)\n",
      "output:1.341554045677185\n",
      "Parameter containing:\n",
      "tensor([ 0.3083, -0.1524, -0.1559], requires_grad=True)\n",
      "tensor([0.3208, 0.2862, 0.3930], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4059396982192993\n",
      "Parameter containing:\n",
      "tensor([ 0.3090, -0.1527, -0.1563], requires_grad=True)\n",
      "tensor([0.4754, 0.3146, 0.2100], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1852381229400635\n",
      "Parameter containing:\n",
      "tensor([ 0.3096, -0.1531, -0.1566], requires_grad=True)\n",
      "tensor([0.3537, 0.2949, 0.3514], grad_fn=<SoftmaxBackward>)\n",
      "output:1.35616135597229\n",
      "Parameter containing:\n",
      "tensor([ 0.3103, -0.1534, -0.1569], requires_grad=True)\n",
      "tensor([0.2950, 0.3949, 0.3101], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4451371431350708\n",
      "Parameter containing:\n",
      "tensor([ 0.3110, -0.1538, -0.1572], requires_grad=True)\n",
      "tensor([0.3620, 0.2708, 0.3672], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3442840576171875\n",
      "Parameter containing:\n",
      "tensor([ 0.3116, -0.1540, -0.1576], requires_grad=True)\n",
      "tensor([0.3699, 0.3637, 0.2664], grad_fn=<SoftmaxBackward>)\n",
      "output:1.332808494567871\n",
      "Parameter containing:\n",
      "tensor([ 0.3123, -0.1544, -0.1579], requires_grad=True)\n",
      "tensor([0.3876, 0.2706, 0.3418], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3069279193878174\n",
      "Parameter containing:\n",
      "tensor([ 0.3130, -0.1547, -0.1583], requires_grad=True)\n",
      "tensor([0.2482, 0.5471, 0.2047], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5253961086273193\n",
      "Parameter containing:\n",
      "tensor([ 0.3136, -0.1552, -0.1584], requires_grad=True)\n",
      "tensor([0.3303, 0.3438, 0.3259], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3908638954162598\n",
      "Parameter containing:\n",
      "tensor([ 0.3143, -0.1555, -0.1587], requires_grad=True)\n",
      "tensor([0.3070, 0.2844, 0.4085], grad_fn=<SoftmaxBackward>)\n",
      "output:1.427098274230957\n",
      "Parameter containing:\n",
      "tensor([ 0.3149, -0.1558, -0.1591], requires_grad=True)\n",
      "tensor([0.3749, 0.3369, 0.2882], grad_fn=<SoftmaxBackward>)\n",
      "output:1.325026035308838\n",
      "Parameter containing:\n",
      "tensor([ 0.3156, -0.1562, -0.1594], requires_grad=True)\n",
      "tensor([0.3311, 0.3569, 0.3120], grad_fn=<SoftmaxBackward>)\n",
      "output:1.38975191116333\n",
      "Parameter containing:\n",
      "tensor([ 0.3163, -0.1565, -0.1597], requires_grad=True)\n",
      "tensor([0.3377, 0.3041, 0.3582], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3799149990081787\n",
      "Parameter containing:\n",
      "tensor([ 0.3169, -0.1568, -0.1601], requires_grad=True)\n",
      "tensor([0.3565, 0.3227, 0.3207], grad_fn=<SoftmaxBackward>)\n",
      "output:1.351773977279663\n",
      "Parameter containing:\n",
      "tensor([ 0.3176, -0.1572, -0.1604], requires_grad=True)\n",
      "tensor([0.2901, 0.4372, 0.2727], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:1.4538811445236206\n",
      "Parameter containing:\n",
      "tensor([ 0.3182, -0.1576, -0.1607], requires_grad=True)\n",
      "tensor([0.3876, 0.3172, 0.2952], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3065884113311768\n",
      "Parameter containing:\n",
      "tensor([ 0.3189, -0.1579, -0.1610], requires_grad=True)\n",
      "tensor([0.4236, 0.2991, 0.2772], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2554850578308105\n",
      "Parameter containing:\n",
      "tensor([ 0.3196, -0.1583, -0.1613], requires_grad=True)\n",
      "tensor([0.3948, 0.2918, 0.3134], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2961852550506592\n",
      "Parameter containing:\n",
      "tensor([ 0.3203, -0.1586, -0.1617], requires_grad=True)\n",
      "tensor([0.4668, 0.2905, 0.2428], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1962597370147705\n",
      "Parameter containing:\n",
      "tensor([ 0.3210, -0.1590, -0.1620], requires_grad=True)\n",
      "tensor([0.3237, 0.3694, 0.3069], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4009714126586914\n",
      "Parameter containing:\n",
      "tensor([ 0.3216, -0.1594, -0.1623], requires_grad=True)\n",
      "tensor([0.2697, 0.3819, 0.3483], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4840238094329834\n",
      "Parameter containing:\n",
      "tensor([ 0.3223, -0.1597, -0.1626], requires_grad=True)\n",
      "tensor([0.3913, 0.2477, 0.3611], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3021044731140137\n",
      "Parameter containing:\n",
      "tensor([ 0.3229, -0.1599, -0.1630], requires_grad=True)\n",
      "tensor([0.3147, 0.2523, 0.4330], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4165096282958984\n",
      "Parameter containing:\n",
      "tensor([ 0.3236, -0.1602, -0.1634], requires_grad=True)\n",
      "tensor([0.3410, 0.3733, 0.2857], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3752920627593994\n",
      "Parameter containing:\n",
      "tensor([ 0.3243, -0.1606, -0.1637], requires_grad=True)\n",
      "tensor([0.3014, 0.4265, 0.2721], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4363186359405518\n",
      "Parameter containing:\n",
      "tensor([ 0.3249, -0.1610, -0.1639], requires_grad=True)\n",
      "tensor([0.2823, 0.3052, 0.4125], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4649584293365479\n",
      "Parameter containing:\n",
      "tensor([ 0.3255, -0.1612, -0.1643], requires_grad=True)\n",
      "tensor([0.4867, 0.2507, 0.2625], grad_fn=<SoftmaxBackward>)\n",
      "output:1.169392466545105\n",
      "Parameter containing:\n",
      "tensor([ 0.3262, -0.1616, -0.1647], requires_grad=True)\n",
      "tensor([0.3722, 0.3367, 0.2911], grad_fn=<SoftmaxBackward>)\n",
      "output:1.328951358795166\n",
      "Parameter containing:\n",
      "tensor([ 0.3269, -0.1619, -0.1650], requires_grad=True)\n",
      "tensor([0.3510, 0.3802, 0.2688], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3607584238052368\n",
      "Parameter containing:\n",
      "tensor([ 0.3276, -0.1623, -0.1652], requires_grad=True)\n",
      "tensor([0.3692, 0.3861, 0.2446], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3344486951828003\n",
      "Parameter containing:\n",
      "tensor([ 0.3282, -0.1628, -0.1655], requires_grad=True)\n",
      "tensor([0.3564, 0.2206, 0.4230], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3544867038726807\n",
      "Parameter containing:\n",
      "tensor([ 0.3289, -0.1630, -0.1660], requires_grad=True)\n",
      "tensor([0.3695, 0.3246, 0.3059], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3327829837799072\n",
      "Parameter containing:\n",
      "tensor([ 0.3296, -0.1633, -0.1663], requires_grad=True)\n",
      "tensor([0.3935, 0.2770, 0.3295], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2982676029205322\n",
      "Parameter containing:\n",
      "tensor([ 0.3303, -0.1636, -0.1667], requires_grad=True)\n",
      "tensor([0.2906, 0.3650, 0.3445], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4514714479446411\n",
      "Parameter containing:\n",
      "tensor([ 0.3309, -0.1640, -0.1670], requires_grad=True)\n",
      "tensor([0.3296, 0.2944, 0.3760], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3923895359039307\n",
      "Parameter containing:\n",
      "tensor([ 0.3316, -0.1643, -0.1673], requires_grad=True)\n",
      "tensor([0.3594, 0.2777, 0.3629], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3480457067489624\n",
      "Parameter containing:\n",
      "tensor([ 0.3323, -0.1645, -0.1677], requires_grad=True)\n",
      "tensor([0.2603, 0.2650, 0.4747], grad_fn=<SoftmaxBackward>)\n",
      "output:1.501587152481079\n",
      "Parameter containing:\n",
      "tensor([ 0.3329, -0.1647, -0.1681], requires_grad=True)\n",
      "tensor([0.3131, 0.3511, 0.3359], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4169368743896484\n",
      "Parameter containing:\n",
      "tensor([ 0.3335, -0.1651, -0.1685], requires_grad=True)\n",
      "tensor([0.3892, 0.2350, 0.3758], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3055481910705566\n",
      "Parameter containing:\n",
      "tensor([ 0.3342, -0.1653, -0.1689], requires_grad=True)\n",
      "tensor([0.2675, 0.3388, 0.3937], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4876689910888672\n",
      "Parameter containing:\n",
      "tensor([ 0.3348, -0.1656, -0.1692], requires_grad=True)\n",
      "tensor([0.3509, 0.2739, 0.3751], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3607163429260254\n",
      "Parameter containing:\n",
      "tensor([ 0.3355, -0.1659, -0.1696], requires_grad=True)\n",
      "tensor([0.3590, 0.3400, 0.3010], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3482091426849365\n",
      "Parameter containing:\n",
      "tensor([ 0.3362, -0.1662, -0.1699], requires_grad=True)\n",
      "tensor([0.4158, 0.2940, 0.2902], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2663583755493164\n",
      "Parameter containing:\n",
      "tensor([ 0.3369, -0.1666, -0.1703], requires_grad=True)\n",
      "tensor([0.2350, 0.3658, 0.3992], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5392849445343018\n",
      "Parameter containing:\n",
      "tensor([ 0.3375, -0.1669, -0.1706], requires_grad=True)\n",
      "tensor([0.3656, 0.2463, 0.3882], grad_fn=<SoftmaxBackward>)\n",
      "output:1.339766025543213\n",
      "Parameter containing:\n",
      "tensor([ 0.3381, -0.1671, -0.1710], requires_grad=True)\n",
      "tensor([0.2628, 0.3527, 0.3845], grad_fn=<SoftmaxBackward>)\n",
      "output:1.494882583618164\n",
      "Parameter containing:\n",
      "tensor([ 0.3387, -0.1674, -0.1713], requires_grad=True)\n",
      "tensor([0.3603, 0.3231, 0.3166], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3462861776351929\n",
      "Parameter containing:\n",
      "tensor([ 0.3394, -0.1678, -0.1717], requires_grad=True)\n",
      "tensor([0.2984, 0.3401, 0.3615], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4393603801727295\n",
      "Parameter containing:\n",
      "tensor([ 0.3401, -0.1681, -0.1720], requires_grad=True)\n",
      "tensor([0.3729, 0.2347, 0.3925], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3294072151184082\n",
      "Parameter containing:\n",
      "tensor([ 0.3408, -0.1683, -0.1724], requires_grad=True)\n",
      "tensor([0.2856, 0.4323, 0.2821], grad_fn=<SoftmaxBackward>)\n",
      "output:1.460547924041748\n",
      "Parameter containing:\n",
      "tensor([ 0.3414, -0.1687, -0.1727], requires_grad=True)\n",
      "tensor([0.3720, 0.3095, 0.3185], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3292033672332764\n",
      "Parameter containing:\n",
      "tensor([ 0.3421, -0.1690, -0.1730], requires_grad=True)\n",
      "tensor([0.2587, 0.3854, 0.3559], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5013535022735596\n",
      "Parameter containing:\n",
      "tensor([ 0.3427, -0.1694, -0.1733], requires_grad=True)\n",
      "tensor([0.3023, 0.2936, 0.4042], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4342066049575806\n",
      "Parameter containing:\n",
      "tensor([ 0.3433, -0.1696, -0.1737], requires_grad=True)\n",
      "tensor([0.3196, 0.3690, 0.3114], grad_fn=<SoftmaxBackward>)\n",
      "output:1.407240867614746\n",
      "Parameter containing:\n",
      "tensor([ 0.3440, -0.1700, -0.1740], requires_grad=True)\n",
      "tensor([0.2918, 0.3088, 0.3994], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4500731229782104\n",
      "Parameter containing:\n",
      "tensor([ 0.3446, -0.1703, -0.1744], requires_grad=True)\n",
      "tensor([0.3686, 0.3046, 0.3267], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3340836763381958\n",
      "Parameter containing:\n",
      "tensor([ 0.3453, -0.1706, -0.1747], requires_grad=True)\n",
      "tensor([0.2154, 0.5316, 0.2530], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5758333206176758\n",
      "Parameter containing:\n",
      "tensor([ 0.3459, -0.1710, -0.1749], requires_grad=True)\n",
      "tensor([0.4152, 0.1979, 0.3869], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2694644927978516\n",
      "Parameter containing:\n",
      "tensor([ 0.3465, -0.1712, -0.1753], requires_grad=True)\n",
      "tensor([0.3209, 0.3322, 0.3470], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4050753116607666\n",
      "Parameter containing:\n",
      "tensor([ 0.3472, -0.1715, -0.1757], requires_grad=True)\n",
      "tensor([0.2752, 0.3109, 0.4139], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4760596752166748\n",
      "Parameter containing:\n",
      "tensor([ 0.3478, -0.1718, -0.1761], requires_grad=True)\n",
      "tensor([0.3713, 0.2744, 0.3543], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3305445909500122\n",
      "Parameter containing:\n",
      "tensor([ 0.3485, -0.1721, -0.1764], requires_grad=True)\n",
      "tensor([0.3108, 0.3317, 0.3575], grad_fn=<SoftmaxBackward>)\n",
      "output:1.420447587966919\n",
      "Parameter containing:\n",
      "tensor([ 0.3492, -0.1724, -0.1768], requires_grad=True)\n",
      "tensor([0.3667, 0.3816, 0.2518], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3379604816436768\n",
      "Parameter containing:\n",
      "tensor([ 0.3498, -0.1728, -0.1770], requires_grad=True)\n",
      "tensor([0.3883, 0.2784, 0.3333], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3057758808135986\n",
      "Parameter containing:\n",
      "tensor([ 0.3505, -0.1731, -0.1774], requires_grad=True)\n",
      "tensor([0.3894, 0.3236, 0.2871], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3040598630905151\n",
      "Parameter containing:\n",
      "tensor([ 0.3512, -0.1735, -0.1777], requires_grad=True)\n",
      "tensor([0.3013, 0.3440, 0.3546], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4348599910736084\n",
      "Parameter containing:\n",
      "tensor([ 0.3519, -0.1738, -0.1781], requires_grad=True)\n",
      "tensor([0.2771, 0.3804, 0.3424], grad_fn=<SoftmaxBackward>)\n",
      "output:1.472438097000122\n",
      "Parameter containing:\n",
      "tensor([ 0.3525, -0.1741, -0.1784], requires_grad=True)\n",
      "tensor([0.3427, 0.3089, 0.3484], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3723576068878174\n",
      "Parameter containing:\n",
      "tensor([ 0.3532, -0.1744, -0.1787], requires_grad=True)\n",
      "tensor([0.3509, 0.2904, 0.3587], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3604106903076172\n",
      "Parameter containing:\n",
      "tensor([ 0.3538, -0.1747, -0.1791], requires_grad=True)\n",
      "tensor([0.6288, 0.1588, 0.2125], grad_fn=<SoftmaxBackward>)\n",
      "output:0.9920267462730408\n",
      "Parameter containing:\n",
      "tensor([ 0.3544, -0.1750, -0.1794], requires_grad=True)\n",
      "tensor([0.3448, 0.3409, 0.3143], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3692042827606201\n",
      "Parameter containing:\n",
      "tensor([ 0.3551, -0.1753, -0.1797], requires_grad=True)\n",
      "tensor([0.3218, 0.3459, 0.3323], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4036908149719238\n",
      "Parameter containing:\n",
      "tensor([ 0.3557, -0.1757, -0.1801], requires_grad=True)\n",
      "tensor([0.4160, 0.2490, 0.3350], grad_fn=<SoftmaxBackward>)\n",
      "output:1.26658034324646\n",
      "Parameter containing:\n",
      "tensor([ 0.3564, -0.1759, -0.1805], requires_grad=True)\n",
      "tensor([0.2556, 0.2258, 0.5187], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5116901397705078\n",
      "Parameter containing:\n",
      "tensor([ 0.3570, -0.1761, -0.1809], requires_grad=True)\n",
      "tensor([0.5817, 0.2534, 0.1649], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0487041473388672\n",
      "Parameter containing:\n",
      "tensor([ 0.3576, -0.1765, -0.1811], requires_grad=True)\n",
      "tensor([0.3542, 0.2872, 0.3586], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3555583953857422\n",
      "Parameter containing:\n",
      "tensor([ 0.3583, -0.1768, -0.1815], requires_grad=True)\n",
      "tensor([0.4425, 0.3182, 0.2393], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2296301126480103\n",
      "Parameter containing:\n",
      "tensor([ 0.3590, -0.1772, -0.1818], requires_grad=True)\n",
      "tensor([0.2369, 0.2326, 0.5306], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5417402982711792\n",
      "Parameter containing:\n",
      "tensor([ 0.3595, -0.1773, -0.1822], requires_grad=True)\n",
      "tensor([0.3306, 0.3933, 0.2761], grad_fn=<SoftmaxBackward>)\n",
      "output:1.391310214996338\n",
      "Parameter containing:\n",
      "tensor([ 0.3602, -0.1777, -0.1825], requires_grad=True)\n",
      "tensor([0.3522, 0.2447, 0.4030], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3597569465637207\n",
      "Parameter containing:\n",
      "tensor([ 0.3609, -0.1780, -0.1829], requires_grad=True)\n",
      "tensor([0.3290, 0.3871, 0.2839], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3934202194213867\n",
      "Parameter containing:\n",
      "tensor([ 0.3616, -0.1784, -0.1832], requires_grad=True)\n",
      "tensor([0.3396, 0.3261, 0.3343], grad_fn=<SoftmaxBackward>)\n",
      "output:1.376965045928955\n",
      "Parameter containing:\n",
      "tensor([ 0.3622, -0.1787, -0.1835], requires_grad=True)\n",
      "tensor([0.3533, 0.3546, 0.2921], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3568143844604492\n",
      "Parameter containing:\n",
      "tensor([ 0.3629, -0.1791, -0.1838], requires_grad=True)\n",
      "tensor([0.3964, 0.2262, 0.3773], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2953099012374878\n",
      "Parameter containing:\n",
      "tensor([ 0.3636, -0.1793, -0.1843], requires_grad=True)\n",
      "tensor([0.2519, 0.2853, 0.4629], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5141634941101074\n",
      "Parameter containing:\n",
      "tensor([ 0.3642, -0.1795, -0.1847], requires_grad=True)\n",
      "tensor([0.2549, 0.2416, 0.5035], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5116089582443237\n",
      "Parameter containing:\n",
      "tensor([ 0.3648, -0.1797, -0.1851], requires_grad=True)\n",
      "tensor([0.4336, 0.2909, 0.2755], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2416006326675415\n",
      "Parameter containing:\n",
      "tensor([ 0.3655, -0.1800, -0.1854], requires_grad=True)\n",
      "tensor([0.3289, 0.3471, 0.3241], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3930494785308838\n",
      "Parameter containing:\n",
      "tensor([ 0.3661, -0.1804, -0.1858], requires_grad=True)\n",
      "tensor([0.4172, 0.2609, 0.3218], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2646411657333374\n",
      "Parameter containing:\n",
      "tensor([ 0.3668, -0.1807, -0.1861], requires_grad=True)\n",
      "tensor([0.4333, 0.3280, 0.2387], grad_fn=<SoftmaxBackward>)\n",
      "output:1.242462158203125\n",
      "Parameter containing:\n",
      "tensor([ 0.3675, -0.1811, -0.1864], requires_grad=True)\n",
      "tensor([0.3269, 0.3232, 0.3499], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3960366249084473\n",
      "Parameter containing:\n",
      "tensor([ 0.3682, -0.1814, -0.1868], requires_grad=True)\n",
      "tensor([0.2950, 0.3248, 0.3803], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4448777437210083\n",
      "Parameter containing:\n",
      "tensor([ 0.3688, -0.1817, -0.1871], requires_grad=True)\n",
      "tensor([0.2907, 0.3055, 0.4038], grad_fn=<SoftmaxBackward>)\n",
      "output:1.451825499534607\n",
      "Parameter containing:\n",
      "tensor([ 0.3695, -0.1820, -0.1875], requires_grad=True)\n",
      "tensor([0.3470, 0.2912, 0.3618], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3661658763885498\n",
      "Parameter containing:\n",
      "tensor([ 0.3701, -0.1823, -0.1879], requires_grad=True)\n",
      "tensor([0.3774, 0.4440, 0.1786], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3256242275238037\n",
      "Parameter containing:\n",
      "tensor([ 0.3708, -0.1828, -0.1880], requires_grad=True)\n",
      "tensor([0.3720, 0.3071, 0.3208], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3291200399398804\n",
      "Parameter containing:\n",
      "tensor([ 0.3715, -0.1831, -0.1884], requires_grad=True)\n",
      "tensor([0.3564, 0.3537, 0.2898], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3522063493728638\n",
      "Parameter containing:\n",
      "tensor([ 0.3722, -0.1835, -0.1887], requires_grad=True)\n",
      "tensor([0.2995, 0.2481, 0.4524], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4403589963912964\n",
      "Parameter containing:\n",
      "tensor([ 0.3728, -0.1837, -0.1891], requires_grad=True)\n",
      "tensor([0.3650, 0.2822, 0.3528], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3396919965744019\n",
      "Parameter containing:\n",
      "tensor([ 0.3735, -0.1840, -0.1895], requires_grad=True)\n",
      "tensor([0.2724, 0.3128, 0.4148], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4804036617279053\n",
      "Parameter containing:\n",
      "tensor([ 0.3741, -0.1842, -0.1899], requires_grad=True)\n",
      "tensor([0.3607, 0.3935, 0.2458], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3469749689102173\n",
      "Parameter containing:\n",
      "tensor([ 0.3748, -0.1847, -0.1901], requires_grad=True)\n",
      "tensor([0.4792, 0.2078, 0.3130], grad_fn=<SoftmaxBackward>)\n",
      "output:1.180076241493225\n",
      "Parameter containing:\n",
      "tensor([ 0.3755, -0.1849, -0.1905], requires_grad=True)\n",
      "tensor([0.3728, 0.2912, 0.3360], grad_fn=<SoftmaxBackward>)\n",
      "output:1.328066110610962\n",
      "Parameter containing:\n",
      "tensor([ 0.3762, -0.1852, -0.1909], requires_grad=True)\n",
      "tensor([0.4141, 0.3234, 0.2626], grad_fn=<SoftmaxBackward>)\n",
      "output:1.269059181213379\n",
      "Parameter containing:\n",
      "tensor([ 0.3768, -0.1856, -0.1912], requires_grad=True)\n",
      "tensor([0.2103, 0.2149, 0.5748], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5873496532440186\n",
      "Parameter containing:\n",
      "tensor([ 0.3774, -0.1858, -0.1916], requires_grad=True)\n",
      "tensor([0.4277, 0.3668, 0.2055], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2513854503631592\n",
      "Parameter containing:\n",
      "tensor([ 0.3781, -0.1862, -0.1919], requires_grad=True)\n",
      "tensor([0.2967, 0.2541, 0.4492], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4443377256393433\n",
      "Parameter containing:\n",
      "tensor([ 0.3787, -0.1864, -0.1923], requires_grad=True)\n",
      "tensor([0.4143, 0.2920, 0.2937], grad_fn=<SoftmaxBackward>)\n",
      "output:1.268561840057373\n",
      "Parameter containing:\n",
      "tensor([ 0.3794, -0.1868, -0.1926], requires_grad=True)\n",
      "tensor([0.3660, 0.2541, 0.3800], grad_fn=<SoftmaxBackward>)\n",
      "output:1.338956594467163\n",
      "Parameter containing:\n",
      "tensor([ 0.3801, -0.1870, -0.1931], requires_grad=True)\n",
      "tensor([0.3878, 0.3315, 0.2807], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3064749240875244\n",
      "Parameter containing:\n",
      "tensor([ 0.3808, -0.1874, -0.1934], requires_grad=True)\n",
      "tensor([0.3971, 0.2218, 0.3810], grad_fn=<SoftmaxBackward>)\n",
      "output:1.294490098953247\n",
      "Parameter containing:\n",
      "tensor([ 0.3815, -0.1876, -0.1938], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3139, 0.3720, 0.3141], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4158375263214111\n",
      "Parameter containing:\n",
      "tensor([ 0.3821, -0.1880, -0.1941], requires_grad=True)\n",
      "tensor([0.2021, 0.3124, 0.4855], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5946592092514038\n",
      "Parameter containing:\n",
      "tensor([ 0.3826, -0.1882, -0.1944], requires_grad=True)\n",
      "tensor([0.2928, 0.3146, 0.3926], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4483351707458496\n",
      "Parameter containing:\n",
      "tensor([ 0.3833, -0.1885, -0.1948], requires_grad=True)\n",
      "tensor([0.3052, 0.3964, 0.2984], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4294633865356445\n",
      "Parameter containing:\n",
      "tensor([ 0.3839, -0.1888, -0.1951], requires_grad=True)\n",
      "tensor([0.2966, 0.4576, 0.2458], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4449416399002075\n",
      "Parameter containing:\n",
      "tensor([ 0.3846, -0.1893, -0.1953], requires_grad=True)\n",
      "tensor([0.4786, 0.2839, 0.2375], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1803141832351685\n",
      "Parameter containing:\n",
      "tensor([ 0.3852, -0.1897, -0.1956], requires_grad=True)\n",
      "tensor([0.3578, 0.2699, 0.3723], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3505418300628662\n",
      "Parameter containing:\n",
      "tensor([ 0.3859, -0.1899, -0.1960], requires_grad=True)\n",
      "tensor([0.4710, 0.2454, 0.2836], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1905438899993896\n",
      "Parameter containing:\n",
      "tensor([ 0.3866, -0.1902, -0.1964], requires_grad=True)\n",
      "tensor([0.3782, 0.2707, 0.3511], grad_fn=<SoftmaxBackward>)\n",
      "output:1.320533037185669\n",
      "Parameter containing:\n",
      "tensor([ 0.3873, -0.1905, -0.1967], requires_grad=True)\n",
      "tensor([0.3914, 0.3195, 0.2891], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3011246919631958\n",
      "Parameter containing:\n",
      "tensor([ 0.3880, -0.1909, -0.1971], requires_grad=True)\n",
      "tensor([0.3327, 0.2963, 0.3710], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3875579833984375\n",
      "Parameter containing:\n",
      "tensor([ 0.3886, -0.1912, -0.1974], requires_grad=True)\n",
      "tensor([0.4173, 0.3236, 0.2591], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2645573616027832\n",
      "Parameter containing:\n",
      "tensor([ 0.3893, -0.1916, -0.1977], requires_grad=True)\n",
      "tensor([0.3991, 0.3455, 0.2554], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2905938625335693\n",
      "Parameter containing:\n",
      "tensor([ 0.3900, -0.1920, -0.1980], requires_grad=True)\n",
      "tensor([0.2772, 0.2696, 0.4532], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4743367433547974\n",
      "Parameter containing:\n",
      "tensor([ 0.3906, -0.1922, -0.1984], requires_grad=True)\n",
      "tensor([0.4999, 0.2298, 0.2703], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1520979404449463\n",
      "Parameter containing:\n",
      "tensor([ 0.3913, -0.1925, -0.1988], requires_grad=True)\n",
      "tensor([0.3615, 0.3301, 0.3085], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3445626497268677\n",
      "Parameter containing:\n",
      "tensor([ 0.3920, -0.1928, -0.1991], requires_grad=True)\n",
      "tensor([0.5401, 0.1976, 0.2624], grad_fn=<SoftmaxBackward>)\n",
      "output:1.100400686264038\n",
      "Parameter containing:\n",
      "tensor([ 0.3926, -0.1931, -0.1995], requires_grad=True)\n",
      "tensor([0.4289, 0.2669, 0.3043], grad_fn=<SoftmaxBackward>)\n",
      "output:1.248232126235962\n",
      "Parameter containing:\n",
      "tensor([ 0.3933, -0.1934, -0.1999], requires_grad=True)\n",
      "tensor([0.3636, 0.2942, 0.3422], grad_fn=<SoftmaxBackward>)\n",
      "output:1.341615915298462\n",
      "Parameter containing:\n",
      "tensor([ 0.3940, -0.1937, -0.2002], requires_grad=True)\n",
      "tensor([0.3191, 0.4160, 0.2649], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4092202186584473\n",
      "Parameter containing:\n",
      "tensor([ 0.3946, -0.1941, -0.2005], requires_grad=True)\n",
      "tensor([0.4076, 0.2905, 0.3018], grad_fn=<SoftmaxBackward>)\n",
      "output:1.277940034866333\n",
      "Parameter containing:\n",
      "tensor([ 0.3953, -0.1945, -0.2008], requires_grad=True)\n",
      "tensor([0.2620, 0.4982, 0.2398], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5002946853637695\n",
      "Parameter containing:\n",
      "tensor([ 0.3959, -0.1949, -0.2010], requires_grad=True)\n",
      "tensor([0.3254, 0.2561, 0.4186], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3998935222625732\n",
      "Parameter containing:\n",
      "tensor([ 0.3966, -0.1952, -0.2014], requires_grad=True)\n",
      "tensor([0.2982, 0.2856, 0.4162], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4408297538757324\n",
      "Parameter containing:\n",
      "tensor([ 0.3972, -0.1954, -0.2018], requires_grad=True)\n",
      "tensor([0.3231, 0.2265, 0.4504], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4048421382904053\n",
      "Parameter containing:\n",
      "tensor([ 0.3979, -0.1956, -0.2023], requires_grad=True)\n",
      "tensor([0.3972, 0.2596, 0.3432], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2932121753692627\n",
      "Parameter containing:\n",
      "tensor([ 0.3986, -0.1959, -0.2027], requires_grad=True)\n",
      "tensor([0.4406, 0.3113, 0.2480], grad_fn=<SoftmaxBackward>)\n",
      "output:1.232079029083252\n",
      "Parameter containing:\n",
      "tensor([ 0.3993, -0.1963, -0.2030], requires_grad=True)\n",
      "tensor([0.4003, 0.2616, 0.3381], grad_fn=<SoftmaxBackward>)\n",
      "output:1.288698434829712\n",
      "Parameter containing:\n",
      "tensor([ 0.3999, -0.1966, -0.2034], requires_grad=True)\n",
      "tensor([0.3161, 0.3266, 0.3572], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4123239517211914\n",
      "Parameter containing:\n",
      "tensor([ 0.4006, -0.1969, -0.2037], requires_grad=True)\n",
      "tensor([0.3031, 0.3805, 0.3164], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4324334859848022\n",
      "Parameter containing:\n",
      "tensor([ 0.4012, -0.1972, -0.2040], requires_grad=True)\n",
      "tensor([0.3236, 0.3873, 0.2891], grad_fn=<SoftmaxBackward>)\n",
      "output:1.401615858078003\n",
      "Parameter containing:\n",
      "tensor([ 0.4019, -0.1976, -0.2043], requires_grad=True)\n",
      "tensor([0.2831, 0.4270, 0.2899], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4643127918243408\n",
      "Parameter containing:\n",
      "tensor([ 0.4025, -0.1980, -0.2045], requires_grad=True)\n",
      "tensor([0.4262, 0.3079, 0.2658], grad_fn=<SoftmaxBackward>)\n",
      "output:1.251882791519165\n",
      "Parameter containing:\n",
      "tensor([ 0.4032, -0.1984, -0.2048], requires_grad=True)\n",
      "tensor([0.3725, 0.3783, 0.2492], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3294520378112793\n",
      "Parameter containing:\n",
      "tensor([ 0.4039, -0.1988, -0.2051], requires_grad=True)\n",
      "tensor([0.5231, 0.2834, 0.1935], grad_fn=<SoftmaxBackward>)\n",
      "output:1.122359037399292\n",
      "Parameter containing:\n",
      "tensor([ 0.4045, -0.1992, -0.2053], requires_grad=True)\n",
      "tensor([0.2983, 0.3948, 0.3069], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4399969577789307\n",
      "Parameter containing:\n",
      "tensor([ 0.4052, -0.1996, -0.2056], requires_grad=True)\n",
      "tensor([0.4195, 0.2616, 0.3189], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2614432573318481\n",
      "Parameter containing:\n",
      "tensor([ 0.4059, -0.1999, -0.2060], requires_grad=True)\n",
      "tensor([0.3045, 0.2914, 0.4040], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4307639598846436\n",
      "Parameter containing:\n",
      "tensor([ 0.4065, -0.2001, -0.2064], requires_grad=True)\n",
      "tensor([0.3679, 0.2826, 0.3495], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3354249000549316\n",
      "Parameter containing:\n",
      "tensor([ 0.4072, -0.2004, -0.2068], requires_grad=True)\n",
      "tensor([0.4191, 0.2888, 0.2921], grad_fn=<SoftmaxBackward>)\n",
      "output:1.261752963066101\n",
      "Parameter containing:\n",
      "tensor([ 0.4079, -0.2008, -0.2071], requires_grad=True)\n",
      "tensor([0.4304, 0.2840, 0.2856], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2460155487060547\n",
      "Parameter containing:\n",
      "tensor([ 0.4086, -0.2011, -0.2075], requires_grad=True)\n",
      "tensor([0.2222, 0.3183, 0.4595], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5611400604248047\n",
      "Parameter containing:\n",
      "tensor([ 0.4091, -0.2013, -0.2078], requires_grad=True)\n",
      "tensor([0.3908, 0.2827, 0.3265], grad_fn=<SoftmaxBackward>)\n",
      "output:1.302046298980713\n",
      "Parameter containing:\n",
      "tensor([ 0.4098, -0.2017, -0.2082], requires_grad=True)\n",
      "tensor([0.2589, 0.3209, 0.4202], grad_fn=<SoftmaxBackward>)\n",
      "output:1.501626968383789\n",
      "Parameter containing:\n",
      "tensor([ 0.4104, -0.2019, -0.2085], requires_grad=True)\n",
      "tensor([0.2797, 0.2987, 0.4216], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4692659378051758\n",
      "Parameter containing:\n",
      "tensor([ 0.4111, -0.2022, -0.2089], requires_grad=True)\n",
      "tensor([0.5378, 0.2170, 0.2452], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1030113697052002\n",
      "Parameter containing:\n",
      "tensor([ 0.4117, -0.2025, -0.2092], requires_grad=True)\n",
      "tensor([0.4065, 0.2094, 0.3841], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2814693450927734\n",
      "Parameter containing:\n",
      "tensor([ 0.4124, -0.2027, -0.2097], requires_grad=True)\n",
      "tensor([0.3107, 0.4446, 0.2447], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4229717254638672\n",
      "Parameter containing:\n",
      "tensor([ 0.4130, -0.2031, -0.2099], requires_grad=True)\n",
      "tensor([0.3426, 0.3539, 0.3034], grad_fn=<SoftmaxBackward>)\n",
      "output:1.372532844543457\n",
      "Parameter containing:\n",
      "tensor([ 0.4137, -0.2035, -0.2102], requires_grad=True)\n",
      "tensor([0.5131, 0.2252, 0.2616], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1347997188568115\n",
      "Parameter containing:\n",
      "tensor([ 0.4144, -0.2038, -0.2106], requires_grad=True)\n",
      "tensor([0.4482, 0.3254, 0.2264], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2219582796096802\n",
      "Parameter containing:\n",
      "tensor([ 0.4150, -0.2042, -0.2108], requires_grad=True)\n",
      "tensor([0.4586, 0.2856, 0.2559], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2073099613189697\n",
      "Parameter containing:\n",
      "tensor([ 0.4157, -0.2045, -0.2112], requires_grad=True)\n",
      "tensor([0.3839, 0.3054, 0.3107], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3119471073150635\n",
      "Parameter containing:\n",
      "tensor([ 0.4164, -0.2049, -0.2115], requires_grad=True)\n",
      "tensor([0.3798, 0.3128, 0.3074], grad_fn=<SoftmaxBackward>)\n",
      "output:1.317798376083374\n",
      "Parameter containing:\n",
      "tensor([ 0.4171, -0.2052, -0.2118], requires_grad=True)\n",
      "tensor([0.3472, 0.3170, 0.3358], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3656251430511475\n",
      "Parameter containing:\n",
      "tensor([ 0.4177, -0.2056, -0.2122], requires_grad=True)\n",
      "tensor([0.3257, 0.4050, 0.2693], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3989591598510742\n",
      "Parameter containing:\n",
      "tensor([ 0.4184, -0.2060, -0.2124], requires_grad=True)\n",
      "tensor([0.3357, 0.2809, 0.3834], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3833813667297363\n",
      "Parameter containing:\n",
      "tensor([ 0.4191, -0.2062, -0.2128], requires_grad=True)\n",
      "tensor([0.3934, 0.3422, 0.2644], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2986341714859009\n",
      "Parameter containing:\n",
      "tensor([ 0.4198, -0.2066, -0.2131], requires_grad=True)\n",
      "tensor([0.3002, 0.3667, 0.3331], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4367403984069824\n",
      "Parameter containing:\n",
      "tensor([ 0.4204, -0.2070, -0.2134], requires_grad=True)\n",
      "tensor([0.3282, 0.4280, 0.2438], grad_fn=<SoftmaxBackward>)\n",
      "output:1.396071434020996\n",
      "Parameter containing:\n",
      "tensor([ 0.4211, -0.2074, -0.2137], requires_grad=True)\n",
      "tensor([0.3693, 0.3177, 0.3130], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3330029249191284\n",
      "Parameter containing:\n",
      "tensor([ 0.4218, -0.2078, -0.2140], requires_grad=True)\n",
      "tensor([0.2891, 0.3719, 0.3389], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4537402391433716\n",
      "Parameter containing:\n",
      "tensor([ 0.4224, -0.2081, -0.2143], requires_grad=True)\n",
      "tensor([0.2917, 0.4308, 0.2775], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4511778354644775\n",
      "Parameter containing:\n",
      "tensor([ 0.4230, -0.2085, -0.2145], requires_grad=True)\n",
      "tensor([0.2856, 0.4132, 0.3013], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4600253105163574\n",
      "Parameter containing:\n",
      "tensor([ 0.4237, -0.2089, -0.2148], requires_grad=True)\n",
      "tensor([0.3488, 0.3848, 0.2664], grad_fn=<SoftmaxBackward>)\n",
      "output:1.364147424697876\n",
      "Parameter containing:\n",
      "tensor([ 0.4243, -0.2093, -0.2151], requires_grad=True)\n",
      "tensor([0.4512, 0.2628, 0.2859], grad_fn=<SoftmaxBackward>)\n",
      "output:1.217288851737976\n",
      "Parameter containing:\n",
      "tensor([ 0.4250, -0.2096, -0.2154], requires_grad=True)\n",
      "tensor([0.4012, 0.3190, 0.2798], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2872170209884644\n",
      "Parameter containing:\n",
      "tensor([ 0.4257, -0.2100, -0.2157], requires_grad=True)\n",
      "tensor([0.3372, 0.3382, 0.3246], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3805644512176514\n",
      "Parameter containing:\n",
      "tensor([ 0.4264, -0.2103, -0.2161], requires_grad=True)\n",
      "tensor([0.4036, 0.3515, 0.2449], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2843904495239258\n",
      "Parameter containing:\n",
      "tensor([ 0.4271, -0.2107, -0.2163], requires_grad=True)\n",
      "tensor([0.3116, 0.4176, 0.2708], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4205296039581299\n",
      "Parameter containing:\n",
      "tensor([ 0.4277, -0.2111, -0.2166], requires_grad=True)\n",
      "tensor([0.5116, 0.2307, 0.2577], grad_fn=<SoftmaxBackward>)\n",
      "output:1.136786699295044\n",
      "Parameter containing:\n",
      "tensor([ 0.4284, -0.2114, -0.2169], requires_grad=True)\n",
      "tensor([0.4862, 0.2884, 0.2255], grad_fn=<SoftmaxBackward>)\n",
      "output:1.170395016670227\n",
      "Parameter containing:\n",
      "tensor([ 0.4290, -0.2118, -0.2172], requires_grad=True)\n",
      "tensor([0.3264, 0.3376, 0.3360], grad_fn=<SoftmaxBackward>)\n",
      "output:1.396731972694397\n",
      "Parameter containing:\n",
      "tensor([ 0.4297, -0.2121, -0.2175], requires_grad=True)\n",
      "tensor([0.4558, 0.2723, 0.2720], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2110540866851807\n",
      "Parameter containing:\n",
      "tensor([ 0.4304, -0.2125, -0.2179], requires_grad=True)\n",
      "tensor([0.1946, 0.2723, 0.5331], grad_fn=<SoftmaxBackward>)\n",
      "output:1.6094048023223877\n",
      "Parameter containing:\n",
      "tensor([ 0.4309, -0.2126, -0.2182], requires_grad=True)\n",
      "tensor([0.2987, 0.3894, 0.3119], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4393328428268433\n",
      "Parameter containing:\n",
      "tensor([ 0.4315, -0.2130, -0.2185], requires_grad=True)\n",
      "tensor([0.3304, 0.3616, 0.3081], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3909475803375244\n",
      "Parameter containing:\n",
      "tensor([ 0.4322, -0.2134, -0.2188], requires_grad=True)\n",
      "tensor([0.3977, 0.2811, 0.3212], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2921044826507568\n",
      "Parameter containing:\n",
      "tensor([ 0.4329, -0.2137, -0.2192], requires_grad=True)\n",
      "tensor([0.4033, 0.2727, 0.3240], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2842661142349243\n",
      "Parameter containing:\n",
      "tensor([ 0.4336, -0.2140, -0.2196], requires_grad=True)\n",
      "tensor([0.4614, 0.2899, 0.2487], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2035139799118042\n",
      "Parameter containing:\n",
      "tensor([ 0.4342, -0.2144, -0.2199], requires_grad=True)\n",
      "tensor([0.2905, 0.3240, 0.3855], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4518601894378662\n",
      "Parameter containing:\n",
      "tensor([ 0.4349, -0.2146, -0.2202], requires_grad=True)\n",
      "tensor([0.2586, 0.3747, 0.3667], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5015089511871338\n",
      "Parameter containing:\n",
      "tensor([ 0.4355, -0.2150, -0.2205], requires_grad=True)\n",
      "tensor([0.5818, 0.1548, 0.2633], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0487868785858154\n",
      "Parameter containing:\n",
      "tensor([ 0.4361, -0.2152, -0.2209], requires_grad=True)\n",
      "tensor([0.2777, 0.2606, 0.4617], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4739515781402588\n",
      "Parameter containing:\n",
      "tensor([ 0.4367, -0.2154, -0.2213], requires_grad=True)\n",
      "tensor([0.3876, 0.2710, 0.3415], grad_fn=<SoftmaxBackward>)\n",
      "output:1.306910753250122\n",
      "Parameter containing:\n",
      "tensor([ 0.4374, -0.2157, -0.2217], requires_grad=True)\n",
      "tensor([0.3175, 0.3000, 0.3825], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4105983972549438\n",
      "Parameter containing:\n",
      "tensor([ 0.4381, -0.2160, -0.2221], requires_grad=True)\n",
      "tensor([0.4090, 0.3172, 0.2738], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2761621475219727\n",
      "Parameter containing:\n",
      "tensor([ 0.4387, -0.2163, -0.2224], requires_grad=True)\n",
      "tensor([0.3557, 0.2790, 0.3653], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3535466194152832\n",
      "Parameter containing:\n",
      "tensor([ 0.4394, -0.2166, -0.2228], requires_grad=True)\n",
      "tensor([0.4121, 0.2515, 0.3365], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2721314430236816\n",
      "Parameter containing:\n",
      "tensor([ 0.4401, -0.2169, -0.2232], requires_grad=True)\n",
      "tensor([0.3858, 0.3011, 0.3131], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3091837167739868\n",
      "Parameter containing:\n",
      "tensor([ 0.4408, -0.2172, -0.2235], requires_grad=True)\n",
      "tensor([0.4452, 0.3115, 0.2433], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2258539199829102\n",
      "Parameter containing:\n",
      "tensor([ 0.4415, -0.2176, -0.2238], requires_grad=True)\n",
      "tensor([0.3744, 0.2907, 0.3349], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3258185386657715\n",
      "Parameter containing:\n",
      "tensor([ 0.4421, -0.2179, -0.2242], requires_grad=True)\n",
      "tensor([0.3090, 0.3268, 0.3642], grad_fn=<SoftmaxBackward>)\n",
      "output:1.423155665397644\n",
      "Parameter containing:\n",
      "tensor([ 0.4428, -0.2182, -0.2246], requires_grad=True)\n",
      "tensor([0.3054, 0.4404, 0.2542], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4307938814163208\n",
      "Parameter containing:\n",
      "tensor([ 0.4434, -0.2187, -0.2248], requires_grad=True)\n",
      "tensor([0.4950, 0.2554, 0.2497], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1585147380828857\n",
      "Parameter containing:\n",
      "tensor([ 0.4441, -0.2190, -0.2251], requires_grad=True)\n",
      "tensor([0.4320, 0.3189, 0.2491], grad_fn=<SoftmaxBackward>)\n",
      "output:1.244084358215332\n",
      "Parameter containing:\n",
      "tensor([ 0.4448, -0.2194, -0.2254], requires_grad=True)\n",
      "tensor([0.2750, 0.4935, 0.2315], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4799857139587402\n",
      "Parameter containing:\n",
      "tensor([ 0.4454, -0.2198, -0.2256], requires_grad=True)\n",
      "tensor([0.3163, 0.3583, 0.3254], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4120008945465088\n",
      "Parameter containing:\n",
      "tensor([ 0.4461, -0.2202, -0.2259], requires_grad=True)\n",
      "tensor([0.3599, 0.3456, 0.2945], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3469958305358887\n",
      "Parameter containing:\n",
      "tensor([ 0.4468, -0.2206, -0.2262], requires_grad=True)\n",
      "tensor([0.3831, 0.3185, 0.2984], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3130645751953125\n",
      "Parameter containing:\n",
      "tensor([ 0.4474, -0.2209, -0.2265], requires_grad=True)\n",
      "tensor([0.3481, 0.4043, 0.2475], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3657457828521729\n",
      "Parameter containing:\n",
      "tensor([ 0.4481, -0.2213, -0.2268], requires_grad=True)\n",
      "tensor([0.3844, 0.3560, 0.2596], grad_fn=<SoftmaxBackward>)\n",
      "output:1.311728835105896\n",
      "Parameter containing:\n",
      "tensor([ 0.4488, -0.2217, -0.2271], requires_grad=True)\n",
      "tensor([0.4206, 0.2987, 0.2807], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2596569061279297\n",
      "Parameter containing:\n",
      "tensor([ 0.4495, -0.2221, -0.2274], requires_grad=True)\n",
      "tensor([0.3627, 0.3829, 0.2545], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3438210487365723\n",
      "Parameter containing:\n",
      "tensor([ 0.4502, -0.2225, -0.2276], requires_grad=True)\n",
      "tensor([0.3258, 0.3988, 0.2753], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3985400199890137\n",
      "Parameter containing:\n",
      "tensor([ 0.4508, -0.2229, -0.2279], requires_grad=True)\n",
      "tensor([0.3527, 0.3186, 0.3287], grad_fn=<SoftmaxBackward>)\n",
      "output:1.357485294342041\n",
      "Parameter containing:\n",
      "tensor([ 0.4515, -0.2233, -0.2282], requires_grad=True)\n",
      "tensor([0.5329, 0.2812, 0.1859], grad_fn=<SoftmaxBackward>)\n",
      "output:1.109782338142395\n",
      "Parameter containing:\n",
      "tensor([ 0.4521, -0.2236, -0.2285], requires_grad=True)\n",
      "tensor([0.2365, 0.3419, 0.4215], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5371286869049072\n",
      "Parameter containing:\n",
      "tensor([ 0.4527, -0.2239, -0.2288], requires_grad=True)\n",
      "tensor([0.3708, 0.2116, 0.4176], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3335654735565186\n",
      "Parameter containing:\n",
      "tensor([ 0.4534, -0.2241, -0.2293], requires_grad=True)\n",
      "tensor([0.3906, 0.2759, 0.3335], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3024284839630127\n",
      "Parameter containing:\n",
      "tensor([ 0.4541, -0.2244, -0.2297], requires_grad=True)\n",
      "tensor([0.3713, 0.2916, 0.3371], grad_fn=<SoftmaxBackward>)\n",
      "output:1.330237627029419\n",
      "Parameter containing:\n",
      "tensor([ 0.4548, -0.2247, -0.2300], requires_grad=True)\n",
      "tensor([0.3260, 0.3685, 0.3054], grad_fn=<SoftmaxBackward>)\n",
      "output:1.397506833076477\n",
      "Parameter containing:\n",
      "tensor([ 0.4554, -0.2251, -0.2303], requires_grad=True)\n",
      "tensor([0.4102, 0.3378, 0.2519], grad_fn=<SoftmaxBackward>)\n",
      "output:1.274735689163208\n",
      "Parameter containing:\n",
      "tensor([ 0.4561, -0.2255, -0.2306], requires_grad=True)\n",
      "tensor([0.3896, 0.2973, 0.3131], grad_fn=<SoftmaxBackward>)\n",
      "output:1.303682804107666\n",
      "Parameter containing:\n",
      "tensor([ 0.4568, -0.2258, -0.2310], requires_grad=True)\n",
      "tensor([0.3155, 0.3475, 0.3370], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4132845401763916\n",
      "Parameter containing:\n",
      "tensor([ 0.4575, -0.2262, -0.2313], requires_grad=True)\n",
      "tensor([0.3112, 0.4543, 0.2345], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4227335453033447\n",
      "Parameter containing:\n",
      "tensor([ 0.4581, -0.2266, -0.2315], requires_grad=True)\n",
      "tensor([0.3531, 0.3861, 0.2608], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3578273057937622\n",
      "Parameter containing:\n",
      "tensor([ 0.4588, -0.2270, -0.2318], requires_grad=True)\n",
      "tensor([0.3672, 0.2907, 0.3421], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3363054990768433\n",
      "Parameter containing:\n",
      "tensor([ 0.4595, -0.2273, -0.2321], requires_grad=True)\n",
      "tensor([0.3245, 0.2425, 0.4330], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4017868041992188\n",
      "Parameter containing:\n",
      "tensor([ 0.4601, -0.2276, -0.2326], requires_grad=True)\n",
      "tensor([0.3704, 0.3566, 0.2731], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3319413661956787\n",
      "Parameter containing:\n",
      "tensor([ 0.4608, -0.2279, -0.2329], requires_grad=True)\n",
      "tensor([0.4213, 0.3344, 0.2443], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2592287063598633\n",
      "Parameter containing:\n",
      "tensor([ 0.4615, -0.2283, -0.2331], requires_grad=True)\n",
      "tensor([0.3465, 0.1796, 0.4739], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3720219135284424\n",
      "Parameter containing:\n",
      "tensor([ 0.4622, -0.2285, -0.2337], requires_grad=True)\n",
      "tensor([0.2748, 0.3201, 0.4051], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4764736890792847\n",
      "Parameter containing:\n",
      "tensor([ 0.4628, -0.2288, -0.2340], requires_grad=True)\n",
      "tensor([0.2844, 0.3142, 0.4014], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4615027904510498\n",
      "Parameter containing:\n",
      "tensor([ 0.4634, -0.2291, -0.2344], requires_grad=True)\n",
      "tensor([0.3974, 0.3060, 0.2966], grad_fn=<SoftmaxBackward>)\n",
      "output:1.292554497718811\n",
      "Parameter containing:\n",
      "tensor([ 0.4641, -0.2294, -0.2347], requires_grad=True)\n",
      "tensor([0.3611, 0.2694, 0.3695], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3456575870513916\n",
      "Parameter containing:\n",
      "tensor([ 0.4648, -0.2297, -0.2351], requires_grad=True)\n",
      "tensor([0.3567, 0.3919, 0.2514], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3528223037719727\n",
      "Parameter containing:\n",
      "tensor([ 0.4655, -0.2301, -0.2354], requires_grad=True)\n",
      "tensor([0.2322, 0.4123, 0.3555], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5439164638519287\n",
      "Parameter containing:\n",
      "tensor([ 0.4661, -0.2304, -0.2356], requires_grad=True)\n",
      "tensor([0.4351, 0.3019, 0.2630], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2396032810211182\n",
      "Parameter containing:\n",
      "tensor([ 0.4667, -0.2308, -0.2359], requires_grad=True)\n",
      "tensor([0.3451, 0.3523, 0.3026], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3688623905181885\n",
      "Parameter containing:\n",
      "tensor([ 0.4674, -0.2312, -0.2363], requires_grad=True)\n",
      "tensor([0.3379, 0.2708, 0.3913], grad_fn=<SoftmaxBackward>)\n",
      "output:1.380332589149475\n",
      "Parameter containing:\n",
      "tensor([ 0.4681, -0.2314, -0.2367], requires_grad=True)\n",
      "tensor([0.4044, 0.2652, 0.3304], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2828471660614014\n",
      "Parameter containing:\n",
      "tensor([ 0.4688, -0.2317, -0.2370], requires_grad=True)\n",
      "tensor([0.3741, 0.2694, 0.3565], grad_fn=<SoftmaxBackward>)\n",
      "output:1.326533555984497\n",
      "Parameter containing:\n",
      "tensor([ 0.4694, -0.2320, -0.2374], requires_grad=True)\n",
      "tensor([0.3708, 0.3612, 0.2679], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3313791751861572\n",
      "Parameter containing:\n",
      "tensor([ 0.4701, -0.2324, -0.2377], requires_grad=True)\n",
      "tensor([0.3026, 0.3692, 0.3283], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4330979585647583\n",
      "Parameter containing:\n",
      "tensor([ 0.4708, -0.2327, -0.2380], requires_grad=True)\n",
      "tensor([0.4048, 0.3505, 0.2447], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2826461791992188\n",
      "Parameter containing:\n",
      "tensor([ 0.4715, -0.2332, -0.2383], requires_grad=True)\n",
      "tensor([0.4062, 0.3308, 0.2629], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2802104949951172\n",
      "Parameter containing:\n",
      "tensor([ 0.4721, -0.2335, -0.2386], requires_grad=True)\n",
      "tensor([0.3285, 0.2437, 0.4278], grad_fn=<SoftmaxBackward>)\n",
      "output:1.395632028579712\n",
      "Parameter containing:\n",
      "tensor([ 0.4728, -0.2338, -0.2390], requires_grad=True)\n",
      "tensor([0.3849, 0.2808, 0.3342], grad_fn=<SoftmaxBackward>)\n",
      "output:1.310577392578125\n",
      "Parameter containing:\n",
      "tensor([ 0.4735, -0.2341, -0.2394], requires_grad=True)\n",
      "tensor([0.4192, 0.2109, 0.3699], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2631688117980957\n",
      "Parameter containing:\n",
      "tensor([ 0.4742, -0.2343, -0.2399], requires_grad=True)\n",
      "tensor([0.4141, 0.3144, 0.2714], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2688835859298706\n",
      "Parameter containing:\n",
      "tensor([ 0.4749, -0.2347, -0.2402], requires_grad=True)\n",
      "tensor([0.4587, 0.2559, 0.2854], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2071006298065186\n",
      "Parameter containing:\n",
      "tensor([ 0.4755, -0.2350, -0.2405], requires_grad=True)\n",
      "tensor([0.3329, 0.2249, 0.4422], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3899400234222412\n",
      "Parameter containing:\n",
      "tensor([ 0.4762, -0.2352, -0.2410], requires_grad=True)\n",
      "tensor([0.4140, 0.3157, 0.2703], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2690622806549072\n",
      "Parameter containing:\n",
      "tensor([ 0.4769, -0.2356, -0.2413], requires_grad=True)\n",
      "tensor([0.2528, 0.4090, 0.3382], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5110044479370117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.4775, -0.2359, -0.2416], requires_grad=True)\n",
      "tensor([0.3597, 0.4605, 0.1799], grad_fn=<SoftmaxBackward>)\n",
      "output:1.352121353149414\n",
      "Parameter containing:\n",
      "tensor([ 0.4782, -0.2364, -0.2417], requires_grad=True)\n",
      "tensor([0.3363, 0.3920, 0.2718], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3827927112579346\n",
      "Parameter containing:\n",
      "tensor([ 0.4788, -0.2368, -0.2420], requires_grad=True)\n",
      "tensor([0.4100, 0.2360, 0.3540], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2754743099212646\n",
      "Parameter containing:\n",
      "tensor([ 0.4795, -0.2371, -0.2424], requires_grad=True)\n",
      "tensor([0.3620, 0.3327, 0.3053], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3437693119049072\n",
      "Parameter containing:\n",
      "tensor([ 0.4802, -0.2375, -0.2427], requires_grad=True)\n",
      "tensor([0.3769, 0.2586, 0.3645], grad_fn=<SoftmaxBackward>)\n",
      "output:1.322721004486084\n",
      "Parameter containing:\n",
      "tensor([ 0.4809, -0.2377, -0.2432], requires_grad=True)\n",
      "tensor([0.3383, 0.3086, 0.3531], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3789252042770386\n",
      "Parameter containing:\n",
      "tensor([ 0.4816, -0.2380, -0.2435], requires_grad=True)\n",
      "tensor([0.5131, 0.2312, 0.2557], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1348671913146973\n",
      "Parameter containing:\n",
      "tensor([ 0.4822, -0.2384, -0.2439], requires_grad=True)\n",
      "tensor([0.3273, 0.4457, 0.2270], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3984051942825317\n",
      "Parameter containing:\n",
      "tensor([ 0.4829, -0.2388, -0.2441], requires_grad=True)\n",
      "tensor([0.3001, 0.2314, 0.4684], grad_fn=<SoftmaxBackward>)\n",
      "output:1.440220594406128\n",
      "Parameter containing:\n",
      "tensor([ 0.4835, -0.2390, -0.2445], requires_grad=True)\n",
      "tensor([0.1896, 0.1833, 0.6271], grad_fn=<SoftmaxBackward>)\n",
      "output:1.6256093978881836\n",
      "Parameter containing:\n",
      "tensor([ 0.4840, -0.2391, -0.2450], requires_grad=True)\n",
      "tensor([0.3601, 0.3181, 0.3218], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3466051816940308\n",
      "Parameter containing:\n",
      "tensor([ 0.4847, -0.2394, -0.2453], requires_grad=True)\n",
      "tensor([0.3171, 0.3696, 0.3133], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4109516143798828\n",
      "Parameter containing:\n",
      "tensor([ 0.4854, -0.2398, -0.2456], requires_grad=True)\n",
      "tensor([0.2459, 0.2409, 0.5132], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5263642072677612\n",
      "Parameter containing:\n",
      "tensor([ 0.4860, -0.2400, -0.2460], requires_grad=True)\n",
      "tensor([0.3437, 0.4314, 0.2249], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3735268115997314\n",
      "Parameter containing:\n",
      "tensor([ 0.4867, -0.2404, -0.2462], requires_grad=True)\n",
      "tensor([0.4136, 0.2852, 0.3012], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2695221900939941\n",
      "Parameter containing:\n",
      "tensor([ 0.4873, -0.2407, -0.2466], requires_grad=True)\n",
      "tensor([0.3452, 0.3079, 0.3469], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3686132431030273\n",
      "Parameter containing:\n",
      "tensor([ 0.4880, -0.2411, -0.2469], requires_grad=True)\n",
      "tensor([0.3311, 0.3356, 0.3333], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3896872997283936\n",
      "Parameter containing:\n",
      "tensor([ 0.4887, -0.2414, -0.2473], requires_grad=True)\n",
      "tensor([0.4572, 0.2961, 0.2466], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2092089653015137\n",
      "Parameter containing:\n",
      "tensor([ 0.4894, -0.2418, -0.2476], requires_grad=True)\n",
      "tensor([0.4038, 0.2818, 0.3144], grad_fn=<SoftmaxBackward>)\n",
      "output:1.283517837524414\n",
      "Parameter containing:\n",
      "tensor([ 0.4900, -0.2421, -0.2479], requires_grad=True)\n",
      "tensor([0.3280, 0.3499, 0.3220], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3943160772323608\n",
      "Parameter containing:\n",
      "tensor([ 0.4907, -0.2424, -0.2483], requires_grad=True)\n",
      "tensor([0.4477, 0.2505, 0.3018], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2222914695739746\n",
      "Parameter containing:\n",
      "tensor([ 0.4914, -0.2427, -0.2486], requires_grad=True)\n",
      "tensor([0.3532, 0.2857, 0.3611], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3571064472198486\n",
      "Parameter containing:\n",
      "tensor([ 0.4921, -0.2430, -0.2490], requires_grad=True)\n",
      "tensor([0.3012, 0.3267, 0.3720], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4351322650909424\n",
      "Parameter containing:\n",
      "tensor([ 0.4927, -0.2433, -0.2494], requires_grad=True)\n",
      "tensor([0.3611, 0.2958, 0.3431], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3451995849609375\n",
      "Parameter containing:\n",
      "tensor([ 0.4934, -0.2436, -0.2497], requires_grad=True)\n",
      "tensor([0.3406, 0.3979, 0.2615], grad_fn=<SoftmaxBackward>)\n",
      "output:1.376537799835205\n",
      "Parameter containing:\n",
      "tensor([ 0.4940, -0.2441, -0.2500], requires_grad=True)\n",
      "tensor([0.5186, 0.2268, 0.2546], grad_fn=<SoftmaxBackward>)\n",
      "output:1.127740740776062\n",
      "Parameter containing:\n",
      "tensor([ 0.4947, -0.2444, -0.2503], requires_grad=True)\n",
      "tensor([0.3750, 0.3853, 0.2397], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3260738849639893\n",
      "Parameter containing:\n",
      "tensor([ 0.4954, -0.2448, -0.2506], requires_grad=True)\n",
      "tensor([0.4137, 0.3020, 0.2843], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2694334983825684\n",
      "Parameter containing:\n",
      "tensor([ 0.4961, -0.2451, -0.2509], requires_grad=True)\n",
      "tensor([0.2776, 0.3495, 0.3729], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4717419147491455\n",
      "Parameter containing:\n",
      "tensor([ 0.4967, -0.2454, -0.2512], requires_grad=True)\n",
      "tensor([0.2909, 0.3781, 0.3310], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4511053562164307\n",
      "Parameter containing:\n",
      "tensor([ 0.4973, -0.2458, -0.2515], requires_grad=True)\n",
      "tensor([0.2667, 0.2761, 0.4572], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4908136129379272\n",
      "Parameter containing:\n",
      "tensor([ 0.4979, -0.2460, -0.2519], requires_grad=True)\n",
      "tensor([0.3338, 0.3261, 0.3401], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3855719566345215\n",
      "Parameter containing:\n",
      "tensor([ 0.4986, -0.2463, -0.2523], requires_grad=True)\n",
      "tensor([0.3064, 0.3217, 0.3719], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4272974729537964\n",
      "Parameter containing:\n",
      "tensor([ 0.4993, -0.2466, -0.2526], requires_grad=True)\n",
      "tensor([0.2165, 0.5750, 0.2085], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5775892734527588\n",
      "Parameter containing:\n",
      "tensor([ 0.4998, -0.2471, -0.2528], requires_grad=True)\n",
      "tensor([0.4034, 0.3210, 0.2756], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2841036319732666\n",
      "Parameter containing:\n",
      "tensor([ 0.5005, -0.2474, -0.2531], requires_grad=True)\n",
      "tensor([0.2420, 0.4321, 0.3258], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5286586284637451\n",
      "Parameter containing:\n",
      "tensor([ 0.5011, -0.2478, -0.2533], requires_grad=True)\n",
      "tensor([0.3770, 0.3110, 0.3120], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3218257427215576\n",
      "Parameter containing:\n",
      "tensor([ 0.5018, -0.2481, -0.2536], requires_grad=True)\n",
      "tensor([0.3166, 0.3321, 0.3513], grad_fn=<SoftmaxBackward>)\n",
      "output:1.411532998085022\n",
      "Parameter containing:\n",
      "tensor([ 0.5024, -0.2484, -0.2540], requires_grad=True)\n",
      "tensor([0.4250, 0.2940, 0.2810], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2534945011138916\n",
      "Parameter containing:\n",
      "tensor([ 0.5031, -0.2488, -0.2543], requires_grad=True)\n",
      "tensor([0.3500, 0.3152, 0.3348], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3614840507507324\n",
      "Parameter containing:\n",
      "tensor([ 0.5038, -0.2491, -0.2547], requires_grad=True)\n",
      "tensor([0.3498, 0.3328, 0.3174], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3617724180221558\n",
      "Parameter containing:\n",
      "tensor([ 0.5045, -0.2495, -0.2550], requires_grad=True)\n",
      "tensor([0.3453, 0.3595, 0.2952], grad_fn=<SoftmaxBackward>)\n",
      "output:1.368671178817749\n",
      "Parameter containing:\n",
      "tensor([ 0.5051, -0.2498, -0.2553], requires_grad=True)\n",
      "tensor([0.3893, 0.3068, 0.3039], grad_fn=<SoftmaxBackward>)\n",
      "output:1.304107427597046\n",
      "Parameter containing:\n",
      "tensor([ 0.5058, -0.2502, -0.2556], requires_grad=True)\n",
      "tensor([0.3920, 0.3453, 0.2627], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3005919456481934\n",
      "Parameter containing:\n",
      "tensor([ 0.5065, -0.2506, -0.2559], requires_grad=True)\n",
      "tensor([0.3547, 0.2996, 0.3457], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3546169996261597\n",
      "Parameter containing:\n",
      "tensor([ 0.5072, -0.2509, -0.2563], requires_grad=True)\n",
      "tensor([0.3601, 0.3282, 0.3118], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3466360569000244\n",
      "Parameter containing:\n",
      "tensor([ 0.5079, -0.2512, -0.2566], requires_grad=True)\n",
      "tensor([0.3416, 0.3223, 0.3361], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3739899396896362\n",
      "Parameter containing:\n",
      "tensor([ 0.5085, -0.2516, -0.2570], requires_grad=True)\n",
      "tensor([0.4304, 0.3278, 0.2418], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2463927268981934\n",
      "Parameter containing:\n",
      "tensor([ 0.5092, -0.2520, -0.2572], requires_grad=True)\n",
      "tensor([0.3638, 0.3727, 0.2636], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3419196605682373\n",
      "Parameter containing:\n",
      "tensor([ 0.5099, -0.2524, -0.2575], requires_grad=True)\n",
      "tensor([0.3219, 0.3655, 0.3127], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4037494659423828\n",
      "Parameter containing:\n",
      "tensor([ 0.5106, -0.2527, -0.2578], requires_grad=True)\n",
      "tensor([0.4956, 0.2718, 0.2326], grad_fn=<SoftmaxBackward>)\n",
      "output:1.157780408859253\n",
      "Parameter containing:\n",
      "tensor([ 0.5112, -0.2531, -0.2581], requires_grad=True)\n",
      "tensor([0.3680, 0.4177, 0.2143], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3376190662384033\n",
      "Parameter containing:\n",
      "tensor([ 0.5119, -0.2536, -0.2583], requires_grad=True)\n",
      "tensor([0.3123, 0.2913, 0.3964], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4187425374984741\n",
      "Parameter containing:\n",
      "tensor([ 0.5126, -0.2538, -0.2587], requires_grad=True)\n",
      "tensor([0.4514, 0.2890, 0.2596], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2170934677124023\n",
      "Parameter containing:\n",
      "tensor([ 0.5132, -0.2542, -0.2590], requires_grad=True)\n",
      "tensor([0.4039, 0.3276, 0.2685], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2834022045135498\n",
      "Parameter containing:\n",
      "tensor([ 0.5139, -0.2546, -0.2593], requires_grad=True)\n",
      "tensor([0.3186, 0.2909, 0.3905], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4091403484344482\n",
      "Parameter containing:\n",
      "tensor([ 0.5146, -0.2548, -0.2597], requires_grad=True)\n",
      "tensor([0.3394, 0.2444, 0.4162], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3789868354797363\n",
      "Parameter containing:\n",
      "tensor([ 0.5152, -0.2551, -0.2602], requires_grad=True)\n",
      "tensor([0.4886, 0.2697, 0.2417], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1669795513153076\n",
      "Parameter containing:\n",
      "tensor([ 0.5159, -0.2554, -0.2605], requires_grad=True)\n",
      "tensor([0.3221, 0.3364, 0.3415], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4031929969787598\n",
      "Parameter containing:\n",
      "tensor([ 0.5166, -0.2558, -0.2608], requires_grad=True)\n",
      "tensor([0.3557, 0.3707, 0.2736], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3535573482513428\n",
      "Parameter containing:\n",
      "tensor([ 0.5172, -0.2561, -0.2611], requires_grad=True)\n",
      "tensor([0.4516, 0.2409, 0.3075], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2170382738113403\n",
      "Parameter containing:\n",
      "tensor([ 0.5179, -0.2564, -0.2615], requires_grad=True)\n",
      "tensor([0.3167, 0.3132, 0.3701], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4115490913391113\n",
      "Parameter containing:\n",
      "tensor([ 0.5186, -0.2567, -0.2618], requires_grad=True)\n",
      "tensor([0.3843, 0.3426, 0.2731], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3116047382354736\n",
      "Parameter containing:\n",
      "tensor([ 0.5193, -0.2571, -0.2621], requires_grad=True)\n",
      "tensor([0.2975, 0.3921, 0.3105], grad_fn=<SoftmaxBackward>)\n",
      "output:1.441243290901184\n",
      "Parameter containing:\n",
      "tensor([ 0.5199, -0.2575, -0.2624], requires_grad=True)\n",
      "tensor([0.5060, 0.1550, 0.3390], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1460740566253662\n",
      "Parameter containing:\n",
      "tensor([ 0.5206, -0.2577, -0.2629], requires_grad=True)\n",
      "tensor([0.3595, 0.2906, 0.3498], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3475797176361084\n",
      "Parameter containing:\n",
      "tensor([ 0.5212, -0.2580, -0.2633], requires_grad=True)\n",
      "tensor([0.3027, 0.3424, 0.3549], grad_fn=<SoftmaxBackward>)\n",
      "output:1.432805061340332\n",
      "Parameter containing:\n",
      "tensor([ 0.5219, -0.2583, -0.2636], requires_grad=True)\n",
      "tensor([0.3586, 0.3755, 0.2659], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3494468927383423\n",
      "Parameter containing:\n",
      "tensor([ 0.5226, -0.2587, -0.2639], requires_grad=True)\n",
      "tensor([0.3687, 0.3315, 0.2998], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3339588642120361\n",
      "Parameter containing:\n",
      "tensor([ 0.5232, -0.2591, -0.2642], requires_grad=True)\n",
      "tensor([0.3296, 0.3837, 0.2867], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3924285173416138\n",
      "Parameter containing:\n",
      "tensor([ 0.5239, -0.2595, -0.2645], requires_grad=True)\n",
      "tensor([0.4211, 0.2607, 0.3181], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2591259479522705\n",
      "Parameter containing:\n",
      "tensor([ 0.5246, -0.2598, -0.2648], requires_grad=True)\n",
      "tensor([0.3866, 0.2808, 0.3326], grad_fn=<SoftmaxBackward>)\n",
      "output:1.308100938796997\n",
      "Parameter containing:\n",
      "tensor([ 0.5253, -0.2601, -0.2652], requires_grad=True)\n",
      "tensor([0.3423, 0.3040, 0.3537], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3730719089508057\n",
      "Parameter containing:\n",
      "tensor([ 0.5260, -0.2604, -0.2656], requires_grad=True)\n",
      "tensor([0.3871, 0.3708, 0.2420], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3082407712936401\n",
      "Parameter containing:\n",
      "tensor([ 0.5266, -0.2608, -0.2658], requires_grad=True)\n",
      "tensor([0.3706, 0.3422, 0.2872], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3313944339752197\n",
      "Parameter containing:\n",
      "tensor([ 0.5273, -0.2612, -0.2661], requires_grad=True)\n",
      "tensor([0.5032, 0.3473, 0.1495], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1500482559204102\n",
      "Parameter containing:\n",
      "tensor([ 0.5280, -0.2616, -0.2663], requires_grad=True)\n",
      "tensor([0.2828, 0.3076, 0.4096], grad_fn=<SoftmaxBackward>)\n",
      "output:1.464172124862671\n",
      "Parameter containing:\n",
      "tensor([ 0.5286, -0.2619, -0.2667], requires_grad=True)\n",
      "tensor([0.3429, 0.3037, 0.3533], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3720769882202148\n",
      "Parameter containing:\n",
      "tensor([ 0.5293, -0.2622, -0.2671], requires_grad=True)\n",
      "tensor([0.3844, 0.2798, 0.3358], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3113723993301392\n",
      "Parameter containing:\n",
      "tensor([ 0.5300, -0.2625, -0.2674], requires_grad=True)\n",
      "tensor([0.2939, 0.5010, 0.2051], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4518349170684814\n",
      "Parameter containing:\n",
      "tensor([ 0.5306, -0.2630, -0.2676], requires_grad=True)\n",
      "tensor([0.3573, 0.2741, 0.3687], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3512768745422363\n",
      "Parameter containing:\n",
      "tensor([ 0.5313, -0.2633, -0.2680], requires_grad=True)\n",
      "tensor([0.3952, 0.3389, 0.2660], grad_fn=<SoftmaxBackward>)\n",
      "output:1.295997142791748\n",
      "Parameter containing:\n",
      "tensor([ 0.5320, -0.2637, -0.2683], requires_grad=True)\n",
      "tensor([0.4317, 0.2944, 0.2739], grad_fn=<SoftmaxBackward>)\n",
      "output:1.244248628616333\n",
      "Parameter containing:\n",
      "tensor([ 0.5327, -0.2640, -0.2686], requires_grad=True)\n",
      "tensor([0.3342, 0.4025, 0.2633], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3861724138259888\n",
      "Parameter containing:\n",
      "tensor([ 0.5333, -0.2644, -0.2689], requires_grad=True)\n",
      "tensor([0.2761, 0.3146, 0.4093], grad_fn=<SoftmaxBackward>)\n",
      "output:1.474522590637207\n",
      "Parameter containing:\n",
      "tensor([ 0.5339, -0.2647, -0.2692], requires_grad=True)\n",
      "tensor([0.3424, 0.3198, 0.3378], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3727667331695557\n",
      "Parameter containing:\n",
      "tensor([ 0.5346, -0.2650, -0.2696], requires_grad=True)\n",
      "tensor([0.4277, 0.3313, 0.2410], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2502375841140747\n",
      "Parameter containing:\n",
      "tensor([ 0.5353, -0.2654, -0.2699], requires_grad=True)\n",
      "tensor([0.3163, 0.2338, 0.4500], grad_fn=<SoftmaxBackward>)\n",
      "output:1.414949655532837\n",
      "Parameter containing:\n",
      "tensor([ 0.5360, -0.2656, -0.2703], requires_grad=True)\n",
      "tensor([0.2676, 0.3798, 0.3526], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4873881340026855\n",
      "Parameter containing:\n",
      "tensor([ 0.5366, -0.2660, -0.2706], requires_grad=True)\n",
      "tensor([0.4431, 0.2470, 0.3099], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2286224365234375\n",
      "Parameter containing:\n",
      "tensor([ 0.5373, -0.2663, -0.2710], requires_grad=True)\n",
      "tensor([0.4737, 0.2857, 0.2406], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1868996620178223\n",
      "Parameter containing:\n",
      "tensor([ 0.5379, -0.2666, -0.2713], requires_grad=True)\n",
      "tensor([0.3456, 0.2875, 0.3669], grad_fn=<SoftmaxBackward>)\n",
      "output:1.368316411972046\n",
      "Parameter containing:\n",
      "tensor([ 0.5386, -0.2669, -0.2717], requires_grad=True)\n",
      "tensor([0.3187, 0.3323, 0.3489], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4083360433578491\n",
      "Parameter containing:\n",
      "tensor([ 0.5393, -0.2672, -0.2720], requires_grad=True)\n",
      "tensor([0.3821, 0.2366, 0.3812], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3157273530960083\n",
      "Parameter containing:\n",
      "tensor([ 0.5399, -0.2675, -0.2725], requires_grad=True)\n",
      "tensor([0.3414, 0.3715, 0.2871], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3746508359909058\n",
      "Parameter containing:\n",
      "tensor([ 0.5406, -0.2679, -0.2727], requires_grad=True)\n",
      "tensor([0.2922, 0.3766, 0.3312], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4491362571716309\n",
      "Parameter containing:\n",
      "tensor([ 0.5413, -0.2682, -0.2730], requires_grad=True)\n",
      "tensor([0.3739, 0.2872, 0.3389], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3264708518981934\n",
      "Parameter containing:\n",
      "tensor([ 0.5419, -0.2685, -0.2734], requires_grad=True)\n",
      "tensor([0.3193, 0.3590, 0.3217], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4075500965118408\n",
      "Parameter containing:\n",
      "tensor([ 0.5426, -0.2689, -0.2737], requires_grad=True)\n",
      "tensor([0.5349, 0.2604, 0.2046], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1068570613861084\n",
      "Parameter containing:\n",
      "tensor([ 0.5432, -0.2692, -0.2740], requires_grad=True)\n",
      "tensor([0.3861, 0.3107, 0.3031], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3087003231048584\n",
      "Parameter containing:\n",
      "tensor([ 0.5439, -0.2696, -0.2743], requires_grad=True)\n",
      "tensor([0.4213, 0.2694, 0.3094], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2588163614273071\n",
      "Parameter containing:\n",
      "tensor([ 0.5446, -0.2699, -0.2747], requires_grad=True)\n",
      "tensor([0.2598, 0.3187, 0.4215], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5002875328063965\n",
      "Parameter containing:\n",
      "tensor([ 0.5452, -0.2702, -0.2751], requires_grad=True)\n",
      "tensor([0.4176, 0.3004, 0.2819], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2638682126998901\n",
      "Parameter containing:\n",
      "tensor([ 0.5459, -0.2705, -0.2754], requires_grad=True)\n",
      "tensor([0.2299, 0.3796, 0.3904], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5474541187286377\n",
      "Parameter containing:\n",
      "tensor([ 0.5465, -0.2708, -0.2757], requires_grad=True)\n",
      "tensor([0.3791, 0.2649, 0.3560], grad_fn=<SoftmaxBackward>)\n",
      "output:1.319303035736084\n",
      "Parameter containing:\n",
      "tensor([ 0.5471, -0.2711, -0.2761], requires_grad=True)\n",
      "tensor([0.3661, 0.3246, 0.3094], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3378205299377441\n",
      "Parameter containing:\n",
      "tensor([ 0.5478, -0.2714, -0.2764], requires_grad=True)\n",
      "tensor([0.3377, 0.3122, 0.3501], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3799024820327759\n",
      "Parameter containing:\n",
      "tensor([ 0.5485, -0.2717, -0.2768], requires_grad=True)\n",
      "tensor([0.3453, 0.2958, 0.3589], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3686676025390625\n",
      "Parameter containing:\n",
      "tensor([ 0.5492, -0.2720, -0.2771], requires_grad=True)\n",
      "tensor([0.3986, 0.2658, 0.3356], grad_fn=<SoftmaxBackward>)\n",
      "output:1.291039228439331\n",
      "Parameter containing:\n",
      "tensor([ 0.5499, -0.2723, -0.2775], requires_grad=True)\n",
      "tensor([0.3801, 0.2842, 0.3357], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3175127506256104\n",
      "Parameter containing:\n",
      "tensor([ 0.5505, -0.2726, -0.2779], requires_grad=True)\n",
      "tensor([0.3029, 0.3626, 0.3345], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4324634075164795\n",
      "Parameter containing:\n",
      "tensor([ 0.5512, -0.2730, -0.2782], requires_grad=True)\n",
      "tensor([0.3424, 0.3849, 0.2727], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3735564947128296\n",
      "Parameter containing:\n",
      "tensor([ 0.5519, -0.2734, -0.2785], requires_grad=True)\n",
      "tensor([0.4665, 0.2898, 0.2437], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1965816020965576\n",
      "Parameter containing:\n",
      "tensor([ 0.5525, -0.2737, -0.2788], requires_grad=True)\n",
      "tensor([0.4198, 0.1308, 0.4494], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2671763896942139\n",
      "Parameter containing:\n",
      "tensor([ 0.5532, -0.2739, -0.2793], requires_grad=True)\n",
      "tensor([0.4106, 0.3856, 0.2038], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2757596969604492\n",
      "Parameter containing:\n",
      "tensor([ 0.5539, -0.2744, -0.2796], requires_grad=True)\n",
      "tensor([0.3421, 0.2691, 0.3888], grad_fn=<SoftmaxBackward>)\n",
      "output:1.374068260192871\n",
      "Parameter containing:\n",
      "tensor([ 0.5546, -0.2746, -0.2800], requires_grad=True)\n",
      "tensor([0.3443, 0.2803, 0.3754], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3704578876495361\n",
      "Parameter containing:\n",
      "tensor([ 0.5553, -0.2749, -0.2804], requires_grad=True)\n",
      "tensor([0.3767, 0.3653, 0.2580], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3230223655700684\n",
      "Parameter containing:\n",
      "tensor([ 0.5559, -0.2753, -0.2806], requires_grad=True)\n",
      "tensor([0.3984, 0.3071, 0.2945], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2910666465759277\n",
      "Parameter containing:\n",
      "tensor([ 0.5566, -0.2757, -0.2810], requires_grad=True)\n",
      "tensor([0.1555, 0.7065, 0.1380], grad_fn=<SoftmaxBackward>)\n",
      "output:1.6906392574310303\n",
      "Parameter containing:\n",
      "tensor([ 0.5571, -0.2761, -0.2810], requires_grad=True)\n",
      "tensor([0.3461, 0.2562, 0.3977], grad_fn=<SoftmaxBackward>)\n",
      "output:1.368516206741333\n",
      "Parameter containing:\n",
      "tensor([ 0.5578, -0.2763, -0.2814], requires_grad=True)\n",
      "tensor([0.2759, 0.3947, 0.3294], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4745149612426758\n",
      "Parameter containing:\n",
      "tensor([ 0.5584, -0.2767, -0.2817], requires_grad=True)\n",
      "tensor([0.4555, 0.3007, 0.2438], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2116875648498535\n",
      "Parameter containing:\n",
      "tensor([ 0.5591, -0.2770, -0.2820], requires_grad=True)\n",
      "tensor([0.4324, 0.3062, 0.2615], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2434000968933105\n",
      "Parameter containing:\n",
      "tensor([ 0.5597, -0.2774, -0.2823], requires_grad=True)\n",
      "tensor([0.3984, 0.3713, 0.2303], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2923738956451416\n",
      "Parameter containing:\n",
      "tensor([ 0.5604, -0.2779, -0.2826], requires_grad=True)\n",
      "tensor([0.4218, 0.3056, 0.2726], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2579946517944336\n",
      "Parameter containing:\n",
      "tensor([ 0.5611, -0.2782, -0.2829], requires_grad=True)\n",
      "tensor([0.2766, 0.1950, 0.5284], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4801013469696045\n",
      "Parameter containing:\n",
      "tensor([ 0.5617, -0.2784, -0.2834], requires_grad=True)\n",
      "tensor([0.3597, 0.2689, 0.3715], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3478376865386963\n",
      "Parameter containing:\n",
      "tensor([ 0.5624, -0.2786, -0.2838], requires_grad=True)\n",
      "tensor([0.3125, 0.4132, 0.2742], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4189627170562744\n",
      "Parameter containing:\n",
      "tensor([ 0.5631, -0.2790, -0.2840], requires_grad=True)\n",
      "tensor([0.3207, 0.2705, 0.4088], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4065918922424316\n",
      "Parameter containing:\n",
      "tensor([ 0.5637, -0.2793, -0.2844], requires_grad=True)\n",
      "tensor([0.3512, 0.2767, 0.3721], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3602252006530762\n",
      "Parameter containing:\n",
      "tensor([ 0.5644, -0.2796, -0.2848], requires_grad=True)\n",
      "tensor([0.4082, 0.2645, 0.3273], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2774384021759033\n",
      "Parameter containing:\n",
      "tensor([ 0.5651, -0.2799, -0.2852], requires_grad=True)\n",
      "tensor([0.3669, 0.3393, 0.2938], grad_fn=<SoftmaxBackward>)\n",
      "output:1.33663809299469\n",
      "Parameter containing:\n",
      "tensor([ 0.5658, -0.2802, -0.2855], requires_grad=True)\n",
      "tensor([0.3611, 0.3291, 0.3099], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3451274633407593\n",
      "Parameter containing:\n",
      "tensor([ 0.5664, -0.2806, -0.2859], requires_grad=True)\n",
      "tensor([0.5625, 0.2339, 0.2036], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0719897747039795\n",
      "Parameter containing:\n",
      "tensor([ 0.5671, -0.2809, -0.2861], requires_grad=True)\n",
      "tensor([0.3615, 0.3063, 0.3323], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3445481061935425\n",
      "Parameter containing:\n",
      "tensor([ 0.5677, -0.2812, -0.2865], requires_grad=True)\n",
      "tensor([0.3581, 0.3531, 0.2888], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3497047424316406\n",
      "Parameter containing:\n",
      "tensor([ 0.5684, -0.2816, -0.2868], requires_grad=True)\n",
      "tensor([0.3500, 0.3303, 0.3198], grad_fn=<SoftmaxBackward>)\n",
      "output:1.361523151397705\n",
      "Parameter containing:\n",
      "tensor([ 0.5691, -0.2820, -0.2871], requires_grad=True)\n",
      "tensor([0.3224, 0.3454, 0.3322], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4027283191680908\n",
      "Parameter containing:\n",
      "tensor([ 0.5698, -0.2823, -0.2874], requires_grad=True)\n",
      "tensor([0.3747, 0.2597, 0.3656], grad_fn=<SoftmaxBackward>)\n",
      "output:1.32597017288208\n",
      "Parameter containing:\n",
      "tensor([ 0.5704, -0.2826, -0.2879], requires_grad=True)\n",
      "tensor([0.2957, 0.4939, 0.2104], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4486191272735596\n",
      "Parameter containing:\n",
      "tensor([ 0.5711, -0.2831, -0.2880], requires_grad=True)\n",
      "tensor([0.3813, 0.2915, 0.3271], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3156466484069824\n",
      "Parameter containing:\n",
      "tensor([ 0.5718, -0.2834, -0.2884], requires_grad=True)\n",
      "tensor([0.3722, 0.2935, 0.3343], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3289557695388794\n",
      "Parameter containing:\n",
      "tensor([ 0.5724, -0.2837, -0.2888], requires_grad=True)\n",
      "tensor([0.4443, 0.2791, 0.2766], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2267441749572754\n",
      "Parameter containing:\n",
      "tensor([ 0.5731, -0.2840, -0.2891], requires_grad=True)\n",
      "tensor([0.3422, 0.2868, 0.3710], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3734550476074219\n",
      "Parameter containing:\n",
      "tensor([ 0.5738, -0.2843, -0.2895], requires_grad=True)\n",
      "tensor([0.3172, 0.4402, 0.2426], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4131067991256714\n",
      "Parameter containing:\n",
      "tensor([ 0.5745, -0.2848, -0.2897], requires_grad=True)\n",
      "tensor([0.3149, 0.3076, 0.3776], grad_fn=<SoftmaxBackward>)\n",
      "output:1.414513349533081\n",
      "Parameter containing:\n",
      "tensor([ 0.5751, -0.2850, -0.2901], requires_grad=True)\n",
      "tensor([0.3505, 0.3553, 0.2943], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3610063791275024\n",
      "Parameter containing:\n",
      "tensor([ 0.5758, -0.2854, -0.2904], requires_grad=True)\n",
      "tensor([0.3803, 0.1913, 0.4284], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3205478191375732\n",
      "Parameter containing:\n",
      "tensor([ 0.5765, -0.2856, -0.2909], requires_grad=True)\n",
      "tensor([0.4742, 0.2611, 0.2647], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1861071586608887\n",
      "Parameter containing:\n",
      "tensor([ 0.5771, -0.2860, -0.2912], requires_grad=True)\n",
      "tensor([0.2923, 0.2404, 0.4673], grad_fn=<SoftmaxBackward>)\n",
      "output:1.452040433883667\n",
      "Parameter containing:\n",
      "tensor([ 0.5778, -0.2862, -0.2916], requires_grad=True)\n",
      "tensor([0.3929, 0.3590, 0.2482], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2997746467590332\n",
      "Parameter containing:\n",
      "tensor([ 0.5785, -0.2866, -0.2919], requires_grad=True)\n",
      "tensor([0.2720, 0.3152, 0.4128], grad_fn=<SoftmaxBackward>)\n",
      "output:1.481032371520996\n",
      "Parameter containing:\n",
      "tensor([ 0.5791, -0.2868, -0.2923], requires_grad=True)\n",
      "tensor([0.2469, 0.2377, 0.5154], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:1.5250056982040405\n",
      "Parameter containing:\n",
      "tensor([ 0.5797, -0.2870, -0.2927], requires_grad=True)\n",
      "tensor([0.3097, 0.4104, 0.2799], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4231470823287964\n",
      "Parameter containing:\n",
      "tensor([ 0.5803, -0.2874, -0.2930], requires_grad=True)\n",
      "tensor([0.4152, 0.2551, 0.3298], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2676773071289062\n",
      "Parameter containing:\n",
      "tensor([ 0.5810, -0.2877, -0.2933], requires_grad=True)\n",
      "tensor([0.4610, 0.2886, 0.2504], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2040953636169434\n",
      "Parameter containing:\n",
      "tensor([ 0.5817, -0.2880, -0.2937], requires_grad=True)\n",
      "tensor([0.4186, 0.3041, 0.2773], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2625433206558228\n",
      "Parameter containing:\n",
      "tensor([ 0.5824, -0.2884, -0.2940], requires_grad=True)\n",
      "tensor([0.5400, 0.2677, 0.1923], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1005544662475586\n",
      "Parameter containing:\n",
      "tensor([ 0.5830, -0.2888, -0.2942], requires_grad=True)\n",
      "tensor([0.4404, 0.2790, 0.2806], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2321045398712158\n",
      "Parameter containing:\n",
      "tensor([ 0.5837, -0.2891, -0.2946], requires_grad=True)\n",
      "tensor([0.4243, 0.3211, 0.2546], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2548372745513916\n",
      "Parameter containing:\n",
      "tensor([ 0.5844, -0.2895, -0.2949], requires_grad=True)\n",
      "tensor([0.3714, 0.2588, 0.3698], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3307712078094482\n",
      "Parameter containing:\n",
      "tensor([ 0.5851, -0.2898, -0.2953], requires_grad=True)\n",
      "tensor([0.4068, 0.2449, 0.3482], grad_fn=<SoftmaxBackward>)\n",
      "output:1.279740571975708\n",
      "Parameter containing:\n",
      "tensor([ 0.5858, -0.2901, -0.2957], requires_grad=True)\n",
      "tensor([0.3254, 0.4191, 0.2554], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3998358249664307\n",
      "Parameter containing:\n",
      "tensor([ 0.5864, -0.2905, -0.2959], requires_grad=True)\n",
      "tensor([0.2934, 0.3184, 0.3882], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4474291801452637\n",
      "Parameter containing:\n",
      "tensor([ 0.5871, -0.2908, -0.2963], requires_grad=True)\n",
      "tensor([0.2929, 0.3898, 0.3174], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4482557773590088\n",
      "Parameter containing:\n",
      "tensor([ 0.5877, -0.2911, -0.2966], requires_grad=True)\n",
      "tensor([0.2444, 0.4139, 0.3418], grad_fn=<SoftmaxBackward>)\n",
      "output:1.524505615234375\n",
      "Parameter containing:\n",
      "tensor([ 0.5883, -0.2915, -0.2968], requires_grad=True)\n",
      "tensor([0.4196, 0.2719, 0.3084], grad_fn=<SoftmaxBackward>)\n",
      "output:1.261094331741333\n",
      "Parameter containing:\n",
      "tensor([ 0.5890, -0.2918, -0.2972], requires_grad=True)\n",
      "tensor([0.2332, 0.4536, 0.3133], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5434281826019287\n",
      "Parameter containing:\n",
      "tensor([ 0.5895, -0.2921, -0.2974], requires_grad=True)\n",
      "tensor([0.4039, 0.2459, 0.3502], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2839787006378174\n",
      "Parameter containing:\n",
      "tensor([ 0.5902, -0.2924, -0.2978], requires_grad=True)\n",
      "tensor([0.3480, 0.2820, 0.3701], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3649706840515137\n",
      "Parameter containing:\n",
      "tensor([ 0.5909, -0.2927, -0.2982], requires_grad=True)\n",
      "tensor([0.4486, 0.3019, 0.2495], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2210803031921387\n",
      "Parameter containing:\n",
      "tensor([ 0.5916, -0.2931, -0.2985], requires_grad=True)\n",
      "tensor([0.3988, 0.3232, 0.2780], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2906711101531982\n",
      "Parameter containing:\n",
      "tensor([ 0.5923, -0.2934, -0.2988], requires_grad=True)\n",
      "tensor([0.4577, 0.2391, 0.3032], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2086442708969116\n",
      "Parameter containing:\n",
      "tensor([ 0.5929, -0.2937, -0.2992], requires_grad=True)\n",
      "tensor([0.3597, 0.3713, 0.2690], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3478130102157593\n",
      "Parameter containing:\n",
      "tensor([ 0.5936, -0.2941, -0.2995], requires_grad=True)\n",
      "tensor([0.3698, 0.3900, 0.2402], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3337407112121582\n",
      "Parameter containing:\n",
      "tensor([ 0.5943, -0.2946, -0.2998], requires_grad=True)\n",
      "tensor([0.3796, 0.3628, 0.2576], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3188514709472656\n",
      "Parameter containing:\n",
      "tensor([ 0.5950, -0.2950, -0.3000], requires_grad=True)\n",
      "tensor([0.5752, 0.1899, 0.2350], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0564005374908447\n",
      "Parameter containing:\n",
      "tensor([ 0.5956, -0.2952, -0.3004], requires_grad=True)\n",
      "tensor([0.4720, 0.2525, 0.2756], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1891546249389648\n",
      "Parameter containing:\n",
      "tensor([ 0.5963, -0.2955, -0.3007], requires_grad=True)\n",
      "tensor([0.5379, 0.2363, 0.2258], grad_fn=<SoftmaxBackward>)\n",
      "output:1.102898359298706\n",
      "Parameter containing:\n",
      "tensor([ 0.5969, -0.2959, -0.3010], requires_grad=True)\n",
      "tensor([0.3893, 0.3419, 0.2688], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3044540882110596\n",
      "Parameter containing:\n",
      "tensor([ 0.5976, -0.2963, -0.3013], requires_grad=True)\n",
      "tensor([0.4412, 0.1159, 0.4430], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2377123832702637\n",
      "Parameter containing:\n",
      "tensor([ 0.5983, -0.2964, -0.3019], requires_grad=True)\n",
      "tensor([0.4542, 0.2831, 0.2627], grad_fn=<SoftmaxBackward>)\n",
      "output:1.213222861289978\n",
      "Parameter containing:\n",
      "tensor([ 0.5989, -0.2967, -0.3022], requires_grad=True)\n",
      "tensor([0.3033, 0.2710, 0.4257], grad_fn=<SoftmaxBackward>)\n",
      "output:1.433309555053711\n",
      "Parameter containing:\n",
      "tensor([ 0.5996, -0.2970, -0.3026], requires_grad=True)\n",
      "tensor([0.4443, 0.3385, 0.2173], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2277145385742188\n",
      "Parameter containing:\n",
      "tensor([ 0.6003, -0.2974, -0.3029], requires_grad=True)\n",
      "tensor([0.2702, 0.3708, 0.3590], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4832894802093506\n",
      "Parameter containing:\n",
      "tensor([ 0.6009, -0.2977, -0.3032], requires_grad=True)\n",
      "tensor([0.3355, 0.2831, 0.3813], grad_fn=<SoftmaxBackward>)\n",
      "output:1.383611798286438\n",
      "Parameter containing:\n",
      "tensor([ 0.6016, -0.2980, -0.3036], requires_grad=True)\n",
      "tensor([0.4161, 0.2546, 0.3293], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2663438320159912\n",
      "Parameter containing:\n",
      "tensor([ 0.6023, -0.2983, -0.3040], requires_grad=True)\n",
      "tensor([0.4306, 0.2760, 0.2935], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2457938194274902\n",
      "Parameter containing:\n",
      "tensor([ 0.6029, -0.2986, -0.3043], requires_grad=True)\n",
      "tensor([0.6188, 0.1739, 0.2073], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0036377906799316\n",
      "Parameter containing:\n",
      "tensor([ 0.6035, -0.2989, -0.3046], requires_grad=True)\n",
      "tensor([0.3948, 0.3174, 0.2878], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2962610721588135\n",
      "Parameter containing:\n",
      "tensor([ 0.6042, -0.2992, -0.3049], requires_grad=True)\n",
      "tensor([0.3761, 0.3262, 0.2977], grad_fn=<SoftmaxBackward>)\n",
      "output:1.323293685913086\n",
      "Parameter containing:\n",
      "tensor([ 0.6049, -0.2996, -0.3053], requires_grad=True)\n",
      "tensor([0.4045, 0.2276, 0.3679], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2836716175079346\n",
      "Parameter containing:\n",
      "tensor([ 0.6055, -0.2998, -0.3057], requires_grad=True)\n",
      "tensor([0.2819, 0.3905, 0.3276], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4651802778244019\n",
      "Parameter containing:\n",
      "tensor([ 0.6062, -0.3002, -0.3060], requires_grad=True)\n",
      "tensor([0.4078, 0.2983, 0.2939], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2776888608932495\n",
      "Parameter containing:\n",
      "tensor([ 0.6069, -0.3005, -0.3063], requires_grad=True)\n",
      "tensor([0.4116, 0.3042, 0.2843], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2723785638809204\n",
      "Parameter containing:\n",
      "tensor([ 0.6075, -0.3009, -0.3066], requires_grad=True)\n",
      "tensor([0.6519, 0.1726, 0.1755], grad_fn=<SoftmaxBackward>)\n",
      "output:0.9650008082389832\n",
      "Parameter containing:\n",
      "tensor([ 0.6081, -0.3012, -0.3069], requires_grad=True)\n",
      "tensor([0.5753, 0.2250, 0.1997], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0561580657958984\n",
      "Parameter containing:\n",
      "tensor([ 0.6087, -0.3015, -0.3072], requires_grad=True)\n",
      "tensor([0.3740, 0.2732, 0.3529], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3266780376434326\n",
      "Parameter containing:\n",
      "tensor([ 0.6093, -0.3018, -0.3076], requires_grad=True)\n",
      "tensor([0.3289, 0.2848, 0.3863], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3936060667037964\n",
      "Parameter containing:\n",
      "tensor([ 0.6100, -0.3020, -0.3080], requires_grad=True)\n",
      "tensor([0.5363, 0.2543, 0.2094], grad_fn=<SoftmaxBackward>)\n",
      "output:1.105057954788208\n",
      "Parameter containing:\n",
      "tensor([ 0.6106, -0.3024, -0.3083], requires_grad=True)\n",
      "tensor([0.3671, 0.3605, 0.2725], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3367993831634521\n",
      "Parameter containing:\n",
      "tensor([ 0.6113, -0.3028, -0.3085], requires_grad=True)\n",
      "tensor([0.2737, 0.2531, 0.4732], grad_fn=<SoftmaxBackward>)\n",
      "output:1.480749249458313\n",
      "Parameter containing:\n",
      "tensor([ 0.6120, -0.3030, -0.3090], requires_grad=True)\n",
      "tensor([0.4595, 0.2325, 0.3079], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2062952518463135\n",
      "Parameter containing:\n",
      "tensor([ 0.6126, -0.3033, -0.3094], requires_grad=True)\n",
      "tensor([0.3480, 0.2590, 0.3930], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3655939102172852\n",
      "Parameter containing:\n",
      "tensor([ 0.6133, -0.3035, -0.3098], requires_grad=True)\n",
      "tensor([0.3337, 0.3067, 0.3596], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3858551979064941\n",
      "Parameter containing:\n",
      "tensor([ 0.6140, -0.3038, -0.3101], requires_grad=True)\n",
      "tensor([0.3626, 0.4093, 0.2281], grad_fn=<SoftmaxBackward>)\n",
      "output:1.344992995262146\n",
      "Parameter containing:\n",
      "tensor([ 0.6146, -0.3043, -0.3104], requires_grad=True)\n",
      "tensor([0.3440, 0.3456, 0.3104], grad_fn=<SoftmaxBackward>)\n",
      "output:1.370424509048462\n",
      "Parameter containing:\n",
      "tensor([ 0.6153, -0.3046, -0.3107], requires_grad=True)\n",
      "tensor([0.3591, 0.3555, 0.2854], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3483208417892456\n",
      "Parameter containing:\n",
      "tensor([ 0.6160, -0.3050, -0.3110], requires_grad=True)\n",
      "tensor([0.3407, 0.3666, 0.2927], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3756572008132935\n",
      "Parameter containing:\n",
      "tensor([ 0.6167, -0.3054, -0.3113], requires_grad=True)\n",
      "tensor([0.3500, 0.3437, 0.3062], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3614646196365356\n",
      "Parameter containing:\n",
      "tensor([ 0.6173, -0.3058, -0.3116], requires_grad=True)\n",
      "tensor([0.4096, 0.3163, 0.2741], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2752209901809692\n",
      "Parameter containing:\n",
      "tensor([ 0.6180, -0.3061, -0.3119], requires_grad=True)\n",
      "tensor([0.3661, 0.3465, 0.2873], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3379206657409668\n",
      "Parameter containing:\n",
      "tensor([ 0.6187, -0.3065, -0.3122], requires_grad=True)\n",
      "tensor([0.3187, 0.3745, 0.3068], grad_fn=<SoftmaxBackward>)\n",
      "output:1.408579707145691\n",
      "Parameter containing:\n",
      "tensor([ 0.6194, -0.3069, -0.3125], requires_grad=True)\n",
      "tensor([0.2499, 0.5310, 0.2191], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5213894844055176\n",
      "Parameter containing:\n",
      "tensor([ 0.6200, -0.3073, -0.3126], requires_grad=True)\n",
      "tensor([0.2175, 0.2570, 0.5256], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5721008777618408\n",
      "Parameter containing:\n",
      "tensor([ 0.6205, -0.3075, -0.3130], requires_grad=True)\n",
      "tensor([0.4121, 0.2391, 0.3488], grad_fn=<SoftmaxBackward>)\n",
      "output:1.272341012954712\n",
      "Parameter containing:\n",
      "tensor([ 0.6212, -0.3078, -0.3135], requires_grad=True)\n",
      "tensor([0.3223, 0.2625, 0.4152], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4044101238250732\n",
      "Parameter containing:\n",
      "tensor([ 0.6219, -0.3080, -0.3139], requires_grad=True)\n",
      "tensor([0.4126, 0.3067, 0.2807], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2709660530090332\n",
      "Parameter containing:\n",
      "tensor([ 0.6226, -0.3084, -0.3142], requires_grad=True)\n",
      "tensor([0.2392, 0.3558, 0.4049], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5325815677642822\n",
      "Parameter containing:\n",
      "tensor([ 0.6231, -0.3086, -0.3145], requires_grad=True)\n",
      "tensor([0.3133, 0.3522, 0.3346], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4166467189788818\n",
      "Parameter containing:\n",
      "tensor([ 0.6238, -0.3090, -0.3148], requires_grad=True)\n",
      "tensor([0.5455, 0.1850, 0.2695], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0937232971191406\n",
      "Parameter containing:\n",
      "tensor([ 0.6244, -0.3092, -0.3152], requires_grad=True)\n",
      "tensor([0.3772, 0.2725, 0.3503], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3219661712646484\n",
      "Parameter containing:\n",
      "tensor([ 0.6251, -0.3095, -0.3156], requires_grad=True)\n",
      "tensor([0.3554, 0.4237, 0.2209], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3560587167739868\n",
      "Parameter containing:\n",
      "tensor([ 0.6258, -0.3100, -0.3158], requires_grad=True)\n",
      "tensor([0.4250, 0.2787, 0.2963], grad_fn=<SoftmaxBackward>)\n",
      "output:1.253575325012207\n",
      "Parameter containing:\n",
      "tensor([ 0.6265, -0.3103, -0.3162], requires_grad=True)\n",
      "tensor([0.3759, 0.3138, 0.3103], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3234732151031494\n",
      "Parameter containing:\n",
      "tensor([ 0.6272, -0.3106, -0.3165], requires_grad=True)\n",
      "tensor([0.2962, 0.2900, 0.4139], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4437685012817383\n",
      "Parameter containing:\n",
      "tensor([ 0.6278, -0.3109, -0.3169], requires_grad=True)\n",
      "tensor([0.5064, 0.2746, 0.2190], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1436316967010498\n",
      "Parameter containing:\n",
      "tensor([ 0.6284, -0.3113, -0.3172], requires_grad=True)\n",
      "tensor([0.3515, 0.3954, 0.2531], grad_fn=<SoftmaxBackward>)\n",
      "output:1.360472321510315\n",
      "Parameter containing:\n",
      "tensor([ 0.6291, -0.3117, -0.3174], requires_grad=True)\n",
      "tensor([0.2341, 0.2650, 0.5009], grad_fn=<SoftmaxBackward>)\n",
      "output:1.544126272201538\n",
      "Parameter containing:\n",
      "tensor([ 0.6297, -0.3119, -0.3178], requires_grad=True)\n",
      "tensor([0.5359, 0.1836, 0.2805], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1060302257537842\n",
      "Parameter containing:\n",
      "tensor([ 0.6303, -0.3121, -0.3182], requires_grad=True)\n",
      "tensor([0.3546, 0.3088, 0.3366], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3546655178070068\n",
      "Parameter containing:\n",
      "tensor([ 0.6310, -0.3124, -0.3186], requires_grad=True)\n",
      "tensor([0.6158, 0.1843, 0.1998], grad_fn=<SoftmaxBackward>)\n",
      "output:1.0071139335632324\n",
      "Parameter containing:\n",
      "tensor([ 0.6316, -0.3127, -0.3189], requires_grad=True)\n",
      "tensor([0.2334, 0.3191, 0.4475], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5428279638290405\n",
      "Parameter containing:\n",
      "tensor([ 0.6322, -0.3129, -0.3192], requires_grad=True)\n",
      "tensor([0.4322, 0.3147, 0.2531], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2437739372253418\n",
      "Parameter containing:\n",
      "tensor([ 0.6328, -0.3133, -0.3195], requires_grad=True)\n",
      "tensor([0.3146, 0.3599, 0.3256], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4147238731384277\n",
      "Parameter containing:\n",
      "tensor([ 0.6335, -0.3137, -0.3198], requires_grad=True)\n",
      "tensor([0.4028, 0.2956, 0.3016], grad_fn=<SoftmaxBackward>)\n",
      "output:1.284822940826416\n",
      "Parameter containing:\n",
      "tensor([ 0.6342, -0.3140, -0.3202], requires_grad=True)\n",
      "tensor([0.4145, 0.3088, 0.2766], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2682486772537231\n",
      "Parameter containing:\n",
      "tensor([ 0.6349, -0.3144, -0.3205], requires_grad=True)\n",
      "tensor([0.3872, 0.3426, 0.2701], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3074009418487549\n",
      "Parameter containing:\n",
      "tensor([ 0.6355, -0.3147, -0.3208], requires_grad=True)\n",
      "tensor([0.3011, 0.4198, 0.2791], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4365172386169434\n",
      "Parameter containing:\n",
      "tensor([ 0.6362, -0.3151, -0.3210], requires_grad=True)\n",
      "tensor([0.3915, 0.3238, 0.2847], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3010869026184082\n",
      "Parameter containing:\n",
      "tensor([ 0.6369, -0.3155, -0.3214], requires_grad=True)\n",
      "tensor([0.3316, 0.3618, 0.3066], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3891280889511108\n",
      "Parameter containing:\n",
      "tensor([ 0.6375, -0.3159, -0.3217], requires_grad=True)\n",
      "tensor([0.2960, 0.2589, 0.4450], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4452306032180786\n",
      "Parameter containing:\n",
      "tensor([ 0.6382, -0.3161, -0.3221], requires_grad=True)\n",
      "tensor([0.2779, 0.4140, 0.3081], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4718267917633057\n",
      "Parameter containing:\n",
      "tensor([ 0.6388, -0.3165, -0.3223], requires_grad=True)\n",
      "tensor([0.3901, 0.3001, 0.3099], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3030260801315308\n",
      "Parameter containing:\n",
      "tensor([ 0.6395, -0.3168, -0.3227], requires_grad=True)\n",
      "tensor([0.4112, 0.3247, 0.2641], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2730766534805298\n",
      "Parameter containing:\n",
      "tensor([ 0.6402, -0.3172, -0.3230], requires_grad=True)\n",
      "tensor([0.4492, 0.2799, 0.2710], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2200578451156616\n",
      "Parameter containing:\n",
      "tensor([ 0.6409, -0.3175, -0.3233], requires_grad=True)\n",
      "tensor([0.3566, 0.2719, 0.3716], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3523699045181274\n",
      "Parameter containing:\n",
      "tensor([ 0.6415, -0.3178, -0.3237], requires_grad=True)\n",
      "tensor([0.3334, 0.4007, 0.2659], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3873438835144043\n",
      "Parameter containing:\n",
      "tensor([ 0.6422, -0.3182, -0.3240], requires_grad=True)\n",
      "tensor([0.4208, 0.2131, 0.3661], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2608445882797241\n",
      "Parameter containing:\n",
      "tensor([ 0.6429, -0.3185, -0.3244], requires_grad=True)\n",
      "tensor([0.3551, 0.2669, 0.3780], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3547110557556152\n",
      "Parameter containing:\n",
      "tensor([ 0.6436, -0.3187, -0.3248], requires_grad=True)\n",
      "tensor([0.2824, 0.4304, 0.2872], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4655027389526367\n",
      "Parameter containing:\n",
      "tensor([ 0.6442, -0.3191, -0.3251], requires_grad=True)\n",
      "tensor([0.2581, 0.5781, 0.1638], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5129458904266357\n",
      "Parameter containing:\n",
      "tensor([ 0.6448, -0.3196, -0.3252], requires_grad=True)\n",
      "tensor([0.3082, 0.3459, 0.3458], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4242753982543945\n",
      "Parameter containing:\n",
      "tensor([ 0.6455, -0.3200, -0.3255], requires_grad=True)\n",
      "tensor([0.4317, 0.3083, 0.2601], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2443768978118896\n",
      "Parameter containing:\n",
      "tensor([ 0.6462, -0.3203, -0.3258], requires_grad=True)\n",
      "tensor([0.4770, 0.2463, 0.2767], grad_fn=<SoftmaxBackward>)\n",
      "output:1.1823813915252686\n",
      "Parameter containing:\n",
      "tensor([ 0.6468, -0.3206, -0.3262], requires_grad=True)\n",
      "tensor([0.3352, 0.2720, 0.3928], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3843886852264404\n",
      "Parameter containing:\n",
      "tensor([ 0.6475, -0.3209, -0.3266], requires_grad=True)\n",
      "tensor([0.3853, 0.3641, 0.2506], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3107035160064697\n",
      "Parameter containing:\n",
      "tensor([ 0.6482, -0.3213, -0.3269], requires_grad=True)\n",
      "tensor([0.3381, 0.4008, 0.2611], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3803393840789795\n",
      "Parameter containing:\n",
      "tensor([ 0.6488, -0.3217, -0.3271], requires_grad=True)\n",
      "tensor([0.3857, 0.2922, 0.3221], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3093886375427246\n",
      "Parameter containing:\n",
      "tensor([ 0.6495, -0.3221, -0.3275], requires_grad=True)\n",
      "tensor([0.2529, 0.4793, 0.2678], grad_fn=<SoftmaxBackward>)\n",
      "output:1.5133178234100342\n",
      "Parameter containing:\n",
      "tensor([ 0.6501, -0.3225, -0.3277], requires_grad=True)\n",
      "tensor([0.3687, 0.3066, 0.3247], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3339383602142334\n",
      "Parameter containing:\n",
      "tensor([ 0.6508, -0.3228, -0.3280], requires_grad=True)\n",
      "tensor([0.2598, 0.5240, 0.2162], grad_fn=<SoftmaxBackward>)\n",
      "output:1.505455493927002\n",
      "Parameter containing:\n",
      "tensor([ 0.6514, -0.3233, -0.3282], requires_grad=True)\n",
      "tensor([0.3576, 0.2370, 0.4054], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3519865274429321\n",
      "Parameter containing:\n",
      "tensor([ 0.6521, -0.3235, -0.3286], requires_grad=True)\n",
      "tensor([0.4937, 0.2010, 0.3053], grad_fn=<SoftmaxBackward>)\n",
      "output:1.160830020904541\n",
      "Parameter containing:\n",
      "tensor([ 0.6528, -0.3238, -0.3290], requires_grad=True)\n",
      "tensor([0.3482, 0.2782, 0.3736], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3646190166473389\n",
      "Parameter containing:\n",
      "tensor([ 0.6534, -0.3240, -0.3294], requires_grad=True)\n",
      "tensor([0.4428, 0.2721, 0.2851], grad_fn=<SoftmaxBackward>)\n",
      "output:1.228866457939148\n",
      "Parameter containing:\n",
      "tensor([ 0.6541, -0.3244, -0.3298], requires_grad=True)\n",
      "tensor([0.3922, 0.3997, 0.2081], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3022491931915283\n",
      "Parameter containing:\n",
      "tensor([ 0.6548, -0.3248, -0.3300], requires_grad=True)\n",
      "tensor([0.3368, 0.3874, 0.2758], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3818676471710205\n",
      "Parameter containing:\n",
      "tensor([ 0.6555, -0.3252, -0.3303], requires_grad=True)\n",
      "tensor([0.3843, 0.3003, 0.3153], grad_fn=<SoftmaxBackward>)\n",
      "output:1.3112525939941406\n",
      "Parameter containing:\n",
      "tensor([ 0.6562, -0.3256, -0.3306], requires_grad=True)\n",
      "tensor([0.3106, 0.3389, 0.3505], grad_fn=<SoftmaxBackward>)\n",
      "output:1.4206527471542358\n",
      "Parameter containing:\n",
      "tensor([ 0.6568, -0.3259, -0.3309], requires_grad=True)\n",
      "tensor([0.3435, 0.4173, 0.2393], grad_fn=<SoftmaxBackward>)\n",
      "output:1.373138666152954\n",
      "Parameter containing:\n",
      "tensor([ 0.6575, -0.3263, -0.3312], requires_grad=True)\n",
      "tensor([0.3677, 0.3386, 0.2937], grad_fn=<SoftmaxBackward>)\n",
      "output:1.335587978363037\n",
      "Parameter containing:\n",
      "tensor([ 0.6582, -0.3267, -0.3315], requires_grad=True)\n",
      "tensor([0.4084, 0.3501, 0.2414], grad_fn=<SoftmaxBackward>)\n",
      "output:1.2775423526763916\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = regM()\n",
    "    output.backward()\n",
    "    print('output:{}'.format(output))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.load_state_dict(torch.load(\"checkpoints/Cityscapes/layerwise_policy_train_20600iter.model\")['state_dict'])\n",
    "# mtlmodel.load_state_dict(torch.load(\"checkpoints/Cityscapes/task_alter_train_5200iter.model\")['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_idx = 0\n",
    "for i, data in enumerate(valDataloaderDict[tasks[task_idx]]):\n",
    "    x = data['input']\n",
    "    y = data['label']\n",
    "    break\n",
    "    \n",
    "task = tasks[task_idx]\n",
    "tau = 2.0518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtlmodel.train()\n",
    "loss_list = []\n",
    "for i, data in enumerate(valDataloaderDict[task]):\n",
    "    x1 = data['input'].cuda()\n",
    "    y1 = data['label'].cuda()\n",
    "\n",
    "    output = mtlmodel(x1, 'mtl', task, tau=tau, hard=False)\n",
    "\n",
    "    if 'mask' in data:\n",
    "        loss = criterionDict[task](output, y1, data['mask'].cuda())\n",
    "        metricDict[task](output, y1, data['mask'].cuda())\n",
    "    else:\n",
    "        loss = criterionDict[task](output, y1)\n",
    "        metricDict[task](output, y1)\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "avg_loss = np.mean(loss_list)\n",
    "val_results = metricDict[task].val_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.595853839069605"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTLModel(\n",
       "  (headsDict): ModuleDict(\n",
       "    (segment_semantic): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (depth_zbuffer): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (net): ModuleList(\n",
       "    (0): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    )\n",
       "    (1): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (3): PoolNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): AbstractPool(\n",
       "        (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (7): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (10): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (11): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (14): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (17): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (18): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (21): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (24): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (25): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (26): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (27): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (28): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (29): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (30): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (31): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (32): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (33): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (34): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (35): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (36): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (37): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (38): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (39): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (40): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (41): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (42): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (43): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (44): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (45): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (46): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (47): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (48): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (49): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (50): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (51): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (52): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (53): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (54): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (55): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (56): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (57): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (58): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (59): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (60): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "    )\n",
       "    (61): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (62): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (63): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (64): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (65): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (66): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (67): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (68): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (69): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (70): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (71): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (72): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (73): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (74): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (75): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (76): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (77): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (78): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (79): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (80): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (81): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (82): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (83): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (84): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (85): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (86): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (87): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (88): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (89): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (90): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (91): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (92): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (93): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (94): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (95): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (96): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (97): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (98): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (99): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (100): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (101): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (102): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (103): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (104): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "    )\n",
       "    (105): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (106): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (107): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (108): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (109): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (110): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (111): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (112): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (113): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (114): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (115): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (116): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (117): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "    (118): Conv2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (119): BN2dNode(\n",
       "      (taskOp): ModuleDict(\n",
       "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (policy): ParameterDict(\n",
       "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
       "      )\n",
       "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (120): EltNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): EltwiseOp(op=1)\n",
       "    )\n",
       "    (121): ReLUNode(\n",
       "      (taskOp): ModuleDict()\n",
       "      (policy): ParameterDict()\n",
       "      (basicOp): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (inputNode): InputNode()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# output = mtlmodel(x.cuda(), 'pre_train', tasks[task_idx])\n",
    "output = mtlmodel(x.cuda(), 'pre_train_specific', tasks[task_idx])\n",
    "# output = mtlmodel(x.cuda(), 'mtl', task=task, tau=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29efe438>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.permute(0,2,3,1)[i].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29fdee10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.permute(0,2,3,1)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad29f9f320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATHklEQVR4nO3dfbBU9X3H8feHy+VBQPGBoEEMiODEhwQNMTQmNqkmUaYTNE0pZGrQ2BJTncZJMi1qJ3U6k5nUxjjJNDGjIyOmBjRBK01JIqE+NElFUAmKBEWCgRseFA0PXgP34ds/9ty4ud6Fy57de3b5fV4zd+7Z32/P7ndnLx/O2XP2fBURmFm6BhVdgJkVyyFgljiHgFniHAJmiXMImCXOIWCWuLqFgKSLJW2QtFHS/Ho9j5nlo3qcJyCpBXge+AiwFVgFzImI52r+ZGaWS722BM4DNkbEpog4ACwGZtbpucwsh8F1etxxwJay21uB91W685DBR8WwoaPrVIqZAext3/ZKRIzpPV6vEDgkSfOAeQDDhhzD9DM/W1QpZklYvuqml/oar9fuQBswvuz2ydnYH0TE7RExLSKmtQ4+qk5lmNmh1CsEVgGTJU2UNASYDSyt03OZWQ512R2IiE5J1wI/AVqABRGxrh7PZWb51O0zgYhYBiyr1+ObWW34jEGzxBV2dMDqq3voYA6Mbq0437q7g5bfdw5gRWnoOHroQedb9+wfoEr6zyFwhNp11nDe9zdPV5z/33vPZdwjewawojRs+ssWUN9zOiCm3N14IeDdAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS50OER6jhu7r58cp3V5x/2/buAazGGplD4Ag1cvPrTLmr6CqsGXh3wCxxDgGzxDkEzBLnEDBLXNUhIGm8pIclPSdpnaTPZ+M3SWqTtCb7mVG7cs2s1vIcHegEvhgRT0kaBTwpaXk2d2tEfC1/eWZWb1WHQERsA7Zly3slrad0qXEzayI1+UxA0gTgHGBlNnStpLWSFkg6thbPYWb1kTsEJI0ElgDXRcQe4DZgEjCV0pbCLRXWmydptaTVHZ3tecswsyrlCgFJrZQC4J6IuB8gInZERFdEdAN3UGpJ9hbuO2DWGPIcHRBwJ7A+Ir5eNn5S2d0uA56tvjwzq7c8RwfOBy4HnpG0Jhu7AZgjaSoQwGbA/cXMGlieowM/o+9LKrrXgFkT8RmDZonzV4nNamjydxvvkuKH4hAwq6FBB7qKLuGweXfALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHG5v0UoaTOwF+gCOiNimqTjgHuBCZSuLjQrIl7L+1xmVnu12hL4cERMjYhp2e35wIqImAysyG6bWQOq1+7ATGBhtrwQuLROz2NmOdUiBAJ4SNKTkuZlY2OzDkUA24GxvVdy3wGzxlCLKwt9ICLaJL0NWC7pV+WTERGSovdKEXE7cDvA0SPe/pZ5MxsYubcEIqIt+70TeIBSs5EdPf0Hst878z6PmdVH3g5EI7KOxEgaAXyUUrORpcDc7G5zgQfzPI+Z1U/e3YGxwAOlZkQMBr4XET+WtAq4T9JVwEvArJzPY2Z1kisEImIT8O4+xncBF+Z5bDMbGD5j0CxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBJX9fUEJJ1OqbdAj1OBLwOjgb8FXs7Gb4iIZdU+j5nVV9UhEBEbgKkAklqANkrXGLwSuDUivlaLAs2svmq1O3Ah8GJEvFSjxzOzAVKrEJgNLCq7fa2ktZIWSDq2Rs9hZnWQOwQkDQE+Dnw/G7oNmERpV2EbcEuF9dx8xKwB1GJL4BLgqYjYARAROyKiKyK6gTso9SF4i4i4PSKmRcS01sFH1aAMM6tGLUJgDmW7Aj1NRzKXUepDYGYNKtclx7OGIx8BPls2fLOkqZR6FG7uNWdmDSZv34HXgeN7jV2eqyIzG1A+Y9AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxOU6RGhWjddPGcFrU1qqXn/cI/tQZ3cNK0qbQ8AG3LbzxcY53656/YtWfobBew/UsKK0eXfALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8T5EGEO7eOOou2THRXnR60azom/2DOAFb3p1bNGMWT2jorzr//XiYxdWUxtecWNr7Cvs+8/3c7uQYz+8rABrqh/uoa38saNu4sr4GN9D/crBCQtAP4c2BkRZ2Vjx1HqOzCB0sVDZkXEa5IEfAOYAbQDV0TEU/mqb0z7j27hH6f9sOL8zTs/Dr8YwILKtJ8onnjX/RXnJ6/5HGNXDmBBNbTijKUV59q7D/AJPjOA1fRf19BB/Owg70m9VTo9q7+7A3cBF/camw+siIjJwIrsNpSuOTg5+5lH6cKjZtag+hUCEfEY8Gqv4ZnAwmx5IXBp2fjdUfI4MLrXdQfNrIHk+WBwbERsy5a3A2Oz5XHAlrL7bc3GzKwB1eToQEQEpQuL9pv7Dpg1hjwhsKNnMz/7vTMbbwPGl93v5Gzsj7jvgFljyBMCS4G52fJc4MGy8U+rZDqwu2y3wcwaTH8PES4CPgScIGkr8M/AV4H7JF0FvATMyu6+jNLhwY2UDhFeWeOarQb+e87X2D5rRCHPPa5lHzCyLo991KAh3HDff1Scv337h3jl70+u+vHHf+vXXD7m5xXn5z56FYT6nGsZ2lX189ZTv0IgIuZUmLqwj/sGcE2eoqz+prSOYEprUc9enwDoccFBzhVaefQWVlB9CEwd9ZuDPv7wUfvp7u47BIYM6az6eevJpw2bJc4hYJY4h4BZ4hwCZolzCJglziFglriGuJ7AlNNe5cdLKx/bPZj3PjWL428aUuOKamPorkHE6mcrzu9/aAKfGv9Exfn7z3470VndYaUR7/yTqtbrMePDn6Rrw8aq1m0583SWLb831/PXy5XHrOWY775Rcf7mZR/ntEX7Ks4vm3EOyzrOrjjfecsgBg06rDPoC+ctAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS1xCHCPM4bng7+95xbMX54TsP0PJG5cuC59HSEazaM7Hy/O9BrZUPX/521zE8MuL0ivPRXf0lwVvbu1my7+iq11dHY37jrT8O/rqP5uhBlQ8RAujAQV57Zxd0Vf5KcMerwyr+17q/Nd97Ui8qffO3WNPePSye+Mn4Q9+xCmff+neMe7gxr6+v5zbR3X7kXVqtyPME9nX/nr84eXrF+Y6L3sP/3H1nxfnTvnc1k770eD1KK9xP4wdPRsS03uPeHTBL3CFDQNICSTslPVs29m+SfiVpraQHJI3OxidIekPSmuznO3Ws3cxqoD9bAnfx1sYjy4GzIuJdwPPA9WVzL0bE1Ozn6tqUaWb1csgQ6KvxSEQ8FBE9n548Djmu12RmharFZwKfAX5UdnuipKclPSrpg5VWKu878PKuxrwAo1kKcoWApBuBTuCebGgbcEpEnAN8AfiepD6PiZT3HRhzfKVWiWZWb1WfJyDpCkqdii/MrjBMROwH9mfLT0p6EZgCrM5fapV1nv8aG088prqVA05bXPlrpersZtDvKs8fSlcTH4s/GP1uL6c9ckXdHn/NBd9h5KDq2o8P27bvoLWd8HSVRTWxqkJA0sXAPwB/GhHtZeNjgFcjokvSqZQ6E2+qSaVVWnveIjivunXbuw/wicWV21zrQCedm39TZWVHrs623zLpU7+t2+O//FInI6vchu1at4FJn6ptPc3ukCFQofHI9cBQYLkkgMezIwEXAP8iqQPoBq6OiN7djM2sgRwyBCo0HunzlKuIWAIsyVuUmQ0cnzFoljiHgFniHAJmiXMI2BFlkP+kD1vTX08gr/f+0+doba/wdeqA0RvXV1w3jtDj/I3ur7/0RaKl786/BIziyPwqcL0kHwJjHtxA167KRzF9QnPjGfn9lUWXcETxtpNZ4hwCZolzCJglziFgljiHgFniHAJmiWv6Q4Tv/PnlTLy6rer1D3Z40KyZtIx9Gxp0kP/XK3y7u+lDoKOjxf+QzQBJcLAQqMC7A2aJq7bvwE2S2sr6C8wom7te0kZJGyR9rF6Fm1ltVNt3AODWsv4CywAknQHMBs7M1vm2JF9F1KyBVdV34CBmAosjYn9E/BrYSNVX+DOzgZDnM4FrszZkCyT1tAUeB2wpu8/WbOwt3HfArDFUGwK3AZOAqZR6DdxyuA/gvgNmjaGqQ4QRsaNnWdIdwA+zm21AeY/xk7MxM6uzzu07Dn2nPlS1JSDppLKblwE9Rw6WArMlDZU0kVLfgSeqqszMBkS1fQc+JGkqEMBm4LMAEbFO0n3Ac5Tak10TEd7hN2tgNe07kN3/K8BX8hRlZgPHZwyaJc4hYJY4h4BZ4pr+W4RvP343HRe9p+L8sF/+hq6XXx7AisyaS9OHwGNnPwB3V55//xeuZtRih4BZJd4dMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHHV9h24t6znwGZJa7LxCZLeKJv7Th1rN7Ma6M93B+4C/p2yM/Qj4q96liXdAuwuu/+LETG1RvWZWZ3158pCj0ma0NecJAGzgD+rcV1mNkDyfibwQWBHRLxQNjZR0tOSHpX0wZyPb2Z1lverxHOARWW3twGnRMQuSe8B/lPSmRGxp/eKkuYB8wBOGdf032g2a1pVbwlIGgx8Ari3ZyxrP7YrW34SeBGY0tf6bj5i1hjy7A5cBPwqIrb2DEga09OAVNKplPoObMpXopnVU38OES4C/g84XdJWSVdlU7P5410BgAuAtdkhwx8AV0dEf5uZmlkBqu07QERc0cfYEmBJ/rLMbKD4jEGzxDkEzBLnEDBLXNMfoJ/y6FxOvXxdxflRXSsHsBqz5tP0IdAdIjo7iy7DrGl5d8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDXF04I3oZv2B9qrW7WpviJdg1rQa4l/QlmdGct2E91e17hRW17gas7R4d8AscQ4Bs8Q5BMwS15+LioyX9LCk5yStk/T5bPw4ScslvZD9PjYbl6RvStooaa2kc+v9Isysev3ZEugEvhgRZwDTgWsknQHMB1ZExGRgRXYb4BJKlxWbTOlCorfVvGozq5lDhkBEbIuIp7LlvcB6YBwwE1iY3W0hcGm2PBO4O0oeB0ZLOqnWhZtZbRzWZwJZE5JzgJXA2IjYlk1tB8Zmy+OALWWrbc3GzKwB9TsEJI2kdP3A63r3EYiIAOJwnljSPEmrJa3uYP/hrGpmNdSvEJDUSikA7omI+7PhHT2b+dnvndl4GzC+bPWTs7E/Ut53oJWh1dZvZjn15+iAgDuB9RHx9bKppcDcbHku8GDZ+KezowTTgd1luw1m1mD6c9rw+cDlwDM9LciBG4CvAvdlfQheotSYFGAZMAPYCLQDV9ayYDOrrf70HfgZoArTF/Zx/wCuyVmXmQ0QnzFoljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeJUuhpYwUVILwOvA68UXUsOJ9Dc9UPzv4Zmrx/q+xreERFjeg82RAgASFodEdOKrqNazV4/NP9raPb6oZjX4N0Bs8Q5BMwS10ghcHvRBeTU7PVD87+GZq8fCngNDfOZgJkVo5G2BMysAIWHgKSLJW2QtFHS/KLr6S9JmyU9I2mNpNXZ2HGSlkt6Ift9bNF1lpO0QNJOSc+WjfVZc9ZL8pvZ+7JW0rnFVf6HWvuq/yZJbdn7sEbSjLK567P6N0j6WDFVv0nSeEkPS3pO0jpJn8/Gi30PIqKwH6AFeBE4FRgC/BI4o8iaDqP2zcAJvcZuBuZny/OBfy26zl71XQCcCzx7qJop9ZP8EaUWdNOBlQ1a/03Al/q47xnZ39NQYGL2d9ZScP0nAedmy6OA57M6C30Pit4SOA/YGBGbIuIAsBiYWXBNecwEFmbLC4FLiyvlrSLiMeDVXsOVap4J3B0ljwOje1rRF6VC/ZXMBBZHxP6I+DWlBrnn1a24foiIbRHxVLa8F1gPjKPg96DoEBgHbCm7vTUbawYBPCTpSUnzsrGx8WYb9u3A2GJKOyyVam6m9+babHN5QdkuWEPXL2kCcA6wkoLfg6JDoJl9ICLOBS4BrpF0QflklLbnmurQSzPWDNwGTAKmAtuAWwqtph8kjQSWANdFxJ7yuSLeg6JDoA0YX3b75Gys4UVEW/Z7J/AApU3NHT2ba9nvncVV2G+Vam6K9yYidkREV0R0A3fw5iZ/Q9YvqZVSANwTEfdnw4W+B0WHwCpgsqSJkoYAs4GlBdd0SJJGSBrVswx8FHiWUu1zs7vNBR4spsLDUqnmpcCns0+opwO7yzZZG0avfeTLKL0PUKp/tqShkiYCk4EnBrq+cpIE3Amsj4ivl00V+x4U+Wlp2Segz1P69PbGouvpZ82nUvrk+ZfAup66geOBFcALwE+B44qutVfdiyhtMndQ2r+8qlLNlD6R/lb2vjwDTGvQ+r+b1bc2+0dzUtn9b8zq3wBc0gD1f4DSpv5aYE32M6Po98BnDJolrujdATMrmEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS9/+q/4AucXLCvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seg\n",
    "def resize_pred(pred, gt):\n",
    "    return F.interpolate(pred, size=gt.shape[-2:])\n",
    "pred = output\n",
    "gt = y.cuda()\n",
    "output = resize_pred(pred, gt)\n",
    "prediction = torch.argmax(output, dim=1)\n",
    "plt.imshow(prediction.cpu().detach().numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aad3ffc1208>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX0klEQVR4nO2da2ykZ3XH/2cuvnt93Ys3uwnJKmlJuCStFRWRFqoIGvKhAVVCRBVKBWL5ABJIfChKK5GPUVVAqEVImyYiVFyERBGplFJCBI0oKoo35LLJAtnm0uz9Zq+vY3tmTj94QCbx8z/GY8+MeP4/ybI9Z573Pe/zvv95Z+Y85xxzdwghfv8ptNsBIURrkNiFyASJXYhMkNiFyASJXYhMKLVyZ12lPu8tD6WfYMY3UK2Ssfx1y0tNvq4V0r5ZrcmIRj0YX69xe4EcWzSn9Tq3R4dG5iXcf7TviCiSxOYlOq5icD1Fhx1tn/keHJeXi0lbpTKDldWFDb1rSuxmdgeALwEoAvgXd7+fPb+3PIR3HPpI0u7s5AAoXJxOG3u66dja+C5qj6j1pKeqNFNpatu2ssrtcwvU7gN9aWMwp1ZZpnbUuCC9p4uPL6fnzRaDeYteBNmLPwD09qRtgaDqu8icIr5WrcZfoK1K5jW4HlavGk7anpz6ctK25dudmRUBfBnA+wDcCOBuM7txq9sTQuwszby3vRXACXd/yd1XAHwLwF3b45YQYrtpRuxXAXht3f8nG4/9FmZ22MymzGxqpbbYxO6EEM2w49/Gu/sRd59098muIv8cJITYOZoR+ykAB9f9f6DxmBCiA2lG7E8CuN7MrjWzLgAfAvDI9rglhNhuthx6c/eqmX0SwH9iLfT2kLs/HwyCVVaS5vroAB8+kg6f2Rz/PqB4aY7aV64epfby+fn0vpeC8FUQpvFSOm4KAN7fy7c/m/YNQQjIh4OQ5MIsty+nzycAukagdt0bvuL5LQonTlK77eLXCwuv+Sy/HgpLQViwGJyzIHxG107sGeO7XiQhRxLRayrO7u6PAni0mW0IIVqDlssKkQkSuxCZILELkQkSuxCZILELkQkSuxCZ0NJ8dgBwkv9cvHCFj2XpmF1BqmWQ0lj+BV/8t3TLNUlbz3//go4t7BqkdlsK8rq7+bHVJ8bT+57m8WQsB/Hg/mCJc5SGSua98PJpPrarzDfNUnsB2Ez62G0wiNGvBumzER6c0xKR3mWugwKpEWCkRoDu7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCa0PPRmLFQTpUuODadtUaXSoEoqhnh4rPdlUtl2326+7fmgHBerggqEaaqFK6T6bFRKejWY82h8gJNQkLHw0yZYHeapv2VyTdTPX6RjC1FoLqhmbMG8+TxJmR4IUr2r5Hog8tKdXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMaG2c3b251EEWX4y6kQZx0foQT5csnk3H2X0liFUHaaK+wOPwFqXvsrLEQZlqmmqJuEurResXZkgp6uCcROWaw32za+Lag2kbAFwh5bmjbQPwIKXaBtPrOnxpiY9l55SlFNOtCiF+b5DYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITGhtnN0MKKd3SUtFA7A5krcdlFv2wF6Y5/nw3kdyzqM4e7NliYvBa3K0xoAR5F1b5HtQg8DYGoMgTz9cIxCVsSbn3IJ9rx7gbZPLZ0h9AwC4EpTwLpMy2UEb7RpZE+Ln0tdKU2I3s1cAzAGoAai6+2Qz2xNC7BzbcWf/c3fnZT+EEG1Hn9mFyIRmxe4AfmBmR83s8EZPMLPDZjZlZlMrtaAWmxBix2j2bfxt7n7KzPYAeMzMfuHuT6x/grsfAXAEAIZ69gXfqAghdoqm7uzufqrx+zyA7wK4dTucEkJsP1sWu5n1m9ngr/8G8F4Ax7bLMSHE9tLM2/i9AL7bqI9dAvANd/8+HVGr89xt0s4ZCPLGWa47AETtfYO687WxdP5xcYHnH3s3bz1swXFHsXAfScdlLWjJ7GztAoLcaSD2rZKe17BufHBOvcx98950vrwt8bUJrOY8gDjXfqCf2uk1Mc1bNhdJHwK2LmLLYnf3lwC8favjhRCtRaE3ITJBYhciEyR2ITJBYhciEyR2ITKh5S2bGWHJZFZ6OCorHLVNDsI8xYukJHKVp4HaPLd7ND5qH0x89yh0NjpEzXWSkgwAFqW4Vog98C0qY126HIQNSdjR+3m7Z5y9wLfdE7TZDlKq2bxEy0ydXetq2SyEkNiFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMaG2cvV6HL6bTQeszPLWvwOLNQZzdgvbAHsSbaQpsL4+51k6fpfbixF5qxwpPUwUrcx2UgrZo/cEQj/HT8t4IYsIRs7wcs/UGsXJSLtqiOd2VTmkGgPp5XmPVg+0X94wnbVF6LC2hTdKldWcXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhNaG2cvFlAgMUSv8ng1i8Oz7QJx/rLNBvFi1ha5znPhLSg7HMVso7LF9BU7aE1cm57hu64HcfIgbxvz6XltKp4MwJd4CW9Wqtrn5/m+y0GL7/FRaq9fnqF2nyP77wpKj7NceuWzCyEkdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhNaG2d3wEmN8yjnvDCczjn3RZ6XHeZdBzFdWl/94mW+bdZqGvEaARtKt2QGgPpgenwhaD1cCPLN62FOebA2gsTZC0G757Ae/8gwH79Ejn33GN82q3cPxPUTonbUJJbuZM4AwNlxkXUV4Z3dzB4ys/NmdmzdY6Nm9piZvdj4PRJtRwjRXjbzNv6rAO543WOfBfC4u18P4PHG/0KIDiYUu7s/AeD171PvAvBw4++HAbx/e90SQmw3W/3MvtfdzzT+PgsgWUTNzA4DOAwAPYWgZ5kQYsdo+tt4d3eQ5ffufsTdJ919sqsQFAgUQuwYWxX7OTObAIDG7/Pb55IQYifYqtgfAXBP4+97AHxve9wRQuwU4Wd2M/smgHcDGDezkwA+B+B+AN82s48CeBXABze1NwOsmH598SukBzqAtU8MCVsQkwWpVw8Atp/Xbqd1xss8/7gwwiOTPsdj2V4JeoWznPLouKMe6dQKYJivAWBx/KjvvAc17aPe82xewjh6dD1FBDnpWE7XR4iuZWdjPT3fodjd/e6E6fZorBCic9ByWSEyQWIXIhMkdiEyQWIXIhMkdiEyofUpriR8FpZMJqmg1ddO8rEkPRYAqqM8zbR0maQdXpqmY6PjQoG/5hZIe18AtC0znW+g6VbXmOZttrF/T9p2aYbvOyj/7cG8VQ6l993zyzNJG4A4dBa1fA7srN10wYJ7MNGBzaSvNd3ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhciEFsfZnccfg/K7rFx0oa+Pjo1K+y5exUsiV96S3v6eR3hqrgUlk6NYtgdtkb2cPrZCEO/1Ci81TdsDA6iP8RRXkGO3vqByEVk/AADezc9peS6dxnrlHQfp2KGnzlE7EMTZgzi9s1bYe4Iy12xe5hRnFyJ7JHYhMkFiFyITJHYhMkFiFyITJHYhMkFiFyITWhtnLxiNKftAECsnbZejtsZRzLb3Ai8tXO0msfCgnHJUjpnGTTdhByuxTcoOAzyvGgBWSE44ANgKz4ev7E3P2+AzvFQ0yPoBAPCuwF5Mx/hXe/l9zknJcyAo3w3EcfZeUuZ6ga99oGtVSOtx3dmFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyITWxtmLRfgu0qa3VuPje9O51fW+IO+6j8c9F0k8GAAKxDUWMwUAW+SxbrDcZiCu7U7mzaOa9QHVXn6JLO/j2+8/lY4ZV67j9fDLV/i8eYnfq+rltG8W1dMP2kFH58T7ghoFLM8/itEzYyG93fDObmYPmdl5Mzu27rH7zOyUmT3d+Lkz2o4Qor1s5m38VwHcscHjX3T3mxs/j26vW0KI7SYUu7s/AeByC3wRQuwgzXxB90kze7bxNn8k9SQzO2xmU2Y2tVIN1kILIXaMrYr9KwAOAbgZwBkAn0890d2PuPuku092lXiiixBi59iS2N39nLvX3L0O4AEAt26vW0KI7WZLYjeziXX/fgDAsdRzhRCdQRhnN7NvAng3gHEzOwngcwDebWY3Yy3k9wqAj29mZ/VyEZWD6T7pXVd4TjmLR6+M8Dh7scJj+D2XgjrghFo/j7PXxnjOeHkmyF8OwvA0zj7Kc+0L80vUXprn81Ja4rn2hWra+dIcj6Mv7w7qGwTzwui5zK+HKFe+Osx9Y8cNAHWyRqDew/ddqKTj8CwPPxS7u9+9wcMPRuOEEJ2FlssKkQkSuxCZILELkQkSuxCZILELkQmtTXE1npa4uitIFa2RkslBuuPqILdP/wFPKxw4nQ6lWI1PY9ccD/PUevm+61083XJ1V9reHYQUV4OQpZeCdtNVnipamUif0+IyTwOtdfNzthKcU2NllYPq3MVlHlorkXbQALB4FQ+3Gtl/lH5bnifH3UyKqxDi9wOJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyISWx9nrJG7rxl97aqTNLtsuACwPcnvvBZ6SWCNLAHovBmPDeHEQb+4KYt1k95VDPI7edyFIUV3mx7Y8wi+hWjdpm9zH1w9U+/hxOzejZzodr17czfe9Mhi0ZHZuj3wvz6d965nhc86ul3pX+lrTnV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITGhpnL3aa7j0lvQu+08HbXQJq/3cPnctt4//nNvr5XTcdHF30NZ4hMdcS0v8uD14SV7tT2+/5zLf9tIY9332Ou57/6nAdzK8HqwfWCXdvQGgm8TRAcCL6e13zfGxfed5HYDpG3icvR4oq05KGKz08xNeGUsfFyutoDu7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJnQ2nx28JhxFJtcHt563LT/tSD52bYe41/ZtfXc5c1gvOw8tUdzuriX+17gXZWxOsDHLxwg9faDLtnlBb7tpfEgz5/My2pQ32D6zbyWf3memlHr4ed8ZSi9/+7pYNus/AErKc83C5jZQTP7kZm9YGbPm9mnGo+PmtljZvZi4/dItC0hRPvYzNv4KoDPuPuNAP4EwCfM7EYAnwXwuLtfD+Dxxv9CiA4lFLu7n3H3pxp/zwE4DuAqAHcBeLjxtIcBvH+HfBRCbAO/0xd0ZvYmALcA+BmAve5+pmE6C2BvYsxhM5sys6nq4kIzvgohmmDTYjezAQDfAfBpd59db3N3B7DhNxLufsTdJ919stQXZKsIIXaMTYndzMpYE/rX3f3fGg+fM7OJhn0CwPmdcVEIsR2EoTczMwAPAjju7l9YZ3oEwD0A7m/8/l60rXoJqIynQzGFlaDk8nA6nLE0uUTHlo/zFrz1Mt93lXTgXRnhpX8RRP26pvm+ozAP8215jI/1Ag8RVa+pUHu9GrRNJsfuS7ycc6EalHse5zHJ5bG0b97Fz1nXpahNdtBWeZafdBYSZemvAFDtJ63LyenYTJz9nQA+DOA5M3u68di9WBP5t83sowBeBfDBTWxLCNEmQrG7+0+Qvjfdvr3uCCF2Ci2XFSITJHYhMkFiFyITJHYhMkFiFyITWpviWnL42ErSvLyftw8e6EvnW87Nk2AzgNXBIJ4cLO4z4lphNSiJPM6Pazl4yS1WgjUAfeljq/GOzeg7G5S5XmhuXp1cYdXd6WsB4C26AaB3fJHaV5bTAWs7w9tkT77nBWqf+uGbqb2yh8fxC8vpea9M8PUD5WmyBoCcTt3ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhciElsbZu7tWccPBc0n7ibO76fjFSrpN7sTYFTr2DLUCVuRx0epqOrZ500G+9ddmhql9do7b99xxktoHy+n1BxXWwxfAlWUeiK/V+f3gXRMnqL1ASnTXWT9nAI+fvIHaI996u9Nx/IUyX/vw018dovb9t6avYwC4bugitS9W09fy0eO8v/jqvnQNbi+n51t3diEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEyoaVxdodhtZ6OVw/28xrllZV0fvKF2QE69q0HTlH7StDb+Or+dB/dZy7tp2O7g5judW/nvrF9A0CpkM5/HivzllvPXrmK2t82xH17Uw+PJ3eRQgA/uHQTH1vied1vHePrD94zcixpe3l5Dx370tI4tf/8wgFqr5LrHAAODaTnre+tPM//ldl0M4BL5FrTnV2ITJDYhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITNhMf/aDAL4GYC8AB3DE3b9kZvcB+BiAC42n3uvuj7JtDZWW8N69x5P2E4s89vnC9N6k7VCQP3z09EFqPzDM8+HPLg1ued+9xXT+MRDH+OeqvMb57Eo6J/2PJ16lY6M4+b7SDLXP1Xld+X+/+PakbbCUzsMHgI9c+1Nqf3aen9OjC+m88L8ceoqOXayn880B4N4b/oPa//65u6j99MBQ0nZhjjcx2D88m7Sx+gGbWVRTBfAZd3/KzAYBHDWzxxq2L7r7P25iG0KINrOZ/uxn0Cj04u5zZnYcAF92JYToOH6nz+xm9iYAtwD4WeOhT5rZs2b2kJmNJMYcNrMpM5tamObLAIUQO8emxW5mAwC+A+DT7j4L4CsADgG4GWt3/s9vNM7dj7j7pLtP9o/wz0FCiJ1jU2I3szLWhP51d/83AHD3c+5ec/c6gAcA3LpzbgohmiUUu5kZgAcBHHf3L6x7fGLd0z4AIJ1iJIRoO5v5Nv6dAD4M4Dkze7rx2L0A7jazm7EWjnsFwMejDY0WF/HXQz9P2j+3cAcdf8tYOt3yl7M8bNffw78vOD27i9r3DM4nbVEK6lItnZoLAMcuTlD7m8fOUvtfTDyftD3w8m107F9dnT4fAHBmZZjaD3RdpvbRrnRb5Wt7LyRtAPCN1/ibxQ8f/B9qL5P02v+a5y2Xr+66RO2jxfT1AAATQ+nwGACcn0unZO8bmqNjl1bT1xMrz72Zb+N/go27PtOYuhCis9AKOiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhPMPZ0St93sv2nYP/atdyXt79v1DB3/z2dvT9r+sJ+30H21MkrtZ5bSKYcA0FVIx2xLBd7ueV8Pj7kOFHmq59v6/o/af3wlHTPe3z1Dx35gF4+z39TFU1j/afoaat9dSh/7t89N0rH7e/m8Hb3Iyznfc006Dv/yMm8P3lPgacm3D6bXNgDA96+8jdpv6kuvGXng1T+lY9+198Wk7cEP/Rinn5/ZMNiuO7sQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmdDSOLuZXQCwvrbxOABey7h9dKpvneoXIN+2ynb6do27b7iIoKVif8POzabcna+saBOd6lun+gXIt63SKt/0Nl6ITJDYhciEdov9SJv3z+hU3zrVL0C+bZWW+NbWz+xCiNbR7ju7EKJFSOxCZEJbxG5md5jZL83shJl9th0+pDCzV8zsOTN72sym2uzLQ2Z23syOrXts1MweM7MXG7837LHXJt/uM7NTjbl72szubJNvB83sR2b2gpk9b2afajze1rkjfrVk3lr+md3MigB+BeA9AE4CeBLA3e7+QksdSWBmrwCYdPe2L8Awsz8DMA/ga+7+lsZj/wDgsrvf33ihHHH3v+0Q3+4DMN/uNt6NbkUT69uMA3g/gL9BG+eO+PVBtGDe2nFnvxXACXd/yd1XAHwLAO9cnynu/gSA17dcuQvAw42/H8baxdJyEr51BO5+xt2favw9B+DXbcbbOnfEr5bQDrFfBeC1df+fRGf1e3cAPzCzo2Z2uN3ObMBedz/T+PssgL3tdGYDwjbereR1bcY7Zu620v68WfQF3Ru5zd3/CMD7AHyi8Xa1I/G1z2CdFDvdVBvvVrFBm/Hf0M6522r782Zph9hPATi47v8Djcc6Anc/1fh9HsB30XmtqM/9uoNu4/f5NvvzGzqpjfdGbcbRAXPXzvbn7RD7kwCuN7NrzawLwIcAPNIGP96AmfU3vjiBmfUDeC86rxX1IwDuafx9D4DvtdGX36JT2nin2oyjzXPX9vbn7t7yHwB3Yu0b+f8F8Hft8CHh13UAnmn8PN9u3wB8E2tv61ax9t3GRwGMAXgcwIsAfghgtIN8+1cAzwF4FmvCmmiTb7dh7S36swCebvzc2e65I361ZN60XFaITNAXdEJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkwv8DzPuleesiLDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# depth\n",
    "plt.imshow(output.cpu().detach().numpy()[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 1.9348e-01,  1.9046e-01,  1.7868e-01,  ...,  1.6289e-01,\n",
       "            1.3305e-01,  1.4691e-01],\n",
       "          [ 1.1127e-01,  1.8490e-02, -1.9056e-02,  ...,  1.0792e-01,\n",
       "            7.5129e-02,  2.6224e-02],\n",
       "          [ 5.9161e-02,  1.2628e-01,  4.1456e-02,  ...,  4.8540e-02,\n",
       "           -5.2689e-02, -2.5313e-02],\n",
       "          ...,\n",
       "          [-1.7076e-01, -1.6649e-01, -5.4048e-02,  ..., -4.0136e-02,\n",
       "           -1.8000e-01, -5.5735e-02],\n",
       "          [-9.9670e-02, -1.1982e-01, -4.6479e-02,  ..., -2.8480e-02,\n",
       "           -1.6647e-01, -4.2167e-02],\n",
       "          [-1.4900e-02, -1.7457e-01, -1.2356e-01,  ..., -1.2068e-01,\n",
       "           -1.8828e-01, -1.7409e-01]],\n",
       "\n",
       "         [[ 3.9546e-01,  2.6007e-01,  3.0369e-01,  ...,  3.1506e-01,\n",
       "            2.8149e-01,  3.6778e-01],\n",
       "          [ 2.1045e-01,  1.4817e-01,  1.9734e-01,  ...,  2.0418e-01,\n",
       "            2.5394e-01,  2.3090e-01],\n",
       "          [ 2.2047e-01,  7.8727e-02,  2.1716e-01,  ...,  2.0573e-01,\n",
       "            2.2162e-01,  1.1520e-01],\n",
       "          ...,\n",
       "          [ 7.8002e-03, -7.3256e-02, -3.7424e-02,  ...,  2.4563e-02,\n",
       "            1.7132e-02, -3.9162e-02],\n",
       "          [-8.2261e-02,  4.3826e-02,  1.0954e-02,  ...,  9.4626e-02,\n",
       "           -5.4367e-02,  8.6645e-02],\n",
       "          [-7.2165e-02, -6.1762e-02, -2.8604e-02,  ..., -9.3454e-02,\n",
       "            2.0433e-02, -3.5397e-02]],\n",
       "\n",
       "         [[ 3.0470e-01,  2.9425e-01,  1.6970e-01,  ...,  3.0008e-01,\n",
       "            4.0986e-01,  3.4495e-01],\n",
       "          [ 2.1641e-01,  2.3366e-01,  2.4421e-01,  ...,  3.0606e-01,\n",
       "            2.5837e-01,  3.7265e-01],\n",
       "          [ 2.6652e-01,  2.9613e-01,  1.8087e-01,  ...,  3.3646e-01,\n",
       "            2.9466e-01,  2.2690e-01],\n",
       "          ...,\n",
       "          [ 1.7562e-02,  1.2545e-01,  1.0439e-01,  ...,  8.7839e-02,\n",
       "            5.2315e-02,  6.9824e-02],\n",
       "          [-2.8949e-03,  3.3556e-02,  1.0388e-01,  ...,  6.7428e-02,\n",
       "            2.3506e-02,  5.6610e-02],\n",
       "          [ 1.2620e-02,  4.2862e-04, -2.9687e-02,  ...,  5.9172e-02,\n",
       "            3.1879e-03,  1.3941e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1861e-01, -6.9252e-02, -4.2111e-02,  ..., -4.9531e-02,\n",
       "           -5.0002e-02, -2.2789e-01],\n",
       "          [-1.2462e-01,  7.9621e-02,  3.1477e-01,  ...,  3.6418e-01,\n",
       "            1.0495e-01, -1.4629e-01],\n",
       "          [-2.5711e-01, -4.7194e-02,  2.3762e-01,  ...,  2.4443e-01,\n",
       "            1.1825e-01, -1.2448e-01],\n",
       "          ...,\n",
       "          [ 3.8341e-03,  1.2940e-02, -1.8498e-01,  ..., -2.3982e-01,\n",
       "           -1.2807e-01, -6.5849e-02],\n",
       "          [ 1.6280e-02, -2.2919e-01, -5.4524e-01,  ..., -5.5618e-01,\n",
       "           -2.8119e-01, -8.4630e-02],\n",
       "          [ 2.9217e-02, -1.4963e-01, -5.5530e-01,  ..., -5.1312e-01,\n",
       "           -3.5225e-01, -1.8325e-02]],\n",
       "\n",
       "         [[-1.3248e-01, -1.5879e-02, -7.3597e-02,  ...,  5.9925e-02,\n",
       "            2.0742e-02, -2.2118e-01],\n",
       "          [-9.0274e-02,  1.2198e-01,  2.4148e-01,  ...,  2.6748e-01,\n",
       "            1.1626e-01, -1.5355e-01],\n",
       "          [-2.5510e-01,  1.2519e-02,  2.6392e-01,  ...,  2.2350e-01,\n",
       "            7.7663e-02, -8.9623e-02],\n",
       "          ...,\n",
       "          [ 6.0900e-03, -3.6701e-02, -1.4688e-01,  ..., -1.5240e-01,\n",
       "            7.8715e-03,  2.9904e-02],\n",
       "          [ 1.1815e-01, -1.5965e-01, -5.5559e-01,  ..., -6.1041e-01,\n",
       "           -3.0734e-01,  4.5595e-02],\n",
       "          [ 9.5426e-02, -1.5706e-01, -4.7803e-01,  ..., -5.8104e-01,\n",
       "           -2.3293e-01,  1.2288e-01]],\n",
       "\n",
       "         [[-3.0093e-01, -9.1831e-02, -1.7149e-02,  ..., -1.7721e-02,\n",
       "           -1.9420e-02, -1.9703e-01],\n",
       "          [-1.4186e-01,  3.0824e-02,  1.3841e-01,  ...,  3.2936e-01,\n",
       "            9.5610e-02, -1.3391e-01],\n",
       "          [-1.9598e-01, -9.5541e-02,  1.7769e-01,  ...,  2.3178e-01,\n",
       "            6.7531e-02, -2.2220e-01],\n",
       "          ...,\n",
       "          [ 1.0961e-01,  9.5990e-02, -4.3585e-02,  ..., -7.1444e-02,\n",
       "           -1.6975e-03, -2.0844e-02],\n",
       "          [ 9.3435e-02, -1.3798e-01, -4.1175e-01,  ..., -4.7734e-01,\n",
       "           -1.4935e-01,  7.6791e-02],\n",
       "          [ 1.8279e-01, -1.7677e-01, -4.9691e-01,  ..., -4.8496e-01,\n",
       "           -1.1588e-01,  1.5386e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3422e-01,  5.6946e-02, -4.4012e-02,  ...,  7.5978e-02,\n",
       "            1.3772e-01,  1.4103e-01],\n",
       "          [ 9.2428e-02,  4.5984e-02, -7.3937e-02,  ...,  1.3230e-02,\n",
       "            1.8350e-01,  1.0859e-01],\n",
       "          [ 8.7874e-02,  3.8481e-02, -2.9248e-02,  ..., -6.9481e-02,\n",
       "            4.7970e-02,  6.6456e-02],\n",
       "          ...,\n",
       "          [ 3.3562e-01,  3.2084e-01,  3.8629e-01,  ...,  3.6651e-01,\n",
       "            3.8906e-01,  3.8730e-01],\n",
       "          [ 4.3496e-01,  3.4643e-01,  3.1617e-01,  ...,  3.5348e-01,\n",
       "            2.8155e-01,  3.0870e-01],\n",
       "          [ 3.4012e-01,  4.4205e-01,  4.0788e-01,  ...,  3.8313e-01,\n",
       "            2.8415e-01,  3.3847e-01]],\n",
       "\n",
       "         [[ 1.5787e-01,  1.2103e-02,  1.3330e-02,  ..., -3.5541e-02,\n",
       "            1.2316e-01,  1.5220e-01],\n",
       "          [ 1.6519e-01, -6.7258e-02, -5.6864e-02,  ...,  1.3928e-01,\n",
       "            8.3508e-02,  2.0923e-01],\n",
       "          [ 1.0559e-01, -5.6640e-02, -8.6579e-02,  ..., -1.9612e-02,\n",
       "            3.5222e-02,  5.6342e-02],\n",
       "          ...,\n",
       "          [ 3.2311e-01,  3.9540e-01,  3.4362e-01,  ...,  2.4250e-01,\n",
       "            4.4043e-01,  3.0391e-01],\n",
       "          [ 4.1096e-01,  4.0907e-01,  4.4725e-01,  ...,  4.2726e-01,\n",
       "            4.4643e-01,  3.1863e-01],\n",
       "          [ 2.7936e-01,  4.1867e-01,  2.8060e-01,  ...,  3.8285e-01,\n",
       "            3.7155e-01,  3.2962e-01]],\n",
       "\n",
       "         [[-4.2859e-02,  3.0449e-03,  1.1235e-02,  ...,  3.3652e-02,\n",
       "           -1.3945e-03,  6.2101e-02],\n",
       "          [-8.8811e-03, -1.5289e-01, -1.3418e-01,  ...,  1.3978e-02,\n",
       "           -5.1278e-02,  1.8524e-02],\n",
       "          [-1.2932e-01, -1.5300e-01, -8.2819e-02,  ..., -1.5588e-01,\n",
       "           -2.7543e-02,  8.3585e-03],\n",
       "          ...,\n",
       "          [ 2.9860e-01,  1.9212e-01,  3.2739e-01,  ...,  2.7992e-01,\n",
       "            3.6012e-01,  3.6647e-01],\n",
       "          [ 2.7816e-01,  3.3447e-01,  3.9162e-01,  ...,  2.5194e-01,\n",
       "            2.6685e-01,  2.1791e-01],\n",
       "          [ 1.7084e-01,  2.2893e-01,  1.7858e-01,  ...,  2.2817e-01,\n",
       "            2.7910e-01,  2.2406e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-6.5441e-03, -1.4997e-01, -2.2663e-01,  ..., -2.8896e-01,\n",
       "           -1.6126e-01, -6.5877e-02],\n",
       "          [ 2.1835e-02, -1.7180e-01, -2.9062e-01,  ..., -4.3270e-01,\n",
       "           -3.0434e-01, -8.7422e-02],\n",
       "          [-2.8007e-01, -2.7005e-01, -3.6075e-01,  ..., -4.0973e-01,\n",
       "           -4.3757e-01, -3.4216e-01],\n",
       "          ...,\n",
       "          [ 1.4845e-01,  1.5642e-01,  3.1548e-01,  ...,  2.8312e-01,\n",
       "            1.4152e-01,  5.3966e-02],\n",
       "          [ 6.4303e-01,  5.5613e-01,  6.7680e-01,  ...,  8.9608e-01,\n",
       "            9.0418e-01,  7.6326e-01],\n",
       "          [ 6.7288e-02,  3.1130e-01,  4.9437e-01,  ...,  3.8273e-01,\n",
       "            2.7193e-01, -7.8445e-02]],\n",
       "\n",
       "         [[-6.7413e-02, -3.3412e-01, -5.3041e-01,  ..., -4.3082e-01,\n",
       "           -1.8933e-01, -1.0943e-02],\n",
       "          [-1.7898e-01, -4.7312e-01, -6.7110e-01,  ..., -5.2439e-01,\n",
       "           -3.6046e-01, -1.3699e-01],\n",
       "          [-4.5686e-01, -5.1416e-01, -6.4736e-01,  ..., -6.6663e-01,\n",
       "           -4.7206e-01, -3.1133e-01],\n",
       "          ...,\n",
       "          [ 1.3257e-01,  1.7986e-01,  3.2450e-01,  ...,  3.1813e-01,\n",
       "            1.1754e-01, -5.1540e-03],\n",
       "          [ 3.9899e-01,  6.9933e-01,  9.9808e-01,  ...,  9.6575e-01,\n",
       "            6.0016e-01,  3.8259e-01],\n",
       "          [-6.2643e-02,  1.3653e-01,  2.7354e-01,  ...,  3.0888e-01,\n",
       "            1.9806e-01, -4.5998e-02]],\n",
       "\n",
       "         [[ 3.0253e-01, -9.1092e-05, -9.2978e-02,  ..., -3.2222e-01,\n",
       "           -8.7659e-02,  9.9027e-02],\n",
       "          [ 2.3355e-02, -3.0976e-01, -4.0508e-01,  ..., -4.0812e-01,\n",
       "           -4.1611e-01,  1.8582e-02],\n",
       "          [-2.9185e-01, -4.5287e-01, -3.2448e-01,  ..., -4.9735e-01,\n",
       "           -4.5263e-01, -5.0443e-01],\n",
       "          ...,\n",
       "          [ 2.5353e-01,  2.4393e-01,  3.8372e-01,  ...,  4.8763e-01,\n",
       "            4.2574e-01,  3.0660e-01],\n",
       "          [ 5.7360e-01,  6.8942e-01,  8.0363e-01,  ...,  9.0279e-01,\n",
       "            8.4379e-01,  6.9271e-01],\n",
       "          [ 4.3728e-02,  2.2124e-01,  4.7603e-01,  ...,  4.5979e-01,\n",
       "            1.8919e-01,  5.1313e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.6919e-01,  2.5433e-01,  2.9159e-03,  ..., -3.9586e-01,\n",
       "            8.3945e-02,  4.3993e-01],\n",
       "          [ 6.5795e-01,  3.8393e-01,  6.0518e-03,  ..., -1.8555e-01,\n",
       "            2.0616e-01,  4.9549e-01],\n",
       "          [ 7.3804e-01,  5.1392e-01,  1.7820e-01,  ..., -1.7999e-01,\n",
       "            3.3974e-01,  6.7964e-01],\n",
       "          ...,\n",
       "          [ 9.9047e-02,  1.3656e-02,  1.5119e-01,  ...,  2.1338e-01,\n",
       "            8.3008e-02, -4.1418e-02],\n",
       "          [-4.2290e-01, -1.5473e-01,  5.2264e-01,  ...,  1.0115e+00,\n",
       "            2.1076e-01, -5.3830e-01],\n",
       "          [-9.2606e-01, -5.5183e-01,  1.0243e-01,  ...,  5.1740e-01,\n",
       "           -1.0539e-01, -8.4427e-01]],\n",
       "\n",
       "         [[ 3.2742e-01,  1.4614e-01, -2.8483e-01,  ..., -5.5120e-01,\n",
       "           -1.0849e-01,  2.3948e-01],\n",
       "          [ 3.1597e-01, -5.9796e-02, -5.0310e-01,  ..., -8.5854e-01,\n",
       "           -4.0636e-01,  2.8207e-01],\n",
       "          [ 4.4305e-01,  1.9004e-01, -2.4569e-01,  ..., -5.5117e-01,\n",
       "           -4.9872e-02,  4.0563e-01],\n",
       "          ...,\n",
       "          [-6.9567e-02,  3.1811e-02,  1.1075e-01,  ...,  2.8371e-01,\n",
       "            2.5547e-01, -1.3306e-01],\n",
       "          [-4.0439e-01,  1.2942e-01,  8.2752e-01,  ...,  1.3252e+00,\n",
       "            5.8959e-01, -3.7102e-01],\n",
       "          [-7.4728e-01, -2.0629e-01,  3.8899e-01,  ...,  8.9909e-01,\n",
       "            1.5730e-01, -6.0746e-01]],\n",
       "\n",
       "         [[ 5.7015e-01,  2.9280e-01, -1.5205e-01,  ..., -3.7604e-01,\n",
       "           -3.5444e-02,  3.5109e-01],\n",
       "          [ 4.9243e-01,  3.1588e-01, -2.4055e-01,  ..., -4.4189e-01,\n",
       "           -8.0116e-02,  4.0551e-01],\n",
       "          [ 5.5391e-01,  2.3244e-01, -2.8367e-01,  ..., -6.7547e-01,\n",
       "           -1.0455e-01,  3.8945e-01],\n",
       "          ...,\n",
       "          [-1.6580e-02, -9.8518e-02,  8.5997e-02,  ...,  1.3854e-01,\n",
       "            1.7825e-01,  4.1639e-02],\n",
       "          [-6.1325e-01,  7.5046e-02,  1.0402e+00,  ...,  1.4916e+00,\n",
       "            6.1806e-01, -5.2196e-01],\n",
       "          [-1.1111e+00, -5.0135e-01,  3.6084e-01,  ...,  8.5078e-01,\n",
       "           -2.6013e-02, -9.8660e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0151e-01,  2.6595e-01,  1.6414e-01,  ...,  1.3755e-01,\n",
       "            1.0831e-01,  1.5255e-01],\n",
       "          [ 1.0509e-01,  1.3370e-01,  2.7623e-02,  ...,  1.0069e-01,\n",
       "            1.7135e-01,  1.4601e-01],\n",
       "          [ 1.6061e-01,  7.0673e-02,  1.1678e-01,  ...,  4.6247e-02,\n",
       "            1.3165e-01,  9.9891e-02],\n",
       "          ...,\n",
       "          [-1.5515e-01,  1.5890e-01, -8.8612e-02,  ..., -1.0895e-02,\n",
       "           -4.8173e-03, -1.5800e-02],\n",
       "          [-1.6857e-01,  8.4968e-02, -1.4325e-01,  ..., -8.5013e-02,\n",
       "           -8.1094e-02, -9.6158e-02],\n",
       "          [-2.6491e-01, -2.0877e-01, -2.1962e-01,  ..., -3.2122e-01,\n",
       "           -1.9045e-01, -3.0430e-01]],\n",
       "\n",
       "         [[ 3.5865e-01,  3.2134e-01,  2.2935e-01,  ...,  1.8148e-01,\n",
       "            1.8431e-01,  3.0497e-01],\n",
       "          [ 1.9506e-01,  2.6378e-01,  2.5425e-01,  ...,  6.8954e-02,\n",
       "            2.2453e-01,  2.9814e-01],\n",
       "          [ 2.6994e-01,  1.8870e-01,  1.9531e-01,  ...,  2.1734e-01,\n",
       "            1.4369e-01,  2.5881e-01],\n",
       "          ...,\n",
       "          [-4.0266e-02,  1.6479e-01, -4.9579e-02,  ...,  4.4656e-03,\n",
       "            1.3128e-01,  1.1565e-01],\n",
       "          [-9.3170e-02,  8.2513e-02, -9.2415e-02,  ..., -3.1801e-02,\n",
       "            1.3341e-01,  7.0919e-02],\n",
       "          [-1.8617e-01, -1.2449e-01, -2.6227e-01,  ..., -2.2110e-01,\n",
       "           -9.4408e-02, -1.5824e-01]],\n",
       "\n",
       "         [[ 2.8263e-01,  2.3268e-01,  3.3404e-01,  ...,  2.1798e-01,\n",
       "            2.5800e-01,  3.7063e-01],\n",
       "          [ 2.1164e-01,  2.1857e-01,  1.7825e-01,  ...,  1.8385e-01,\n",
       "            3.4764e-01,  3.6397e-01],\n",
       "          [ 3.3122e-01,  3.5719e-01,  2.4490e-01,  ...,  1.6883e-01,\n",
       "            3.2318e-01,  3.0268e-01],\n",
       "          ...,\n",
       "          [ 1.1991e-01,  1.1887e-01,  6.5936e-02,  ...,  1.0902e-01,\n",
       "            2.2308e-01,  2.0605e-01],\n",
       "          [ 7.4227e-02,  1.7524e-01,  1.1089e-01,  ..., -2.3913e-03,\n",
       "            6.3422e-02,  2.2222e-01],\n",
       "          [-5.4117e-02, -9.3127e-04, -1.3712e-01,  ..., -7.2513e-02,\n",
       "            7.5968e-02, -2.8270e-03]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.net[0].taskOp.segment_semantic.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-1.8881e-03,  1.8505e-02,  4.4373e-02,  ..., -1.2325e-02,\n",
       "           -4.9379e-02, -4.5097e-02],\n",
       "          [ 9.0981e-02,  4.1538e-02,  2.7948e-02,  ...,  1.1081e-01,\n",
       "            5.2511e-02, -2.9954e-02],\n",
       "          [ 8.2137e-02,  1.5644e-01,  7.6825e-02,  ...,  5.3679e-02,\n",
       "           -4.4415e-02, -1.1095e-02],\n",
       "          ...,\n",
       "          [ 7.3310e-03,  6.0403e-03,  1.1486e-01,  ...,  1.0638e-01,\n",
       "           -2.8108e-02,  1.0947e-01],\n",
       "          [ 4.7898e-02,  2.8627e-02,  1.0086e-01,  ...,  9.8602e-02,\n",
       "           -4.2270e-02,  8.3925e-02],\n",
       "          [ 1.5200e-01, -1.0719e-03,  4.9900e-02,  ...,  3.8274e-02,\n",
       "           -4.1196e-02, -3.8045e-02]],\n",
       "\n",
       "         [[ 1.4453e-01,  2.7311e-02,  1.0204e-01,  ...,  4.7457e-02,\n",
       "            3.2276e-03,  7.7583e-02],\n",
       "          [ 7.5282e-02,  4.6295e-02,  1.1917e-01,  ...,  7.4346e-02,\n",
       "            8.8846e-02,  3.4213e-02],\n",
       "          [ 1.2747e-01,  6.2407e-04,  1.4398e-01,  ...,  8.4125e-02,\n",
       "            9.4608e-02, -9.4846e-03],\n",
       "          ...,\n",
       "          [ 1.1121e-01,  2.1481e-02,  4.6624e-02,  ...,  8.4637e-02,\n",
       "            8.9381e-02,  4.6499e-02],\n",
       "          [-5.3406e-03,  1.1978e-01,  8.3513e-02,  ...,  1.4217e-01,\n",
       "           -7.0136e-03,  1.3663e-01],\n",
       "          [ 3.3121e-02,  4.8038e-02,  8.0051e-02,  ..., -2.9424e-03,\n",
       "            9.7495e-02,  3.0149e-02]],\n",
       "\n",
       "         [[ 1.0928e-01,  1.0661e-01, -5.2876e-03,  ...,  4.1116e-02,\n",
       "            1.3826e-01,  6.8635e-02],\n",
       "          [ 5.1532e-02,  8.8661e-02,  1.2679e-01,  ...,  1.1119e-01,\n",
       "            2.2422e-02,  1.1979e-01],\n",
       "          [ 9.1390e-02,  1.3639e-01,  2.7758e-02,  ...,  1.0734e-01,\n",
       "            4.9759e-02, -8.2104e-03],\n",
       "          ...,\n",
       "          [ 6.0015e-02,  1.5993e-01,  1.4492e-01,  ...,  8.7620e-02,\n",
       "            6.7153e-02,  9.6024e-02],\n",
       "          [ 6.8995e-03,  4.6961e-02,  1.1227e-01,  ...,  3.9240e-02,\n",
       "           -5.4205e-03,  2.8307e-02],\n",
       "          [ 4.5946e-02,  4.3813e-02,  1.0798e-02,  ...,  6.9518e-02,\n",
       "           -7.5302e-06,  1.2491e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6683e-02,  4.0883e-02,  1.8854e-03,  ..., -3.5610e-02,\n",
       "            2.0711e-02, -5.5826e-02],\n",
       "          [ 6.5390e-03,  1.4310e-02,  1.2567e-01,  ...,  1.2795e-01,\n",
       "            8.4157e-03, -3.3070e-02],\n",
       "          [-2.4160e-02, -9.2382e-03,  1.2563e-01,  ...,  8.8822e-02,\n",
       "            8.4750e-02,  6.4453e-02],\n",
       "          ...,\n",
       "          [-5.6057e-02, -2.7686e-02, -1.1744e-01,  ..., -1.3452e-01,\n",
       "           -1.1310e-01, -1.0587e-01],\n",
       "          [-9.0233e-02, -1.0198e-01, -1.7668e-01,  ..., -1.5836e-01,\n",
       "           -9.5884e-02, -1.4824e-01],\n",
       "          [-1.3170e-01, -4.3328e-02, -1.9971e-01,  ..., -1.2959e-01,\n",
       "           -1.8088e-01, -1.0824e-01]],\n",
       "\n",
       "         [[ 6.5237e-02,  8.2193e-02, -4.4000e-02,  ...,  5.9249e-02,\n",
       "            7.6291e-02, -5.5090e-02],\n",
       "          [ 5.8939e-02,  8.5619e-02,  9.2491e-02,  ...,  7.8200e-02,\n",
       "            5.2773e-02, -2.5329e-02],\n",
       "          [-2.3218e-02,  5.9611e-02,  1.8186e-01,  ...,  1.1307e-01,\n",
       "            7.1722e-02,  1.0947e-01],\n",
       "          ...,\n",
       "          [-5.9529e-02, -9.7144e-02, -9.9871e-02,  ..., -5.1507e-02,\n",
       "            1.8222e-02, -1.3077e-02],\n",
       "          [-5.7967e-03, -7.0799e-02, -2.1638e-01,  ..., -2.3015e-01,\n",
       "           -1.5042e-01, -4.3843e-02],\n",
       "          [-7.7959e-02, -8.3283e-02, -1.4523e-01,  ..., -2.1414e-01,\n",
       "           -9.7252e-02, -2.0398e-03]],\n",
       "\n",
       "         [[-7.0311e-02,  3.8725e-02,  4.2139e-02,  ..., -2.4517e-03,\n",
       "            5.6167e-02, -6.2173e-03],\n",
       "          [ 8.0540e-02,  7.2283e-02,  6.3451e-02,  ...,  2.0380e-01,\n",
       "            9.8312e-02,  6.0935e-02],\n",
       "          [ 1.1160e-01,  2.7187e-02,  1.6186e-01,  ...,  1.7844e-01,\n",
       "            1.2706e-01,  4.5506e-02],\n",
       "          ...,\n",
       "          [ 2.4663e-02,  2.0921e-02, -1.2830e-02,  ...,  1.0798e-02,\n",
       "           -9.6339e-03, -8.3221e-02],\n",
       "          [-6.9342e-02, -1.0163e-01, -1.4304e-01,  ..., -1.5820e-01,\n",
       "           -4.4681e-02, -4.7298e-02],\n",
       "          [-3.8436e-02, -1.6238e-01, -2.3991e-01,  ..., -1.8330e-01,\n",
       "           -3.4149e-02, -8.4074e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.9152e-02, -3.8948e-02, -1.2797e-01,  ..., -2.0761e-02,\n",
       "            7.0034e-03, -5.8029e-02],\n",
       "          [-1.2377e-01, -9.2795e-02, -1.8889e-01,  ..., -1.1239e-01,\n",
       "            2.8573e-03, -1.3575e-01],\n",
       "          [-7.1021e-02, -5.2340e-02, -1.1218e-01,  ..., -1.4661e-01,\n",
       "           -8.1519e-02, -1.4942e-01],\n",
       "          ...,\n",
       "          [-8.8186e-02, -1.1111e-01, -4.1545e-02,  ..., -5.9266e-02,\n",
       "           -4.8225e-02, -5.9224e-02],\n",
       "          [ 4.1756e-02, -5.5240e-02, -8.9392e-02,  ..., -4.5421e-02,\n",
       "           -1.1895e-01, -8.5804e-02],\n",
       "          [-1.6163e-02,  6.2620e-02,  1.9841e-02,  ...,  2.5227e-03,\n",
       "           -8.8995e-02, -1.2645e-02]],\n",
       "\n",
       "         [[-1.0932e-02, -9.2565e-02, -7.3016e-02,  ..., -1.4462e-01,\n",
       "           -3.5945e-02, -1.1159e-01],\n",
       "          [-3.9224e-02, -1.7961e-01, -1.6024e-01,  ..., -5.4298e-03,\n",
       "           -9.6810e-02, -1.5061e-02],\n",
       "          [-4.2473e-02, -1.1623e-01, -1.5375e-01,  ..., -1.1052e-01,\n",
       "           -9.9568e-02, -1.4858e-01],\n",
       "          ...,\n",
       "          [-2.2643e-02,  5.5030e-02,  7.4580e-03,  ..., -9.5128e-02,\n",
       "            6.2888e-02, -8.1478e-02],\n",
       "          [ 5.1431e-02,  3.8648e-02,  7.1968e-02,  ...,  5.8726e-02,\n",
       "            7.5018e-02, -4.5972e-02],\n",
       "          [-4.4147e-02,  6.7776e-02, -7.9680e-02,  ...,  3.2825e-02,\n",
       "            2.7359e-02,  1.1439e-02]],\n",
       "\n",
       "         [[-1.3977e-01, -4.0036e-02, -2.3115e-02,  ..., -9.3089e-03,\n",
       "           -6.6147e-02, -3.1765e-02],\n",
       "          [-8.6717e-02, -1.5617e-01, -1.3510e-01,  ..., -7.7681e-03,\n",
       "           -1.0239e-01, -8.3606e-02],\n",
       "          [-1.5576e-01, -1.2300e-01, -5.4681e-02,  ..., -1.3348e-01,\n",
       "           -3.8712e-02, -5.6399e-02],\n",
       "          ...,\n",
       "          [-1.4161e-02, -1.3291e-01,  6.6734e-03,  ..., -4.3878e-02,\n",
       "            1.6141e-02,  2.0091e-02],\n",
       "          [-5.9224e-02,  8.6859e-03,  5.9822e-02,  ..., -7.6480e-02,\n",
       "           -6.5007e-02, -1.2244e-01],\n",
       "          [-9.6133e-02, -4.1339e-02, -1.0000e-01,  ..., -4.3956e-02,\n",
       "            1.1956e-02, -1.0825e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.6009e-01, -1.9781e-01, -2.0495e-01,  ..., -2.4006e-01,\n",
       "           -2.0049e-01, -2.1981e-01],\n",
       "          [-1.1412e-01, -1.8976e-01, -2.3827e-01,  ..., -3.5196e-01,\n",
       "           -3.1394e-01, -2.2623e-01],\n",
       "          [-2.7263e-01, -2.0449e-01, -2.6106e-01,  ..., -2.6931e-01,\n",
       "           -3.4568e-01, -3.1177e-01],\n",
       "          ...,\n",
       "          [ 1.2993e-01,  6.8711e-02,  1.8003e-01,  ...,  1.4971e-01,\n",
       "            2.7778e-02,  5.9070e-03],\n",
       "          [ 6.1805e-01,  4.1368e-01,  4.4756e-01,  ...,  6.5496e-01,\n",
       "            7.3237e-01,  7.2099e-01],\n",
       "          [ 1.0684e-01,  2.4300e-01,  3.5639e-01,  ...,  2.4212e-01,\n",
       "            1.9912e-01, -3.7643e-02]],\n",
       "\n",
       "         [[-2.2964e-01, -3.9647e-01, -5.1924e-01,  ..., -3.9028e-01,\n",
       "           -2.3974e-01, -1.7248e-01],\n",
       "          [-3.2909e-01, -5.1372e-01, -6.3841e-01,  ..., -4.6136e-01,\n",
       "           -3.8922e-01, -2.9042e-01],\n",
       "          [-4.9083e-01, -4.9362e-01, -5.9250e-01,  ..., -5.7717e-01,\n",
       "           -4.4176e-01, -3.4792e-01],\n",
       "          ...,\n",
       "          [ 9.5847e-02,  6.3920e-02,  1.5848e-01,  ...,  1.5702e-01,\n",
       "           -2.2176e-02, -7.3767e-02],\n",
       "          [ 3.7119e-01,  5.3811e-01,  7.4545e-01,  ...,  7.0009e-01,\n",
       "            4.0607e-01,  3.2723e-01],\n",
       "          [-3.2275e-02,  3.7533e-02,  9.0675e-02,  ...,  1.2375e-01,\n",
       "            8.4111e-02, -3.0541e-02]],\n",
       "\n",
       "         [[ 9.1340e-02, -1.0028e-01, -1.2097e-01,  ..., -3.1570e-01,\n",
       "           -1.7155e-01, -9.5974e-02],\n",
       "          [-1.6211e-01, -3.7429e-01, -3.9909e-01,  ..., -3.6765e-01,\n",
       "           -4.6528e-01, -1.5412e-01],\n",
       "          [-3.2777e-01, -4.3549e-01, -2.7377e-01,  ..., -3.9685e-01,\n",
       "           -4.0161e-01, -5.1445e-01],\n",
       "          ...,\n",
       "          [ 2.2381e-01,  1.4478e-01,  2.2986e-01,  ...,  3.3815e-01,\n",
       "            3.0017e-01,  2.5566e-01],\n",
       "          [ 6.0110e-01,  5.9775e-01,  6.2023e-01,  ...,  7.1481e-01,\n",
       "            7.2459e-01,  7.1145e-01],\n",
       "          [ 1.3323e-01,  2.0006e-01,  3.8098e-01,  ...,  3.7882e-01,\n",
       "            1.7407e-01,  1.6331e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0958e-01,  8.5405e-02,  1.6207e-01,  ...,  1.3733e-02,\n",
       "            1.7304e-01,  2.0652e-01],\n",
       "          [ 2.5334e-01,  1.3793e-01,  1.3710e-01,  ...,  2.0194e-01,\n",
       "            2.1380e-01,  1.6340e-01],\n",
       "          [ 3.0407e-01,  2.1367e-01,  2.4087e-01,  ...,  1.5908e-01,\n",
       "            2.6772e-01,  2.8596e-01],\n",
       "          ...,\n",
       "          [ 2.6788e-01,  2.0282e-01,  2.8065e-01,  ...,  3.2407e-01,\n",
       "            2.5097e-01,  2.4438e-01],\n",
       "          [ 7.9057e-02,  1.8837e-01,  3.3231e-01,  ...,  4.8041e-01,\n",
       "            2.7250e-01,  1.4326e-01],\n",
       "          [ 8.6786e-02,  1.9163e-01,  3.5202e-01,  ...,  4.3784e-01,\n",
       "            3.4447e-01,  2.1363e-01]],\n",
       "\n",
       "         [[-8.5786e-02, -2.5866e-02, -5.2851e-02,  ..., -4.2326e-02,\n",
       "            1.3406e-02, -2.6057e-03],\n",
       "          [-9.9259e-02, -2.6698e-01, -2.6504e-01,  ..., -3.3792e-01,\n",
       "           -3.3015e-01, -2.6936e-02],\n",
       "          [ 3.5468e-02, -3.1086e-02, -4.4233e-02,  ..., -6.5587e-02,\n",
       "           -3.5204e-02,  5.8893e-02],\n",
       "          ...,\n",
       "          [ 1.1945e-01,  1.8033e-01,  1.6820e-01,  ...,  2.5330e-01,\n",
       "            2.5018e-01,  7.5003e-02],\n",
       "          [ 7.6678e-02,  3.3485e-01,  4.1735e-01,  ...,  5.0506e-01,\n",
       "            4.0683e-01,  1.8820e-01],\n",
       "          [ 1.5558e-01,  3.1569e-01,  3.3694e-01,  ...,  4.7152e-01,\n",
       "            3.0406e-01,  2.5056e-01]],\n",
       "\n",
       "         [[ 7.6451e-02,  3.1400e-02, -3.8363e-02,  ...,  2.1706e-02,\n",
       "           -1.6686e-03,  5.8998e-02],\n",
       "          [ 3.5040e-02,  6.3375e-02, -6.7294e-02,  ...,  2.4780e-02,\n",
       "           -3.7639e-02,  9.8991e-02],\n",
       "          [ 1.3202e-01,  2.9531e-04, -1.1175e-01,  ..., -2.0559e-01,\n",
       "           -8.5566e-02,  7.5696e-02],\n",
       "          ...,\n",
       "          [ 1.8560e-01,  1.9509e-01,  3.5868e-01,  ...,  3.2477e-01,\n",
       "            3.2440e-01,  2.8330e-01],\n",
       "          [ 2.1788e-01,  4.3615e-01,  6.4752e-01,  ...,  6.9252e-01,\n",
       "            5.9177e-01,  3.2042e-01],\n",
       "          [ 2.2971e-01,  3.1784e-01,  4.6639e-01,  ...,  5.8299e-01,\n",
       "            4.1029e-01,  3.1998e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.2384e-02,  1.0712e-01,  4.5798e-02,  ...,  2.1719e-02,\n",
       "           -6.6324e-02, -5.1191e-02],\n",
       "          [-7.2668e-02, -5.8957e-02, -7.4742e-02,  ...,  6.9956e-03,\n",
       "           -3.6493e-02, -1.3680e-01],\n",
       "          [ 3.1078e-02, -1.2669e-02,  8.3280e-02,  ..., -4.6805e-02,\n",
       "           -1.3146e-02, -1.0897e-01],\n",
       "          ...,\n",
       "          [-2.6120e-02,  1.1696e-01,  4.9857e-03,  ...,  1.1745e-01,\n",
       "            3.5596e-02,  9.8396e-03],\n",
       "          [ 2.3642e-02,  1.0695e-01, -4.1315e-03,  ...,  5.7631e-02,\n",
       "           -1.3937e-02,  5.2891e-03],\n",
       "          [ 9.5991e-02,  8.1035e-02,  1.1794e-01,  ...,  1.6321e-02,\n",
       "            6.3304e-02, -5.7973e-02]],\n",
       "\n",
       "         [[ 1.9198e-01,  1.3765e-01,  8.3738e-02,  ...,  3.2911e-02,\n",
       "           -2.4238e-02,  7.1116e-02],\n",
       "          [-4.2372e-03,  5.9821e-02,  1.2987e-01,  ..., -5.0988e-02,\n",
       "            4.6882e-03,  2.2649e-02],\n",
       "          [ 7.9848e-02,  2.5288e-02,  8.8045e-02,  ...,  7.6979e-02,\n",
       "           -5.4888e-02,  1.1912e-02],\n",
       "          ...,\n",
       "          [ 1.6449e-02,  1.3121e-01,  6.6725e-02,  ...,  1.0976e-01,\n",
       "            1.4587e-01,  8.3812e-02],\n",
       "          [ 3.0585e-02,  6.3675e-02,  1.1716e-03,  ...,  7.4248e-02,\n",
       "            1.4842e-01,  9.9108e-02],\n",
       "          [ 9.0442e-02,  9.9373e-02,  2.2783e-02,  ...,  6.4793e-02,\n",
       "            8.6218e-02, -3.9031e-03]],\n",
       "\n",
       "         [[ 8.9923e-02,  2.9298e-02,  1.6825e-01,  ...,  3.4455e-02,\n",
       "            2.4535e-02,  1.1417e-01],\n",
       "          [ 2.3448e-03,  1.5306e-02,  4.9995e-02,  ...,  4.0442e-02,\n",
       "            1.2179e-01,  8.7534e-02],\n",
       "          [ 9.7047e-02,  1.5361e-01,  9.7889e-02,  ..., -1.1014e-02,\n",
       "            9.3893e-02,  3.3833e-02],\n",
       "          ...,\n",
       "          [ 4.0533e-02,  2.7074e-03,  7.9974e-02,  ...,  8.5046e-02,\n",
       "            1.3238e-01,  8.2900e-02],\n",
       "          [ 6.6170e-02,  1.0521e-01,  1.3531e-01,  ...,  4.2043e-03,\n",
       "           -1.2089e-02,  1.3392e-01],\n",
       "          [ 1.2661e-02,  7.5848e-02,  1.1228e-02,  ...,  7.0121e-02,\n",
       "            1.2090e-01, -9.2491e-03]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlmodel.net[0].taskOp.depth_zbuffer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTLModel(\n",
      "  (headsDict): ModuleDict(\n",
      "    (segment_semantic): ASPPHeadNode(\n",
      "      (fc1): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc2): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc3): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc4): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (depth_zbuffer): ASPPHeadNode(\n",
      "      (fc1): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc2): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc3): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (fc4): Classification_Module(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv3): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (net): ModuleList(\n",
      "    (0): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (depth_zbuffer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (1): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (3): PoolNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): AbstractPool(\n",
      "        (pool_op): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (7): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (10): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (11): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (14): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (17): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (18): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (21): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (24): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (25): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (26): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (27): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (28): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (29): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (30): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (depth_zbuffer): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "    (31): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (32): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (33): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (34): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (35): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (36): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (37): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (38): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (39): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (40): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (41): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (42): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (43): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (44): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (45): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (46): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (47): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (48): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (49): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (50): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (51): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (52): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (53): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (54): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (55): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (56): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (57): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (58): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (59): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (60): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (depth_zbuffer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "    )\n",
      "    (61): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (62): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (63): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (64): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (65): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (66): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (67): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (68): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (69): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (70): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (71): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (72): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (73): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (74): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (75): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (76): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (77): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (78): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (79): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (80): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (81): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (82): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (83): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (84): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (85): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (86): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (87): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (88): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (89): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (90): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (91): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (92): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (93): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (94): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (95): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (96): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (97): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (98): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (99): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (100): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (101): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (102): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (103): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (104): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "        (depth_zbuffer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
      "    )\n",
      "    (105): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (106): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (107): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (108): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (109): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (110): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (111): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (112): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (113): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (114): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (115): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (116): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (117): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "    (118): Conv2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (depth_zbuffer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (119): BN2dNode(\n",
      "      (taskOp): ModuleDict(\n",
      "        (segment_semantic): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "        (depth_zbuffer): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (policy): ParameterDict(\n",
      "          (segment_semantic): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "          (depth_zbuffer): Parameter containing: [torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "      )\n",
      "      (basicOp): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000000149011612, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (120): EltNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): EltwiseOp(op=1)\n",
      "    )\n",
      "    (121): ReLUNode(\n",
      "      (taskOp): ModuleDict()\n",
      "      (policy): ParameterDict()\n",
      "      (basicOp): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (inputNode): InputNode()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mtlmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
